
                                  ┏━━━━━━━━━━━━━━━━━━━┓
                                  ┃   ROADMAP DEMOO   ┃
                                  ┗━━━━━━━━━━━━━━━━━━━┛

multi-tags npm publish:
  - does several npm publish for several npm tags
     - each with different .npmignore or PACKAGE.files
  - check if this already exists
  - use it in my projects:
     - @dev npm tag which including docs and examples

trylib (separate project):
  - called "trylib"??? trypack??? trythis??? tpx??? tpm??? trymodule???
  - usage: trylib PKG...
     - PKG is the same syntax as npm install PKG
     - can specify several PKG
  - steps:
     - run `npm install -g --no-save --no-update-notifier PKG...` inside that directory
        - also do it on any peerDependencies
        - i.e. binaries are now in $PATH
        - should give good error message on EACCESS (although unlikely) pointing to npm doc about the topic
        - always use @dev tag if it exists???
     - if `example|examples` directory exists:
        - print that examples are available, and their location
        - for each PKG
        - if they have other dependencies (except peerDependencies), must manually install them???
     - if opts.repl BOOL true:
        - start a Node REPL with `const VAR = require(MAIN);...`
           - using `package.json` `main` field
           - VAR is camelCase of MAIN
           - throw error if no `main` field or path does not resolve
           - one require() for each PKG
        - def: true if `package.json` `main` exists, but not `bin`
  - use in all my examples

Goal:
  - enforce code examples that are:
     - easy to understand:
        - avoid passing arguments to interpreter
        - command should allow passing 0 arguments and no stdin:
           - arguments and stdin are ok providing they are optional
        - print results
        - no polluting with test setups and assertions
     - interactive:
        - separate full file (not just README sample), runnable and editable
           - should work well with online playgrounds
     - correct:
        - tested and in sync with code
           - do it with snapshot testing of output
  - focus on full examples, not just README samples
     - README samples are only tested by including them into full examples

For Node.js only

Has own binary

Enforce no other deps than production deps???
  - what about peerDeps???
     - what about optional peerDeps??? E.g. `log-process-errors` have each test runner as an optional peerDep
        - once this is figured out, add examples for `options.testing` to `log-process-errors`

How to run tests that should use a different binary (e.g. `ava` for `log-process-errors` examples)???
  - how to make those work in online playground???
  - maybe require to fire through Bash file???
     - but then would the spawn process inherit the `require()` mocking???

Should rely on ava:
  - fire through binary not programmatic
  - should disable Babel and Power assert
  - should forward its status code and stdout|stderr

opts.cwd 'DIR':
  - def: process.cwd()
  - use to resolve opts.examples|doc|snapshotDir|watch

opts.examples "GLOB"[_ARR]
  - example files to run/test
     - directory are recursed over
  - def:
     - `package.json` `directories.example` if defined
     - otherwise ['example', 'examples']
     - otherwise error
  - only matches either:
     - *.js|mjs, fired with `node`
     - *.sh, fired with `bash`
  - no arguments passed to interpreter or to command

Always snapshot exit code:
  - if null, should normalize to 1
     - this can happen when process is killed with a signal

options.stream:
  - which stream to snapshot
     - also which one to filter out and check for "ready"
  - "both" (def), "stdout", "stderr" or NUM

opts.snapshotDir "DIR":
  - passed to ava
  - def: "PWD/examples_snapshots"??? or "PWD/LIBRARY_NAME"???

opts.update BOOL:
  - update snapshots (passed to ava)
  - def: false

options.filter REGEXP[_STR]_ARR
  - filter out part of the output from snapshot
  - goal: unpredictable output like PID, current time or file paths
  - line-wise:
     - newline is either \n or \r\n
        - do it by replacing all \r\n to \n
        - then using REGEXP on whole output with 'm' flag and removing 's' flag
  - don't document that REGEXP_STR is possible
     - it's only used for CLI input
  - flags:
     - if REGEXP_STR: add 'i', 'g', 'm', 'u' flags
     - if REGEXP: add 'g', 'm' flags, remove 's' flag, keep other flags as is
        - do it by cloning REGEXP
  - always filter out stack traces (not error messages)

Output order:
  - should not fail if snapshot differs only by line order
  - reason: it might be unpredictable

"Ready":
  - reads output and when a line is only printing either "ready" or "done", kill the process
  - reason: long-running examples like servers
  - normalize "ready|done" to lowercase and remove anything but letters

options.timeout NUM (def: 5 mins)

options.concurrency NUM

Sync check:
  - validate that examples and documentation are in sync
  - in example file, line with comment "example of ID"
     - case-insensitive
     - whitespace-insensitive
     - must start with that
     - discard non alphanumeric chars
        - i.e. works with any language comments
  - in documentation Markdown files (e.g. README):
     - HTML comment "example of ID" before code block
        - does not have to be right before (e.g. there can be an eslint-disable comment in-between)
     - uses options.doc GLOB_ARR:
        - directory are recursed over
        - def: *.md + {doc,docs,documentation,example,examples}/**/*.md
     - only Markdown files
        - other formats (e.g. HTML, RST, AsciiDoc, RTF, TeX) not implemented yet, but can do it in future
           - i.e. should make it easy to add new formats

Module mocking:
  - *.js:
     - mock require('LIBRARY') and node -r LIBRARY/*
     - probably do it by requiring some code first with -r flag
     - use a require() mocking library
     - should point to package root
  - *.sh:
     - parse `package.json` `bin` field
        - if does not exist, noop
     - use those to define `alias LIBRARY='...'`
        - make sure it works on Windows
  - both should be requirable with -r flag:
     - so examples can be run in development: node -r ... examples/FILE.js

opts.reporter STR:
  - can be:
     - "mini": def Ava reporter
     - "spec": ava --verbose
     - "tap"
  - same default logic as ava (i.e. "spec" if CI or not tty)

opts.colors: same as ava

opts.watch:
  - "GLOB"_ARR
     - passed to ava opts.sources and opts.watch
     - can be BOOL (def: false) where true which defaults to common top-level source/build directory names
     - unless false, opts.examples|doc are always added
  - sync checks must be part of each unit test so they are re-fired on watch
  - stdin must work (e.g. "u" to update snapshots)

Use in my own tests:
  - use binary
  - do not publish examples anymore:
     - change examples/README.md and each example top comment
        - see unix-permissions and examples/contain.js|sh for how it should look (I started it)
     - in package.json remove "examples" and "*~" (if no publish)
  - remove examples/utils.js|sh
  - should be used as "gulp example[w]"
     - fired after gulp unit
        - reason: gulp unit gives more precise errors
     - should be well documented
     - CONTRIBUTING.md should mention examples are tested

Do not mention shabangs in documentation nor Medium article:
  - reasons:
     - do not work on Windows
     - some languages do not support them (e.g. Windows Batch files)
     - do not allow multiple possible interpreters per file

Catchphrase: "Write code examples even a cow would understand"

Logo:
  - cow font, no icon
  - use no-cow font then blend with free for commercial usage cow patterns (cause i cant find any such cow font).

Medium article:
  - "How to write code examples for your grandma"
     - i.e. also talk about how to start with synopsis then quick options then full API the  full example. Also use online playground.
  - feature picture: some geeky grandma
     - maybe use the grandma computer meme and write some pun about cookies
        - "let me teach you about cookies"
  - can start with "Poor documentation is the number one problem with open-source according to the survey ..." (https://opensourcesurvey.org/2017/)
  - can include sentences: "Developers speak code", "Holy cow"
  - use same points as demoo goals, plus the extra following ones:
     - "how to run in terminal" instructions
     - available online playgrounds
     - avoid compile step if possible
        - if necessary, make it as simple as possible
