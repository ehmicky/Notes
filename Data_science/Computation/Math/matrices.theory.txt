
                                  ┏━━━━━━━━━━━━━━┓
                                  ┃   MATRICES   ┃
                                  ┗━━━━━━━━━━━━━━┛

Matrices :
  - vocabulaire :
    - dimension 2, m*n
      - si m == n, square matrix
      - si m == 1, row matrix
      - si n == 1, column matrix
    - éléments sont des "entries"
    - souvent noté A, B, C, ...
    - indexes [i,j]. A[x,k] souvent noté Aₓₖ
  - contrairement à C, et en accord avec R, row est avant column pour indexation ("RC" convention)
  - main/major/leading/primary/principale diagonale :
    - diagonale d'une square matrix allant de [0,0] à [n,n]
    - pour rectangular matrix, row/columns en dehors du square sont des 0
    - autre diagonale est l'anti/counter/secondary/minor diagonale
  - égalité :
    - A == B, si même dimensions et mêmes entries
  - zero matrix :
    - matrix dont tous les entries sont 0
  - identity matrix :
    - carré, 0 partout, sauf 1 dans la main diagonale
    - notée Iₙ, pour une taille n
  - elementary matrix :
    - matrix pouvant être obtenue via une seule "elementary row operations" sur une identity matrix
    - forment le general linear group of invertible matrices
  - transposition :
    - swap rows et colonnes
    - noté A^t
    - (A+B)^t = A^t + B^t
      (A*B)^t = B^t * A^t
  - inverse matrice :
    - matrice A⁻¹ tel que A*A⁻¹ = Iₙ
      - l'inverse d'A⁻¹ est de même A
    - certaines matrices sont invertibles, d'autres non ("singular")
      - rectangular matrices sont toujours singulars
    - peut être trouvée avec une Gauss-Jordan reduction, où A⁻¹ est l'inconnu
      - si non-invertible, une rangée de A sera remplie de 0 à un moment
      - ex :
        [1  -1]
        [-1 -1]
        [1  -1 1 0] [1 -1 1  0] [1 -1  1  0] [1 -1    1    0] [-1  1   -1    0] [-1 0 -1/2  1/2] [1 0  1/2 -1/2]
        [-1 -1 0 1] [1  1 0 -1] [0  2 -1 -1] [0  1 -1/2 -1/2] [ 0  1 -1/2 -1/2] [ 0 1 -1/2 -1/2] [0 1 -1/2 -1/2]
        Donc [ 1 -1]⁻¹ = [ 1/2 -1/2]
             [-1 -1]     [-1/2 -1/2]
    - "diviser" (terme à éviter pour matrices) revient à multiplier par A⁻¹
    - matrice 2*2 :
      - "déterminant" est a*d - b*c
      - si déterminant est 0, pas d'inverse
      - inverse de [a c] peut être trouvé simplement par : [ d -c]/dét.
                   [b d]                                   [-b  a]

Matrices opérations :
  - addition :
    - simple addition des éléments entre eux
  - multiplication :
    - avec une valeur scalaire ("scalar multiplication") :
      - simplement multiplication de la valeur avec chaque élément de la matrice
    - avec une autre matrice :
      - soit A*B = C
      - alors C[i,j] = CrossProd(A[j,],B[,i])
      - ex:
         [a b]   [e f]   [ae+bg fa+bh]
         [c d] * [g h] = [ce+dg cf+dh]
      - propriétés :
        - pas commutatif : A*B != B*A
        - associatif : (AB)C = A(BC)
        - distributif over addition : A(B + C) = AB + AC
        - pour les square matrices :
          - Iₙ*A = A
    - avec un vecteur :
      - pareil que matrice, sauf que produit vecteur (autres colonnes du résultat pas considérées)
      - ex :
         [a b]   [e]   [ae+bg]
         [c d] * [g] = [ce+dg]
      - par conséquent column matrice * row matrice donne une matrice multipliant chacun, et row * column donne sa somme
    - dimension de produit de A et B :
      - si A a dimension m₁*n₁ et B m₂*n₂
      - n₁ doit == m₂
      - produit a dimension m₁ * n₂
  - outer product :
    - soit deux vecteurs A et B
    - A ⊗ B = A * B^t
    - soit matrice produisant multiplication de chaque élément de A avec chaque élément de B
    - généralisation à d'autres dimensions : multiplication de chaque élément de A avec B pareil, mais donne nombres de
      dimensions supplémentaires
  - inner product
    - soit deux vecteurs A et B
    - A · B = A^t * B
    - soit scalaire égal à somme des multiplication de chaque élément de A et B entre eux

Gauss-Jordan reduction :
  - sert à résoudre A*B = C, lorsque B est inconnu
    - ne marche que si un B est possible
      - sinon renvoie une matrice, mais elle n'est pas bonne (vérifier donc)
    - concatène A et C en une seule matrice A∥C
      - C contient les "constant terms"
      - rangées sont notées Rₙ ou Rₓ
    - utilise les "elementary operations" sur A∥C, car ne change pas le fait que A*B = C
      - équivalent des opérations sur équations pour R, comme multiplier chaque côté, mais pour matrices
      - types (a != 0) :
        - row multiplication : Rₙ *= a     (noté aRₙ)
        - row addition :       Rₙ += b*Rₓ  (noté Rₙ + bRₓ)
        - row switching :      swap(Rₙ,Rₓ) (noté Rₙ <-> Rₓ)
      - peuvent être reversed par une "inverse operation", avec même opération, mais a₂ = 1/a, b₂ = -b
    - but : transformer A en Iₙ, de sorte d'avoir B = C
      - A doit donc être squared
  - étapes :
    1) - sélectionner première case non-0 de R₁ comme "case pivot" d'une "colonne pivot"
       - diviser R₁ par case pivot, de sorte que case pivot soit 1
    2) Mettre à 0 toute la colonne pivot, sauf case pivot, avec pour chaque row (hors row de la case pivot) :
        - Rₙ - bRₓ, où b = "case à mettre à 0"
    3) faire pareil avec R₂, etc.
    4) Diviser chaque row par case pivot, via aRₙ, pour que toutes cases pivot == 1
    5) B = nouveau C
  - optionel :
    - simplification à toute étape avec un /= a (aRₙ) si row a nombre aux facteurs communs
  - matrice est dite "reduced row echelon form" si solution d'un Gauss-Jordan reduction :
    - dont row avec que des 0
    - mais pas si row inconsistent ou si pas encore résolue entièrement avec des 1 et 0
    - colonnes peuvent être swappées
  - ex:
    [1 3] * [x z] = [11 19]
    [2 4]   [y w]   [16 28]

    [1 3 11 19] [1 3 11 19] [1  3 11 19] [1 3 11 19] [1/3 1 11/3 19/3] [1/3 0 2/3 4/3] [1 0 2 4]
    [2 4 16 28] [1 2 8  14] [0 -1 -3 -5] [0 1  3  5] [0   1    3    5] [0   1   3   5] [0 1 3 5]
    Donc :
    [x z] = [2 4]
    [y w]   [3 5]

    1 -1 0
    1  1 2

    1  1
    1 0 1
    0  1 1

Matrices et équations :
  - système équation peut être représentés par des produits de matrices ("augmented matrix") :
    - {3x + 5y   = 10}
      {4x - 3y = 12}
      [3  5] * [x] = [10]
      [4 -3]   [y]   [12]
    - première matrice est le coefficient matrice
    - aussi noté A*X = C
    - si variable absente, 0
  - pour chaque row :
    - si prochaine case pivot est 0 :
      - si que des 0 sur R₂, etc. -> cette équation est équivalente
      - si que des 0, sauf un des constant terms -> équation inconsistente
      - sinon switch colonnes ou rangées pour continuer
    - si plus d'équations que de variables, pour vérifier qu'équations supplémentaires sont redondantes, et non insolubles :
      - résoudre avec dernière colonne comme pivot
      - si constants terms = ceux d'équation du dessus, redondante, sinon système insoluble
    - si moins d'équations que de variables, undetermined system :
      - mettre terme résolu de l'autre côté de l'équation pour avoir
  - peut ensuite être résolu par une Gauss-Jordan reduction
  - solution peut aussi être trouvée par :
    - si A*X = C, alors X = A⁻¹*C
    - si A n'a pas d'inverse, système inconsistent ou redondant
    - A doit être squared
