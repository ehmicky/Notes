
            
   SUPABASE  
            



VERSION ==>                       #18-06-2023

BREAKING FEATURES ==>             #New Supabase breaking features, or new Postgres versions
                                  #Can:
                                  #  - pause then restart PROJECT (free only)
                                  #  - manually backup PROJECT, then create a new one, restoring backup

PRICING ==>                       #Free: 0$, Pro: 25$/month per PROJECT, Enterprise: custom
                                  #Can set a spend cap
                                  #Can see usage in UI
PAUSING ==>                       #Automatically done in free after 1 week inactivity

SUPPORT ==>                       #Pro only

SUMMARY ==>                       #Users: organizations, permissions, plan
                                  #Projects: pausing, region
                                  #Database: schemas, meta API, postgres CONF, compute add-on, extensions, wrappers, pgtap, lint
                                  #Connection: SSL, network restrictions|bans, timeout, pgBouncer
                                  #Role: anon|authenticated|service_role, dashboard_user, postgres, supabase_*, POLICY
                                  #Backups: daily, PITR, manual
                                  #Migrations: diff|manual, local|remote
                                  #Postgrest: OpenAPI, REST, SQL FUNC, max ROWs, GraphQL
                                  #Storage: CDN, buckets, images, metadata, signed URL, transform
                                  #Edge functions: Deno, deploy, call, webhooks
                                  #Realtime: channel, broadcast, postgres changes, presence
                                  #Auth: email, one-time password, email templates, email server, SMS, MFA, OAuth, SAML, SSO, users, UI helpers
                                  #Vector
                                  #Encryption: secrets, vault, column encryption
                                  #Logs: reports, edge, database, storage, functions, realtime, auth, prometheus
                                  #API: keys, JWT expiry|refresh, management API, custom|vanity domains, self-hosting
                                  #Clients: API, JavaScript, TypeScript types, CLI, local dev, UI, framework adapters, marketplace

                                  ┌────────────────────────┐
                                  │   ORGANIZATION USERS   │
                                  └────────────────────────┘

ORG ==>                           #Sets of USERs and PROJECTs

GET TOP_API_DOMAIN/organizations
supabase orgs list                #List all ORGs

POST TOP_API_DOMAIN/organizations #Create an ORG

XORG.id                           #ORG_ID
XORG.name                         #'ORG_NAME'

USER ==>                          #Supabase direct users, not end-USERs
                                  #Can have permissions:
                                  #  - billing only (read/write)
                                  #  - readonly: project read, PUBLIC_API_KEY read, database read, AUTH read, EDGE_FUNC read, logs, reports
                                  #  - developer: also API_KEYs, database write, STORAGE, AUTH write, READ_FUNC write
                                  #  - administrator: also user permissions, billing write, PROJECTs write
                                  #  - owner: also ORG, billing email address
                                  #Unless Enterprise, only: owner, developer

                                  ┌─────────────┐
                                  │   PROJECT   │
                                  └─────────────┘

PROJECT                           #DATABASE + other Supabase features related to it
                                  #Max: 2 (free), unlim (pro)
                                  #There should be one per environment (production, staging, dev, etc.)
PROJECT_NAME                      #PROJECT human-friendly NAME
PROJECT_ID                        #PROJECT ID
CONF.project_id                   #Also called "reference ID"

CLOUD PROVIDER ==>                #AWS. Can pick REGION

POST TOP_API_DOMAIN/projects
supabase projects
 create PROJECT_NAME              #
--interactive|-i                  #
--org-id                          #ORG_ID
--plan free|pro                   #
--region REGION                   #

GET TOP_API_DOMAIN/projects
supabase projects list            #List all PROJECTs

XPROJECT.id                       #PROJECT_ID
XPROJECT.name                     #PROJECT_NAME
XPROJECT.organization_id          #ORG_ID
XPROJECT.region                   #'REGION'
XPROJECT.created_at               #'TIMESTAMPTZ'

                                  ┌──────────────┐
                                  │   DATABASE   │
                                  └──────────────┘

supabase/postgres                 #Docker image with Postgres
                                  #On Ubuntu
                                  #Meant to host on AWS
                                  #Includes:
                                  #  - more EXTENSIONs
                                  #  - pgBouncer
                                  #  - postgrest
                                  #  - WAL-G
                                  #  - GoTrue
                                  #  - Kong
                                  #  - nginx
                                  #  - admin API and manager
                                  #  - Prometheus exporter
                                  #  - ROLEs, security, etc.
                                  #Uses Ansible and Terraform

XPROJECT.database.version
CONFIG.db.major_version           #NUM (def: 15, i.e. 15.1)

CLUSTER                           #'main'
DATABASE                          #'postgres'

CONFIG.api.schemas                #"Exposed" SCHEMAs, i.e. available to public APIs
                                  #Also full PRIVILEGEs with anon|authenticated|service_role ROLEs
                                  #Def: public, graphql_public, storage

CONFIG.api.extra_search_path      #'SCHEMA'_ARR (def: 'public')
ENVVAR search_path                #"$user" + extra_search_path
                                  #Also "extensions", if postgres ROLE

ENVVAR lc_collate|lc_ctype        #'C.UTF-8'
ENVVAR lc_*                       #Others are 'en_US.UTF-8'

supabase/postgres-meta            #CRUD API to execute DDL through SQL
                                  #For ENTITYs: TABLE, COL, FUNC, TFUNC, ROLE, TYPE, SCHEMA, EXTENSION, PUBLICATION
                                  #Can also use SQL query: execute, `explain`, format, parse

                                  ┌─────────────────┐
                                  │   PERFORMANCE   │
                                  └─────────────────┘

DATABASE SIZE ==>                 #40-60MB taken by Supabase utilities
                                  #Pricing: max 500MB (free), 8GB then 1$/8GB
                                  #Max:
                                  #  - self-serve: 200GB
                                  #  - from support: 64TB (pro), 1PB (enterprise)
                                  #Autoscaling:
                                  #  - when reaching 90% of size
                                  #  - adds 50% more
                                  #  - max once per 6h
                                  #  - pro only

DATABASE EGRESS ==>               #2GB/month (free), 50GB/month then 1$/10GB (pro)

EC2 INSTANCE TYPES ==>            #Per PROJECT
                                  #"Compute add-ons"
                                  #
                                  #Pricing per month ($):   0    5   50  100  200  400  950 1860  2790  3720
                                  #Memory (GB):             1    2    4    8   16   32   64  128   192   256
                                  #Max I/O (Mbps):       2606 2606 2606 4750 4750 4750 4750 9500 14250 19000
                                  # (for 30min per day)
                                  #Mean I/O (Mbps):        87  174  347  630 1188 2375 4750 9500 14250 19000
                                  #Max IOPS (thousands)    12   12   12   20   20   20   20   40    50    80
                                  # (for 30min per day)
                                  #Mean IOPS (thousands)   .5    1    2    4    6   12   20   40    50    80
                                  #Max direct connections: 10   30   50  100  200  350  420  450   480   500
                                  #Max pooled connections: 50   75  150  300  600 1200 2800 5600  8600 11600
                                  #pgBouncer connections: 200  200  200  300  700 1500 3000 6000  9000 12000
                                  #vCPUs:                   2    2    2    2    4    8   16   32    48    64
                                  #vCPUs shared:          yes  yes  yes   no   no   no   no   no    no    no
                                  #
                                  #Can see memory, I/O, vCPU, network usage in UI

POSTGRES CONF ==>                 #The following depends on EC2 instance type
                                  #Below are figures for lowest one
work_mem                          #.004% of RAM
wal_buffers                       #.008% of RAM
shared_buffers                    #25% of RAM
shared_memory_size                #40% of RAM
effective_cache_size              #75% of RAM
max_slot_wal_keep_size            #100% of RAM
min_wal_size                      #100% of RAM
max_wal_size                      #400% of RAM
effective_io_concurrency          #200
max_connections                   #Max direct + pooled connections
max_worker_processes              #4 (instead of 8)
max_parallel_workers              #2 (instead of 8)
max_parallel_workers_per_gather   #1 (instead of 2)
random_page_cost                  #1.1 (instead of 4)

supabase postgres-config update   #Sets Postgres CONF VARs
 --config VAR=VAL                 #Only for:
                                  #  - work_mem
                                  #  - shared_buffers
                                  #  - effective_cache_size
                                  #  - max_connections
                                  #  - max_worker_processes
                                  #  - max_parallel_workers
                                  #  - max_parallel_workers_per_gather
                                  #  - statement_timeout
                                  #  - maintenance_work_mem
                                  #  - max_parallel_maintenance_workers
                                  #  - session_replication_role
                                  #Restarts the CLUSTER
--replace-existing-overrides      #Erase previous calls to `update --config`

                                  ┌────────────────┐
                                  │   EXTENSIONS   │
                                  └────────────────┘

EXTENSIONS ==>                    #Automatically enabled:
                                  #  - uuid-ossp
                                  #  - pgjwt
                                  #  - pgcrypto, pgsodium
                                  #  - pg_safeupdate
                                  #  - supabase_vault
                                  #Automatically enabled (not documented yet???):
                                  #  - pg_stat_statements
                                  #     - also shown in UI "Reports > Query performance"
                                  #  - pg_net
                                  #     - used by webhooks
                                  #  - pg_graphql
                                  #  - auto_explain
                                  #Also available (on top of ones automatically available with Postgres):
                                  #  - pg_cron
                                  #  - pg_hashids
                                  #  - pg_jsonschema
                                  #  - wrappers
                                  #  - pgsql-http
                                  #  - supautils
                                  #Also available (not documented yet???):
                                  #  - pgvector
                                  #  - plpgsql_check: PL/PGSQL linter
                                  #  - plv8: JavaScript LANGUAGE (V8)
                                  #  - plcoffee: CoffeeScript LANGUAGE
                                  #  - plls: LiveScript LANGUAGE
                                  #  - pg_tle: EXTENSIONs framework
                                  #  - pgtap: unit testing
                                  #  - pgaudit: security audit through logs
                                  #  - pg_stat_monitor: query performance monitoring
                                  #  - hypopg: create fake INDEXs, so they show up on `explain`, to see if worth creating them
                                  #  - pg_repack: like `cluster` or `vacuum full` for does not lock
                                  #  - rum: ACCESS_METHOD like gin but optimized for TSQUERY|TSVECTOR
                                  #  - postgis*: geometric operations
                                  #  - address_standardizer[_data_us]: part of PostGIS, normalize a shipping address
                                  #  - pgrouting: PostGIS routes
                                  #  - pgroonga[_database]: use Groonga, a text search database
                                  #  - timescaledb: Time series database

extensions                        #SCHEMA with some EXTENSIONs, e.g. pg_stat_statements
                                  #Some EXTENSIONs have own SCHEMAs, e.g. pgbouncer, pgsodium, pgtle, vault, net

WRAPPERS ==>                      #See doc in Postgres
                                  #Can create FDW|FSERVER|FTABLEs from the UI

                                  ┌──────────────────────┐
                                  │   DATABASE TESTING   │
                                  └──────────────────────┘

supabase test db                  #Run PGTAP pg_prove on all WORKDIR/tests/**/*.sql|pg
                                  #PGTAP can also be added as PG extension

supabase test new "FILENAME"      #Create dummy WORKDIR/tests/FILENAME.sql
--template|-t                     #Always 'pgtap'

supabase db lint                  #Lint for DDL errors in local database, including plpgsql_check
--level                           #'warning' (def) or 'error'
--schema|-s 'SCHEMA,...'          #Def: all
--linked                          #Run on remote database instead

                                  ┌────────────────┐
                                  │   CONNECTION   │
                                  └────────────────┘

XPROJECT.database.host
PG_HOST                           #db.PROJECT_DOMAIN
CONFIG.api.port
PG_PORT                           #5432

ENVVAR SUPABASE_DB_PASSWORD       #When logging to `postgres` ROLE
supabase link --password|-p STR   #Prompted with CLI otherwise
supabase ... --password|-p STR    #Many CLI commands can override it too

ENVVAR ssl_ca_file
ENVVAR ssl_cert_file
ENVVAR ssl_key_file               #Server SSL is setup, i.e. encrypts query in-transit

supabase ssl-enforcement update
 --enable|disable
  -db-ssl-enforcement             #Use LIBPQ.sslmode 'verify-full', i.e. require client SSL certificate
supabase ssl-enforcement get      #

ENVVAR statement_timeout          #Def: 8s if ROLE authenticated, 3s if ROLE anon
                                  #Can be changed up to 2min

                                  ┌──────────────────────────┐
                                  │   NETWORK RESTRICTIONS   │
                                  └──────────────────────────┘

POST                              #Add NETWORK_RESTRICTIONS, i.e. IP restrictions for PGBouncer and Postgres database
 API_DOMAIN/network-restrictions  #Not for Rest|GraphQL, Storage, Realtime APIs
supabase network-restrictions     #Does not work if an EDGE_FUNC needs to connect to the database
 update                           #Def: none
--db-allow-cird ID[/MASK]         #Can be 0.0.0.0/0 to remove any

GET
 API_DOMAIN/network-restrictions
supabase network-restrictions get #Get NETWORK_RESTRICTIONS

XNETWORK_RESTRICTIONS.entitlement #'[dis]allowed'
XNETWORK_RESTRICTIONS.status      #'stored|applied'
XNETWORK_RESTRICTIONS
 .[old_]config.dbAllowedCidrs     #'ID[/MARK]'_ARR

POST API_DOMAIN/network-bans
 /retrieve
supabase network-bans get         #See IP banned by Supabase
DELETE API_DOMAIN/network-bans
supabase network-bans remove
 --db-unban-ip IP                 #Unban

XNETWORK_BANS
 .banned_ipv4_addresses           #'IP'_ARR

                                  ┌───────────────┐
                                  │   PGBOUNCER   │
                                  └───────────────┘

PGBOUNCER ==>                     #Is used to pool connections
                                  #Runs on same credentials|URL, but port 6543
                                  #Meant for connections opened|closed often, e.g. in serverless functions
                                  #Document it ???
POOL MODE ==>                     #Of pgBouncer. Whether one connection per session, transaction, or statement
                                  #Lower has better performance, but disables some PG features

pgbouncer_logs                    #SQL TABLE with logs for PGBouncer
PGBOUNCER_LOGS.id                 #'UUID'
PGBOUNCER_LOGS.timestamp          #TIMESTAMPTZ
PGBOUNCER_LOGS.event_message      #STR

                                  ┌───────────┐
                                  │   ROLES   │
                                  └───────────┘

AUTHENTICATION ==>                #scram-sha-256 password
                                  #Main one is for postgres, which can be set|reset
                                  #Exception: anon|authenticated|service_role ROLEs
                                  #  - those have no `login` PRIVILEGE
                                  #  - they are set from initial session ROLE "authenticator"
                                  #  - they use API_KEYs instead
                                  #dashboard_user ROLE also has no `login` PRIVILEGE, but I'm unsure how it is set

PRIVILEGES ==>                    #No ROLE has `admin option` PRIVILEGE

authenticator                     #Initial session ROLE in API requests
                                  #Managed by Postgrest
                                  #No `inherit` PRIVILEGE
anon                              #ROLE for anonymous API requests
                                  #`usage` PRIVILEGEs on all SCHEMAs, except realtime|vault|supabase_migrations
authenticated                     #ROLE for authenticated API requests, for users
                                  #`usage` PRIVILEGEs on all SCHEMAs, except realtime|vault|supabase_migrations
service_role                      #ROLE for privileged API requests, for users
                                  #`usage` PRIVILEGEs on all SCHEMAs, except realtime|vault|supabase_migrations

dashboard_user                    #ROLE for API requests made through UI
                                  #`createrole`, `createdb`, `replication` PRIVILEGEs
                                  #Full PRIVILEGEs on DATABASE and on extensions|storage|auth SCHEMAs
                                  #No PRIVILEGEs on other SCHEMAs

postgres                          #ROLE for programmatic access, for users
                                  #Owner of DATABASE
                                  #`createrole`, `createdb`, `replication`, `bypassrls` PRIVILEGEs
                                  #Not superuser ROLE
                                  #Full PRIVILEGEs on public|extensions|storage|auth|supabase_migrations SCHEMAs
                                  #`usage` PRIVILEGEs on other SCHEMAs
                                  #Can set itself to ROLEs: anon|authenticated|service_role or supabase_*_admin

supabase_*                        #ROLEs meant for support or built-in features
                                  #Uses supautils EXTENSION to protect those (see its doc)
supabase_admin                    #Only superuser ROLE
                                  #Full access to everything
supabase_read_only_user           #ROLE member of pg_read_all_data
                                  #`bypassrls` PRIVILEGE
supabase_auth_admin               #ROLE owning auth SCHEMA|ENTITYs
                                  #No `inherit` PRIVILEGE, but `createrole`
supabase_functions_admin          #ROLE owning Edge functions SCHEMA|ENTITYs
                                  #No `inherit` PRIVILEGE, but `createrole`
supabase_storage_admin            #ROLE owning storage SCHEMA|ENTITYs
                                  #No `inherit` PRIVILEGE, but `createrole`
                                  #Can set itself to ROLEs: anon|authenticated|service_role
supabase_replication_admin        #ROLE for logical replication features
                                  #`replication` PRIVILEGE

POLICY                            #Row-level security enabled by default on TABLEs of exposed SCHEMAs
                                  #`service_role` ROLE has `bypassrls` PRIVILEGE

                                  ┌─────────────┐
                                  │   BACKUPS   │
                                  └─────────────┘

DAILY BACKUPS ==>                 #pg_dumpall, once per day, last 7 days (pro only)

PITR BACKUPS ==>                  #Per-second backup
                                  #Uses WAL physical replication, with WAL-G tool
                                  #Threshold: either specific WAL file size, or 2 mins
                                  #Keeps 7 days by default (can set it)
                                  #  - 100$ per 7d
                                  #Cannot be used together with daily backups

supabase db dump                  #Runs pg_dump
                                  #Excludes Supabase|EXTENSIONs managed SCHEMAs
--file|-f FILE                    #Def: stdout
--data-only                       #Include (only) data
--role-only                       #Include (only) ROLEs
--keep-comments                   #

                                  ┌────────────────┐
                                  │   MIGRATIONS   │
                                  └────────────────┘

MTIME                             #MIGRATION timestamp YYYYMMDDHHMMSS, used as identifier and to specify order
MNAME                             #MIGRATION name

supabase migration new MNAME      #Create empty MIGRATION
                                  #Can also set content from stdin

supabase db diff                  #Prints MIGRATION by diffing current local database and last MIGRATION
--file|-f MNAME                   #Create MIGRATION file
--use-migra                       #Smaller diff by using `migra` tool
--schema|-s 'SCHEMA,...'          #Def: all
--linked                          #Apply remotely instead

supabase db remote commit         #Add a new MIGRATION by diffing remote database and last MIGRATION
                                  #Uses name "remote_commit"
--schema|-s 'SCHEMA,...'          #Def: all

supabase db reset                 #Apply MIGRATIONs to local database, after resetting it
--linked                          #Apply remotely instead

supabase db up                    #Apply MIGRATIONs to local database, incrementally

supabase db push                  #Apply MIGRATIONs to remote database, incrementally
--dry-run                         #

supabase migration list           #Print all local|remote MIGRATIONs names|timestamps

supabase migration repair MTIME   #Fixes supabase_migrations.schema_migrations TABLE in remote database
--status                          #If:
                                  #  - 'reverted': delete ROW
                                  #  - 'applied': add ROW, using local MIGRATION

WORKDIR/migrations/MTIME_MNAME.sql#MIGRATION, i.e. SQL file describing DDL
                                  #Including Postgres CONF, EXTENSIONs, FUNCs, POLICYs, PRIVILEGEs, etc.
                                  #Only diff since last once
                                  #Meant to be git committed

WORKDIR/seed.sql                  #Initial MIGRATION run only locally
                                  #Meant for local dummy data

supabase_migrations               #SCHEMA
supabase_migrations
 .schema_migrations               #TABLE with all MIGRATIONs
supabase_migrations
 .schema_migrations.version       #'MTIME'
supabase_migrations
 .schema_migrations.statements    #'SQL'. MIGRATION contents

auth|storage|supabase_functions
 .migrations                      #TABLE with migrations done by Supabase on auth|storage|supabase_functions.*

                                  ┌───────────────┐
                                  │   POSTGREST   │
                                  └───────────────┘

REST_DOMAIN                       #PROJECT_DOMAIN/rest/v1

REST_DOMAIN/...                   #Proxies to postgREST routes (see its doc)
                                  #Uses Cloudflare + Kong
                                  #Can use HTTP/3
Content-Encoding: br [S]          #
Strict-Transport-Security:
 max-age=2592000;
 includeSubDomains [S]            #

REST_DOMAIN/                      #/ route, i.e. OpenAPI as JSON
                                  #OpenAPI as HTML also available when logged in the UI
REST_DOMAIN/TABLE                 #/TABLE route, i.e. REST CRUD
REST_DOMAIN/rpc/FUNC              #/rpc/FUNC route, i.e. SQL FUNC

CLIENT.rest                       #@supabase/postgrest-js POSTGREST_CLIENT
CLIENT.*                          #Forwards to CLIENT.rest.*
COPTS.db.schema                   #Forwards to POPTS.schema

CONFIG.api.max_rows
POSTGREST_CONF.db-max-rows        #Def: 1e3, max: 1e6

                                  ┌─────────────┐
                                  │   GRAPHQL   │
                                  └─────────────┘

DATABASE GRAPHQL ==>              #Automatic GraphQL CRUD endpoints
                                  #Includes introspection
                                  #Uses PG extension "pg_graphql"
                                  #The extension uses itself postgREST, i.e. similar features as REST API

graphql.resolve('QUERY'
 [, $VARS_JSONB_OBJ[, 'OPNAME'
 [, EXTENSIONS_JSONB]]])->JSONB   #SQL FUNC resolving GraphQL query

GRAPHIQL ==>                      #Available in API docs

GRAPHQL_DOMAIN                    #'PROJECT_DOMAIN/graphql/v1'

query                             #Automatically populates foreign keys

query.TABLECollection.edges       #Get ROWs of TABLE
                                  #OBJ_ARR: node ROW_OBJ

graphql_public                    #SCHEMA with GraphQL???

graphql                           #SCHEMA with GraphQL???

https://github.com/supabase/pg_graphql ???

                                  ┌─────────────┐
                                  │   STORAGE   │
                                  └─────────────┘

STORAGE ==>                       #For big files
                                  #Max: 1GB (free), 100GB then 1$/50GB (pro)
                                  #Max egress: 2GB (free), 200GB then 1$/100GB (pro)

CDN ==>                           #S3 through Cloudflare
SMART CDN CACHING ==>             #Automatically re-cache changed OBJECT on CDN

supabase/storage-api              #Repository

STORAGE_DOMAIN                    #PROJECT_DOMAIN/storage/v1

INBUCKET ==>                      #Storage API

@supabase/storage-js              #Version 2.5.4
new StorageClient
 (STORAGE_DOMAIN[, OPTS])         #STORAGE
CLIENT.storage                    #new StorageClient()
OPTS.apikey                       #'API_KEY'
OPTS.Authorization                #'Bearer API_KEY'

RES.data                          #VAL
RES.error                         #ERROR

storage                           #SCHEMA

                                  ┌─────────────────────┐
                                  │   STORAGE BUCKETS   │
                                  └─────────────────────┘

BUCKET                            #Main directory

SQL_BUCKET                        #ROW in storage.buckets TABLE
SQL_BUCKET|XBUCKET.id|name        #'BUCKET'
SQL_BUCKET|XBUCKET.owner          #REGROLE
SQL_BUCKET|XBUCKET
 .created_at|updated_at           #TIMESTAMPTZ
SQL_BUCKET|XBUCKET.public         #BOOL. If false (def), can still download, but not create URL
SQL_BUCKET|XBUCKET
 .allowed_mime_types              #'MIME'_ARR (def: null). Can use *
CONFIG|SQL_BUCKET|XBUCKET
 .file_size_limit                 #BIGINT (def: null)
SQL_BUCKET.avif_autodetection     #BOOL (def: false)

FOLDER                            #Sub-directory
                                  #Actually just prefix in OBJECT's name
FNAME                             #'[FOLDER/]NAME'

POST STORAGE_DOMAIN/bucket
STORAGE.createBucket
 ('BUCKET'[, OPTS])->RES          #
OPTS.public                       #BOOL
OPTS.fileSizeLimit                #NUM|null
OPTS.allowedMimeTypes             #'MIME'_ARR|null

PUT STORAGE_DOMAIN/bucket/BUCKET
STORAGE.updateBucket
 ('BUCKET'[, OPTS])->RES          #Same OPTS as createBucket()

GET STORAGE_DOMAIN/bucket/BUCKET
STORAGE.getBucket('BUCKET')->RES  #

GET STORAGE_DOMAIN/bucket
STORAGE.listBuckets()->RES        #

POST STORAGE_DOMAIN
 /bucket/BUCKET/empty
STORAGE.emptyBucket('BUCKET')
 ->RES                            #

DELETE
 STORAGE_DOMAIN/bucket/BUCKET
STORAGE.deleteBucket('BUCKET')
 ->RES                            #

                                  ┌─────────────────────┐
                                  │   STORAGE OBJECTS   │
                                  └─────────────────────┘

OBJECT                            #Single file
OBJECT_CONTENT                    #BLOB|FILE|FORMDATA|ARRBUFFER
                                  #Max size: 50MB (free), 5GB (pro)

SQL_OBJECT                        #ROW in storage.objects TABLE
                                  #Does not include OBJECT_CONTENTs
                                  #  - i.e. backups must manually download everything
SQL_OBJECT|XOBJECT.id             #'UUID'
SQL_OBJECT|XOBJECT.bucket_id      #SQL_BUCKET.id
XOBJECT.buckets                   #XBUCKET_ARR
SQL_OBJECT|XOBJECT.name           #'FNAME'
SQL_OBJECT|XOBJECT.owner          #REGROLE
SQL_OBJECT|XOBJECT.version        #STR
storage.filename('FNAME')
 ->'NAME.EXT'                     #
storage.extension('FNAME')->'EXT' #
SQL_OBJECT.path_tokens            #[...FOLDER, 'NAME']
storage.foldername('FNAME')
 ->[...FOLDER]                    #
SQL_OBJECT|XOBJECT
 .created|updated_at              #TIMESTAMPTZ
SQL_OBJECT|XOBJECT
 .last_accessed_at                #TIMESTAMPTZ
SQL_OBJECT|XOBJECT.metadata       #OBJ_JSONB of METADATA
METADATA.size                     #NUM
METADATA.contentLength            #NUM
METADATA.eTag                     #STR
METADATA.mimetype                 #'MIME'
METADATA.cacheControl             #STR: HTTP Cache-Control [S]
METADATA.lastModified             #'DATE'
METADATA.httpStatusCode           #NUM

STORAGE.from('BUCKET')->STORAGE   #Must be called before following methods

GET
 STORAGE_DOMAIN/object/list/BUCKET
GET STORAGE_DOMAIN
 /object/BUCKET/FNAME_GLOB
STORAGE.list
 ('BUCKET'[, OPTS][, OBJ])->RES   #List OBJECTs
OPTS.search                       #STR. Search in FNAMEs
OPTS.sortBy.order                 #'asc' (def) or 'desc'
OPTS.sortBy.column                #'COL'
OPTS.offset|limit                 #NUM
OBJ.signal                        #ABORT_SIGNAL

POST STORAGE_DOMAIN
 /object/BUCKET/FNAME_GLOB
STORAGE.upload
 ('FNAME', OBJECT_CONTENT[, OPTS])
 ->RES                            #Add an OBJECT
OPTS.cacheControl                 #STR (def: 'max-age=3600')
                                  #Can use query params for cache busting
OPTS.contentType                  #STR (def: 'text/plain;charset=UTF-8' for ARRBUFFER, guessed otherwise)
OPTS.upsert                       #BOOL (def: false)
OPTS.duplex                       #STR

POST
 STORAGE_DOMAIN/upload/resumable
POST|PUT|PATCH STORAGE_DOMAIN
 /upload/resumable/FNAME_GLOB     #Streaming upload. See online doc

PUT STORAGE_DOMAIN
 /object/BUCKET/FNAME_GLOB
STORAGE.update
 ('FNAME', OBJECT_CONTENT[, OPTS])#Replace an OBJECT
 ->RES                            #Same OPTS as upload()

POST STORAGE_DOMAIN/object/move
STORAGE.move('FNAME', 'FNAME2')
 ->RES                            #

POST STORAGE_DOMAIN/object/copy
STORAGE.copy('FNAME', 'FNAME2')
 ->RES                            #

DELETE STORAGE_DOMAIN
 /object/BUCKET[/FNAME_GLOB]
STORAGE.remove('FNAME'_ARR)->RES  #

GET STORAGE_DOMAIN/object[/info]
 /authenticated/BUCKET/FNAME_GLOB
STORAGE.download('FNAME')->RES    #Get an OBJECT

POST STORAGE_DOMAIN/object
 /sign/BUCKET
STORAGE.getPublicUrl              #Returns 'STORAGE_DOMAIN/object/public/BUCKET/FNAME', to get an OBJECT
 ('FNAME'[, OPTS])->RES           #Only if BUCKET is public
OPTS.download                     #BOOL|'FILENAME' (def: false): set HTTP headers to make it downloadable

GET STORAGE_DOMAIN/object[/info]
 /public/BUCKET/FNAME_GLOB        #Use signed URL

POST STORAGE_DOMAIN/object        #Same for a private BUCKET.
 /sign/BUCKET/FNAME_GLOB          #Includes a temporary private key.
STORAGE.createSignedUrl           #  - included in cache key, i.e. poorer caching
 ('FNAME', NUM[, OPTS])->RES      #NUM is expiration in secs

GET STORAGE_DOMAIN/object
 /sign/BUCKET/FNAME_GLOB          #Use signed URL

POST STORAGE_DOMAIN/object
 /sign/BUCKET
STORAGE.createSignedUrls
 ('FNAME'_ARR, NUM[, OPTS])->RES  #Same for multiple URLs

POST STORAGE_DOMAIN/object/upload
 /sign/BUCKET
STORAGE.createSignedUploadUrl     #Same but allows uploads
 ('FNAME')->RES                   #Expiration is always 2h

PUT STORAGE_DOMAIN/object/upload
 /sign/BUCKET
STORAGE.uploadToSignedUrl
 ('FNAME', 'TOKEN', OBJECT_CONTENT#Like upload() but with 'TOKEN' returned by createSignedUploadUrl()
 [, OPTS])->RES                   #Same OPTS as upload()

                                  ┌─────────────────────┐
                                  │   IMAGE TRANSFORM   │
                                  └─────────────────────┘

GET STORAGE_DOMAIN/render/image
 /public|authenticated|sign
 /BUCKET/FNAME_GLOB               #Like GET STORAGE_DOMAIN/object/... but for an image with transformation

OPTS.transform                    #Last argument of STORAGE.download|getPublicUrl()
                                  #Transform image response
                                  #For PNG|JPEG|WebP|AVIF|GIF|ICO|SVG|HEIC|BMP|TIFF
                                  #Max 25MB
                                  #Max 50 megapixels
                                  #Max 100/month then 1$ per 200 transforms
                                  #Pro only
                                  #Uses a fork of `imgproxy`
TRANSFORM.height|width            #1-2500
TRANSFORM.resize                  #'cover|contain|fill'
TRANSFORM.format                  #Unless set to 'origin', automatically convert to a better format,
                                  #e.g. to WebP if client supports it
TRANSFORM.quality                 #20-100 (def: 80)

                                  ┌────────────────────┐
                                  │   EDGE FUNCTIONS   │
                                  └────────────────────┘

EDGE FUNCTION ==>                 #Built on Deno Subhosting
                                  #Compared to SQL FUNC:
                                  #  - pros:
                                  #     - low latency
                                  #     - JavaScript
                                  #  - con: slower compute
                                  #No access to filesystem nor npm:*
                                  #Content-Type [S] cannot be text/html
                                  #Max requests per month: 5e5 (free), 2e6 then 1$ per 5e5 (pro)
                                  #Max size per EDGE_FUNC: 2MB (free), 10MB (pro)
                                  #Max count: 10 (free), 100 then 1$ per 10 (pro)

supabase/functions-relay          #Backend which proxies to Deno Subhosting
                                  #Small Deno Oak API
                                  #Meant to add: JWT verification, logging, rate limiting

supabase_functions                #SCHEMA with Edge functions features

EDGE_FUNC                         #Edge function's name. Convention: hyphenated

XEDGE_FUNC.entrypoint_path
./functions/EDGE_FUNC/index.ts    #Main file
./functions/_NOT_EDGE_FUNC        #Helpers

supabase functions new EDGE_FUNC  #Initializes ./functions/EDGE_FUNC/index.ts

DELETE
 API_DOMAIN/functions/EDGE_FUNC
supabase functions
 delete EDGE_FUNC                 #Delete remotely (not locally)

POST API_DOMAIN/functions
PATCH
 API_DOMAIN/functions/EDGE_FUNC
supabase functions
 deploy EDGE_FUNC                 #

GET API_DOMAIN/functions          #List EDGE_FUNCs

GET API_DOMAIN/functions/EDGE_FUNC#

GET API_DOMAIN/functions
 /EDGE_FUNC/body
supabase functions
 download EDGE_FUNC               #Download source code of EDGE_FUNC

supabase functions serve          #Run EDGE_FUNCs locally
                                  #FUNC_DOMAIN is http://localhost:54321/functions/v1
                                  #Print stdout|stderr logs
                                  #Hot reloading

XEDGE_FUNC.verify_jwt
CONFIG.functions.EDGE_FUNC
 .verify_jwt
supabase functions deploy|serve
--no-verify-jwt                   #Unless specified, EDGE_FUNC requests must be authenticated with an API_KEY

XEDGE_FUNC.import_map[_path]
CONFIG.functions.EDGE_FUNC
 .import_map
supabase functions deploy|serve
--import-map FILE                 #Deno import maps
                                  #Def: ./functions/import_map.json

XEDGE_FUNC.id                     #ID
XEDGE_FUNC.slug                   #'EDGE_FUNC' slugified
XEDGE_FUNC.name                   #'EDGE_FUNC'
XEDGE_FUNC.version                #NUM
XEDGE_FUNC.status                 #'ACTIVE|REMOVED|THROTTLED'
XEDGE_FUNC.created_at|updated_at  #'DATE_NUM'

                                  ┌─────────────────────────┐
                                  │   EDGE FUNCTIONS CALL   │
                                  └─────────────────────────┘

FUNC_DOMAIN                       #https://PROJECT_ID.functions.supabase.co
FUNC_DOMAIN/EDGE_FUNC             #Call EDGE_FUNC. Any HTTP method

@supabase/functions-js            #Version 2.1.2
new FunctionsClient('URL'[, OPTS])#FUNCTIONS
OPTS.headers                      #OBJ
OPTS.customFetch                  #Def: globalThis.fetch, or `cross-fetch`

CLIENT.functions                  #new FunctionsClient(FUNC_DOMAIN)

FUNCTIONS.invoke
 ('EDGE_FUNC'[, OPTS])->>RES      #
OPTS.method                       #'GET|POST|PUT|PATCH|DELETE' (def: 'POST')
OPTS.headers                      #OBJ
OPTS.body                         #Any supported by fetch(): STR|BLOB|ARRBUFFER|FORMDATA|RSTREAM
                                  #Other values (e.g. OBJ|ARR) are serialized to JSON
                                  #  - unless Content-Type [C] set
RES.data                          #Response as is
                                  #Automatically parses based on Content-Type [S]:
                                  #  - application/json: JSON
                                  #  - application/octet-stream: BLOB
                                  #  - multipart/form-data: FORMDATA
RES.error                         #ERROR|null
                                  #Error classes:
                                  #  - FunctionsHttpError: 4**|5** response
                                  #  - FunctionsFetchError: while calling fetch(), i.e. network error

                                  ┌──────────────┐
                                  │   WEBHOOKS   │
                                  └──────────────┘

WEBHOOKS ==>                      #TFUNC on insert|update|delete of a given TABLE, calling either:
                                  #  - HTTP[S] request
                                  #     - GET|POST
                                  #  - EDGE_FUNC
                                  #     - i.e. POST request to it
                                  #JSON payload OBJ:
                                  #  - type 'INSERT|UPDATE|DELETE'
                                  #  - schema 'SCHEMA'
                                  #  - table 'TABLE'
                                  #  - record VAL_ARR|null
                                  #  - old_record VAL_ARR|null
                                  #Uses pg_net EXTENSION

supabase_functions.hooks          #TABLE with all webhooks completed requests
supabase_functions.hooks
 .request_id                      #INT8
supabase_functions.hooks.id       #HOOK id
supabase_functions.hooks.hook_name#"HOOK" name
supabase_functions.hooks
 .hook_table_id                   #TABLE.oid
supabase_functions.hooks
 .created_at                      #TIMESTAMPTZ

                                  ┌──────────────┐
                                  │   REALTIME   │
                                  └──────────────┘

REALTIME ==>                      #Repository "supabase/realtime"
                                  #Uses Elixir/Phoenix

realtime                          #SCHEMA with realtime features

CHANNEL                           #Namespace for events
                                  #Max CHANNELs: 500 for all CLIENTs, 100 per CLIENT
                                  #Number of CLIENTs (with >=1 CHANNEL): 200 (free), 500 then .01$ per CLIENT (pro)
EVENT_TYPE                        #'broadcast|postgres_changes|presence'
EVENT                             #Sub-type of EVENT_TYPE

PAYLOAD                           #Event payload OBJ
                                  #Properties must be BOOL|NUM|STR|null|undefined
                                  #Max size: 250KB (free), 3MB (pro)
                                  #  - 1MB for postgres_changes
                                  #Max count: 2e6/month (free), 5e6 then 1$ per 4e5 (pro)
                                  #Max per sec: 100 (free), 500 (pro)

ROPTS.params.eventsPerSecond      #NUM (def: 10, max: 1000). Rate limit.
                                  #10 times lower for EVENT_TYPE 'presence'

ROPTS.headers|params.apikey       #API_KEY. Def: current one
                                  #To change, must set on both headers|params
CLIENT.realtime.setAuth('API_KEY')#

                                  ┌─────────────┐
                                  │   CHANNEL   │
                                  └─────────────┘

@supabase/realtime-js             #Version 2.7.3

REALTIME_DOMAIN                   #PROJECT_DOMAIN/realtime/v1
                                  #Must use wss://

new RealtimeClient
 ('REALTIME_DOMAIN'[, ROPTS])     #RCLIENT
CLIENT.realtime                   #new RealtimeClient()
CLIENT.*                          #Forwards to CLIENT.realtime.*
COPTS.realtime.*                  #Forwards to ROPTS.*

RCLIENT.channel
 ('CHANNEL'[, RCOPTS])
 ->CHANNEL                        #Max per sec, for all RCLIENTs: 100 (free), 500 (pro)

RCLIENT.getChannels()->CHANNEL_ARR#

RCLIENT.removeChannel(CHANNEL)    #
RCLIENT.removeAllChannels()       #

CHANNEL.on('EVENT_TYPE',          #Add listener
 OPTS, FUNC(PAYLOAD))->CHANNEL    #OPTS:
                                  #  - event '*|EVENT'
                                  #  - any other EVENT_TYPE-specific

CHANNEL.subscribe([FUNC(STR)])    #Start listening
                                  #FUNC() called when done
                                  #STR: 'SUBSCRIBED'

CHANNEL.send(OBJ)->>              #Send event. OBJ:
                                  #  - type 'EVENT_TYPE'
                                  #  - event 'EVENT'
                                  #  - payload PAYLOAD

                                  ┌───────────────┐
                                  │   BROADCAST   │
                                  └───────────────┘

EVENT_TYPE 'broadcast'            #Custom EVENT|PAYLOAD

RCOPTS.broadcast.ack              #BOOL (def: false). Make CHANNEL.send() PROMISE wait on first listener to receive

RCOPTS.broadcast.self             #BOOL (def: false). Whether to receive own events.

                                  ┌──────────────────────┐
                                  │   POSTGRES CHANGES   │
                                  └──────────────────────┘

EVENT_TYPE 'postgres_changes'     #Database row change
                                  #EVENT: 'INSERT|UPDATE|DELETE|TRUNCATE'
                                  #OPTS:
                                  #  - schema 'SCHEMA'
                                  #  - table 'TABLE' (def: all)
                                  #  - filter STR: like Postgrest, e.g. 'VAR=OP.VAL,...'
                                  #PAYLOAD:
                                  #  - new row OBJ
                                  #  - old row OBJ
                                  #     - only if TABLE `replica identity` is `full`, in SQL

LOGICAL REPLICATION ==>           #Must be used, i.e. a PUBLICATION `realtime.supabase_realtime` on TABLE
                                  #Can done from the UI
ENVVAR max_replication_slots      #5 (instead of 10)
ENVVAR wal_level                  #'logical'

supabase inspect
 db:replication-slots             #Print logical REPLICATION info

                                  ┌──────────────┐
                                  │   PRESENCE   │
                                  └──────────────┘

EVENT_TYPE 'presence'             #RCLIENT-specific VAL, sync automatically with all other RCLIENTs
                                  #Several RCLIENTs can have same VAL
                                  #  - by using same 'ID'
                                  #  - resolved using CRDT
                                  #EVENT:
                                  #  - 'sync': change
                                  #  - 'join': add
                                  #     - PAYLOAD OBJ: newPresences PRESENCE_STATE
                                  #  - 'leave': delete
                                  #     - PAYLOAD OBJ: leftPresences PRESENCE_STATE
                                  #Max messages per sec: 20 (free), 50 (pro)

RCOPTS.presence.key               #RCLIENT-specific 'ID'
                                  #Def: random UUID
PRESENCE_STATE                    #OBJ, with keys being 'ID' and values being each RCLIENT-specific VAL

CHANNEL.track(VAL)->>STR          #Mark VAL as the value to sync for current RCLIENT
                                  #STR is 'ok|error'
CHANNEL.untrack()->>STR           #Undo

CHANNEL.presenceState()
 ->PRESENCE_STATE                 #

                                  ┌──────────┐
                                  │   AUTH   │
                                  └──────────┘

AUTH ==>                          #Max USERs: 5e4 (free), 1e5 then 1$ per 300 USERs (pro)

supabase/gotrue                   #Auth API
                                  #Written in Go

auth                              #SCHEMA with auth features
                                  #Document it ???

https://app.supabase.com/         #SSO sign-in page for: Google, Azure, Okta, SAML
 sign-in-sos                      #See online doc for how to setup
                                  #Enterprise only
supabase sso ...                  #CLI for SSO (mostly CRUD)

@supabase/gotrue-js               #
new GoTrueClient(...)             #AUTH
CLIENT.auth                       #new GoTrueClient()

AUTH_DOMAIN                       #PROJECT_DOMAIN/auth/v1

AUTH UI ==>                       #React component for all AUTH features

FRONTEND HELPERS ==>              #For Next.js, Remix, SvelteKit

CONFIG.auth[.email].enable_signup #BOOL (def: true)

POST AUTH_DOMAIN/logout
AUTH.signOut()->RES               #

GET AUTH_DOMAIN/token
 ?grant_type=refresh_token        #Get refresh token

MFA ==>                           #Not documented yet

                                  ┌───────────┐
                                  │   EMAIL   │
                                  └───────────┘

POST AUTH_DOMAIN/signup           #Signup with email.
AUTH.signUp(OBJ)->RES             #Request payload OBJ:
                                  #  - email|password STR
                                  #  - options OBJ:
                                  #     - data OBJ: USER.data
                                  #     - captchaToken STR
                                  #        - must set hCaptcha secret key in UI first
                                  #        - then get the captchaToken using a React component
                                  #RES: user USER
                                  #Max 1 per minute

POST AUTH_DOMAIN/token
 ?grant_type=password             #Login with email+password
AUTH.signInWithPassword(OBJ)->RES #Request payload OBJ: email|password STR
                                  #Max 1 per minute

POST AUTH_DOMAIN/generate_link    #
POST AUTH_DOMAIN/magiclink        #Login with email + one-time password sent by mail
AUTH.signInWithOtp(OBJ)->RES      #Request payload OBJ: email STR
                                  #Max 1 per minute

POST AUTH_DOMAIN/recover          #Like signInWithOtp() but resets password.
AUTH.resetPasswordForEmail        #I.e. should redirect user to new password page.
 ('EMAIL')->RES                   #Request payload OBJ: email STR
                                  #Max 1 per minute

POST AUTH_DOMAIN/invite           #Send one-time password by email
AUTH.api.inviteUserByEmail        #Must be privileged
 ('EMAIL')->RES                   #Request payload OBJ: email STR

CONF.auth.email
 .enable_confirmations            #BOOL (def: true). Send email confirmation on signup

CONF.auth.email                   #BOOL (def: true). When changing email address,
 .double_confirm_changes          #send emails to both addresses on email change

EMAIL CONFIRMATION TIMEOUT ==>    #Def: 1 day
MIN PASSWORD LENGTH ==>           #Def: 6

EMAIL TEMPLATES ==>               #For each of the above
                                  #If free, contains Supabase branding

CONF.auth.site_url                #'URL' (def: http://localhost:3000)
                                  #For email|OAuth confirmation links
CONF.additional_redirect_urls     #'URL'_ARR (def: ['https://localhost:3000'])

EMAIL SERVER ==>                  #Can use private SMTP server
                                  #Otherwise max: 30/h (free), 100/h (pro)

                                  ┌─────────┐
                                  │   SMS   │
                                  └─────────┘

PROVIDER ==>                      #One of: Twilio, Messagebird, Textloca, Vonage
                                  #Usually configure:
                                  #  - API key|token[s]
                                  #  - sender field

POST AUTH_DOMAIN/signup           #Signup with phone number.
AUTH.signUp(OBJ)->RES             #Request payload OBJ: phone|password STR
                                  #Max 1 per minute

POST AUTH_DOMAIN/otp              #Login with SMS sent.
AUTH.signInWithOtp(OBJ)->RES      #Request payload OBJ: phone STR
                                  #Max 30 per hour (can be set), 1 per minute

POST AUTH_DOMAIN/verify           #Verify SMS sent.
AUTH.verifyOtp(OBJ)->RES          #Request payload OBJ:
                                  #  - phone STR
                                  #  - token STR
                                  #  - type 'sms'
                                  #RES: session OBJ:
                                  #  - access_token 'USER_API_KEY'
                                  #  - token_type 'bearer'
                                  #  - expires_in NUM
                                  #  - refresh_token STR
                                  #Max 360 per hour

SMS PASSWORD TIMEOUT ==>          #Def: 1m
SMS PASSWORD LENGTH ==>           #Def: 6

SMS TEMPLATE ==>                  #Def: 'Your code is {{ .Code }}'

                                  ┌───────────┐
                                  │   OAUTH   │
                                  └───────────┘

AUTH.signInWithOAuth(OPTS)->RES   #Signup|login with OAuth. OPTS:
                                  #  - provider STR among:
                                  #     - Google, Azure
                                  #     - Facebook, Apple, Twitter, LinkedIn
                                  #     - GitHub, Gitlab, Bitbucket
                                  #     - Notion, Slack, Discord, Zoom
                                  #     - Spotify, Twitch
                                  #     - Keycloak, WorkOS
                                  #  - options OBJ:
                                  #     - queryParams OBJ
                                  #     - scopes STR
                                  #  - redirectTo 'REDIRECT_URL'

CONFIG.auth.external.PROVIDER
 .enabled                         #BOOL (def: false). OAuth providers
CONFIG.auth.external.PROVIDER
 .client_id                       #'CLIENT_ID'. Public API key. Sometimes called differently, e.g. "API key"
CONFIG.auth.external.PROVIDER
 .secret                          #STR. Private API key. Sometimes called differently, e.g. "secret key"
CONFIG.auth.external.PROVIDER.url #'URL'. Not for all providers

GET AUTH_DOMAIN/authorize         #Redirects to OAuth provider

GET AUTH_DOMAIN/callback          #Done after login. Redirects to REDIRECT_URL
CONFIG.auth.external.PROVIDER     #'REDIRECT_URL'
 .redirect_uri                    #Def:
                                  #  - Site URL:
                                  #     - production domain
                                  #     - specified in UI
                                  #  - Redirect URLs:
                                  #     - additional URLs for development, e.g. http://localhost:3000/**
                                  #     - specified in UI
                                  #     - can use **

SAML ==>                          #Can be used too

                                  ┌──────────┐
                                  │   USER   │
                                  └──────────┘

GET AUTH_DOMAIN/admin/users       #List USERs

POST AUTH_DOMAIN/admin/users
GET AUTH_DOMAIN/user
AUTH.getUser()->RES               #Retrieve USER

PUT AUTH_DOMAIN/user
AUTH.updateUser(USER)->RES        #Update USER

DELETE AUTH_DOMAIN/user/USER      #Delete USER

USER                              #USER JavaScript OBJ
USER.email                        #STR
USER.password                     #STR
USER.data                         #OBJ custom metadata

auth.users                        #TABLE with USERs
USER.id                           #'UUID'
auth.uid()->'UUID'                #SQL FUNC returning USER.id
USER.role                         #'ROLE'
USER.email                        #'EMAIL'
USER.encrypted_password           #STR
USER.phone                        #STR

SESSION                           #Auth session specific OBJ
AUTH.getSession()->>SESSION       #
AUTH.setSession(SESSION)          #
AUTH.onAuthStateChange
 (FUNC(SESSION))->OBJ             #OBJ: data: subscription: unsubscribe()

                                  ┌────────────┐
                                  │   VECTOR   │
                                  └────────────┘

pgvector                          #Postgres EXTENSION for `vector`, TYPE with INT_ARR meant to be a "fingerprint"
                                  #Defines OP|FUNCs to compute distance and search by similarities (closest neighbor)
                                  #Also defines an ACCESS_METHOD `ivfflat`
                                  #VECTOR raw values ("embeddings") are usually computed by AI tools like OpenAI
                                  #VECTORs are usually associated with metadata, i.e. related information

supabase/vecs                     #Python client library
                                  #Does only SQL CRUD on `vector` TYPE

                                  ┌────────────────┐
                                  │   ENCRYPTION   │
                                  └────────────────┘


SECRETS ==>                       #Environment variables set for a given PROJECT

GET API_DOMAIN/secrets
supabase secrets list             #Values only show checksums

POST API_DOMAIN/secrets
supabase secrets set ENVVAR=VAL   #
--env-file FILE                   #

DELETE API_DOMAIN/secrets
supabase secrets unset ENVVAR     #

XSECRET.name                      #'ENVVAR'
XSECRET.value                     #'VAL'

ENVVAR SUPABASE_URL               #Current domain (from Kong)
ENVVAR SUPABASE_DB_URL            #Postgres connection URL
ENVVAR SUPABASE_ANON_KEY          #PUBLIC_API_KEY
ENVVAR SUPABASE_SERVICE_ROLE_KEY  #PRIVATE_API_KEY

ENVVAR HOSTNAME                   #STR
ENVVAR JWT_SECRET                 #STR
ENVVAR VERIFY_JWT_SECRET          #'true|false'

./functions/.env                  #ENVVARs
supabase function serve
 --env-file FILE                  #

./.env                            #ENVVARS, used by CLI
"env(ENVVAR)"                     #Get ENVVAR in CONFIG

supabase_vault                    #Postgres EXTENSION like Supabase secrets, but as SQL TABLE instead of ENVVARs

COLUMN ENCRYPTION ==>             #Encrypt a COL using supabase_vault secrets_encrypt_secret_secret TFUNC
                                  #Can specify associated COLs, for integrity check
                                  #Creates a sibling VIEW `public_TABLE` with an additional public_TABLE.decrypted_COL

GET API_DOMAIN/pgsodium           #
POST API_DOMAIN/pgsodium          #
XPGSODIUM.root_key                #STR. pgsodium root secret used by secrets and supabase_vault

                                  ┌──────────┐
                                  │   LOGS   │
                                  └──────────┘

*_logs                            #Accessible only through UI
                                  #Uses Logflare
                                  #Retention: 1d (free), 7d (pro)
                                  #Max 1000 ROWs

REPORTS ==>                       #Charts built on top of *_logs. Mostly:
                                  #  - CPU, I/O, RAM, database size
                                  #  - network igress|egress, requests count|speed for: Database, Auth, Storage, Realtime
                                  #  - users count for Auth
                                  #  - TRANSFORM

CUSTOMER_DOMAIN                   #PROJECT_DOMAIN/customers/v1
GET CUSTOMER_DOMAIN               #To integrate with Prometheus, for better charts
 /privileged/metrics              #Must be privileged
                                  #Pro only

supabase inspect db:cache-hit     #Print TABLE|INDEXs cache hit ratio
supabase inspect db:index-usage   #Print INDEX usage

                                  ┌───────────────┐
                                  │   EDGE LOGS   │
                                  └───────────────┘

edge_logs                         #SQL TABLE with logs for REST, GraphQL, Auth, Storage, Realtime

EDGE_LOGS.id                      #'UUID'
EDGE_LOGS.timestamp               #TIMESTAMPTZ
EDGE_LOGS.event_message           #'METHOD | STATUS_NUM | IP | ID | URL | USER-AGENT'

EDGE_LOGS.metadata                #METADATA_ARR

METADATA.request                  #REQ_ARR
REQ.url                           #'URL'
REQ.protocol                      #'http[s]:'
REQ.method                        #STR, e.g. 'GET'
REQ.host                          #'DOMAIN'
REQ.port                          #NUM|null
REQ.path                          #'/PATH'
REQ.search                        #'?...'|null
REQ.headers                       #OBJ_ARR
REQ.cf                            #CF
CF.country                        #STR, e.g. 'FR'
CF.*                              #More request info

METADATA.response                 #RES_ARR
RES.status_code                   #NUM
RES.origin_time                   #NUM. Duration
RES.headers                       #OBJ

                                  ┌───────────────────┐
                                  │   DATABASE LOGS   │
                                  └───────────────────┘

postgres_logs                     #SQL TABLE with logs for SQL statements
                                  #Require enabling pgAudit PG Extension
                                  #  - can also configure it
                                  #Document pgaudit ???
POSTGRES_LOGS.id                  #'UUID'
POSTGRES_LOGS.timestamp           #TIMESTAMPTZ
POSTGRES_LOGS.event_message       #STR
POSTGRES_LOGS.metadata            #METADATA
METADATA.host                     #'db-PROJECT_ID'

METADATA.parsed                   #PARSED
PARSED.user_name                  #STR
PARSED.error_severity             #STR among 'LOG|ERROR|FATAL|PANIC'
PARSED.backend_type               #STR
PARSED.command_tag                #STR
PARSED.connection_from            #STR
PARSED.database_name              #STR
PARSED.process_id                 #NUM
PARSED.query_id                   #NUM
PARSED.session_id                 #STR
PARSED.session_line_num           #NUM
PARSED.session_start_time         #STR
PARSED.sql_state_code             #STR
PARSED.timestamp                  #STR
PARSED.transaction_id             #NUM
PARSED.virtual_transaction_id     #STR

ENVVAR log_connections            #true
ENVVAR log_destination            #'csvlog'
ENVVAR log_line_prefix            #Also includes %h (host)
ENVVAR log_rotation*              #0

???

                                  ┌──────────────────┐
                                  │   STORAGE LOGS   │
                                  └──────────────────┘

storage_logs                      #SQL TABLE wiht logs for Storage
STORAGE_LOGS.id                   #'UUID'
STORAGE_LOGS.timestamp            #TIMESTAMPTZ
STORAGE_LOGS.event_message        #STR

STORAGE_LOGS.metadata             #METADATA
METADATA.context.host             #STR
METADATA.context.pid              #NUM
METADATA.level                    #STR
METADATA.project                  #'PROJECT_ID'
METADATA.reqId                    #STR
METADATA.res.statusCode           #NUM
METADATA.responseTime             #NUM
METADATA.tenantId                 #STR

METADATA.req                      #REQ
REQ.url                           #'URL'
REQ.method                        #STR
REQ.hostname                      #STR
REQ.headers                       #OBJ
REQ.remoteAddress                 #STR
REQ.remotePort                    #NUM

                                  ┌─────────────────────────┐
                                  │   EDGE FUNCTIONS LOGS   │
                                  └─────────────────────────┘

function_edge_logs                #SQL TABLE with logs for Edge FUNCs request|responses
                                  #Also shows aggregate in UI: execution time, requests count
FUNCTION_EDGE_LOGS.id             #'UUID'
FUNCTION_EDGE_LOGS.timestamp      #TIMESTAMPTZ
FUNCTION_EDGE_LOGS.event_message  #STR

FUNCTION_EDGE_LOGS.metadata       #METADATA
METADATA.function_id              #'UUID'
METADATA.project_ref              #'PROJECT_ID'
METADATA.version                  #'DEPLOYMENT_ID'
METADATA.deployment_id            #'PROJECT_ID_FUNC_ID_DEPLOYMENT_ID'
METADATA.request                  #Like EDGE_LOGS, except:
                                  #  - no REQ.cf
                                  #  - path -> pathname
METADATA.response                 #Like EDGE_LOGS, except:
                                  #  - RES.origin_time -> METADATA.execution_time_ms

function_logs                     #SQL TABLE with logs for Edge FUNCs stdout|stderr
FUNCTION_LOGS.id                  #'UUID'
FUNCTION_LOGS.timestamp           #TIMESTAMPTZ
FUNCTION_LOGS.event_message       #STR

FUNCTION_LOGS.metadata            #METADATA
METADATA.function_id
METADATA.project_ref
METADATA.version
METADATA.deployment_id            #Like function_edge_logs
METADATA.execution_id             #STR
METADATA.event_type               #STR
METADATA.level                    #STR
METADATA.region                   #STR
METADATA.timestamp                #STR

                                  ┌───────────────────┐
                                  │   REALTIME LOGS   │
                                  └───────────────────┘

realtime_logs                     #SQL TABLE wiht logs for Realtime
REALTIME_LOGS.id                  #'UUID'
REALTIME_LOGS.timestamp           #TIMESTAMPTZ
REALTIME_LOGS.event_message       #STR

REALTIME_LOGS.metadata            #METADATA
METADATA.level                    #STR
METADATA.external_id              #STR

METADATA.measurements             #MEASUREMENTS
MEASUREMENTS.connected            #NUM
MEASUREMENTS.connected_cluster    #NUM
MEASUREMENTS.limit                #NUM
MEASUREMENTS.SUM                  #NUM

ROPTS.log_level                   #'error|warn|info|debug'
                                  #Set to 'info' to log joins|leaves of RCLIENTs|CHANNELs

                                  ┌───────────────┐
                                  │   AUTH LOGS   │
                                  └───────────────┘

auth_logs                         #SQL TABLE with logs for AUTH
AUTH_LOGS.id                      #'UUID'
AUTH_LOGS.timestamp               #TIMESTAMPTZ
AUTH_LOGS.event_message           #STR

AUTH_LOGS.metadata                #METADATA
METADATA.status                   #NUM
METADATA.method                   #STR
METADATA.host                     #STR
METADATA.path                     #STR
METADATA.remote_addr              #STR
METADATA.level                    #STR
METADATA.msg                      #STR
METADATA.component                #STR
METADATA.referer                  #STR
METADATA.timestamp                #STR
METADATA.duration                 #NUM

METADATA.auth_event               #AUTH_EVENT
AUTH_EVENT.action                 #STR
AUTH_EVENT.actor_id               #STR
AUTH_EVENT.actor_username         #STR
AUTH_EVENT.log_type               #STR

AUTH_EVENT.traits                 #TRAITS
TRAITS.provider                   #STR
TRAITS.user_email                 #STR
TRAITS.user_id                    #STR
TRAITS.user_phone                 #STR

                                  ┌─────────┐
                                  │   API   │
                                  └─────────┘

KONG ==>                          #Is used as the API gateway for all API calls

NON-MANAGEMENT APIS ==>           #All of: REST, GraphQL, Realtime, Auth, Storage, Edge Functions call

MANAGEMENT API ==>                #Used for parts of the product which do not have own APIs

Content-Type:
 application/json [C|S]           #

API USAGE ==>                     #Can see in Reports UI, for REST, GraphQL, Auth, Storage, Realtime
                                  #Can filter by request (method, path, query params, User-Agent [C], X-Client-Info [C])
                                  #and response (status code)

X*                                #Means ENTITY returned by an API call

                                  ┌────────────┐
                                  │   DOMAIN   │
                                  └────────────┘

TOP_API_DOMAIN                    #https://api.supabase.com/v1
API_DOMAIN                        #TOP_API_DOMAIN/projects/PROJECT_ID

PROJECT_DOMAIN                    #https://PROJECT_ID.supabase.co

CUSTOM_DOMAIN                     #Custom PROJECT_DOMAIN
                                  #Old PROJECT_DOMAIN does not work anymore
                                  #Pro only
POST API_DOMAIN/custom-hostname
 /initialize                      #Start CUSTOM_DOMAIN
supabase domains create           #Outputs TXT records to setup on DNS registrar
--custom-hostname DOMAIN          #

POST API_DOMAIN/custom-hostname
 /reverify
supabase domains reverify         #Finish CUSTOM_DOMAIN, once TXT records setup

POST API_DOMAIN/custom-hostname
 /activate
supabase domains activate         #Activate CUSTOM_DOMAIN

GET API_DOMAIN/custom-hostname
supabase domains get              #Print CUSTOM_DOMAIN

DELETE API_DOMAIN/custom-hostname
supabase domains delete           #Delete CUSTOM_DOMAIN

XCUSTOM_DOMAIN.custom_hostname    #'CUSTOM_DOMAIN'
XCUSTOM_DOMAIN.status             #Among: "1_not_started", "2_initiated", "3_challenge_verified", "4_origin_setup_completed", "5_services_reconfigured"
XCUSTOM_DOMAIN.data               #OBJ

SUBDOMAIN                         #Custom PROJECT_DOMAIN, but only changing PROJECT_ID
                                  #Old PROJECT_DOMAIN still works
                                  #Does not work with:
                                  #  - CUSTOM_DOMAIN
                                  #  - EDGE_FUNCs
                                  #Pro only
supabase vanity-subdomains
 check-availability
--desired-subdomain SUBDOMAIN     #Check not used by another customer

supabase vanity-subdomains
 activate
--desired-subdomain SUBDOMAIN     #Use SUBDOMAIN

supabase vanity-subdomains get    #Print SUBDOMAIN

supabase vanity-subdomains delete #Delete SUBDOMAIN

                                  ┌─────────────┐
                                  │   API KEY   │
                                  └─────────────┘

API_KEY                           #'JWT' used for non-management API calls
?apikey=API_KEY
apikey: API_KEY [C]               #
Authorization: Bearer API_KEY [C] #Must be done too

PUBLIC_API_KEY                    #'JWT' for anon ROLE
                                  #Available in UI
USER_API_KEY                      #'JWT' for authenticated ROLE
                                  #Created by AUTH login endpoints
PRIVATE_API_KEY                   #'JWT' for service_role ROLE
                                  #Available in UI

ACCESS_TOKEN                      #Token for the management API (including through CLI)
                                  #Created through UI
ENVVAR SUPABASE_ACCESS_TOKEN      #
supabase login                    #Login with ACCESS_TOKEN
                                  #Uses OS-specific way to keep it

                                  ┌─────────┐
                                  │   JWT   │
                                  └─────────┘

pgjwt                             #EXTENSION used under-the-hood (see its doc)

auth.jwt()->JWT_PAYLOAD_JSONB     #SQL FUNC
                                  #Returns Postgrest's TCONF.request.jwt.claims
                                  #Returns null unless ROLE anon|authenticated|service_role

JWT_PAYLOAD.role                  #'anon|authenticated|service_role'
JWT_PAYLOAD.sub                   #'UUID' of USER
JWT_PAYLOAD.name                  #'NAME' of USER
JWT_PAYLOAD.iat                   #DATE_NUM. Start time
JWT_PAYLOAD.exp                   #DATE_NUM. End time (in 10 years)
JWT_PAYLOAD.*                     #Any custom data

Cookie: sb-access-token=JWT [C]   #API_KEY

CONFIG.auth.jwt_expiry            #NUM (in secs). Expiration: def: 1h, max: 7d

Cookie: sb-refresh-token=JWT [C]  #Refresh TOKEN, to extend expiration
                                  #At most 10 (can be set) to avoid stolen token from having too much impact


                                  ┌────────────────┐
                                  │   JAVASCRIPT   │
                                  └────────────────┘

@supabase/supabase-js             #Node/Deno/browsers client
                                  #Version 2.25.0

createClient('PROJECT_DOMAIN',    #CLIENT
 API_KEY[, COPTS])                #Mostly just forwards to other clients: @supabase/storage-js, etc.

CLIENT.fetch(...)                 #Like fetch(...) but with Authentication headers
COPTS.global.fetch                #Custom fetch(...)
COPTS.global.headers              #HTTP headers OBJ

X-Client-Info:
 supabase-js/X.Y.Z [C]            #

                                  ┌────────────────┐
                                  │   TYPESCRIPT   │
                                  └────────────────┘

GET API_DOMAIN/types/typescript   #Generates TypeScript types of database, to stdout
supabase gen types typescript     #OBJ:
                                  #  - Database:
                                  #     - public:
                                  #        - Tables|Views:
                                  #           - NAME
                                  #              - Row OBJ: `select` response type
                                  #              - Insert|Update OBJ: `insert|update` request type
                                  #        - Functions:
                                  #           - FUNC:
                                  #              - Args OBJ
                                  #              - Returns VAL
                                  #        - Enums OBJ
                                  #        - CompositeTypes OBJ
--project-id PROJECT_ID           #
?included_schemas=SCHEMA,...
--schema SCHEMA,...               #
--linked|local                    #Whether to use local|remote database

XTYPES.types.type                 #'JSON_OBJ' with result

createClient<Database>(...)       #Use Database TypeScript type

                                  ┌─────────┐
                                  │   CLI   │
                                  └─────────┘

supabase                          #CLI, version 1.69.3
                                  #Built with Go
                                  #Only for the management API and local development

supabase/setup-cli                #GitHub action
                                  #Version 1.2.0
                                  #Downloads supabase CLI (from GitHub releases) and installs it
                                  #Must then run: supabase init, supabase [db] start
INPUTS|OUTPUTS.version            #'X.Y.Z' (def: latest)

supabase update                   #Upgrade CLI version

CONFIG                            #CLI configuration
                                  #At WORKDIR/config.toml

supabase ...
--experimental                    #Must be used with: supabase domains|vanity-subdomains|network-restrictions|ssl-enforcement
--debug                           #
--dns-resolver                    #'native' (def) or 'https'

ENVVAR SUPABASE_WORKDIR
supabase ... --workdir            #'WORKDIR' (def: './supabase')

supabase init                     #Creates default CONFIG, seed.sql and migations/

supabase ...
 --project-ref PROJECT_ID         #
supabase link
 --project-ref PROJECT_ID         #Set --project-ref default value

supabase completion SHELL         #Print CLI completion script, to source in shell

                                  ┌───────────────┐
                                  │   LOCAL DEV   │
                                  └───────────────┘

supabase start                    #Run Supabase locally:
                                  #  - API: http://localhost:54321
                                  #     - GoTrue, Realtime, Storage, Functions, imgproxy, Kong, postgrest, postgres-meta, logflare, vector
                                  #  - UI: http://localhost:54323
                                  #  - Postgres database: postgresql://postgres:postgres@localhost:54322/postgres
                                  #  - Storage: http://localhost:54324
                                  #  - PUBLIC|PRIVATE_API_KEY, JWT secret
                                  #Uses Docker containers hosted on AWS ECR
--exclude|-x 'SERVICE,...'        #Exclude specific SERVICEs among: edge-runtime gotrue imgproxy inbucket kong logflare migra
                                  #pgadmin-schema-diff postgres-meta postgrest realtime storage-api studio vector
--ignore-health-check             #

CONFIG.db|studio|inbucket.port
CONFIG.inbucket.smtp|pop3_port    #NUM. Port used by `supabase start`

supabase db start                 #Only start Postgres database

supabase stop                     #Stop local server
--backup                          #Caches Docker resources

supabase status                   #Prints local URLs and API_KEYs
--output|-o STR                   #Format among pretty (def), env, json, yaml, toml

                                  ┌────────┐
                                  │   UI   │
                                  └────────┘

supabase/supabase                 #UI
                                  #Unless specified, most features can be done in UI
                                  #app.supabase.com, called "dashboard" or "studio"
                                  #Also contains:
                                  #  - supabase.com
                                  #  - supabase.com/docs
                                  #Uses Supabase itself
                                  #Uses TypeScript, Turborepo, Jest, Next.js, React, Stripe, Babel, Prettier, Storybook

                                  ┌────────────┐
                                  │   OTHERS   │
                                  └────────────┘

OTHER CLIENTS ==>                 #Rust, Ruby, Python, Go, Swift, C#, Java, Kotlin, PHP, Godot engine, Flutter

FRAMEWORK ADAPTERS ==>            #React, Vue, Nuxt, Next.js, Svelte, SvelteKit, Remix

MARKETPLACE ==>                   #List of integrations
                                  #Many come up with guides only, not actual integrations

SELF-HOSTING ==>                  #Can be done on Kubernetes, DigitalOcean, AWS, Terraform, Traefik, StackGres
                                  #Cannot use: Edge Functions, storage CDN, PITR backup, clients (API, CLI, JavaScript)
--db-url 'LIBPQ'                  #Needed with self-hosting when using many CLI commands
