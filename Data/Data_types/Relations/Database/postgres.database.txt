
            
   POSTGRES  
            



TO DOCUMENT:
  - CTE documentation in SELECT reference
  - partition of|by in CREATE TABLE reference

Relationships:
  - can be 0, 0|1, many or 0|many on each side
  - 1-to-1: foreign key
  - all others: third table with foreign keys for both sides
Enum:
  - prefer small tables when possible
How to check that foreign key cover all the primary key values?
Primary key:
  - should always create surrogate key as primary key, even when natural keys are candidate keys
  - should then put non-primary candidate keys with unique constraint
  - check article stackoverflow answered in StackOverflow


TO FINISH ==>                     #  - SSH, GPG
                                  #  - repmgr
                                  #  - Chapter 17, 19, and 18.3.2, and postgres -l
                                  #  - pgcrypto
                                  #  - 39.1. Installing procedural languages
                                  #  - Postgres-XC

VERSION ==>                       #9.3.5


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          MAIN TASKS           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


DATABASE DESIGN ==>               #Modelling (pgModeler)
                                  #  - create tables with right columns, constraints (pkey, fkey, default, check, not null, unique, exclude) and properties (inherits)
                                  #  - using:
                                  #     - normal types (NUM, BOOL, STR, BSTR, BYTEA, DATE|TIME, ENUM) and arrays, ranges
                                  #     - special types (net, dictionary, xml, json, hstore, ltree, geometry) and created types (ctype, domain)
                                  #     - id vs uuid
                                  #     - views for encapsulation, or security restriction per column
                                  #     - [event] triggers
                                  #     - sequences
                                  #     - schemas
                                  #     - foreign tables (including file_fdw for CSV files)
                                  #     - listen|notify for clients communication
                                  #Security:
                                  #  - roles and privileges
                                  #  - authentication
                                  #  - unix_socket_directories
                                  #  - FUNC definition (leakproof, security definer)
                                  #Multithread-safety (transactions, locks)
                                  #Watch out for:
                                  #  - null possibility in queries
                                  #  - SQL injection when concatenating 'SQL' (use quote_*() or format())

PERFORMANCE ==>                   #  - on design, check using:
                                  #     - materialized views instead of views
                                  #     - rules instead of triggers
                                  #     - index
                                  #     - cursors
                                  #     - partitions
                                  #     - prepared statements
                                  #     - large objects
                                  #     - tablespaces
                                  #  - ENVVAR tunning:
                                  #     - disabling durability, decreasing checkpoints frequency, using RAM disks
                                  #     - setting right resources needed for [maintenance_]work_mem, effective_cache_size, wal_buffers, max_stack_depth, temp_file_limit,
                                  #       max_files_per_processes, effective_io_concurrency, shared_buffers, max_connections, statement_timeout
                                  #     - using pgtune
                                  #  - optimizing queries with explain
                                  #  - using pgbench
                                  #  - for big data write, see below best practices
                                  #  - use connection pooling (pgBouncer)
                                  #  - upgrading hardware
                                  #  - FUNC definition (volatility, cost, rows)
                                  #  - TABLE fillfactor, fastupdate
                                  #  - autovacuum tunning

SETUP FOR END USERS               #  - create [A|W]FUNC (possibily from PL/* languages), prepared statements, comments
 AND FUTURE MAINTENANCE ==>       #  - logging
                                  #  - [hot] standby with [a]sync. streaming replication
                                  #  - use pgagent for regular tasks:
                                  #     - pgbadger and pgcluu reports creation
                                  #     - check_postgres
                                  #        - good idea to merge pgbadger, pgcluu and check_postgres into one HTML file with a script
                                  #     - pg_dumpall
                                  #  - if durability, check proper cache usage (wal_sync_method, HDD|filesystem cache)

TESTING ==>                       #  - random filling (datafiller.py)
                                  #  - unit testing (pgTap)
                                  #  - load testing (Tsung)

MAINTENANCE ==>                   #  - monitoring:
                                  #     - use pgadmin, with Server status window, and opening a psql within pgadmin (create proper .psqlrc), or use teamPostgreSQL
                                  #     - resource (should not exceed max_connections and work_mem), space usage or other problems:
                                  #        - pgbadger and pgcluu
                                  #        - pg_top
                                  #        - check_postgres
                                  #  - data update (should create functions):
                                  #     - partitionning
                                  #     - copy "TABLE" from
                                  #  - cluster/reindex (ask for exclusive lock)
                                  #  - check PostgreSQL upgrades, and use pg_upgrade
                                  #  - create restore points with pg_create_restore_point(STR) after critical operations


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          POSTGRESQL           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


ARCHITECTURE ==>                  #RDBMS with focus on standard compliance and extensibility.
                                  #Conform to SQL:2016 for most of it
                                  #Client (psql, pgadmin, etc.) / server (postgres) architecture

LIMITS ==>                        #  - database size: unlim
                                  #  - table size: 32TB
on conflict
 on constraint "CONSTRAINT" ...   #
                                  #  - cols count: 250-1600 depending on TYPE
                                  #  - rows count: unlim
                                  #  - cell size: 1GB
                                  #  - file descriptors: OS-specific (see its doc)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            SYNTAX             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


COMMAND;                          #"Statement"
CLAUSE ==>                        #Part of a COMMAND attached to keywords
                                  #E.g. WHERE BOOL

WHITESPACES ==>                   #Ignored

CASE-SENSITIVITY ==>              #Case-insensitive for:
                                  #  - keywords (other uppercase)
                                  #  - VARs (other lowercase)
"VAR"
U&"VAR2"                          #Make VAR case-sensitive

--COMMENT ...
/* COMMENT */                     #

(VAR [= VAL], ...)                #OPTS. Used in many SQL statements for named parameters.
                                  #VAL is only optional if either:
                                  #  - it has a default value
                                  #  - it has no value, i.e. it is implicitly a BOOL
(VAR [VAL], ...)                  #ZOPTS. Same without = sign

DDL                               #"Data Definition Language"
                                  #Statements operating on entities themselves
                                  #E.g. create, alter, drop, truncate, comment, etc.
DML                               #"Data Manipulation Language"
                                  #Statements operating on entities contents
                                  #E.g. select, insert, update, delete, explain, etc.
DCL                               #"Data Control Language"
                                  #Statements operating on authorization
                                  #E.g. grant, revoke, etc.
TCL                               #"Transaction Control Language"
                                  #Statements operating on transactions
                                  #E.g. commit, rollback, savepoint, etc.

OUTPUT ==>                        #Some statements return the NUM of ROWs manipulated.
                                  #This is separate from the ROW_SET returned by a SUBQUERY, and is not printed by default
                                  #For: select|insert|update|delete|merge|move|fetch|copy|create table as


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             NAME              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


name                              #TYPE of a "VAR", used internally. 64 bytes string.

VAR                               #Any identifier
                                  #[[:alnum:]_]+
                                  #Max 63 chars
"VAR"                             #Allows reserved keywords, and case-sensitive
                                  #"" to escape "
as VAR                            #Some COMMANDs allows optional `as`.
                                  #This allows reserved keywords, but remains case-insensitive unless quoted

"..."                             #Notation to means a VAR (with|without quoting)
                                  #Including "TABLE", "COL", etc.

TEXT <-> NAME
VARCHAR|BPCHAR <=-> NAME          #Type casting


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:         TYPE CASTING          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


pg_typeof(VAL)->'TYPE'            #TYPE as a STR

cast(VAL as TYPE)
VAL::TYPE                         #Explicit casting
TYPE '...'                        #Explicit casting, but UNKNOWN '...' only

ASSIGNMENT CASTING ==>            #Automatic casting when insert value in a COL
                                  #Always implies explicit casting too

IMPLICIT CASTING ==>              #Automatic casting when passing arguments to a FUNC
                                  #Always implies explicit + assignment casting too

TYPE -> TYPE2                     #Means can do implicit casting
TYPE => TYPE2                     #Means can do assignment casting
TYPE ~> TYPE2                     #Means can do explicit casting
TYPE <=-> TYPE2                   #Means TYPE2 => TYPE, TYPE -> TYPE2

pg_cast                           #TABLE with implicit|explicit type casting
pg_cast.oid                       #OID
pg_cast.castsource|casttarget     #pg_type.OID of source|target TYPE
pg_cast.castfunc                  #pg_proc.OID of FUNC used for conversion
                                  #FUNC(TYPE1_VAL[, INT[, BOOL]])->TYPE2_VAL
                                  #  - INT is the pg_attribute.ATTTYPEMOD
                                  #  - BOOL is true if explicit cast
pg_cast.castcontext               #Casting:
                                  #  - 'e': explicit
                                  #  - 'a': assignment
                                  #  - 'i': implicit
pg_cast.castmethod                #How to cast, among:
                                  #  - 'f': castfunc
                                  #  - 'i': C-level I/O functions
                                  #  - 'b': nothing (TYPEs are binary-equivalent)

create cast (TYPE as TYPE2)
 with function FUNC(...)          #Creates a type casting FUNC
 [as assignment|implicit]         #assignment|implicit is 'a|i' castcontext (def: 'e')
create cast ... with inout ...
create cast ...
 without function ...             #Same but with a 'i|b' castmethod (def: 'f')


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          LARGE TYPES          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


VARIABLE BOUNDED LENGTH TYPES     #One of:
 ==>                              #  - numeric(...)
                                  #  - varchar|bpchar
                                  #  - bit(...)
                                  #  - time[stamp][tz]|interval
VARIABLE UNBOUNDED LENGTH TYPES   #One of:
 ==>                              #  - numeric
                                  #  - text
                                  #  - bit varying, bytea
                                  #  - json, xml, hstore
                                  #Max length: 1GB

SIZING CAST ==>                   #Type cast to same type
                                  #Used to enforce size of variable bounded length TYPEs
                                  #  - failing if too large
                                  #  - padding or truncating
                                  #Usually implicit casting

TOAST ==>                         #Large variable length TYPE values are split them in several ~2KB chunks
                                  #Goals:
                                  #  - fit in a single 8KB page, so that computation can happen in-memory only, which is faster
                                  #  - compression, to save space
IN-LINE TOAST ==>                 #Keeps data as is but possibly compress it
                                  #Requires 1|4 additional bytes
                                  #If <127 bytes
OUT-OF-LINE TOAST ==>             #Replace data with 18 bytes pointer to pg_toast_OID TABLE
                                  #If >127 bytes
pg_class.reltoastrelid            #pg_class.oid of the pg_toast_OID "TABLE"
pg_toast.pg_toast_OID             #"TABLE" with TOAST out-of-line data
pg_toast.pg_toast_OID.chunk_id    #Data ID
pg_toast.pg_toast_OID.chunk_seq   #Data chunk serial NUM
pg_toast.pg_toast_OID.chunk_data  #BYTEA with the data

ENVVAR default_toast_compression  #Compress TOASTed values (in-line or out-of-line) among:
                                  #  - 'pglz' (def): Postgres-specific LZMA-like, optimized for speed (not space)
                                  #  - 'lz4': optimized for space
                                  #     - requires compiling with --with-lz4 (is the case with Ubuntu)
create table "TABLE"
 ("COL" TYPE compression ENUM,...)
alter table "TABLE"
 alter [column] "COL"
 set compression ENUM             #Sets compression, like ENVVAR default_toast_compression

alter table "TABLE"               #Sets TOAST behavior among:
 alter [column] "COL"             #  - plain
 set storage ENUM                 #     - no out-of-line nor compression
                                  #     - only possible value for non-variable length TYPEs
                                  #  - extended:
                                  #     - both out-of-line and compression
                                  #     - def for variable length TYPEs
                                  #  - external:
                                  #     - out-of-line but not compression
                                  #     - i.e. faster computation but more space
                                  #  - main:
                                  #     - no out-of-line but compression

create table "TABLE"              #Do not use out-of-line nor compression for values < UINT bytes
 set (toast_tuple_target = UINT)  #Min: 128, max: 8160, def: 2040 (which is usually good)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           OPERATORS           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


operator([SCHEMA.]OP)             #Another way to write OP
                                  #Default SCHEMA: pg_catalog

OPERATORS ==>                     #Operators shared by all TYPEs, except:
                                  #  - geometry, json, xml
                                  #  - but can cast to STR

(VAL)                             #Parenthesis to override operator order

VAL = VAL2
VAL <> VAL2                       #BOOL

VAL > >= < <= VAL2                #BOOL
VAL between [symmetric]           #BOOL. Same as VAL >= VAL2 and VAL <= VAL3
 VAL2 and VAL3                    #If VAL3 < VAL2:
                                  #  - if symmetric: swap them
                                  #  - otherwise: returns false
greatest|least(VAL...)->BOOL      #Using > <

VAL [not] in (VAL2,...)           #BOOL. Whether VAL = <> any VAL2

case [LVAL]
  when TVAL then RVAL
  [...]
  [else RVAL]                     #Switch statement. Substitutes to RVAL where LVAL = TVAL
end                               #Def LVAL is true, i.e. can use TVAL BOOLs, like an if statement


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            UNKNOWN            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


unknown                           #Unknown TYPE
                                  #Has no operators, but is usually implicitly transtyped based on operators
unknown -> VAL                    #Possible with any TYPE
VAL ~> unknown                    #Never possible, except with unknown itself

'...'                             #UNKNOWN
                                  #'' to escape a '
                                  #Otherwise can include any character, including \, newlines and Unicode codepoints.
                                  #Internally encoded as UTF-8
                                  #Used for the literal value of all TYPEs, meant to be cast
                                  #  - noted as TYPE_UNKNOWN, meaning UNKNOWN that can be cast to TYPE
                                  #  - type casting is TYPE-specific, and not specified in pg_cast
$[TAG]$...$[TAG]$                 #Like '...' but can include '
U&'...'                           #Like '...' but can also include \NNNN or \+NNNNNN codepoint
E'...'                            #Like '...' but can use backslash escape sequences
                                  #\b, \f, \n, \r, \t, \v, \\, \NNN, \xNN, \uNNNN, \UNNNNNNNN


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             NULL              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


null                              #Missing data
                                  #Can be any TYPE (def: unknown)
                                  #Often avoided
                                  #  - e.g. with not null CONSTRAINTs

VAL OP null                       #Always return null, except statements below
FUNC(..., null, ...)              #Includes:
                                  #  - null = <> < <= > >= null
                                  #  - case null ..., case VAL when null
                                  #  - ROW = <> ROW2
                                  #  - exists(SUBQUERY)

null or false                     #null
null and true                     #null
null or true                      #true
null and false                    #false

VAL is [not] distinct from VAL2   #Like VAL = <> VAL2 but handles null as any other value.
VAL is [not] null                 #Same as VAL is [not] distinct from null
BOOL is [not] BOOL2               #Same as BOOL is [not] distinct from BOOL2

nullif(VAL, VAL2)->VAL|null       #VAL if <> VAL2, otherwise null
coalesce(VAL,...)->VAL            #First VAL not null

concat(STR,...)->STR2             #See below

null = null                       #Is BOOL for clauses about duplicates (except unique)
                                  #  - group by
                                  #  - partition by
                                  #  - union|intersect|except [all]
                                  #  - distinct
                                  #Is also BOOL inside ARR (but not ROW)
                                  #  - null ARR item is distinct from missing item
where BOOL_REXPR                  #null -> false
check (BOOL_REXPR)                #null -> true

references "TABLE2"("COL2")       #null ROWs are ignored in both COL and COL2
match simple|full                 #For multicolumn foreign keys:
                                  #  - match simple (def): ignore ROW if at least one COL null
                                  #  - match full:
                                  #     - ignore ROW if all COLs null
                                  #     - fail if some COLs null but not others

AFUNC(...)                        #Ignores nulls, except a few ones


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            BOOLEAN            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


boolean                           #TYPE

BOOL => STR                       #Cast as 'true|false'
BOOL <~> INT4                     #Cast as 0|1

true|false|null                   #BOOL

BOOL or BOOL2                     #
BOOL and BOOL2                    #
not BOOL                          #

BOOL > >= < <= BOOL2              #true > false


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            NUMBER             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


NUM                               #INT|FLOAT|money
INT                               #int2|4|8
FLOAT                             #float4|8|numeric

int2
smallint                          #TYPE. Signed 2 bytes integer
int4
integer                           #TYPE. Signed 4 bytes integer
int8
bigint                            #TYPE. Signed 8 bytes integer

float4
real                              #TYPE. 4 bytes float
float8
double precision                  #TYPE. 8 bytes float

numeric[(NUM[, NUM2])]            #TYPE. Fixed precision integer with NUM digits including NUM2 decimals
decimal[(NUM[, NUM2])]            #NUM2 can be negative: NUM2 last integer digits are zeros
                                  #Def NUM,NUM2: unbounded
                                  #Def NUM2: 0
                                  #Max NUM[2]: 1e3
                                  #Min NUM2: -1e3
                                  #Max value: 1e130000, min epsilon: 1e-16000
                                  #Rounded nearest, then towards [-]Infinity

INT2 <=-> INT4 <=-> INT8
 <=-> NUMERIC                     #When cast as smaller TYPE, fails if beyond max size.
 <=-> FLOAT4 <=-> FLOAT8          #When cast from FLOAT to INT, rounds nearest, then towards 0

money                             #TYPE. Like numeric(Infinity, 2)
                                  #Max value: 1e17
MONEY <=> NUMERIC
INT4|8 => MONEY                   #Type cast

NUM                               #Literal NUM
NUMe...                           #TYPE:
                                  #  - numeric: decimals or NUMe...
                                  #  - bigint: >= 2**31
                                  #  - integer: otherwise
-0                                #Same as +0

'NaN'
'[-]Infinity'                     #FLOAT_UNKNOWN

NUM + - / * NUM2                  #
-NUM                              #

INT & | # << >> INT2
~INT                              #Bitwise operations
INT # INT2                        #xor

power(NUM, NUM2)->FLOAT
NUM ^ NUM2                        #

mod(NUM, NUM2)->NUM3
NUM % NUM2                        #

div(NUM, NUM2)->INT               #trunc(NUM/NUM2)

|/ NUM                            #Square root
cbrt(NUM)->NUM
||/ NUM                           #Cube root

factorial(INT)->FLOAT             #

exp(NUM)->FLOAT                   #
ln(NUM)->FLOAT                    #
log10(NUM)->FLOAT                 #
log(NUM[, NUM2])->FLOAT           #Def: 10

abs(NUM)->NUM
@ NUM                             #
sign(NUM)                         #-1, 0 or 1

ceil(NUM)->FLOAT                  #
floor(NUM)->FLOAT                 #
trunc(NUM[, INT])->FLOAT          #Def INT: 0
round(NUM[, INT])->FLOAT          #Def INT: 0

[a]cos|sin|tan(NUM)->FLOAT        #
cot(NUM)->FLOAT                   #
atan2(NUM, NUM2)->FLOAT           #
degrees|radians(NUM)->FLOAT       #Conversion
pi()->FLOAT                       #

generate_series(NUM, NUM2[, NUM3])
 ->NUM4_SET                       #From NUM to NUM2, with step NUM3 (def: 1)

width_bucket
 (NUM, NUM2, NUM3, INT)->INT2     #Bucket index INT2 of value NUM in an histogram from NUM2 to NUM3 with INT buckets.

to_hex(NUM)->STR                  #Hexadecimal, lowercase, without 0x prefix

to_char(NUM, STR)->STR2           #Use format STR, e.g. '999D9' (3 integer digits, 1 decimal digit)
                                  #Not documented yet


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            STRINGS            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


STR                               #varchar|bpchar|text (not char|name)
'...'                             #Personal notation meaning a STR
                                  #Including 'TABLE', 'COL', etc.
'STR'                             #Notation meaning a literal STR value

STRINGS ==>                       #Unless specified otherwise, operations are done Unicode codepoint-wise
                                  #  - including astral
                                  #  - "character" usually means "Unicode codepoint"
                                  #Unicode-aware, e.g. case
                                  #1-based indices

varchar[(NUM)]                    #TYPE. STR with NUM max Unicode codepoints (def: unlim)
                                  #Max NUM: 1e7
bpchar[(NUM)]
char(NUM)                         #TYPE. Like varchar, but pads with spaces (slower and takes more space)
text                              #TYPE. Like varchar, but variable length

BPCHAR -> VARCHAR|TEXT            #Type cast removes padded spaces
VAL -> STR                        #For all TYPEs
                                  #Usually looks like '...' TYPE_UNKNOWN
                                  #  - e.g. row(VAL,...) -> '(VAL,...)'

'...'                             #STR_UNKNOWN

ascii('CHAR')->UINT               #Unicode codepoint
chr(UINT)->'CHAR'                 #Inverse

[char_]length(STR)->INT           #In Unicode codepoints
bit|octet_length(STR)->INT        #In UTF-8 bits|bytes

position(STR in STR2)->UINT       #Index of STR inside STR2. 0 if not found.

left|right(STR, UINT)->STR2       #UINT first|last characters
substring
 (STR from UINT [for UINT2])->STR2#UINT2 characters (def: all) from index UINT
overlay(STR placing STR2
 from UINT [for UINT2])->STR3     #Replace substring(STR from UINT [for UINT2]) by STR2

STR || STR2                       #Concatenation
concat(STR,...)->STR2             #Same as STR || ... but ignores nulls
concat_ws(STR, STR2...)           #Same but with separator STR

repeat(STR, UINT)->STR2           #
reverse(STR)->STR2                #

replace(STR, STR2, STR3)->STR4    #Replace each occurence of STR2 by STR3 in STR
translate
 (STR, 'CHAR...', 'CHAR2...')
 ->STR2                           #Replace each CHAR in STR by CHAR2
split_part(STR, STR2, UINT)
 ->STR3|null                      #Split STR by delimiter STR2 and returns item number UINT

lower|upper(STR)->STR2            #
initcap(STR)->STR2                #Titleize. upper() to first character, and characters after a non-letter|digit
                                  #lower() otherwise

trim([trailing|leading|both]
 [STR from] STR2)->STR3           #Remove (def: both) characters among STR (def: ' ') from STR2
l|rpad(STR, UINT[, STR2])->STR3   #Pads STR with STR2 (def: ' ') to length UINT.
                                  #If lower length, truncates.


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             CHAR              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


char                              #TYPE. Like char(1)

'CHAR'                            #CHAR_UNKNOWN

CHAR <~> INT4                     #Type cast from first digit, e.g. '2' <~> 2
CHAR <=-> TEXT
CHAR <=> VARCHAR|BPCHAR           #Type cast. Truncate first Unicode codepoint


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           ESCAPING            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


quote_ident(STR)->STR             #Escape STR to use as SQL "VAR"
                                  #Wrap in "" if needed, and escape "
quote_literal(VAL)->STR           #Escape STR to use as SQL STR
                                  #Wrap in '', and escape ' \
                                  #If not STR, stringify
quote_nullable(VAL)->STR          #Same as quote_literal(VAL), but if VAL is null, returns 'NULL', not null

format(STR, VAL...)->STR2         #Similar to sprintf(). Can use:
                                  #  - %I: quote_ident()
                                  #  - %s: quote_literal() without the outside ''
                                  #  - %L: quote_nullable()


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           GLOBBING            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


'GLOB'                            #Only two special characters: % (like *) and _ (like ?)
                                  #No file expansion

STR [not] [i]like 'GLOB'          #BOOL. True if matches
 [escape 'CHAR']                  #i if case-insensitive
                                  #'CHAR' is escape character (def: '\').


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            REGEXP             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


'REGEXP'                          #Also with some different syntaxes:
                                  #  - \< \> -> \m \M
                                  #  - \b \B -> \y \Y
                                  #Also does not have:
                                  #  - greediness
                                  #  - n|p|w flags
                                  #  - modifiers (\u \l ...)
                                  #  - [...&&--...]
                                  #  - (?<GROUP>)
                                  #  - \p{PROP}
                                  #Use locales|Unicode for case and [[:...:]]

STR [!]~[*] 'REGEXP'              #BOOL. True if matches
                                  #* if case-insensitive

substring(STR, 'REGEXP')          #Returns first match
 ->STR2|null                      #If there is an outer set of parenthesis, return that part only
regexp_matches                    #Returns first match (or all if FLAG 'g')
 (STR, STR2[, 'FLAGS'])->ARR_SET  #If no match, empty SET
                                  #ARR are parenthesis matches (if none, single item)

regexp_replace
 (STR, 'REGEXP', STR2[, 'FLAGS'])
 ->STR3                           #Replace matches by STR2

regexp_split_to_array
 (STR, 'REGEXP'[, 'FLAGS'])       #Split STR using REGEXP delimiter.
 ->STR_ARR                        #If delimiter not found, returns {STR}
regexp_split_to_table(...)
 ->STR_SET                        #Same but as a SET


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             ENUM              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


ENUM_TYPE                         #Each enum has its own TYPE

'...'                             #ENUM_VAL_UNKNOWN

create type ENUM_TYPE
 as enum(ENUM_VAL...)             #Arguments list decides ordering

alter type ENUM_TYPE add value
 [if not exists] ENUM_VAL
 [before|after ENUM_VAL2]         #

ENUM_VAL < <= > >= ENUM_VAL2      #BOOL. Using ordering

enum_first|last(ENUM_VAL)         #First|last ENUM_VAL of the same type
 ->ENUM_VAL2                      #null::ENUM_TYPE can be used as argument
enum_range(ENUM_VAL)              #All ENUM_VALs of the same type
 ->ENUM_VAL_ARR                   #null::ENUM_TYPE can be used as argument
enum_range(ENUM_VAL, ENUM_VAL2)   #From ENUM_VAL to ENUM_VAL2
 ->ENUM_VAL_ARR                   #null::ENUM_TYPE can be used to represent start|end


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             BITS              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


BSTR                              #BIT|VARBIT

bit[(NUM)]                        #TYPE. BIT, i.e. like STR, but bit-wise
                                  #Def NUM: 1
                                  #Max NUM: 1e8
                                  #0-based indices
varbit[(NUM)]
bit varying[(NUM)]                #TYPE. VARBIT, i.e. same but variable length (unless NUM)

BIT <-> VARBIT                    #Type cast. Truncates last bits if needed.
BIT <~> INT4|8                    #Type cast. Fails if larger than max INT

B'...'                            #BIT with 0|1s
X'...'                            #BIT with hex chars

BSTR & | # << >> BSTR2            #
~BSTR                             #

get_bit(BSTR|BYTEA, UINT)->0|1    #
set_bit(BSTR|BYTEA, UINT, 0|1)
 ->BSTR|BYTEA                     #


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             BYTES             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


bytea                             #TYPE. Like BSTR but byte-wise
                                  #0-based indices

'...'                             #BYTEA_UNKNOWN, using UTF-8 endoding
'\x...'                           #If starting with \x, ... is hex only

encode(BYTEA, STR)->STR2          #Converts to format STR:
                                  #  - 'hex': hex only
                                  #  - 'escape': octal \NNN only if not [[:print:]]
                                  #  - 'base64'
decode(STR, STR2)->BYTEA          #Inverse

get_byte(BYTEA, UINT)->0-255      #
set_byte(BYTEA, UINT, 0-255)
 ->BYTEA                          #

trim(...)                         #Same as STR, but for BYTEA

md5(STR|BYTEA)->STR2              #

BYTEA|BSTR || BYTEA|BSTR
bit|octet_length(...)
overlay(...)
position(...)
substring(...)                    #Same as STR, but for BYTEA|BSTR


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:        INTEGER ARRAYS         :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


INT_ARR                          ##Not a specific type, just any one-dimensional ARR of INTs.
                                 ##All following will not work if contains null.
                                 ##1-based indices
                                 ##Postgres extension 'intarray'

INT_ARR @> INT2_ARR              ##BOOL. Is superset|equal
INT_ARR <@ INT2_ARR              ##BOOL. Is subset|equal
INT_ARR && INT2_ARR              ##BOOL. True if any INT = any INT2

query_int                        ##TYPE
QUERY_INT                        ##'INT' which can use & | ! () e.g. 'INT & !(INT2 | INT3)'
INT_ARR @@ QUERY_INT
QUERY_INT ~~ INT_ARR             ##BOOL. Whether it matches

icount(INT_ARR)->NUM             ##Number of elements, including duplicates
idx(INT_ARR, INT2)->UINT         ##Index of first element with value INT2
                                 ##0 if none

subarray(INT_ARR, INT2[, INT3])  ##Slice from INT2 (included) to INT3 (excluded, def: end)
 ->INT_ARR                       ##INT2|3 can be negative to be index from end

INT_ARR + INT2[_ARR]             ##Concatenate
INT_ARR | INT2[_ARR]             ##Concatenate. Remove duplicates and sort.
INT_ARR & INT2_ARR               ##Intersection. Remove duplicates and sort.
INT_ARR - INT2[_ARR]             ##Difference. Remove duplicates and sort.

sort(INT_ARR[, 'desc'])->INT_ARR ##
uniq(INT_ARR)->INT_ARR           ##Remove duplicates. Must be first sorted


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           DATE/TIME           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


date                              #TYPE
'YYYY-MM-DD'                      #DATE_UNKNOWN

time                              #TYPE
'HH:MM:SS[.SSSSSS]'               #TIME_UNKNOWN

timestamp                         #TYPE
'DATE TIME'                       #TIMESTAMP_UNKNOWN

TIME[TZ] <= TIMESTAMP[TZ]         #Type cast, removing DATE
DATE <=-> TIMESTAMP[TZ]           #Type cast, removing TIME or filling it with midnight

ENVVAR DateStyle                  #When reading ambiguous DATE (day is from 1 to 12), how to read it: "DMY" (def), "MDY" or "YMD"

'[-]infinity'                     #DATE|TIMESTAMP_UNKNOWN
isfinite(DATE|TIMESTAMP|INTERVAL)
 ->BOOL                           #Whether [-]Infinity

'epoch'                           #DATE|TIMESTAMP_UNKNOWN

'yesterday|today|tomorrow'        #DATE|TIMESTAMP_UNKNOWN (midnight)
'allballs'                        #TIME_UNKNOWN (midnight)

'now'                             #DATE|TIME|TIMESTAMP_UNKNOWN
current_time[stamp]|date          #Same but directly DATE|TIMETZ|TIMESTAMPTZ instead of UNKNOWN
local_time[stamp]|date            #Same but using current TZ
statement_timestamp()
 ->TIMESTAMPTZ
transaction_timestamp()
 ->TIMESTAMPTZ                    #Beginning of statement|transaction

DATE + - NUM                      #DATE
DATE - DATE2                      #NUM

DATE + - TIME                     #TIMESTAMP

extract
 (PERIOD from TIME[STAMP]|INTERVL)#PERIOD: millenium, century, decade, [iso]year, quarter, month, week, day, [iso]dow (day of week),
 ->UINT                           #doy, hour, minute, [micro|milli]seconds, timezone[_hour|minute], epoch
date_trunc('PERIOD',
 TIMESTAMP|INTERVAL[, 'TZ'])
 ->TIMESTAMP|INTERVAL             #Truncates until PERIOD

to_char(TIMESTAMP|INTERVAL, STR)  #Use format STR, e.g. 'HH24:MI:SS'
 ->STR2                           #Not documented yet
to_timestamp(STR, STR2)
 ->TIMESTAMPTZ
to_date(STR, STR2)->DATE
to_number(STR, STR2)->FLOAT       #Inverse

generate_series
 (TIMESTAMP, TIMESTAMP2, INTERVAL)
 ->TIMESTAMP_SET                  #From TIMESTAMP to TIMESTAMP2, with step INTERVAL

pg_sleep(FLOAT)                   #Sleeps FLOATS seconds
                                  #Time resolution is OS-specific, often 10ms


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          TIME ZONES           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


LOCALES ==>                       #Used, including current timezone, unless specified otherwise

timetz                            #TYPE
'TIME[TZ]'                        #TIMETZ_UNKNOWN. TZ is [GMT]-|+NUM

timestamptz                       #TYPE
'TIMESTAMP[TZ]'                   #TIMESTAMPTZ_UNKNOWN

TIME <=-> TIMETZ
TIMESTAMP <=-> TIMESTAMPTZ        #Type cast, using local TZ

TZ                                #Use either of the following ones
pg_timezone_names                 #TABLE with TZs by names (e.g. 'America/New_York') with offset and DST
pg_timezone_abbrevs               #Same but by abbreviation (e.g. 'PST')
ENVVAR timezone                   #Def: system one

TIME[STAMP][TZ] at time zone 'TZ' #TIME[STAMP]TZ


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           INTERVAL            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


interval [PERIOD [to PERIOD2]]    #TYPE
                                  #PERIOD is year|month|day|hour|minute|second (def: any)

TIME <=-> INTERVAL                #Type cast

'SS[.SSSSSS]'
'[YYYY-[MM-[DD]]]
 [HH:[MM:[SS[.SSSSS]]]]'          #INTERVAL_UNKNOWN
ENVVAR intervalstyle              #INTERVAL format among:
                                  #  - 'postgres' (def)
                                  #  - 'sql_standard'
                                  #  - 'ISO_8601'

DATE + - INTERVAL                 #TIMESTAMP
TIME[STAMP]|INTERVAL + - INTERVAL #TIME[STAMP]|INTERVAL
TIME[STAMP] - TIME[STAMP]2        #INTERVAL

INTERVAL * / NUM                  #
-INTERVAL                         #

justify_days(INTERVAL)->INTERVAL  #Modulo on days, e.g. 35 days -> 1 month 5 days
justify_hours(INTERVAL)->INTERVAL #Modulo on hours, e.g. 30 hours -> 1 day 6 hours
justify_interval
 (INTERVAL)->INTERVAL             #justify_days() + justify_hours()


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:              OID              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


oid                               #TYPE for an ID of a VAR.
                                  #Internally like an int4
                                  #32 bits, i.e. only use for uniqueness if:
                                  #  - TABLE-scoped
                                  #  - either:
                                  #     - random on <2e3 items
                                  #     - serial on <2e9 items

regproc                           #TYPE alias to OID. ID of a FUNC name
regprocedure                      #TYPE alias to OID. ID of a FUNC implementation
regoper                           #Like regproc but for OP
regoperator                       #Like regprocedure but for OP
regtype                           #TYPE alias to OID. ID of a TYPE.
regconfig                         #TYPE alias to OID. ID of a REGCONF.
regdictionary                     #TYPE alias to OID. ID of a DICTIONARY.
regcollation                      #TYPE alias to OID. ID of a COLLATION.
regnamespace                      #TYPE alias to OID. ID of a NAMESPACE.
regrole                           #TYPE alias to OID. ID of a ROLE.

INT8 <=-> OID|REG*
INT2 -> OID|REG*                  #Type cast

regclass                          #TYPE alias to OID. "TABLE" name.
VARCHAR|TEXT -> REGCLASS          #Type cast

tid                               #TYPE. ID of a ROW
xid                               #TYPE. ID of a transaction, 4 bytes
xid8                              #TYPE. ID of a transaction, 8 bytes
cid                               #TYPE. ID of a command

XID8 ~> XID                       #Type cast


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            RANDOM             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


random()->FLOAT                   #From 0 to 1
                                  #Cycle of 3e14 numbers
                                  #PRNG not crypto-secure
setseed(FLOAT)                    #FLOAT is from 0 to 1

normal_rand(INT, FLOAT, FLOAT2)  ##INT random variables following N(FLOAT, FLOAT2)
 ->INT_SET                       ##Postgres extension 'tablefunc'


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             UUID              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


uuid                             ##TYPE
                                 ##Postgres extension 'uuid-ossp'
'nnnn-nnnn-nnnn-nnnn-nnnn-
 nnnn-nnnn-nnnn'                 ##UUID_UNKNOWN. Dashes all optional

uuid_generate_v1[mc]()->UUID     ##UUID v1
                                 ##If mc, uses a random multicast MAC address
uuid_generate_v3|5               ##UUID v3|5
 (uuid_ns_*(), STR)->UUID        ##* is dns|url|oid|x500
uuid_generate_v4()->UUID         ##UUID v4


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             JSON              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


json                              #TYPE. Including scalar types.
                                  #Must be well-formed.

'JSON'                            #JSON_UNKNOWN
KEY                               #UINT|STR

JSONB ~> BOOL|NUM|STR             #Type cast. Fail if top-level value is not BOOL|NUM|STR|null

JSON->KEY                         #OBJ[KEY] as JSON2
JSON->>KEY                        #OBJ[KEY] as 'JSON2'
JSON#>KEY_ARR
JSON#>>KEY_ARR                    #Same but with multiple successive KEYs

CONVERSION ==>                    #ARR item <-> SET element
                                  #OBJ <-> ROW
                                  #OBJ key <-> COL

to_json(VAL)->JSON                #
array_to_json(ARR)->ARR_JSON      #
row_to_json(ROW)->OBJ_JSON        #

json_array_elements(ARR_JSON)->SET#Converts ARR_JSON to SET
json_array_length(ARR_JSON)->UINT #ARR.length
json_populate_record              #Converts OBJ_JSON to ROW
 (null::ROW_TYPE, OBJ_JSON)->ROW  #OBJ keys not in ROW_TYPE are omitted
json_populate_recordset
 (null::ROW_TYPE, OBJ_ARR_JSON)
 ->ROW_SET                        #Converts OBJ_ARR_JSON to ROW_SET

json_each(OBJ_JSON)->ROW_SET      #Each OBJ entry -> ROW with COLs: key STR, value JSON
json_each_text(OBJ_JSON)->ROW_SET #Same but value COL is STR
json_object_keys(OBJ_JSON)
 ->STR_SET                        #Each OBJ key -> STR


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:              XML              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


xml                               #TYPE. Not documented yet

STR ~> XML                        #Type cast

'XML'                             #XML_UNKNOWN

xmlparse(document|content STR)    #Must be well-formed.
 ->XML                            #content: for fragments
xmlserialize(document|content XML
 as [var]char|text)->STR          #
enum_first|last(ENUM_VAL)         #First|last ENUM_VAL of the same type
 ->ENUM_VAL2                      #null::ENUM_TYPE can be used as argument


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            HSTORE             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


hstore                           ##TYPE. OBJ where keys are identifiers
                                 ##Postgres extension 'hstore'
VAL                              ##'VAL'|null

STR ~> HSTORE                    ##Type cast, using 'KEY=>VAL,...'

'KEY=>VAL,...'                   ##HSTORE_UNKNOWN
                                 ##"" to escape KEY|VAL for whitespace , = >
hstore(['KEY', VAL]_ARR)->HSTORE ##
hstore(['KEY', VAL, ...])->HSTORE##
hstore('KEY'_ARR, VAL_ARR)
 ->HSTORE                        ##

HSTORE->'KEY'                    ##VAL
HSTORE->'KEY'_ARR                ##VAL_ARR

HSTORE ? 'KEY'                   ##BOOL. True if HSTORE->'KEY' exists
defined(HSTORE, 'KEY')->BOOL     ##True if HSTORE->'KEY' exists and is not null
HSTORE ?& 'KEY'_ARR              ##BOOL. True if all of HSTORE->'KEY' exists
HSTORE ?| 'KEY'_ARR              ##BOOL. True if any of HSTORE->'KEY' exists

HSTORE @> HSTORE2                ##BOOL. HSTORE is superset of HSTORE2 (including equal)
HSTORE <@ HSTORE2                ##BOOL. Same with subset (or equal)

akeys(HSTORE)->'KEY'_ARR         ##
avals(HSTORE)->VAL_ARR           ##
%# HSTORE                        ##['KEY', VAL]_ARR
%% HSTORE                        ##['KEY', VAL, ...]

HSTORE || HSTORE2                ##Merge. HSTORE2 has priority
HSTORE - HSTORE2                 ##Substract. Only for HSTORE2 entries with same key + value
HSTORE - 'KEY'[_ARR]             ##Substract.
slice(HSTORE, 'KEY'_ARR)->HSTORE2##Pick.
                                 ##If 'KEY' not found, ignored.

hstore(ROW)->HSTORE              ##Using COL names as KEYs
ROW #= HSTORE                    ##ROW2. Set ROW values using HSTORE

skeys(HSTORE)->'KEY'_SET
svals(HSTORE)->VAL_SET           ##Same as akeys|avals() but as SET
each(HSTORE)->ROW_SET            ##With COLs: key STR, value STR

HSTORE ~> JSON[B]                ##Type cast, similar to hstore_to_json()
hstore_to_json(HSTORE)->OBJ_JSON ##OBJ values are all STR|null
hstore_to_json_loose(HSTORE)
 ->OBJ_JSON                      ##Same but OBJ values can also be NUM or BOOL (with VAL 't|f')


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             LTREE             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


ltree                            ##TYPE. Array of VAR representing a reference
                                 ##0-based indices
                                 ##Postgres extension 'ltree'

'VAR.VAR2....'                   ##LTREE_UNKNOWN
                                 ##VAR is [[:alpha:]_], max 256 characters.
                                 ##Max 65e3 VARs
                                 ##Can be empty ''

LTREE < <= >= > LTREE2           ##Compare first VAR, then second, etc.
                                 ##Missing VAR is less

LTREE @> LTREE2                  ##BOOL. Is parent of equal.
LTREE <@ LTREE2                  ##BOOL. Is child of equal.
LTREE_ARR @> <@ LTREE2
LTREE @> <@ LTREE2_ARR           ##BOOL. Same but "any of"
LTREE_ARR ?@> ?<@ LTREE2         ##LTREE|null. First LTREE that @> <@ LTREE2

LTREE || LTREE2                  ##LTREE3. Concatenate as 'LTREE.LTREE2'

nlevel(LTREE)->UINT              ##Number of VARs

index(LTREE, LTREE2[, INT])      ##If LTREE2 is inside LTREE, indice of VAR where it starts
 ->INT2                          ##Otherwise, returns -1
                                 ##Ignore first INT VARs (def: 0).
                                 ##INT can be negative to specify from end

subltree(LTREE, UINT, UINT2)
 ->LTREE2                        ##Sliced from VAR at index UINT (included) to UINT2 (excluded)
subpath(LTREE, INT[, INT2])      ##Same but:
 ->LTREE                         ##  - negative INT[2] is indice from the end
                                 ##  - otherwise INT2 is number of VARs (def: all)

lca(LTREE_ARR)->LTREE2
lca(LTREE...)->LTREE2            ##Common prefix ('' if none)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            LQUERY             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


lquery                           ##TYPE. Globbing-like query against a LTREE (full match)

'VAR.VAR2...'                    ##LQUERY_UNKNOWN.
                                 ##Same syntax as LTREE with following additional one.
*                                ##Any multiple VARs
*{[NUM],[NUM2]}                  ##NUM (def: 0) to NUM2 (def: any) multiple VARs
VAR*                             ##Any suffix
VAR%                             ##Matches _-separated parts
VAR@                             ##Case insensitive
VAR|VAR2                         ##Or
!VAR                             ##Not

LTREE[_ARR] ~ LQUERY
LQUERY ~ LTREE[_ARR]             ##BOOL. Whether [any] LTREE fully matches LQUERY
LTREE[_ARR] ? LQUERY_ARR
LQUERY_ARR ? LTREE[_ARR]         ##BOOL. Whether [any] LTREE fully matches any LQUERY

LTREE_ARR ?~ LQUERY              ##LTREE|null. First LTREE that ~ LQUERY


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           LTXTQUERY           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


ltxtquery                        ##TYPE. Like lquery but partial match

'...'                            ##LTXTQUERY_UNKNOWN
                                 ##Single VAR. Also following syntax.
VAR*
VAR%
VAR@
VAR | VAR2
!VAR                             ##Like LQUERY
VAR & VAR2                       ##And

LTREE[_ARR] @ LTXTQUERY
LTXTQUERY @ LTREE[_ARR]          ##BOOL. Whether [any] LTREE partially matches LTXTQUERY

LTREE_ARR ?@ LTXTQUERY           ##LTREE|null. First LTREE that @ LTXTQUERY


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             INET              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


inet                              #TYPE
'IPv4|6'                          #INET_UNKNOWN

cidr                              #TYPE
'CIDR'                            #CIDR_UNKNOWN

INET|CIDR => STR                  #Type cast
INET => CIDR                      #Type cast

INET >> >>= << <<= INET2          #Containing|contained within [or equal]

INET | & INET2
~INET                             #Bitwise operations

INET + - INET|UINT                #From last to first field.

family(INET)->4|6                 #

network(INET)->CIDR               #
host(INET)->'INET'                #Remove CIDR mask

masklen(INET)->UINT               #NUM of bits of network mask
set_masklen(INET|CIDR, UINT)
 ->INET|CIRD                      #Sets network mask
netmask(INET)->INET2              #Subnet mask
hostmask(INET)->INET2             #Cisco wildcard

broadcast(INET)->INET2            #Broadcast IP

text(INET)->STR                   #Serialize in a long way
abbrev(INET|CIDR)->STR            #Serialize in a short way


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:              MAC              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


macaddr                           #TYPE
'NN:NN:NN:NN:NN:NN'               #MACADDR_UNKNOWN

macaddr8                          #TYPE
'NN:NN:NN:NN:NN:NN:NN:NN'         #MACADDR8_UNKNOWN

MACADDR <-> MACADDR8              #Type cast

MACADDR[8] | & MACADDR[8]2
~MACADDR[8]                       #Bitwise operations

trunc(MACADDR[8])->MACADDR[8]     #Put second half as 00


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           GEOMETRY            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


point                             #TYPE
'(NUM,NUM2)'                      #POINT_UNKNOWN

line                              #TYPE. Infinite LINE
'((NUM,NUM2),(NUM3,NUM4))'        #LINE_UNKNOWN
'{NUM,NUM2,NUM3}'                 #LINE_UNKNOWN as NUMx + NUM2y + NUM3

lseg                              #TYPE. Segment LINE
'((NUM,NUM2),(NUM3,NUM4))'        #LSEG_UNKNOWN

box                               #TYPE. Rectangle.
'((NUM,NUM2),(NUM3,NUM4))'        #BOX_UNKNOWN (diagonal)

path                              #TYPE
polygon                           #TYPE. Like closed PATH
'((NUM,NUM2)...)'                 #Closed PATH_UNKNOWN
'[(NUM,NUM2)...]'                 #Open PATH_UNKNOWN

circle                            #TYPE
'<(NUM,NUM2),NUM3>'               #CIRCLE_UNKNOWN

POINT <~ LSEG <~ BOX
 <~> CIRCLE <~> POLYGON           #Type casts
POINT => BOX
BOX => POLYGON
PATH <=> POLYGON                  #Type casts

cube                             ##TYPE. N-dimensional cube
                                 ##Postgres extension 'cube'
'(NUM...), (NUM2...)'            ##CUBE_UNKNOWN diagonal

GEOMETRY OPERATORS ==>            #Many operators for shift, rotation, scaling, getting points|distance like center, positions, etc. exist
                                  #Including for cube
                                  #Not documented yet


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             RANGE             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


RANGE ==>                         #Like an ARR of size 2 indicating start and end.

int4range                         #RANGE TYPE of INT4
int8range                         #RANGE TYPE of INT8
numrange                          #RANGE TYPE of NUMERIC
daterange                         #RANGE TYPE of DATE
ts[tz]range                       #RANGE TYPE of TIMESTAMP[TZ]

create type TYPE as range(OPTS)   #New RANGE TYPE.
OPTS.subtype                      #TYPE of start|end
OPTS.subtypediff                  #FUNC(VAL, VAL2)->UINT, computing distance
OPTS.canonical                    #FUNC2(VAL)->VAL (def: noop) transforming each VAL
OPTS.subtype_opclass              #OPCLASS
OPTS.collation                    #COLLATION
OPTS.multirange_type_name         #'TYPE' of MULTIRANGE
                                  #Def: replace 'range' by 'multirange', or append '_multirange'

'[VAL, VAL2]'
'[VAL, VAL2)'                     #RANGE_UNKNOWN. Square brackets include, parenthesis exclude.
'(VAL, VAL2]'                     #Def VAL[2]: null
'(VAL, VAL2)'                     #If TYPE is discrete, VAL2] is normalized to VAL2+1)
RANGE_TYPE(VAL, VAL2[, STR])
 ->RANGE                          #Same. STR is e.g. '[)' (def) or '()'

null                              #Like [-]Infinity
lower|upper_inf(RANGE)->BOOL      #Whether null

'empty'                           #Empty RANGE. VAL[2] are both null, but not handled like Infinity
isempty(RANGE)->BOOL              #

lower|upper(RANGE)->VAL[2]        #
lower|upper_inc(RANGE)->BOOL      #Whether [] or ()

RANGE @> VAL|RANGE2               #BOOL. Is superset|equal
VAL|RANGE <@ RANGE2               #BOOL. Is subset|equal
RANGE && RANGE2                   #BOOL. Whether overlaps

RANGE << RANGE2                   #BOOL. Whether RANGE end before RANGE2 start
RANGE >> RANGE2                   #Same as RANGE2 << RANGE
RANGE &< RANGE2                   #BOOL. Whether RANGE start before RANGE2 start, and RANGE end before RANGE2 end
RANGE &> RANGE2                   #Same as RANGE2 &< RANGE
RANGE -|- RANGE2                  #BOOL. Whether RANGE end adjacent to RANGE2

RANGE + RANGE2                    #RANGE3. Union. Must overlap or be contiguous.
range_merge(RANGE, RANGE2)->RANGE3#Union. If does not overlap nor contiguous, fill the gap.
RANGE - RANGE2                    #[RANGE.begin, RANGE2.begin]
                                  #If RANGE2.begin < RANGE.begin:
                                  #  - if RANGE2.end > RANGE.end, returns [RANGE.begin, RANGE.end]
                                  #  - otherwise returns empty
RANGE * RANGE2                    #RANGE3. Intersection. Empty if none.


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          MULTIRANGE           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


MULTIRANGE ==>                    #Combination of multiple RANGEs
                                  #Behaves like a RANGE with potential gaps
                                  #If RANGEs overlapped, normalized by being merged

int4multirange
int8multirange
nummultirange
datemultirange
ts[tz]multirange                  #MULTIRANGE TYPEs

RANGE ~> MULTIRANGE               #Type cast

'{RANGE,...}'                     #MULTIRANGE_UNKNOWN
MULTIRANGE_TYPE([RANGE,...])
 ->MULTIRANGE                     #Same

OPERATORS ==>                     #All FUNCs and operators for RANGE work with MULTIRANGE too
                                  #Can mix RANGE and MULTIRANGE arguments, except for + - *

range_merge(MULTIRANGE)->RANGE    #Convert to single RANGE, filling any gap
multirange(RANGE)->MULTIRANGE     #Inverse

unnest(MULTIRANGE)->RANGE_SET     #


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             ARRAY             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


array                             #TYPE2 with 0-n values of same TYPE
TYPE[]                            #Dimensions are defined at write-time.
                                  #Underlying TYPE can be another ARR for multidimensional ARRs.
                                  #1-based indices
                                  #Max length 1.3e8

array[VAL...]                     #ARR literal value.
'{VAL,...}'                       #ARR_UNKNOWN
'[UINT[:UINT2]]...={VAL,...}'     #Same but with specific:
                                  #  - lower bound UINT (included)
                                  #     - def: 0
                                  #  - upper bound UINT2 (included)
                                  #     - def: UINT
                                  #     - must be UINT + ARR.length - 1, i.e. cannot truncate|extend
                                  #One [...] per dimension

ARR[UINT]                         #VAL. null if out-of-bound.
ARR[UINT:UINT2]                   #ARR2, from UINT (included) to UINT2 (included)
                                  #Uses max(UINT2, ARR.length)
                                  #Empty if UINT2 < UINT, or if UINT > ARR.length
ARR[UINT:]                        #Same as ARR[UINT:ARR.length]
ARR[:UINT2]                       #Same as ARR[0:UINT2]

ARR = <> ARR2                     #BOOL. Done deeply
                                  #null can be compared, and is different from missing item
ARR < <= > >= ARR2                #BOOL, with first item compared first, etc.
                                  #Missing item < present item < null

VAL OP any|all (ARR)              #BOOL. Whether VAL OP any|all ARR item

ARR @> ARR2                       #BOOL. Is superset|equal
ARR <@ ARR2                       #BOOL. Is subset|equal
ARR && ARR2                       #BOOL. Overlaps, i.e. at least one item equal

array_ndims(ARR)->UINT|null       #NUM of dimensions. null if empty ARR
array_dims(ARR)->'[UINT:UINT2]...'#Each dimensions lower|upper bound
generate_subscripts(ARR, UINT3)
 ->[UINT, UINT2]_SET              #Dimension UINT3 lower|upper bound
array_lower(ARR, UINT3)->UINT     #Dimension UINT3 lower bound
array_upper(ARR, UINT3)->UINT2    #Dimension UINT3 upper bound
array_length(ARR, UINT3)->UINT    #array_upper - array_lower

ARR || VAL
VAL || ARR
array_append(ARR, VAL)->ARR       #Append
ARR || ARR2
array_cat(ARR, ARR2)->ARR         #Concatenates

array(SSUBQUERY)->ARR             #
unnest(ARR)->SET                  #Flattens ARR and returns as SET

array_to_string                   #Cast each ARR item to STR, then join with 'DELIM'.
 (ARR[, 'DELIM'[, 'NULL']])->STR  #If 'NULL' specified, nulls are transformed to it. Otherwise, they are ignored.
string_to_array                   #Inverse
 (STR, 'DELIM'|null[, 'NULL'])    #If DELIM is null, split each character.
 ->ARR                            #If DELIM is '', returns STR as ARR with single item

array_fill                        #ARR where all values are VAL
 (VAL, UINT_ARR[, UINT_ARR2])->ARR#Number of dimensions is UINT_ARR[2].length
                                  #UINT_ARR are upper bounds, UINT_ARR2 lower bounds (def: {1,...})

array_remove(ARR, VAL)->ARR       #Filter out any element = VAL
                                  #ARR must be one-dimensional
array_replace(ARR, VAL, VAL2)->ARR#Same but replace with VAL2


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:              ROW              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


ROW_TYPE                          #Conceptually like an OBJ
                                  #Also called "composed type" or "ctype"
                                  #Max 1600 COLs
                                  #Max size:
                                  #  - after TOAST: 400GB
                                  #  - before TOAST: 8KB
record                            #TYPE of any ROW_TYPE

ROW                               #ROW_TYPE value
COL                               #"Column", i.e. ROW property
                                  #Ordered
                                  #Named. Can have duplicate names
                                  #  - e.g. select 1 as a, 2 as a;
                                  #  - but (ROW)."COL" fails

create type "ROW"
 as ("COL" TYPE,...)              #Create a new ROW_TYPE

alter type "ROW"
 add attribute "COL" TYPE
 [restrict|cascade]               #cascade or restrict (def): when "ROW" is a "TABLE", whether to modify the "TABLE" too
alter type "ROW"
 drop attribute
 [if exists] "COL" TYPE
 [restrict|cascade]               #
alter type "ROW"
 alter attribute "COL" type TYPE
 [restrict|cascade]               #
alter type "ROW"
 rename attribute "COL" to "COL2"
 [restrict|cascade]               #

[row](VAL,...)                    #ROW
                                  #COL names: fNUM
                                  #"row" is necessary only if only one VAL
'(VAL,...)'                       #Same as ROW_UNKNOWN
                                  #Can cast to ROW_TYPE but not to record

(ROW)."COL"
"COL"(ROW)                        #VAL

ROW = <> ROW2                     #BOOL. Done deeply
                                  #Must have same amount of COLs, but names do not need to match
ROW < <= > >= ROW2                #BOOL, with first COL compared first, etc.


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:              SET              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


SET                               #Like ARR except operations|FUNCs automatically iterate over each item
                                  #Always top-level
SCALAR                            #Opposite of SET

SCALAR_FUNC(SET)->SET             #Iterates over SET items
SCALAR_FUNC(SET, SCALAR)->SET     #Same but repeats SCALAR
                                  #If SCALAR is returned by a FUNC(), re-evaluate it each time
SCALAR_FUNC(SET, SET2)->SET       #Same but fills smaller SET with nulls

SET_FUNC(SCALAR)                  #Fails

SCALAR_OP SET
SET SCALAR_OP SCALAR
SET SCALAR_OP SET2
SET_OP SCALAR                     #Same with operators
select SET ...
select SET, SCALAR ...
select SET, SET2 ...              #`select VAL,...` behaves like SCALAR_FUNC


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           SUBQUERY            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


SUBQUERY                          #ROW_SET that is the result of a select, values, table or execute statement
                                  #I.e. not returned by a FUNC()
                                  #Can only be used when explicitly documented as such
SSUBQUERY                         #SUBQUERY returning a single COL
ZSUBQUERY                         #SUBQUERY returning a single COL + ROW

REXPR                             #Expression which:
                                  #  - is evaluated once per ROW
                                  #     - except if it does not reference the ROW
                                  #  - can refer to the ROW
                                  #Can also use any (ZSUBQUERY), with same ROW behavior

exists(SUBQUERY)->BOOL            #Whether SUBQUERY has at least one ROW
                                  #Since SUBQUERY values are not used, `select 1 ...` is often used

ROW OP any|all SUBQUERY           #BOOL. Whether ROW OP any|all SUBQUERY_ROW
ROW [not] in SUBQUERY             #Same as ROW =|<> any SUBQUERY


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:       USER-DEFINED TYPE       :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


create domain TYPE as TYPE2       #Creates a user-defined TYPE, interchangeable with TYPE2, but with following.
 [default VAL]                    #Default VAL (def: null) (can be: default)
 [not null]                       #
 [check(BOOL_REXPR)]              #
 [constraint "CONSTRAINT"]        #"CONSTRAINT" is name only.
                                  #BOOL_CONSTRAINT can use "value", which refers to the values used.

alter domain TYPE set default VAL #
alter domain TYPE
 set|drop not null                #
alter domain TYPE add
 [not null]
 [check(BOOL_REXPR)]
 [constraint "CONSTRAINT"]        #
 [not valid]                      #Like alter table ... not valid
alter domain TYPE drop constraint
 [if exists] "CONSTRAINT"
 [restrict|cascade]               #
alter domain TYPE
 rename constraint
 "CONSTRAINT" to "CONSTRAINT2"    #

create type TYPE(OPTS)            #Creates user-defined TYPE, based on C functions
                                  #Not documented yet
OPTS.input                        #FUNC
OPTS.ouput                        #FUNC2


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            ENTITY             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


ENTITY                            #Entity that can be created with `create ENTITY ...`
                                  #E.g. table, collation, function, etc.

"ENTITY"                          #Notation depends on entity. It can be one of the following.
VAR,...                           #For most ENTITYs
VAR                               #For access method, collation, conversion, database, event trigger, language,
                                  #subscription, tablespace, text search *
VAR(...),...                      #For aggregate, function, procedure
VAR(TYPE|none, TYPE2|none),...    #For operator
(TYPE as TYPE2)                   #For cast
VAR on "TABLE"                    #For policy, trigger, rule
VAR using INDEX_METHOD            #For operator class|family
for TYPE language LANG            #For transform
for ROLE server SERVER            #For user mapping
                                  #ROLE can be user, current_role, current_user, public

alter ENTITY ... "ENTITY" ...     #Sets ENTITY options after creation
                                  #Not for ENTITY: access method, cast, transform

alter ENTITY "ENTITY"             #Rename an ENTITY.
 rename to "VAR"                  #Not for ENTITY: extension, operator, user mapping

create or replace ENTITY ...      #If "ENTITY" already exists, drop it first.
                                  #For ENTITY:
                                  #  - view, rule, trigger
                                  #  - aggregate, function, procedure
                                  #  - language, transform
create ENTITY if not exists ...   #If "ENTITY" already exists, noop but no error
                                  #For ENTITY: collation, extension, foreign table, index, materialized view, schema,
                                  #sequence, server, statistics, table, user mapping
alter ENTITY if exists ...        #Fail if "ENTITY" does not exist
                                  #For ENTITY: foreign table, index, materialized view, sequence, table, view

create ENTITY ... with (OPTS)     #Common syntax found in multiple ENTITYs
                                  #If OPTS.VAR VAL optional, then also optional in alter ...
                                  #When present the following are available too
alter ENTITY ... set (OPTS)       #Sets OPTS after creation
alter ENTITY ...                  #Sets OPTS to default value
 reset (OPTS.VAR,...)             #Not with ENTITY: publication|subscription

drop ENTITY                       #Delete an ENTITY
 [if exists]                      #Unless set, fails if exists
 "ENTITY"
 [restrict|cascade]               #If there are dependent objects
                                  #  - 'restrict' (def): fail
                                  #  - 'cascade':
                                  #     - drop them, recursively
                                  #     - not allowed for database|tablespace|role|user mapping
                                  #Dependent objects removed even with 'restrict':
                                  #  - database: pg_catalog.* entries
                                  #  - extension: pg_catalog.* entries, routine, table column
                                  #  - table column: constraint, SEQUENCE, index, rule, trigger
                                  #Set TABLESPACE2 of all ENTITYs in a given TABLESPACE
                                  #For ENTITY: table, materialized view, index
                                  #  - role: role membership
                                  #  - operator family: operator class
                                  #Dependent objects removed with 'cascade':
                                  #  - schema: objects in the SCHEMA
                                  #  - table: foreign key constraint
                                  #  - aggregate, [foreign] table, operator, [materialized] view: [materialized] view
                                  #  - access method, operator class|family, text search configuration: index
                                  #  - type, domain: table column
                                  #  - ROW_TYPE: table using `of "ROW_TYPE"`
                                  #  - type, language: function, operator
                                  #  - function: operator, trigger
                                  #  - access method: operator class|family
                                  #  - foreign data wrapper: foreign table, server
                                  #  - server: user mapping
                                  #  - text search dictionary|parser: text search configuration
                                  #  - text search template: text search dictionary


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             TABLE             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


TABLE                             #ROW_SET with a known ROW_TYPE, that is persisted
                                  #Max 32TB total
                                  #Unlimited ROWs
                                  #Max 1e9 per DATABASE

"TABLE"                           #Can be used as ROW_TYPE value
                                  #  - CONSTRAINTs are stripped
                                  #But not as a:
                                  #  - "ROW_TYPE" variable
                                  #  - ROW[_SET] value

create [temp|unlogged]
 table "TABLE"
 [of "ROW_TYPE"]
 (COL_ARG,...)
 [inherits ("PARENT_TABLE",...)]
 [with (OPTS)]
 [on commit ACTION]
 [tablespace TABLESPACE]
 [as SUBQUERY [with [no] data]]   #Creates a TABLE

exclude ... with (OPTS)
unique ... with (OPTS)
primary key ... with (OPTS)       #Same as create ... with (OPTS) but on CONSTRAINT's underlying INDEX

create table ... of "ROW_TYPE"    #ROW_TYPE of (COL_ARG,...)
                                  #"COL" TYPE ... -> "COL" [with options] ...
                                  #  - with options: noop
                                  #Cannot use: inherits, like "TABLE|ROW_TYPE", compression, collate
alter table "TABLE"
 [not] of "ROW_TYPE"              #

create table ...                  #Populates values with SUBQUERY
 as SUBQUERY                      #(COL_ARG,...):
                                  #  - only "COL"
                                  #  - optional
                                  #Cannot use:
                                  #  - of "ROW_TYPE"
                                  #  - inherits
                                  #  - partition by
                                  #  - if not exists
 [with [no] data]                 #Whether to copy values (def) or only ROW_TYPE

select VALS,...                   #Same as `select ...` but creates "TABLE" instead of returning ROW_SET
 into [table] "TABLE" ...         #Prefer `create table as SUBQUERY` as it has more features and is more standard

create table ... with (OPTS)
alter table ... set (OPTS)        #Same OPTS


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          CONSTRAINT           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


CONSTRAINT                        #Condition validating udpates, and making them fail if false
COL_CONSTRAINT                    #Single-COL CONSTRAINT

alter table "TABLE" add COL_ARG   #
 [not valid]                      #Validate CONSTRAINT only on-demand when calling: alter table ... validate constraint ...
alter table "TABLE"
 validate constraint "CONSTRAINT" #

"COL" TYPE [COL_CONSTRAINT...]    #COL_ARG. Define a new COL
alter table "TABLE"
 add column "COL" TYPE ...        #
alter table "TABLE"
 rename [column] "COL" to "COL2"  #
alter table "TABLE"
 alter [column] "COL"
 [set data] type TYPE             #
 [using VAL]                      #VAL used when casting (def: COL value)
alter table "TABLE"
 drop [column] [if exists] "COL"
 [restrict|cascade]               #

check(BOOL_REXPR) ...
unique("COL",...) ...
primary key("COL",...) ...
foreign key("COL",...) references
 "TABLE"("COL2",...) ...          #COL_ARG. Multicolumn CONSTRAINTs

check(BOOL_REXPR)                 #COL_CONSTRAINT. Fails if BOOL false.
                                  #Def "CONSTRAINT" name: "TABLE_COL_check"

[not] null                        #COL_CONSTRAINT
                                  #Same as check("COL" [is] not null)
alter table "TABLE"
 alter [column] "COL"
 set|drop not null                #

exclude                           #COL_ARG
 ("COL"|(REXPR) with OP,...)      #Fails if NEW_ROW."COL" OP ANY_CURRENT_ROW2."COL"
                                  #Can also use REXPR
                                  #OP must be commutative
                                  #Creates a CONSTRAINT "TABLE_COL_excl"
                                  #Creates a btree INDEX
                                  #  - with same name as "CONSTRAINT"
 [where (BOOL_REXPR)]             #Do not fail new ROW if BOOL false

unique                            #COL_CONSTRAINT. Same as exclude("COL" with =)
                                  #I.e. fails if any duplicate value.
                                  #Def "CONSTRAINT" name: "TABLE_COL_key"

primary key                       #COL_CONSTRAINT.
                                  #Same as unique + not null
                                  #Only one per TABLE
                                  #Def "CONSTRAINT" name: "TABLE_pkey"

references "TABLE2"[("COL2")]     #COL_CONSTRAINT. "Foreign key"
                                  #Ensure every COL value references a COL2 value (but not inverse)
                                  #On added|removed|updated values. On both COL|COL2.
                                  #COL2 must be `unique`
                                  #Def COL2: TABLE2 primary key
                                  #Def "CONSTRAINT" name: "TABLE_COL_fkey"
 [match full|simple]              #See null section
 [on delete ACTION]               #When removing COL2 values, do ACTION:
                                  #  - no action (def): fails, deferrable
                                  #  - restrict: fails, not deferrable
                                  #  - set default ["COL",...]: set COL values (def: all) to default
                                  #  - set null ["COL,"...]: set COL values (def: all) to null
                                  #  - cascade: remove COL values too
 [on update ACTION]               #Same but when updating COL2 values
                                  #Cannot specify "COL",... with set default|null

default VAL                       #COL_CONSTRAINT. Value when omitted on insertion.
                                  #VAL is evaluated at insertion time.
alter table "TABLE"
 alter [column] "COL"
 set default VAL                  #
alter table "TABLE"
 alter [column] "COL"
 drop default                     #

generated always as (VAL) stored  #COL_CONSTRAINT. "Generated COL". Value on insertion.
                                  #Readonly on write
                                  #  - but can use `default`
                                  #VAL is evaluated at insertion time.
                                  #Can refer to other non-generated "COL"s of same "TABLE"
                                  #VAL must be purely functional

constraint "CONSTRAINT" COL_ARG   #Assign "CONSTRAINT" name
                                  #Not with: like "TABLE|ROW_TYPE"
alter table "TABLE"
 rename constraint "CONSTRAINT"
 to "CONSTRAINT2"                 #
alter table "TABLE"
 drop constraint [if exists]
 "CONSTRAINT" [restrict|cascade]  #


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          INHERITANCE          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


like "TABLE|ROW_TYPE"             #COL_ARG. Copy (not inherit) the ROW_TYPE as COLs.
                                  #Always copied: COL TYPE, not null
                                  #Never copied: references, where BOOL_REXPR
 [including COL_INFO]...          #Also copy COL_INFO:
                                  #  - defaults: default VAL
                                  #  - indexes: INDEX, primary key, unique, exclude
                                  #  - constraints: check(BOOL_REXPR)
                                  #  - storage: with (OPTS)
                                  #  - generated: generated COL
                                  #  - identity: identity COL
                                  #  - compression
                                  #  - statistics: STATISTICS
                                  #  - comments: comment on ... for COL|INDEX|CONSTRAINT
                                  #  - all: of the above
 [excluding COL_INFO]...          #Do not copy COL_INFO. Only useful when using: including all

create table ...                  #Any "PARENT_TABLE" targets also children
 inherits ("PARENT_TABLE",...)    #  - unless `only "PARENT_TABLE"` is used
                                  #     - can use "PARENT_TABLE*" to do the opposite, but it is default behavior
                                  #  - for most commands using "TABLE", except reindex, vacuum, etc.
                                  #  - can use "TABLE".tableoid to distinguish parent vs child
                                  #TABLE inherits:
                                  #  - COLs of PARENT_TABLE
                                  #     - but keeps its own COLs
                                  #  - not null
                                  #  - check(BOOL_REXPR)
                                  #     - unless using: check(BOOL_REXPR) no inherit
                                  #Does not inherit:
                                  #  - unique
                                  #  - primary key
                                  #  - foreign key
                                  #     - references "TABLE" implicitly means "only (TABLE)"
                                  #  - indexes
                                  #  - rules, triggers
                                  #I.e. this is mostly not useful
alter table "TABLE"
 [no] inherit "PARENT_TABLE"      #


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             VIEW              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


create view "VIEW" as SUBQUERY    #VIEW forward statements to SUBQUERY
                                  #Goal: encapsulation
                                  #Readonly if SUBQUERY uses:
                                  #  - select VAL that is not select "COL"
                                  #  - join
                                  #  - distinct
                                  #  - group by
                                  #  - limit|offset
                                  #  - union|intersect|except
                                  #  - top-level with
                                  #  - with (security_barrier)

create view "VIEW"(COL,...) ...   #Change "COL" names. Omitted COLs keep their names.
alter view "VIEW"
 rename [column] "COL" to "COL2"  #

alter view "VIEW"
 alter [column] "COL"
 drop|set default [VAL]           #Add a `default` CONSTRAINT, forwarded to underlying SUBQUERY

create view "VIEW"
 [with (OPTS)] ...                #
 [with (security_barrier)]        #Ensure ROWs are not securely hidden when using `where BOOL_REXPR`
                                  #Cover channel attacks are still possible
                                  #  - using explain query plans, time of queries, etc.
                                  #  - e.g. to infer size of hidden rows

create recursive view ...         #Allows recursion like in `with recursive ...` CTE


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:       MATERIALIZED VIEW       :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


create materialized view "TABLE"  #Readonly TABLE that is populated on-demand via a SUBQUERY
 [("COL",...)]                    #Like create view ...
 [with (OPTS)]                    #Like create table ...
 as SUBQUERY                      #

refresh materialized view "TABLE" #Re-populates TABLE

create|refresh
 materialized view "TABLE"
 [with [no] data]                 #with data (def): populate at creation time
                                  #with no data: truncate and cannot query until next refresh materialized view

alter materialized view "TABLE"
 rename [column] "COL" to "COL2"
alter materialized view "TABLE"
 alter [column] "COL" set
 statistics|storage|compression
 ...
alter materialized view "TABLE"
 [alter [column] "COL"]
 set (...)
alter materialized view "TABLE"
 [alter [column] "COL"]
 reset (...)
alter materialized view "TABLE"
 cluster on "INDEX"
alter materialized view "TABLE"
 set without cluster
alter materialized view "TABLE"
 set access method ...            #Same as alter table ...


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           TEMPORARY           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


create temp[orary] table ...      #Drop TABLE at end of session
select ...                        #No autovacuum, but can manually run analyze
 into temp[orary] [table] ...     #SCHEMA will be `pg_temp_NUM`
 [on commit ACTION]               #At the end of each successful transaction:
                                  #  - preserve rows (def): nothing
                                  #  - delete rows: truncate TABLE
                                  #  - drop: drop TABLE
ENVVAR temp_buffers               #Max buffers increment size used (def: 8MB)

create temp[orary] view ...       #Drop VIEW at end of session

create temp[orary] sequence ...   #Drop SEQUENCE at end of session
                                  #Can't use any SCHEMA


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           SEQUENCE            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


SEQUENCE                          #TABLE storing a streaming INT algorithm
SEQUENCE.last_value               #INT (def: not set)
SEQUENCE.is_called                #BOOL. Whether setval|nextval() has been called

'"SEQUENCE"'                      #Can be used instead of 'SEQUENCE' to quote the following.
setval('SEQUENCE', INT[, BOOL])   #Sets SEQUENCE.last_value and is_called (def: true)
nextval('SEQUENCE')->INT          #Generates and returns new SEQUENCE.last_value
currval('SEQUENCE')->INT          #Returns SEQUENCE.last_value. Fails if setval|nextval() not called yet
lastval()->INT                    #Previous SEQUENCE.last_value of last SEQUENCE called. Fails if none.

create sequence "SEQUENCE"
 [as int2|4|8]                    #INT TYPE
 [increment [by] INT]             #Def: 1. Added by each nextval()
 [no min|maxvalue]
 [min|maxvalue INT]               #Def: 1 and max value for INT TYPE
 [start [with] INT]               #Def: 1. First value
 [cache INT]                      #Def: 1. Cache next values in advance.
                                  #Cached values are used even if setval() is called
                                  #If >1, concurrent calls to setval|nextval() might jump some values (but still get unique ones)
 [[no] cycle]                     #When reaching maxvalue:
                                  #  - cycle: set to minvalue
                                  #  - no cycle (def): fail
 [owned by none]
 [owned by "TABLE"."COL"]         #Make dropping COL also drop SEQUENCE

alter sequence "SEQUENCE" ...     #Same syntax as create sequence ...
 [restart [with] INT]             #Like setval()

"COL" [small|big]serial           #COL_ARG with:
 COL_CONSTRAINT...                #  - TYPE int2|4|8
                                  #  - default nextval('SEQUENCE')
                                  #  - not null
                                  #"SEQUENCE" is named 'TABLE_COL_seq'

generated always|by default       #COL_CONSTRAINT. "Identity COL". Same as "COL" *serial, with additional features.
 as identity                      #COL TYPE must be int2|4|8.
                                  #nextval() is used:
                                  #  - `by default`: as default VAL
                                  #  - `always`: as `generated` VAL, i.e. readonly except when setting `default`
 [(...)]                          #Passed to `create sequence "SEQUENCE" ...`

insert into ...(...)
 overriding system value          #Make `generated always` behave like `generated by default` instead
 overriding user value            #Make `generated by default` behave like `generated always` instead
                                  #Except: inserted VALs are ignored instead of failing


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            SELECT             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


select
[distinct ...]
[VAL,...]
[from ...]
[where ...]
[group by ...]
[having ...]
[union|intersect|except ...]...
[order by ...]
[limit ...]
[offset ...]                      #Order: from, where, select non-AFUNC, group by, having, select AFUNC,
[fetch ...]                       #distinct, union|intersect|except, order, offset, limit|fetch

select VAL[_SET],...              #Evaluates VALs and returns them as a ROW_SET
                                  #Each VAL[_SET] is returned as a different COL
                                  #  - select VAL,...: multiple COLs
                                  #  - select ROW: single COL with a ROW TYPE
select REXPR,...                  #Can be used
select                            #If no VAL[_SET],..., returned ROWs have 0 COLs
                                  #Does not change how many ROWs are returned

select VAL[_SET]                  #"COL_ALIAS" is COL name in:
 [[as] "COL_ALIAS"],...           #  - return value
                                  #  - REXPR
                                  #Def (in priority):
                                  #  - "FCOL_ALIAS"
                                  #  - "COL" name
                                  #  - "FUNC" name
                                  #  - "?column?"
COL_REXPR                         #REXPR which is often just "COL"
                                  #Can use 1-based COL_INDEX UINT too

values (VAL,...),...              #Evaluates VALs and returns them as a ROW_SET
                                  #Each (VAL,...) is a ROW
                                  #All ROWs must have same TYPE, including number of COLs
                                  #"COL" name: "columnNUM"
                                  #VAL cannot be a SET
                                  #VAL can use (ZSUBQUERY)s
 [order by ...]
 [asc|desc|using OP]
 [limit ...]
 [offset ...]
 [fetch ...]                      #Same as select ...

table "TABLE"                     #Same as select * from "TABLE"

insert|update|delete ...          #Make statement return `select VAL,...` using inserted|updated|deleted ROWs as source
 returning VAL,...                #Can use `[as] COL_ALIAS`
MSUBQUERY                         #Means either a SUBQUERY or a `... returning VAL,...` (which cannot be used as SUBQUERY otherwise)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             FROM              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


select ... from ROW_SET           #Evaluates once per ROW:
                                  #  - select VAL,...
                                  #  - REXPR
                                  #If select VAL,... results in a SET itself, do cartesian product
                                  #ROW_SET must be returned by a FUNC()
select ... from NON_SET           #Converts non-SETs to single-ROW SETs
select ... from NON_ROW_SET       #Converts non-ROWs to single-COL ROWs
                                  #By default, COL name is same as "ROW_ALIAS"

select ...                        #Uses SUBQUERY's ROW_SET return value
 from [lateral] (SUBQUERY)        #Only evaluated once
                                  #  - unless SUBQUERY uses a "ROW_ALIAS" from a previous FROM

select ... from "TABLE"           #Same as as `from (table "TABLE") as "TABLE"`

select ... from FROM              #Name of each ROW to use in:
 [[as] "ROW_ALIAS",...]           #  - REXPR
                                  #  - any next `from FROM`
                                  #(SUBQUERY) can use "ROW_ALIAS" defined by a previous FROM, but:
                                  #  - not in its own `from ...`
                                  #  - must specify `lateral`
                                  #  - i.e. will behave as a REXPR
                                  #Parent query cannot use "ROW_ALIAS" defined by a (SUBQUERY)
                                  #Def: FUNC(...) name
                                  #Required with `from (SUBQUERY)`
["ROW_ALIAS".]"COL"               #COL
                                  #"ROW_ALIAS" can be omitted if there is a single "COL" named like this among all FROMs
["ROW_ALIAS".]*                   #Same as ["ROW_ALIAS".]"COL", ["ROW_ALIAS".]"COL2", ...
                                  #Only in `select VALs`

select ... [as]                   #Rename "ROW_ALIAS"."COL"
 "ROW_ALIAS"("FCOL_ALIAS",...)    #Omitted ones are not renamed

select ... from ROW_SET [as]
 "ROWALIAS"("FCOL_ALIAS" TYPE,...)
select ... from ROW_SET as
 ("FCOL_ALIAS" TYPE,...)          #Define ROW_TYPE
select ... from                   #Each COL must be defined
 rows from(ROW_SET,... as         #Not with `from (SUBQUERY)` nor `from "TABLE"`
 ("FCOL_ALIAS" TYPE,...))         #If `with ordinality`, `rows from(...)` must be used

select ... from ROW_SET
 with ordinality
select ... from rows from(...)    #Concatenates a COL named "ordinality"
 with ordinality                  #Its values is a bigserial starting with 1


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            FILTER             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


select ... where BOOL_REXPR       #Returns no ROWs if BOOL is false
                                  #Conceptually like select ..., BOOL where:
                                  #  - BOOL COL is not returned
                                  #  - ROWs with BOOL false are not returned

select all|distinct ...           #If `distinct`, ignores any ROW if any previous ROW2 is =
 [on (COL_REXPR,...)]             #Computes the values used to compare

select ... from "TABLE"
 tablesample SAMPLE_METHOD(...)   #Removes ROWs randomly
 tablesample bernoulli(0-100)     #Percentage of ROWs to keep
                                  #Percentage is only average over multiple runs
                                  #Probability is applied ROW-wise, i.e. more precise with high number of ROWs
 tablesample system(0-100)        #Same but applied on groups of multiple ROWs at a time
                                  #I.e. faster, but much less precise
 [repeatable FLOAT]               #Random seed (def: different one for each call)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             SORT              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


select ... order by COL_REXPR     #Sort ROWs
                                  #COL_REXPR is the sort value
                                  #  - if union|intersect|except used, can only be "COL"|COL_INDEX
                                  #Unless used, ROWs are unordered
                                  #  - including union|intersect|except result
 [asc|desc|using OP]              #Sorting order (def: asc)
                                  #Can be a comparator OP, e.g. < is like asc, > is like desc
 [nulls first|last]               #Def: nulls first for desc, nulls last for asc

select ... order by ...,...       #Multiple sort values


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             SLICE             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


select ... offset UINT [row[s]]   #Ignores first UINT rows

select ... limit UINT|all
select ...                        #Only returns first UINT rows, after `offset` applied
 fetch first [UINT] row[s] only   #Def UINT: 1
select ...                        #Returns any following ROW if:
 fetch ... row[s] with ties       #  - its COLs targeted by `order by`
                                  #  - are = than the previous ROW
select ... fetch next ...         #Same as: select ... fetch first ...


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           JOIN ROWS           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


select ... union SUBQUERY         #Concatenates ROWs of `select ...` and SUBQUERY
                                  #They must have the same ROW TYPEs
                                  #SUBQUERY "COL" names are not used
                                  #order by, offset, limit:
                                  #  - applied on the merged result
                                  #  - to apply on only SUBQUERY, use parenthesis around it

select ... intersect SUBQUERY     #Same as union, but only keeps ROWs that are = between `select ...` and SUBQUERY

select ... except SUBQUERY        #Same as union, but only removes ROWs that are = between `select ...` and SUBQUERY

select ...                        #Can be done multiple times
 [union|intersect|except ...]...  #Processed left-to-right, except intersect which have priority

select ... union|intersect|except
 distinct|all SUBQUERY            #If "distinct" (def), removes duplicate rows on merged result


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:         JOIN COLUMNS          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


select ...                        #Concatenates COLs of each ROW_SET
 from rows from(ROW_SET,...)      #Smaller ROW_SETs are filled with nulls

select ... from FROM, FROM2
select ... from FROM              #Concatenates COLs of FROM and FROM2
 cross join FROM2                 #ROWs are cartesian product of FROM and FROM2
select ... from FROM
 [inner] join FROM2
 on BOOL_REXPR                    #Like `cross join` but ignores ROWs where BOOL is false

select ... from FROM              #Like `cross join` but:
 left [outer] join FROM2          #  - if a FROM ROW has BOOL false with every FROM2 ROW
 on BOOL_REXPR                    #  - it is kept as a single ROW, with nulls in FROM2 COLs
select ... from FROM
 right [outer] join FROM2
 on BOOL_REXPR                    #Like `left join` but with FROM2 ROWs instead
select ... from FROM
 full [outer] join FROM2
 on BOOL_REXPR                    #Like `left join` + `right join`

select ... from FROM              #Same as: on "ROW_ALIAS"."COL" = "ROW_ALIAS2"."COL" [and ...]
 [...] join FROM2 using("COL",...)#Also merges "ROW_ALIAS"[2]."COL" to a single COL
 [as "ROW_ALIAS3"]                #"ROW_ALIAS3" contains only the "COL",...
select ... from FROM
 natural [...] join FROM2         #Same as `using("COL",...)` with "COL" common between FROM and FROM2

SELF JOIN ==>                     #Using twice the same FROM


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            INSERT             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


insert into "TABLE"[("COL",...)]  #Adds ROWs to "TABLE" using SUBQUERY's ROW_SET return value
 SUBQUERY                         #SUBQUERY must match ("COL",...) arity and TYPEs
                                  #Def ("COL",...): all COLs

default                           #Default VAL, or null
                                  #Can be used within `values(...)` as SUBQUERY
                                  #Also used on missing values if:
                                  #  - ("COL",...): does not pick every "COL"
                                  #  - no ("COL",...): SUBQUERY shorter than amount of COLs
insert into "TABLE" default values#Single ROW with (default,...)

insert into "TABLE"               #Name of each ROW to use in other parts of insert ..., except SUBQUERY
 [as "ROW_ALIAS"] ...             #Def: "TABLE"

insert ... on conflict ...        #Configure behavior when inserted VAL fails an unique or exclude() CONSTRAINT
insert ... on conflict do nothing #Ignore ROW, instead of failing
insert ...                        #Updates current ROW instead of inserting a new one
 on conflict do update set ARG,...#ARG is same syntax as update ... set ARG,...
                                  #Can be used to upsert
                                  #If new VALs still fail, do not repeat
                                  #Can use `excluded` as a "ROW_ALIAS" for the VALs being inserted
                                  #Only with unique CONSTRAINT, not `exclude()`
insert ...
 on conflict do update set ...
 where BOOL_REXPR                 #If false, ignore ROW instead

on conflict                       #Only apply for a specific unique|exclude CONSTRAINT
 on constraint "CONSTRAINT" ...   #Required when using `on conflict do update set`
on conflict ("COL",...)           #Same as `on constraint` but targeting CONSTRAINT through its COLs
on conflict (...)                 #Same as `on constraint` but targeting CONSTRAINT through its underlying INDEX
                                  #(...) is same `create index "INDEX"(...)`
                                  #  - including `(...) where BOOL_REXPR` for partial INDEXs


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            UPDATE             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


update "TABLE" set                #Set values of current ROWs
 "COL" = VAL,...                  #Other COLs are kept as is
                                  #VAL can be `default`
                                  #VAL is evaludated once per ROW
 ("COL",...) = [row](VAL,...),... #`row` is required if only one COL
 ("COL",...) = (SUBQUERY),...     #SUBQUERY must return either:
                                  #  - a single ROW
                                  #  - no ROWs: converted to a ROW filled with nulls

update "TABLE" [as] "ROW_ALIAS"   #Name of each current ROW
 ...                              #To use in other parts of `update ...`, including in (SUBQUERY)
                                  #Def: "TABLE"
["ROW_ALIAS".]"COL"               #Like `select ...`

update ... from FROM,...          #Allows using FROMs inside other parts of update ...
                                  #Same syntax as `select ... from FROM,...`
                                  #`where BOOL_REXPR` is called with cross-join, i.e. each TABLE_ROW + FROMS_ROW
                                  #For any given TABLE_ROW, if `where BOOL_REXPR` filters in:
                                  #  - 0 ROW: no update is done
                                  #  - 1 ROW: `set ...` can use filtered FROMS_ROW
                                  #  - >1 ROWs: `set ...` uses an unspecified filtered FROMS_ROW (to avoid)

update ... where BOOL_REXPR       #Only sets values on ROWs with BOOL true


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            DELETE             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


delete from "TABLE"
[[as] "ROW_ALIAS"]
[using FROM,...]                  #Same as `update ...` but deleting ROWs instead
[where BOOL_REXPR]                #Def BOOL_REXPR: true, i.e. delete all ROWs


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           TRUNCATE            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


truncate table "TABLE",...        #Delete all ROWs
                                  #Faster and more vacuum-friendly than `delete from` with no `where BOOL_REXPR`
[restart|continue identity]       #If `restart` (def: `continue`): call `alter sequence "SEQUENCE" restart`
[restrict|cascade]                #If `cascade` (def: `restrict`): truncates any "TABLE2" depending on "TABLE" too
                                  #  - e.g. due to foreign keys


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:    COMMON TABLE EXPRESSION    :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


with                              #"CTE". Same as: ... from (MSUBQUERY) as "ROW_ALIAS"[("FCOL_ALIAS",...)]
 "ROW_ALIAS"[("FCOL_ALIAS",...)]  #Except:
 as (MSUBQUERY)                   #  - MSUBQUERY, not just SUBQUERY
 ... from "ROW_ALIAS" ...         #  - evaluates MSUBQUERY once when used multiple times
                                  #  - simpler to read
                                  #The main COMMAND can be select|table|values, insert|update|delete or merge
                                  #MSUBQUERY can use `with ...` itself, but only with `select` sub-MSUBQUERYs

with "ROW_ALIAS" ... as (...),    #Can use multiple ones
  "ROW_ALIAS2" ... as (...), ...  #"ROW_ALIAS" can be used inside the next MSUBQUERYs

with recursive ...                #Allow using "ROW_ALIAS" inside its own MSUBQUERY.
                                  #MSUBQUERY must be:
                                  #  select ... union select ... from "ROW_ALIAS" ... where BOOL_REXPR
                                  #Recursion happens bottom-up:
                                  #  - first recursion skips `union ...`
                                  #  - next recursions are repeated until `union ...` returns no ROWs
                                  #     - usually when BOOL_REXPR false for all ROWs


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             COPY              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


copy (MSUBQUERY) to SOURCE        #Export TABLE to a SOURCE. Append ROWs
copy "TABLE"[("COL",...)]         #SOURCE can be:
 to SOURCE                        #  - 'ABSOLUTE_PATH'
                                  #  - stdout
                                  #  - program 'PROGRAM'
                                  #     - piped to stdin
                                  #     - use current shell
                                  #Only export data, not schema (including TYPEs)
                                  #"TABLE" cannot be "VIEW", but TABLE can be (table "VIEW")
 [where BOOL_REXPR]               #Filter ROWs to export

copy "TABLE"[("COL",...)]         #Import SOURCE to a TABLE. Append ROWs
 from SOURCE                      #SOURCE can be:
                                  #  - 'RELATIVE|ABSOLUTE_PATH'
                                  #     - relative to server's process CWD
                                  #  - stdin
                                  #  - program 'PROGRAM'
                                  #     - using its stdout
                                  #     - use current shell

copy ... with ZOPTS               #
ZOPTS.format                      #Can be:
                                  #  - 'text' (def):
                                  #     - DSV
                                  #     - EOF is line can be '\.'
                                  #     - can use \b \f \n \r \t \v \\ \NNN \xNN \DELIM \NULL
                                  #  - 'csv'
                                  #  - 'binary': Postgres-specific binary format
                                  #TYPEs:
                                  #  - text|csv: serialize to STR
                                  #     - except BOOL, serialized to t|f
                                  #  - binary:
                                  #     - preserve most TYPEs
                                  #     - but cast some TYPEs close to each other, e.g. money|int8 or bpchar|varchar|text

ZOPTS.encoding                    #'ENCODING' (def: client_encoding)
ZOPTS.freeze                      #BOOL (def: false). Do a `vacuum freeze` first

TEXT|CSV ONLY ==>
ZOPTS.delimiter                   #'CHAR'. COL delimiter
                                  #Def: '\t' (text) or ',' (csv)
ZOPTS.null                        #STR used for null values
                                  #Def: '\N' (text) or '' (csv)

CSV ONLY ==>                      #
ZOPTS.header                      #BOOL (def: false) or match.
                                  #Make first CSV row the "COL" names
                                  #If `match` (only with `copy from`), fail if CSV header does not match "COL" names
ZOPTS.quote                       #'CHAR' (def '"')
ZOPTS.escape                      #'CHAR' (def: '\')
ZOPTS.force_quote ("COL",...)|*   #Always quote specific COLs (except null values)
                                  #Only with `copy to`
ZOPTS.force_not_null ("COL",...)  #Cast nulls as STR, in specific COLs
                                  #Only with `copy from`
ZOPTS.force_null ("COL",...)      #Never cast nulls as STR, even if quoted, in specific COLs
                                  #Only with `copy from`

ENVVAR DateStyle                  #Should be set to 'ISO'
ENVVAR IntervalStyle              #Should not be set to 'sql_standard'


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           AGGREGATE           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


select ... group by COL_REXPR,... #Group ROWs that are equal by all of COL_REXPR,...
                                  #Each ROW_SET group is reduced to a single ROW
                                  #If a COL uses AFUNC(), it:
                                  #  - reduces ROW_SET into a SCALAR
                                  #  - cannot be targeted by a COL_REXPR
                                  #Some COLs cannot be reduced:
                                  #  - if neither:
                                  #     - uses COL_REXPR, or a superset of it
                                  #        - e.g. if COL_REXPR is `a * 2`, using `a * 2 + 1`
                                  #     - uses AFUNC()
                                  #     - "functional dependency", i.e. a COL_REXPR:
                                  #        - is a "COL"
                                  #        - that is a primary key
                                  #        - of the same "TABLE"
                                  #  - then:
                                  #     - cannot use any "ROW_ALIAS"[."COL"]
                                  #     - all those COLs are computed in a single separate ROW_SET, combined with a cartesian product
                                  #If no `group by`, AFUNC() operates on all ROWs as a single group

select ... having BOOL_REXPR      #Like `where BOOL_REXPR` except:
                                  #  - after `group by`
                                  #  - can use AFUNC()

grouping sets, cube, rollup???
See SELECT reference ???

AFUNC(SET, ...)->SCALAR           #"Aggregate function". Reduce a SET to a SCALAR
                                  #If SCALAR is passed as argument, it is handled like a SET with a single item.
                                  #Must be used inside a REXPR.
                                  #Unless specified, ignore nulls

AFUNC(distinct ...)               #Ignore duplicate SET values
AFUNC(... order by ...)           #Sort SET. Same syntax as `select ...`

*_agg(...)                        #Does not ignore nulls
array_agg(SET)->ARR               #AFUNC. Converts to ARR
json[b]_agg(SET)->ARR_JSON[B]     #AFUNC. Converts to ARR_JSON[B]
json[b]_object_agg
 ('KEY'_SET, VAL_SET)->OBJ_JSON[B]#AFUNC. Converts to OBJ_JSON[B]
xml_agg(SET)->XML                 #AFUNC. Converts to XML
string_agg
 (STR_SET, DELIM_STR|BYTEA)
 ->STR|BYTEA                      #AFUNC. Converts to STR|BYTEA

count(SET)->UINT                  #AFUNC. Number of values, excluding nulls
count(*)->UINT                    #AFUNC. Number of values, including nulls

min|max(SET)->VAL                 #AFUNC
sum(NUM|INTERVAL_SET)
 ->NUM|INTERVAL                   #AFUNC
avg(NUM|INTERVAL_SET)
 ->NUM|INTERVAL                   #AFUNC

bit_and|or|xor(INT|BIT_SET)
 ->INT|BIT                        #AFUNC. Bitwise and|or|xor
bool_or(BOOL_SET)->BOOL           #AFUNC. BOOL or
bool_and|every(BOOL_SET)->BOOL    #AFUNC. BOOL and

range_agg
 ([MULTI]RANGE_SET)->[MULTI]RANGE #AFUNC. Union
range_intersect_agg
 ([MULTI]RANGE_SET)->[MULTI]RANGE #AFUNC. Intersection

corr(COL, COL)                    #r
regr_r2(COL, COL2)                #r₂
stddev|var|covar_pop_samp
 (COL, COL2)                      #Standard deviation, variance, covariance, / (n-1) or /n
regr_count(COL, COL2)             #Exclude row with one null
regr_avgx|y(COL, COL2)            #sum(VAL[2]/regr_count(VAL, VAL2))
regr_intercept|slope
(VAL|TABLE, VAL|TABLE2)           #
regr_sxx|syy|sxy                  #In order:
(VAL|TABLE, VAL|TABLE2)           #  - sxx: sum(VAL^2) - sum(VAL)^2/regr_count(VAL, VAL2)
                                  #  - syy: sum(VAL2^2) - sum(VAL2)^2/regr_count(VAL, VAL2)
                                  #  - sxy: sum(VAL*VAL2) - sum(VAL)*sum(VAL2)/regr_count(VAL, VAL2)

create aggregate AFUNC            #Creates an AFUNC(COL,...):
(TYPE...) (sfunc = FUNC,          #  - TYPE are type of each COL.
stype = TYPE2                     #  - each VAL... of each COL is passed inside successive FUNC(VAL2, VAL...)
[, finalfunc = FUNC2]             #     - VAL2 is the return value of the last FUNC(), and its type is TYPE2
[, initcond = STR]                #     - its value in the first FUNC() is TYPE2 STR (typecasting from STR) (def: null)
)                                 #  - last FUNC can be different if FUNC2(VAL2) is defined: takes only one ARG, and can return any type.
                                  #  - last VAL2 is returned
                                  #  - by convention, null should be ignored in FUNC, unless there are only null, where null should be
                                  #    returned


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            WINDOW             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


See again `select ...` documentation for full syntax???

AFUNC (COL) over                  #Window function WFUNC:
([partition by "COL"]             #  - the whole expression returns a COL of length n (not 1)
 [order by ...]                   #  - for each element, AFUNC() is fired on a moving WINDOW, for each COL group. Groups are defined as:
 [rows|range between              #     - if "partition by": according to identical VAL in "COL"
 WORD and WORD2])                 #     - if no "partition by":
                                  #        - if "order by": same, but each group also include previous groups
                                  #        - if no "order by": only one group
                                  #  - WINDOW is:
                                  #     - inside each group, between WORD and WORD2, which can be:
                                  #        - unbounded|VAL preceding|following
                                  #        - current row: according to current element
                                  #     - def is between unbounded preceding and unbounded following, which means AFUNC() is applied on
                                  #       the whole group each time
                                  #     - if there is a group of identical VAL..., current row means:
                                  #        - if range: for each VAL, the first one for WORD, and the last one for WORD2
                                  #        - if rows: for each VAL, that VAL
                                  #  - the output is sorted by COL2, inside each group
                                  #WFUNC are performed after AFUNC, and AFUNC after all the later clauses (e.g. BOOL).
                                  #To include a former in a later, use a command substitution, e.g. instead of AFUNC(COL):
                                  #  (select AFUNC(COL) [from COL])
AFUNC([COL]) over WINDOW,         #If multiple AFUNCs in a statement use the same WINDOW, it can use an alias WINDOW, then put a later
AFUNC2([TABLE2]) over WINDOW ...  #clause, as: window WINDOW as (...)

WFUNC-SPECIFIC AFUNCs
 ==>                              #
row_number()                      #Index inside WINDOW
cume_dist()                       #Row number inside WINDOW, divided by number of rows for the group
first|last_value("COL")           #Returns first|last element of the WINDOW
nth_value("COL", UINT)            #Returns element number UINT of the WINDOW (null if not existing)
lag|lead("COL", UINT[, VAL])      #Returns the element UINT times before|after in the WINDOW (VAL (def: null) if not existing)
rank()                            #Numeral rank, according to "order by", inside WINDOW
dense_rank()                      #Same but if equal value, equal rank too
percent_rank()                    #Same but from 0 to 1
ntile(UINT)                       #Returns 1..UINT, starting from lower to upper value, with equal (if possible) number of values in
                                  #each 1..UINT (buckets)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           FUNCTIONS           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


create [or replace]               #Creates a user-defined function, that can used anywhere.
function FUNC([[VAR]              #  - or replace: if already existing, will be overwritten (fails if different types)
TYPE [default VAL]...])           #  - arguments:
returns TYPE2                     #    - VAL is the default value
as 'STR'                          #    - TYPE can be any but also:
language LANG                     #      - ROW|TABLE:
[window] [immutable|              #        - TABLE are converted to ROW
stable|volatile]                  #        - calling FUNC(TABLE) needs a reference to "TABLE". Examples:
[leakproof] [strict]              #           - select FUNC(TABLE) from "TABLE"
[security                         #           - select * from "TABLE", FUNC(TABLE)
invoker|definer]                  #        - FUNC("TABLE"|"ROW") can also be called "TABLE"|"ROW".FUNC, so it is unwise to name FUNC same
[cost FLOAT]                      #          as a member of "TABLE"|"ROW"
[rows UINT]                       #      - record:
                                  #        - like ROW of any*
                                  #      - pseudo-type:
                                  #        - any[element|[non]array|enum|range]:
                                  #          - polymorphic types.
                                  #          - Must be all of the same type (args and return value), for a specific call.
                                  #          - anyarray|range must have same type as other any*
                                  #          - if return value is polymorphic, at least one arg must be too.
                                  #          - $0 is a VAR with the polymorphic type, initialized to null.
                                  #            Can be used to store return value or do computations.
                                  #        - cstring (null-terminated, for C only)
                                  #    - variadic ARG (must be ARR):
                                  #      - elements of ARR must then be of same TYPE
                                  #      - can fire it with FUNC(..., variadic ARR) or FUNC(..., ...)
                                  #      - is not optional by default, needs to add e.g. variadic VAR TYPE default array[]::TYPE[]
                                  #    - overloading is possible. If multiple choice of casting, the pg_type.typeispreferred is used.
                                  #    - can call by name: FUNC(VAR := VAL)
                                  #  - return value:
                                  #    - always returns a TABLE (TYPE actually means TABLE_TYPE_VAL)
                                  #    - returns first row only, unless setof TYPE is used
                                  #    - can also be in the function args instead of returns ...:
                                  #      - as out ARG...:
                                  #        - ARG... can be assigned inside FUNC instead of the usual way to return a value
                                  #          (in language that permits assigning to VAR, e.g. not SQL but PL/SQL)
                                  #        - if several ARG...:
                                  #          - returns as a multicolumn TABLE in a from clause
                                  #          - otherwise, returns as one ROW
                                  #        - to return more than first row, put also returns setof TYPE (record if several ARG...)
                                  #      - inout ARG is same as ARG out ARG (both ARG and return value)
                                  #    - TYPE2 is like TYPE, but can also be:
                                  #      - void: if no return value
                                  #      - "ROW"|"TABLE" or table(COL TYPE ...): like specifying several out ARG...
                                  #      - record: FUNC must be called with FUNC(...) as [ALIAS]("COL" TYPE ...) to precise types of
                                  #        RECORD
                                  #  - VAR%type: TYPE of a VAR, including "TABLE"."COL". Can be a VAR from the FUNC too
                                  #    (but not for an ARG from another ARG)
                                  #  - body:
                                  #     - STR. Better to use $$...$$ notation
                                  #  - can be written in different LANG (see below):
                                  #     - SQL
                                  #     - pl*: procedural languages, faster than SQL functions, among:
                                  #       - already in PostgreSQL (just need create extension pl*)
                                  #         - plpgsql
                                  #         - plpython
                                  #         - plperl
                                  #         - pltcl
                                  #     - C, faster than pl*
                                  #     - internal:
                                  #       - builtins functions. Can only refer to them by putting the C function name in the body STR
                                  #       - possible (only) use: renaming
                                  #       - actually C functions, but compiled in (not loaded with a shared library)
                                  #  - window:
                                  #     - means it is a WFUNC (only in C and some PL/*)
                                  #       As such, it passes some extra arguments about the current window.
                                  #  - immutable|stable|volatile: used for performance optimization. Can be:
                                  #     - immutable: doesn't read|write global state (including the database or the pg_catalog.*)
                                  #     - stable: doesn't write global state
                                  #     - volatile (def): write|read global state
                                  #  - leakproof: used for performance and security optimization. Means it is immutable, and
                                  #    doesn't give informations about arguments VAL aside from return value (e.g. does not throw errors
                                  #    for some return values but not others, prints arguments VAL, etc.)
                                  #  - strict:
                                  #     - returns automatically null if an arg is null.
                                  #     - for VARIADIC arg, only works if whole VARIADIC is null, not only part of it.
                                  #  - privilege are the ones of:
                                  #      - security invoker (def): the caller
                                  #      - security definer: the user creating the FUNC. Forbids using set role.
                                  #        Should also define function-specific ENVVAR search_path by adding a temporary SCHEMA at the
                                  #        end (to avoid malicious VAR shadowing)
                                  #  - cost FLOAT: CPU cost for the planner (cpu_operation_cost) (def: 1 for C FUNC, 100 for others)
                                  #  - rows UINT: average number of rows returned, for the planner (def: 1000). Only if return value
                                  #    returns several rows.
alter function FUNC(...)
...                               #... is any of the options after language LANG. Can use not leakproof.

alter routine VAR(...)            #Like alter function ... except works also on AFUNC and PROCEDURE
                                  #Cannot use:
                                  #  - called on null input, returns null on null input, strict
                                  #  - support FUNC
drop routine VAR(...),...         #Like drop function ... except works also on AFUNC and PROCEDURE

do [language LANGUAGE]
STR                               #Execute an anonymous function STR (body of function), from LANGUAGE (def: plpgsql)

create [constraint]               #Execute a FUNC for a specific EVENT on "TABLE" or VIEW.
trigger TFUNC                     #Multiple TFUNC are fired alphabetically.
before|after|instead              #  - EVENT can be insert|delete|truncate, or update [of "COL"...]
of EVENT [or EVENT2...]           #    "COL"... means "COL" or "COL2", etc.
on "TABLE"|VIEW [from TABLE2]     #    Truncate only on before|after and on "TABLE".
[for each row]                    #  - before|after|instead of is for the constraint checking + the operation itself (row-wise).
[when (BOOL)]                     #    So before fired even if constraint fails, but not after.
execute procedure FUNC(STR...)    #    If COMMAND is the one triggering EVENT "for each row":
                                  #       - before|instead of are executed row-wise according to COMMAND (so next rows in TFUNC see
                                  #         changes of previous rows by COMMAND)
                                  #       - after is executed table-wise according to COMMAND (so rows in TFUNC see changes of all rows
                                  #         by COMMAND)
                                  #    before|instead of are executed on all rows
                                  #    instead of can only be on VIEW and cannot use when BOOL. Usually used to modify the underlying
                                  #    "TABLE" so users can modify VIEW.
                                  #    Can also use or EVENT2...
                                  #  - FUNC: any language (e.g. PL/* or C) but not SQL. See doc about TFUNC for those languages.
                                  #    Must take no arguments (arguments are passed with special variables) and with a trigger return
                                  #    type, but actually returning:
                                  #     - "before" + "for each row":
                                  #        - null: skip further TFUNC and cancel statement (for that row)
                                  #        - "ROW"|"TABLE" with same structure as new|old (including them):
                                  #          - modified row: modify new and return it.
                                  #          - unmodified row: return old|new according to the operation
                                  #     - otherwise: return null
                                  #  - for each row: fired for each manipulated row (not fired if no manipulated row), and not once for
                                  #    all rows.
                                  #    Necessary for constraint trigger and instead of.
                                  #    Impossible on non-truncate VIEW.
                                  #  - constraint: makes it possible to:
                                  #     - change not deferrable, etc. with set constraints TFUNC deferred|immediate (def: immediate)
                                  #     - use not deferrable, etc. (same as for CONSTRAINT).
                                  #    Must be "after" and "for each row".
                                  #    Can be used to simulate a constraint, in which case an exception should be raised.
                                  #    Can also use set constraints to fire trigger at specific point during current transaction.
                                  #  - when (BOOL):
                                  #     - can use old|new like trigger functions
                                  #     - BOOL cannot be a subquery.
                                  #A TFUNC can fire another one ("cascading triggers"), including recursively.
                                  #Can see current TFUNC depth with pg_trigger_depth()
                                 ##To create a TFUNC notifying of each modification:
                                 ##  - triggered_change_notification([STR]) is a function to use to do notify STR, for each row,
                                 ##    after insert and/or update and/or delete, with payload explaining the modification.
                                 ##  - Postgres extension 'tcn'
create event trigger              #Like TFUNC but EVENT can be DDL not DML:
EFUNC on EVENT                    #  - ddl_command_start|end: before|after a create, alter or drop (except for cluster-wide objects
[when tag in (STR...)]            #    and TFUNC|EFUNC)
execute procedure FUNC()          #  - sql_drop: same but only for drop
                                  #     - FUNC() can use pg_event_trigger_dropped_objects() which returns a TABLE with one row for
                                  #       each dropped objects and COL...:
                                  #        - classid: DATABASE OID
                                  #        - objid: object OID
                                  #        - objsubid: e.g. for columns the attnum
                                  #        - object_type STR
                                  #        - schema_name STR
                                  #        - object_name STR
                                  #        - object_identity STR: SCHEMA.OBJECT name
                                  #STR... are commands (e.g. 'drop table') to filter EFUNC.
                                  #FUNC must return have an event_trigger return type, and takes no arguments.
                                  #Must be superuser.
alter event trigger
disable|enable
[replica|always]                  #
alter table "TABLE"               #all|user:
enable|disable                    #  - not for RULE
[replica|always]                  #  - same but all include system TRIGGER (enforcing CONSTRAINT), not user
rule|trigger                      #replica|always:
RULE|TRIGGER|all|user             #  - def: affects only non-replication sessions (ENVVAR session_replication_role "origin" (def) or
                                  #    "local")
                                  #  - replica: affects only replication sessions (session_replication_role "replica")
                                  #  - always: affects all sessions

create [or replace]               #Creates a macro that modifies a command matching EVENT into COMMANDS (add or replace according to
rule RULE as on EVENT             #"instead"), for "TABLE", when BOOL:
to "TABLE" [where BOOL]           #  - EVENT:
do [instead] COMMANDS             #     - select|insert|update|delete
                                  #     - select must be "instead", non-"where BOOL" and with select COMMAND
                                  #       (similar to create a VIEW)
                                  #  - BOOL:
                                  #     - can refer to old|new."COL" (like triggers)
                                  #COMMANDS:
                                  #  - nothing: with "instead", original EVENT is dropped
                                  #  - COMMAND or (COMMAND;...):
                                  #     - Must be select|insert|update|delete|notify.
                                  #     - For insert, the original EVENT is performed before COMMAND, for others after.
                                  #     - "instead" non-"where BOOL" COMMAND insert|update|delete must be MSUBQUERY
                                  #       so that calling command can use returning itself.
                                  #When to use rules:
                                  #  - VIEW are better than RULE with select EVENT.
                                  #  - rules are similar to TFUNC, often faster but harder and less flexible.
                                  #    Prefer triggers unless performance is critical, in which case check if actually faster.

create operator OP                #Creates an OP, i.e. a FUNC using a sign. Can have one or two arguments.
(left|rightarg = TYPE,            #Can be an already existing OP, with different TYPE (overloading)
procedure = FUNC                  #OP is [+-*/<>=~!##%^&|`?]+
[, commutator = OP2]              #Other args are for optimization (hints the planner in rewriting queries so they match an INDEX):
[, negator = OP3]                 #  - OP2 if VAL OP VAL2 is equivalent to VAL2 OP2 VAL
[, restrict = FUNC2]              #  - OP3 if VAL OP VAL2 is equivalent to not VAL2 OP3 VAL, or OP VAL to not OP3 VAL
[, join = FUNC3]                  #  - FUNC2 tells when using VAL OP VAL2 (returning BOOL), how much portion of the COL is likely to be chosen.
[hashes]                          #    Can choose among default ones:
                                  #      - eqsel: chooses a small portion, like =
                                  #      - neqsel: large portion, like <>
                                  #      - scalar[l|g]tsel: semi-large portion before or after, like < <= or > >=
                                  #  - FUNC3 is like FUNC2 but for VAL OP VAL2. Default ones:
                                  #      - eqjoinsel: like =
                                  #      - neqjoinsel: like <>
                                  #      - scalar[l|g]tjoinsel: like < <= or > >=
                                  #      - areajoinsel: like BOX operators
                                  #      - positionjoinsel: like POINT operators
                                  #      - contjoinsel: like <@ @>
                                  #  - hashes: VAL OP VAL2 is true if hash(VAL) = hash(VAL2)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:      FUNCTIONS LANGUAGES      :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


SQL FUNCTIONS ==>                 #  - execute SQL statements, returns the last one:
                                  #    - a MSUBQUERY
                                  #    - or returns void
                                  #  - either VAR or $NUM is used to refer to ARG...
                                  #    - if VAR is a COL in the current statement, use "TABLE".VAR (for the COL) or FUNC.VAR (for the VAR)
                                  #    - are readonly
                                  #  - some forbidden COMMAND: transactions blocks, vacuum, etc.

PL/PGSQL ==>                      #PL/PGSQL ends with ; but structure have only one ; at end of the structure.
                                  #Arguments:
                                  #  - if VAR is a COL in the current statement, use "TABLE".VAR (for the COL), LABEL.VAR (for a VAR
                                  #    declared in a block LABEL) or FUNC.VAR (for an argument)
                                  #"TABLE" (including COLs) must have same types accross executions because of caching. Solutions:
                                  #  - using RECORD instead of "ROW"|"TABLE"
                                  #  - using execute STR (doesn't cache)
MSUBQUERY ==>                     #In PL/PGSQL, also implies execute MSUBQUERY

<<LABEL>>                         #Scope block. Main function must be in a scope block. Variables are local to the block.
[declare                          #VAR must all be declared, as VAR [constant] TYPE [not null] [default VAL];...
  DECLARATIONS...]                #exception ... catches exceptions:
begin                             #  - EXCEPTION is either:
  STATEMENTS...                   #     - exception word (see appendix online or error messages) or "others" meaning any other exception.
[exception                        #     - SQLSTATE, i.e. an error code NUM typecasted to sqlstate: sqlstate '...'
  when EXCEPTION then ...         #  - can use the local variables when the exception happened.
  ...]                            #  - can use special variables sqlstate (current SQLSTATE) and sqlerrm (error message STR)
end [LABEL]                       #  - get stacked diagnostics VAR = WORD2 ... assigns to VAR2 according to WORD2 among:
                                  #     - returned_sqlstate: like sqlstate
                                  #     - message_text: like sqlerrm
                                  #     - column|constaint|pg_datatype|table|schema_name: column|...|schema raising the exception
                                  #     - pg_exception_detail|hint: extra error messages
                                  #     - pg_exception_context: call stack
                                  #Is also a transaction block, with exceptions rollbacking the transaction.
raise [LEVEL]                     #Raises an exception.
[using VAR = STR ...]             #LEVEL can be exception (def), warning, notice, info, log or debug. Exception throw an exception, but
                                  #others don't, they just print a message.
                                  #VAR = STR provide informations among:
                                  #  - errcode: like EXCEPTION in exception block, but SQLSTATE is as STR
                                  #  - message: like sqlerrm
                                  #  - detail, hint, column|...|schema: like in get stacked diagnostics
                                  #If no using..., rethrow a currently catched exception.
raise [LEVEL] EXCEPTION
 ...                              #Like raise [LEVEL] using errcode = EXCEPTION ...
raise [LEVEL] 'STR',
VAL...  ...                       #Like raise [LEVEL] using message = STR ..., where STR can substitute % symbols with VAL...

return [VAL]                      #Return statement of the function.
                                  #VAL can be omitted:
                                  #  - if out ARG... are used
                                  #  - if void if the return type
return next [VAL]                 #With setof ... return type (multiple rows), add VAL (ROW for multiple columns) or MSUBQUERY to
return query MSUBQUERY            #the returned TABLE. Needs to be called several time, then a return; will return the whole set.
                                  #If VAL is ommitted and out ARG... are used, use the current value of those ARG... instead.

VAR := VAL                        #Assignment
SQL_COMMAND                       #Any SQL command can be performed but:
                                  #  - select ... (except select ... into) (including select VAL or select FUNC()) must be written
                                  #    perform ..., and has no return value
                                  #    - written perform (...) for a with ... query
null;                             #To do nothing (empty line), write null;
MSUBQUERY                         #Put the first row returned into VAR, which can be:
into [strict] VAR                 #  - VAR... for each column
                                  #  - "ROW"|"TABLE" or record for all columns
                                  #If more than one row is returned (and, if select, strict is used), an exception TOO_MANY_ROWS is
                                  #fired. If no row returned and strict, an exception NO_DATA_FOUND if fired.
                                  #select ... into is PL/PGSQL, different than the SQL select ... into

execute STR                       #Execute SQL (not PL/PGSQL) command STR.
[using VAL...]                    #STR can contain $NUM that will substituted by each VAL...:
                                  #  - must be used for all VAR coming from the FUNC ARG...
                                  #  - can only be used in select|insert|update|delete
                                  #  - cannot be used by "TABLE" and "COL": they must be supplied as a STR concatenation
                                  #STR should be escaped:
                                  #  - $$...$$ for the command
                                  #  - use quote_* for dynamic variables

found                             #Variable containing true if last SQL command returned|manipulated at least one row.
get diagnostics                   #WORD can be either:
VAR = WORD                        #  - row_count (assign to VAR the number of rows returned|manipulated by last SQL command)
                                  #  - result_oid: OID of last row manipulated (if table has OIDs)

if BOOL then ...
[elseif BOOL then ...]
[else ...] end if;

case ... end case;                #Like SQL case ... end

[<<LABEL>>]
[while BOOL] loop ...
end loop [LABEL]                  #BOOL is true by def.

[<<LABEL>>]
for "INT" in [reverse]
NUM..NUM2 [by NUM3] loop
... end loop [LABEL]              #

[<<LABEL>>]                       #Iterates over rows returned by MSUBQUERY
for VAR in MSUBQUERY              #VAR can be:
loop ...                          #  - VAR... for each column
end loop [LABEL]                  #  - "ROW"|"TABLE" or record for all columns

[<<LABEL>>]                       #Looping through a VAR2:
foreach VAR [slice NUM]           #  - ARR
in array VAR2 loop ...            #  - ROW: VAR is then VAR... for each value
end loop [LABEL]                  #If NUM > 0, VAR receives an ARR2 of dimension NUM each time (for multidimensional VAR2)

exit [LABEL] [when BOOL]          #Exit a loop or block with LABEL (def: innermost one), if BOOL (def: true)
continue ...                      #Same as exit ... but skip next statements to start a new cycle.

refcursor                         #Special PL/PGSQL type to store a CURSOR.
                                  #Similar as SQL CURSOR (move and close identical). Differences are below.
                                  #Can be declared as:
                                  #  - CURSOR [scroll] cursor [(ARGS...)] for select ...:
                                  #    - like a SQL CURSOR, but:
                                  #      - not opened, needs to do open CURSOR;
                                  #      - if ARGS, can pass arguments to open CURSOR(...);
                                  #  - CURSOR refcursor:
                                  #    - same but needs to specify the query with open, either with open CURSOR [scroll] for select ...
                                  #      or open CURSOR [scroll] for execute ...
                                  #Can be returned or passed as argument:
                                  #  - pass the CURSOR as STR, casted as refcursor, e.g. FUNC(refcursor 'CURSOR')
                                  #  - to use a CURSOR in the calling FUNC, either:
                                  #     - use the names of the CURSOR.
                                  #       No need to return them, they close at end of transaction of calling function.
                                  #       If CURSOR not provided as argument, will generate a random name
                                  #     - return them, and use the return value
fetch ... into VAR                #Just like select ... into VAR (including: cannot fetch several rows)
[<<LABEL>>]
for RECORD
in REFCURSOR[(...)]
loop ... end loop [LABL]          #Loops in a REFCURSOR. Implicitely open and close the REFCURSOR

TFUNC FOR PL/PGSQL ==>            #Return type is trigger, but must return either:
                                  #Arguments are in tg_argv STR_ARR (index starts at 0 and is of size tg_nargs INT).
                                  #Can also use:
                                  #  - new|old RECORD: current row for "for each row" TFUNC (only if "for each row")
                                  #    new is absent if delete, and old is absent if insert.
                                  #  - tg_name STR: TFUNC name
                                  #  - tg_when STR: before|after|instead of
                                  #  - tg_level STR: statement|row ("for each row")
                                  #  - tg_op STR: insert|update|delete|truncate
                                  #  - tg_relid OID: of the TABLE
                                  #  - ts_table_name STR: name of the TABLE
EFUNC FOR PL/PGSQL ==>            #Return type is event_trigger, but doesn't use return.
                                  #Can also use:
                                  #  - tg_event STR: the EVENT
                                  #  - tg_tag STR: the COMMAND

PL/SH ==>                         #plsh, for any installed shell, including Bash:
                                  #  - Impossible: ROW, any*, out ARG, setof
                                  #  - Body: starts with correct shabang.
                                  #  - Arguments: same as the shell (for Bash: $1, "$@", $#, etc.)
                                  #  - Return value:
                                  #    - stdout, with a newline stripped
                                  #    - null if exit (exit code 0) with nothing on stdout
                                  #  - Exception:
                                  #     - printing to stderr
                                  #     - non-0 exit code
                                  #  - SQL commands: fired through psql STR command line.
                                  #  - Can use any executable, as postgres user.
                                  #  - TFUNC and EFUNC:
                                  #    - defines PLSH_TG_* like tg_* in PL/PGSQL (old|new unavailable)
                                  #    - TFUNC() est executee, mais ne modifie jamais le row courant

PL/R ==>                          #plr: for R:
                                  #  - Arguments: named arguments.
                                  #  - Return value: return(VAL)
                                  #  - Types (other than obvious):
                                  #    - dimensions (max 3):
                                  #      - 0 dimension  (TYPE)                    <-> VAL
                                  #      - 1 dimension  (setof TYPE, ARR)         <-> VALv
                                  #      - 2 dimensions (setof ROW, ARR(2 dim)) <-> DATA.FRAME|ARR(2dim)
                                  #        - "TABLE"|"ROW" as argument -> DATA.FRAME, but must use as.data.frame(DATA.FRAME) if want to be returned
                                  #      - 3 dimensions (ARR (3 dim))             <-> ARR(3dim)
                                  #    - null <-> NA|NULL(pref)
                                  #    - BYTEA <-> OBJECT ([un]serialize on RAW)
                                  #    - everything else <-> STR
                                  #  - TFUNC: defines pg.tg.* like tg_* in PL/PGSQL
                                  #  - WFUNC: will pass:
                                  #     - fargNUM...: other values in WINDOW (NUM starts at 1)
                                  #     - fnumrows: WINDOW size
                                  #     - prownum: offset of WINDOW
                                  #  - Global data are possible across calls, including global functions.

PL/R FUNC() ==>                   #
install_rcmd(STR)                 #Execute R code STR (e.g. a function definition).
plr_environ()                     #Returns all environment variables as TABLE with STR columns name and value.
plr_set_display(STR)              #Change the DISPLAY env variable (useful for plots)

PL/R R FUNCTIONS ==>              #
pg.spi.exec(STR)                  #Execute SQL command STR.
                                  #For select ..., returns query as DATA.FRAME (null -> NA).
                                  #For others, returns number of manipulated rows.
pg.spi.prepare                    #Like prepare in SQL
(STR, INT_ARR)                    #INT_ARR are the types oid:
                                  #  - same as in pg_type.oid
                                  #  - can use SQL FUNC() load_r_typenames() to create R variables holding types oid.
                                  #    To see those variables, use SQL FUNC() r_typenames()
                                  #  - must be NA if no arguments
                                  #Returns a PLAN.
pg.spi.execp(PLAN, LIST)          #Like pg.spi.exect(), but executing a PLAN.
                                  #LIST is unnammed:
                                  #  - must contain only NA if no argument.
                                  #  - must be NA for a NULL in SQL
pg.spi.factor(DATA.FRAM)          #Convert non-NUM columns of DATA.FRAME into FACTOR.

pg.spi.cursor(STR, PLAN[, LIST])  #Creates and returns a readonly CURSOR names STR for the command defined by PLAN and LIST.
pg.spi.fetch(CURSOR, BOOL, INT)   #Same as fetch forward|backward (true|false) INT in SQL
pg.spi.close(CURSOR)              #

pg.spi.lastoid()                  #If last action was an insert of a single row, returns OID of that row.
pg.thrownotice|error(STR)         #Like raise notice|exception in PL/PGSQL
pg.quoteliteral|ident(STR)        #Like quote_literal|ident in SQL

PL/R OTHERS ==>                   #
plr_modules                       #TABLE executing plr_modules.modsrc (R code as STR) at start of each session or if reload_plr_modules()
                                  #is called.
                                  #plr_modules.modseq INT is the priority/order of execution.
                                  #Needs to be created as plr_modules(modseq int4, modsrc text). Should be readable by all, writable
                                  #only by trusted users.


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:         DICTIONARIES          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


PRINCIPLES ==>                    #Normalize a STR document by using:
                                  #  - a REGCONF, i.e. a combination of:
                                  #     - a PARSER, that break words into tokens according to whitespaces, hyphens, etc.
                                  #       Can produce overlapping tokens (both the compound token and its parts).
                                  #       Tokens can be words, hyphen-separated token, email address, URL or part of URL (path, host,
                                  #       etc.), numbers, XML tags
                                  #     - a list of DICTIONARY, i.e. a TEMPLATE filled with arguments.
                                  #       Goal is to remove common words, change grammatical forms, etc.
                                  #  - current REGCONF is chosen with ENVVAR default_text_search_config (can be set by initdb -T STR)
                                  #    Can be returned by get_current_ts_config()
                                  #Normalized STR documents are TSVECTOR. Queries are performed using TSQUERY.

LIMITS ==>                        #  - 2KB for lexemes. Max. 2^64 by TSVECTOR. Max 256 positions by lexeme.
                                  #  - 1MB for TSVECTOR (divide a document into several TSVECTOR)
                                  #  - Max. 2^32 elements in a TSQUERY

tsvector                          #Normalized STR document.
                                  #Each word can have a position and weight, i.e. word:NUMLETTER, where NUM is the position is the
                                  #document (1 to 16383) and a weight, A, B, C to D, indicating the level (title, subtitle, etc.)
                                  #Position only serves for relative position comparison, so 16383 is fine.
tsquery                           #A STR, query combination of normalized words on a tsvector.
                                  #Words must be separated by & or | (not space)
                                  #Can include:
                                  #  - () ! & |, e.g. 'word & (word2 | word3)'
                                  #  - word:LETTER...: only words in tsvector with weight LETTER... should match
                                  #  - word:*: not whole word need to match, but only beginning
to_tsquery|vector                 #As opposed to cast(STR as tsquery|vector), it does normalization.
([REGCONFIG, ]STR)                #Only use the later if already normalized.
plainto_tsquery(...)              #Same as to_tsquery() but can't accept operators & | ! (), and implicitely put & between each word

TSQUERY @@ TSVECTOR               #Returns true if match.
STR @@ STR2                       #Automatically call to_tsquery|vector()
TSVECTOR || TSVECTOR2
TSQUERY && || !! TSQURY2
TSQUERY @> @< TSQUERY2            #Contains|is contained

length(TSVECTOR)                  #number of words
strip(TSVECTOR)                   #Removes weights and indexes
setweight(TSVECTOR, 'A|B|C|D')    #Returns TSVECTOR with given weight
numnode(TSQUERY)                  #number of words and operators
querytree(TSQUERY)                #returns TSQUERY without parts that can't be accessed (!word and common words), to detect if a TSQUERY
                                  #can be indexed
ts_rank[_cd]([REAL_ARR,]          #Computes how much TSQUERY matches TSVECTOR. Used with "order by".
 TSVECTOR, TSQUERY[, UINT])       #ts_rank look at the number of occurences, and ts_rank_cd at the proximity of occurences
                                  #(smaller is better)
                                  #REAL_ARR weights occurences according to 4 REAL for the weights D, C, B, A (def: 0.1, 0.2, 0.4, 1).
                                  #UINT is a or'd flag, that computes following operations on output :
                                  #  - 0 (def): nothing
                                  #  - 1: n/(log(len(n))+1)
                                  #  - 2: n/len(n)
                                  #  - 4: n/mean between occurences (only ts_rank_cd)
                                  #  - 8: n/number of unique words
                                  #  - 16: n/(log(number of unique words)+1)
                                  #  - 32: n/(n+1)
ts_headline([REGCONF,] STR,       #Returns a STR3 with matching results.
 TSQUERY[, STR2])                 #To make it faster, use select ts_headline(STR, TSQUERY) from (select ...) where the subquery returns
                                  #only rows that match the TSQUERY.
                                  #STR2 have options, as 'VAR=VAL...':
                                  #  - StartSel, StopSel STR: to be put around matches (def: '<b>' and '</b>')
                                  #  - Min|MaxWords UINT: to filter matches by number of occurences
                                  #  - ShortWord UINT: length minimal of words at being and end of matches
                                  #  - HighlightAll BOOL: negates previous args
                                  #  - FragmentDelimiter STR: between each match in output
                                  #  - MaxFragments UINT: to display in output
ts_rewrite(3 TSQUERY)             #Change occurences of TSQUERY2 inside TSQUERY to TSQUERY3
ts_rewrite(TSQUERY, TABLE)        #Same with a TABLE with two TSQUERY columns

ts_debug([REGCONFIG, ]STR)        #Returns result of conversion STR -> TSVECTOR, as a TABLE with COLs:
                                  #  - alias STR: TYPE of TOKEN
                                  #  - description STR: of TYPE of TOKEN
                                  #  - token STR: original TOKEN
                                  #  - dictionaries STR_ARR and dictionary STR (the one chosen)
                                  #  - lexemes STR_ARR: final tokens
ts_lexize(STR, STR2)              #Returns token STR2 as STR_ARR according to dictionary STR
ts_parse(STR|OID, STR2)           #Same for parser. Returns a TABLE with COLs:
                                  #  - tokid INT: token type
                                  #  - token STR
ts_token_type(STR|OID)            #Returns all token types of the parser STR|OID, as a TABLE with COLs:
                                  #  - tokid INT
                                  #  - alias STR
                                  #  - description STR
ts_stat(STR[, STR2])              #For a query STR returning a TSVECTOR, returning each word in a TABLE:
                                  #  - word STR
                                  #  - ndoc UINT: numero du TSVECTOR
                                  #  - nentry UINT: number of occurences
                                  #If STR2, only lexemes with weights STR2 will be picked.

create text search                #... can be:
configuration REGCONF             #  - parser = STR
(...)                             #  - or copy = REGCONF2
                                  #Dictionaries are specified with alter text search configuration ...
alter text search                 #... controls DICTIONARY for specific TOKEN (as WORD) can be:
configuration REGCONF             #  - add|alter mapping for TOKEN... with DICTIONARY...
...                               #  - drop mapping [if exists] for TOKEN...
                                  #  - alter mapping [for TOKEN...] replace DICTIONARY with DICTIONARY2
                                  #Available ones:
                                  #  - pg_catalog.LANG (def: english), which uses:
                                  #     - LANG_stem DICTIONARY for words, simple DICTIONARY for rest
                                  #     - pg_catalog.default PARSER
                                  #  - pg_catalog.simple, which uses:
                                  #     - simple DICTIONARY for all
                                  #     - pg_catalog.default PARSER

create text search                #Create a DICTIONARY, which is a TEMPLATE but with args filled in ... (as VAR = VAL)
dictionary DICTIONARY             #Available ones:
(template = TEMPLATE, ...)        #  - LANG_stem:
                                  #     - snowball TEMPLATE with language = LANG and stopwords = LANG
                                  #  - simple:
                                  #     - simple TEMPLATE
                                 ## - unaccent:
                                 ##    - filtering dictionary removing accent
                                 ##    - does it according to argument rules (which can be altered), pointing to
                                 ##      SHAREDIR/tsearch_data/ARG.rules.
                                 ##      The default one can be found with unaccent.rules (works for western languages)
                                 ##    - can also use unaccent([ARG, ]STR)
                                 ##    - Postgres extension 'unaccent'
                                 ## - dict_xsyn:
                                 ##    - synonym dictionary: a word is spread into several synonymous words, so that synonymous words
                                 ##      are counted together
                                 ##    - arguments (can be altered):
                                 ##       - rules, pointing to SHAREDIR/tsearch_data/ARG.rules, see example at
                                 ##         SHAREDIR/tsearch_data/xsyn_sample.rules
                                 ##       - matchorig|synonyms BOOL: the original word or synonyms are accepted as input
                                 ##         (def: true and false)
                                 ##       - keeporig|synonyms BOOL: the original word or synonyms are produced in output
                                 ##         (def: true and true)
                                 ##    - Postgres extension 'dict_xsyn'
alter text search
dictionary DICTIONARY(...)        #

create text search                #Creates a TEMPLATE. Must be superuser ROLE.
template TEMPLATE                 #A TEMPLATE:
 ([init = FUNC, ]lexize = FUNC2)  #  - take a STR in input from the parser and can return:
                                  #     - STR_ARR of the normalized words
                                  #     - empty STR_ARR if common words
                                  #     - null if word is unknown, so original STR passed to the next dictionary
                                  #     - STR, with the TSL_FILTER flag on (filtering dictionary): pass STR to the next dictionary
                                  #       dictionary
                                  #       Ex of filtering dictionary: removing accents
                                  #  - usually use FILES:
                                  #     - can be found under SHAREDIR/tsearch_data/FILE.extension (extension depends on TEMPLATE)
                                  #     - FILE must be in UTF-8
                                  #  - use arguments that are filled by DICTIONARY
                                  #Available TEMPLATE:
                                  #  - simple:
                                  #     - arguments: accept BOOL (def: true), stopwords FILE
                                  #     - FILE (extension: .stop) is one word by line
                                  #     - if input:
                                  #        - is found in FILE, returns empty STR_ARR
                                  #        - is not found:
                                  #           - if accept is true, returns word as STR_ARR
                                  #           - if accept is false, returns null
                                  #     - input is lowercased first
                                  #  - synonym:
                                  #     - arguments: casesensitive BOOL (def: false), synonyms FILE (extension: .syn)
                                  #     - FILE (extension: .syn) have two space-separated fields
                                  #     - if input:
                                  #        - is found in first field of FILE, returns second field
                                  #        - otherwise returns null
                                  #     - input is lowercased first if not casesensitive
                                  #       Second field can have * at the end, indicating to be a word:* if used as a TSQUERY
                                  #  - thesaurus:
                                  #     - arguments: dictfile FILE, dictionary DICTIONARY
                                  #     - FILE (extension: .ths) have two colon-separated fields (can contain several words)
                                  #       Can have #comment
                                  #     - if input:
                                  #        - is found in first field of FILE, returns second field
                                  #        - otherwise returns null
                                  #     - first use another DICTIONARY.
                                  #       Common words will be erased by DICTIONARY, but can still match them in first field of FILE
                                  #       with ?
                                  #  - ispell:
                                  #     - arguments: stopwords FILE, afffile FILE2, dictfile FILE3
                                  #     - FILE (extension: .stop): like stopwords in pg_catalog.simple
                                  #     - FILE2 (extension: .affix) and FILE3 (extension: .dict): see doc. for ispell
                                  #     - In short, can turn grammatical variations of a word into a single form.
                                  #  - snowball:
                                  #     - arguments: stopwords FILE, language WORD
                                  #     - like ispell, but simpler and never return null (so should be placed in the end)

create text search
parser PARSER
(start = FUNC, gettoken = FUNC2,
end = FUNC3,                      #Creates a PARSER. Must be superuser ROLE.
lextypes = FUNC4                  #Available ones:
[, headline = FUNC5])             #   - 'pg_catalog.default' (def). Notion of a "letter" depends on locales.

                                 ##Following functions can be used to test similarities between STR.
                                 ##Postgres extension 'fuzzystrmatch'
levenshtein(STR, STR2
 [, INS_COST, DEL_COST,SUB_COST])##Show differences, like agrep
levenshtein_less_equal(..., INT) ##Same but if more than INT, returns INT+1 (faster).
metaphone(STR, INT)              ##Convert to STR to phonetic-style code, and truncate it if more than INT characters (max 255)
                                 ##For english language. Does not work well with Unicode characters.
dmetaphone(STR)                  ##Same but unlim size.


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            CURSORS            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


CURSORS ==>                       #Row iterators over a specific query (executed once when opening the cursor)
declare CURSOR                    #Creates and open a CURSOR for query TABLE (any that would also work in a from ... clause)
[scroll] cursor                   #Is closed at end of transaction (if no transaction, is immediately closed), unless with hold is used.
[with hold]                       #Using select for update|share:
for TABLE                         #  - is not compatible with with hold or scroll
                                  #  - is recommended if using a ... where current of ... to make sure rows are the same
                                  #If scroll, fetch can work backward.
                                  #Starting position is before the first row. After the last row is the end.
fetch [WORD]                      #Return rows of CURSOR according to position specified by WORD, and move it too:
from CURSOR                       #  - forward|backward [NUM|all] (def: forward): retrieves several rows if NUM
                                  #  - relative NUM: 0 for current row
                                  #  - absolute NUM (if negative, from the end): 0 for before first row, more than number of rows for
                                  #    after last row
move [WORD] from CURSOR           #Same but only moves cursor, doesn't return anything.
close CURSOR|all                  #Close a CURSOR (or all). Automatically done at end of transaction for a CURSOR without "with hold"
update|delete ... where           #Same as update|delete ... where BOOL, with BOOL being current position of CURSOR.
current of CURSOR                 #Grouping cannot be used in the TABLE of CURSOR.


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            SCHEMAS            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


create schema SCHEMA              #Creates a SCHEMA (namespace inside a DATABASE).
[authorization USER]              #USER is the owner (def: current_user).

alter ENTITY "ENTITY"
 set schema SCHEMA                #For all ENTITYs that can have a SCHEMA

[SCHEMA.]VAR                      #Access/write a VAR (usually "TABLE" but can be any VAR) for a specific SCHEMA.
                                  #If not specified, use the ENVVAR_ARR search_path, by def. {USER, public}. Searched from left to
                                  #right. If nothing found and writing operation, use the leftest SCHEMA (except USER)

pg_catalog                        #SCHEMA for all pg_* tables and builtins functions and types. It's implicit in the search path.
                                  #To override those builtins, put pg_catalog at the end of the search path

current_schema()                  #
current_schemas([BOOL])           #If true, include implicit ones (e.g. pg_catalog)
pg_is_other_temp_schema(OID)      #Is it a temporary schema
pg_my_temp_schema()               #Temp SCHEMA OID, 0 if none.
pg_TYPE_is_visible(OID)           #Checks if an object is accessible through current SCHEMA path.


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          CONCURRENCY          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


SESSION ==>                       #Beginning and end of a list of commands (e.g. interactive prompt)
CONCURRENCY ==>                   #Uses Multiversion Concurrency Control (MVCC) instead of traditional locks, for best performance
                                  #while still reliable:
                                  #  - transactions create a snapshot of the current state ("database version").
                                  #  - read/write locks are "predicate locks": they don't block, they are just informative, and later on
                                  #    might cancel actions if concurrency problem.
                                  #Best to have consistent data is:
                                  #  - if several statements need to be "write all or nothing", use transactions:
                                  #      - if the state being read can be changed by other clients in the middle of the transaction
                                  #        without problems, use read committed statements
                                  #      - otherwise, use serializable statements, but then if abort, must redo the transaction.
                                  #        Client software usually notify of transaction failures: in such case, client needs to send
                                  #        the request again.
                                  #      - in all cases, put as read only if possible, and deferrable when it's a long operation.
                                  #  - otherwise, transactions are not needed: operations are atomic and ask for the relevant blocking
                                  #    locks, so no concurrency problem (are actually atomic transactions)
                                  #When asking for locks:
                                  #  - Transaction asking for locks will wait ENVVAR lock_timeout (def: 0, in ms) before cancelling,
                                  #    and ENVVAR deadlock_timeout (def: 1s) before checking if there is a deadlock (in which case it
                                  #    is cancelled)
                                  #  - all transactions cannot exceed an average of ENVVAR max_[pred_]locks_per_transaction (def: 64)
                                  #    predicate or not-predicate locks.
                                  #FUNC():
                                  #  - always a single read commited transaction, acquiring locks
                                  #     - begin block of PL/PGSQL is logic-wise, not used for concurrency
                                  #  - finer concurrency control is only at SQL level, so need wrap FUNC() call in a SQL transaction
start transaction                 #Start a transaction (ends with rollback|commit), statements are only committed to the database at the
[isolation level WORD,]           #end of the transaction (but "appear" committed locally inside the statement)
[read write|only,]                #A transaction that has any statement with an error will abort (rollback when committed).
[[not] deferrable]                #WORD can be read committed, repeatable read or serializable.
                                  #Effects of WORD, for W2 -> R1 or W1 (same rows, 1 and 2 are transactions)
                                    +-------------------------------------------+-------------------------------------------+
                                    |                  W2 -> R1                 |                  W2 -> W1                 |
+-----------------------------------+-------------------------------------------+-------------------------------------------+
| atomic or committed transaction 1 |                                    No problems                                        |
| atomic or committed transaction 2 |                                                                                       |
+-----------------------------------+-------------------------------------------+-------------------------------------------+
| ongoing transaction 1             |                                           | read committed: ignores W2                |
| ongoing transaction 2             |                                           | non read committed: aborts (will rollback)|
+-----------------------------------+                 ignores W2                +-------------------------------------------+
| atomic or committed transaction 1 |                                           |                  blocks                   |
| ongoing transaction 2             |                                           |                                           |
+-----------------------------------+-------------------------------------------+-------------------------------------------+
| ongoing transaction 1             | non read committed and R1 -> W2 -> R1:    | non read committed and R1 -> W2 -> W1:    |
| atomic or committed transaction 2 |  ignores W2                               |  aborts (will rollback)                   |
|                                   | else:                                     | else:                                     |
|                                   |  takes W2 into account                    |  takes W2 into account                    |
+-----------------------------------+-------------------------------------------+-------------------------------------------+
                                  #Summary:
                                  #  - read committed (def):
                                  #    - ignores other ongoing transactions, but takes into account changes by committed transactions
                                  #      or atomic statements
                                  #    -> see state for the current statement
                                  #  - repeatable read:
                                  #    - ignores other ongoing transactions, including changes, unless it conflicts, in which case
                                  #      it aborts.
                                  #    -> see state at start of transaction (first statement after "start transaction")
                                  #  - serializable:
                                  #    - like repeatable read, but two concurrent serializable doing a W that depends on a R that is
                                  #      changed by this W: the second will abort.
                                  #      - ex: insert into "TABLE"("COL") select sum("COL") from "TABLE"; by two serializable transactions.
                                  #    -> can virtually consider successful transactions (not aborting) to happen one after the other,
                                  #       while still avoiding blocking locks to achieve it.
                                  #Others:
                                  #  - read write|only (def: read write):
                                  #     - read only allow further concurrency optimization
                                  #     - read only can still write to TEMP
                                  #  - deferrable (def: not deferrable):
                                  #     - if serializable and read only, blocks until sees no chance of being cancelled, then go on.
                                  #     - good if cancellation might take a long time to repeat the transaction (e.g. backups)
                                  #Synchronization of two TRANSACTIONs:
                                  #  - TRANSACTION must:
                                  #     - both be either repeatable read or serializable.
                                  #       If TRANSACTION2 is serializable, so must be TRANSACTION1
                                  #     - if TRANSACTION1 is readonly, so must be TRANSACTION2
                                  #     - Must be just after the "start transaction"
                                  #  - steps:
                                  #     - TRANSACTION1 does select pg_export_snapshot(), which prints a SNAPSHOT_ID
                                  #     - TRANSACTION2 does set transaction snapshot SNAPSHOT_ID, as STR
                                  #Can have extra infos with:
                                  #  - txid_current(): current TRANSACTION_ID
                                  #  - txid_current_snapshot(): current SNAPSHOT_ID
                                  #  - txid_snapshot_xid(SNAPSHOT_ID): returns current transaction ID
                                  #  - txid_snapshot_xmax|xmin(SNAPSHOT_ID)
                                  #  - txid_visible_in_snapshot(TRANSACTION_ID, SNAPSHOT_ID)
set transaction ...               #Changes isolation level, etc. (same as start transaction ...) for current transaction.
                                  #Must be just after the "start transaction"
set session
characteristics                   #Same but for all future transactions.
as transaction ...                #Same as setting ENVVAR default_transaction_isolation|read_only|deferrable
rollback|commit                   #Finishes a transaction.
                                  #For rollback, actions are actually dropped (nothing happens).
savepoint LABEL
rollback to savepoint             #Inside a transaction block, rollback to LABEL go back to the state where savepoint LABEL was (and
LABEL                             #releases all savepoint LABEL that might have been defined after it).
release savepoint LABEL           #Delete a savepoint

prepare transaction STR           #Do a two-phase commit:
                                  #  - transaction is temporary rollbacked (except the ENVVAR changes) and will only be committed once
                                  #    commit prepared STR is done
                                  #  - commit|rollback prepared STR can be done by other clients (not inside a transaction), if same ROLE
                                  #    or superuser ROLE.
                                  #    So goal is to have a single client managing the transaction of other clients
                                  #    ("transaction management system")
                                  #STR must be unique, and less than 200 bytes
                                  #Transaction must not involve notify|[un]listen, TEMP nor CURSOR with hold
                                  #ENVVAR max_prepared_transactions (def: 0, so disabled) is available. Is set, should be
                                  #max_connections * number of prepared_transactions per connection

lock "TABLE" ...                  #Put a blocking lock on "TABLE"... among several mode WORD, and release at end of current transaction:
[in WORD mode] [nowait]           #  - should do it at beginning of transaction if repeatable read or serializable.
                                  #  - locks goal is to conflict with each other
                                  #  - prefer predicate locks
                                  #If can't access lock:
                                  #  - if nowait, only emits error
                                  #  - otherwise, transaction will be rollbacked
                                  #WORD are:
                                  #  - access exclusive (commands that erase data): block everything
                                  #  - exclusive: let up to access share
                                  #  - share row exclusive: let up to row share
                                  #  - share update exclusive (commands that change schemas (clean/analyze/optimize data/alter)): let up
                                  #    to row exclusive
                                  #  - row exclusive (commands that write data)
                                  #  - row share (select for update/share)
                                  #  - access share (commands that read data)
select ... for update             #Gets an access exclusive lock on the rows in ... for "TABLE" (def: all), released at end of transaction
[of "TABLE"...] [nowait]          #(not statement). Cannot use union, intersect or except.
select ... for share
[of "TABLE"...] [nowait]          #Same for share row exclusive

pg_[try_]advisory_                #Gets a lock linked to a ID BIGINT:
[xact_]lock[_shared]              #  - can be "_shared" or not (block lock() attempts, but not lock_shared() attempts)
(BIGINT)                          #  - session-level (stops at unlock() or at end of session)
                                  #    - if "xact_" transaction-level (stops at end of transaction only)
                                  #  - If "try_", only returns false/true but no block if can't get the lock.
                                  #  - can lock several times (needs to unlock several times)
pg_advisory_unlock
[_shared](BIGINT)                 #Returns true if such lock existed.
pg_advisory_unlock_all()          #

set constraints                   #Change the initially deferred|immediate state of CONSTRAINT... (def: all) within the current
all|CONSTRAINT...                 #transaction.
deferred|immediate                #CONSTRAINT can be declared (including during create table ...)
                                  #  - initially immediate (def): constraints are checked at each statement.
                                  #  - initially deferred: at each end of transaction (except not null and check())
                                  #  - not deferrable (def: deferrable): cannot be initially deferred.
                                  #Includes previous statements (retroactively), so can fire at specific point in transaction.
"COL" TYPE ...
 [initially deferred|immediate]
 [[not] deferrable]               #Same for a specific COL_ARG (including multicolumn)
alter table "TABLE"
 alter constraint "CONSTRAINT"
 [initially deferred|immediate]
 [[not] deferrable]               #Same for a specific CONSTRAINT
create ... trigger ...
 on "TABLE"|VIEW [from TABLE2]
 [[not] deferrable]
 [initially deferred|immediate]   #Same for a TFUNC


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:             INDEX             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


create [unique] index             #Create an INDEX on COL...
[concurrently] INDEX              #Cannot be directly used, but makes select|update|delete on COL... faster (used by the planner).
on "TABLE"(COL,...                #Can't create two INDEX with same names, even on different tables.
[OPCLASS])                        #Will be picked when the query use the same expression used in create index ...:
[using INDEX_METHOD]              #  - COL (not "COL"):
[asc|desc]                        #     - "expression index" makes it possible to use INDEX when query usually use COL (e.g. FUNC(COL))
[nulls first|last]                #     - if use operator, needs extra set of parenthesis, e.g. ((COL + VAL))
[with (VAR = VAL...)]             #  - where BOOL:
[where BOOL]                      #     - "partial index" (only on part of "TABLE"), faster when query usually use where BOOL
                                  #     - useful when where BOOL is selective (only few rows)
                                  #  - multiple COL...: "multicolumn index":
                                  #     - should be used only if COL... are almost always queried together
                                  #     - for btree|gist, only faster when using query using COL... in the same order and connected
                                  #       with and (up to the last OP)
                                  #     - for gist, quite slow if first COL has few distinct values
                                  #     - not for spgist
                                  #  - [asc|desc] [nulls first|last]:
                                  #     - "sorted index", faster when querying using order by ...
                                  #     - for btree, useless (except with desc nulls last or asc nulls first, or with multiple COL...
                                  #       with different sort order) since it can scan in both directions and automatically sort.
                                  #  - using INDEX_METHOD (def: btree): see below
                                  #  - OPCLASS:
                                  #     - use a specific OPCLASS for the type of COL instead of the default one
                                  #       The underlying OP must be immutable.
                                  #Others:
                                  #  - unique:
                                  #     - only for btree
                                  #     - use it if COL... can't have duplicate records (faster)
                                  #     - as opposed to usual unique CONSTRAINT, can be done on COL (not only "COL")
                                  #  - concurrently: instead of asking for an exclusive lock, wait for possible conflicting transactions
                                  #    to complete for each row. Slower but will not lock the "TABLE".
                                  #    Can fail: then drop INDEX and recreate it.
                                  #  - with (VAR = VAL...): see create table ...
                                  #An "index-only scan" is a query that can use only the INDEX without even visiting the TABLE (faster).
                                  #A query using "... and|or ..." can use each ... INDEX separately, then combine the result.
                                  #INDEX performances:
                                  #  - makes read faster, but write slower (needs to maintain the INDEX)
                                  #  - is mostly efficient if the query is selective (chooses few rows) on a big table.
                                  #  - to know when to use an INDEX, check with explain if INDEX is chosen by the planner for most-used
                                  #    queries or skipped in favor of a sequential scan.
                                  #Max 32 COLs

create table ...
 exclude|unique|primary key ...   #Those CONSTRAINTs create an underlying INDEX
 [include("COL",...)]
 [with (OPTS)]                    #Configure underlying INDEX

create table ... exclude
 [using INDEX_METHOD]
 ("COL"|(REXPR)
  [OPCLASS]
  [asc|desc]
  [nulls first|last]              #COL_ARG. Configure underlying INDEX
 ,...) ...                        #INDEX_METHOD cannot be gin

INDEX_METHOD ==>                  #"Index accessor method"
                                  #Structure in which indexes are conceptually stored (because in the end they are TABLE), and
                                  #functions to maintain/create those structures.
                                  #In short: way to create INDEX, linked to specific types and operators.
                                  #Are linked to specific OPFAMILY, which are groups of OPCLASS (operator class), which is a combination
                                  #of INDEX_METHOD + TYPE + FUNC...:
                                  #  - an INDEX_METHOD provides an API with few FUNCs to implement
                                  #  - to implement a TYPE, need to write them for those TYPE -> OPCLASS
                                  #  - available OPCLASS and OPFAMILY are usually called TYPE_ops (_TYPE_ops for ARR)
                                  #INDEX_METHOD available are:
                                  #  - btree (def):
                                  #      - implemented on all TYPE for < <= = >= > <> (implies in, between, etc.)
                                  #      - faster if = is used first in queries
                                  #  - gin:
                                  #      - for VAL = one of VAL...
                                  #      - implemented on most operators for:
                                  #         - TSVECTOR
                                  #         - ARR
                                  #         - INT_ARR && <@ @> @@
                                 ##        - HSTORE @> <@ ? ?& ?|
                                 ##     - for INT_ARR, use special OPCLASS gin|gist__int[big]_ops
                                 ##        - big_ops: prefer if big dataset
                                  #  - gist:
                                  #      - implemented on most operators for CIRCLE, POINT, BOX, POLYGON, RANGE, TSQUERY, LTREE
                                  #      - implemented also on TSVECTOR, INT_ARR and HSTORE (like gist):
                                  #         - gin tends to be faster read but slower write
                                  #  - spgist:
                                  #      - implemented on most operators for POINT, RANGE, and on < <= >= = > <> for STR
                                  #  - more are available by adding a row to pg_am. Some are available as EXTENSION.
create operator
class|family ...                  #Create user-defined OPCLASS|OPFAMILY. Need C functions (see doc online)
alter operator
family ...                        #

create table ...
 using ACCESS_METHOD              #

drop index concurrently ...       #Like create index concurrently ...
                                  #Needs to be outside of a transaction, restrict and only one INDEX

reindex index|table|              #Rebuild INDEX... of the target (system is like database but only include system catalogs)
database|system                   #Needed to reclaim space when an INDEX has shrink size a lot.
INDEX|"TABLE"|DATABASE            #Also needed if an INDEX is corrupted due to software bug.
                                  #If corrupted INDEX are on system catalogs, use postgres --single -P instead of postgres, otherwise it
                                  #will crash. Then use reindex and restart.
                                  #Ask for a exclusive lock

cluster [verbose]                 #Makes the physical layout of TABLE rows similar to INDEX_METHOD.
 ["TABLE" [using INDEX_METHOD]]   #Goal is to speed up queries of a TABLE with an INDEX using INDEX_METHOD.
                                  #Is one-time operation (new rows are not clustered). Acquires an exclusive lock.
                                  #Good idea to run analyze afterwards.
                                  #INDEX_METHOD can be ommitted the second time, because remember it. Memory can be altered with:
                                  #  - alter table "TABLE" cluster on INDEX
                                  #  - alter table "TABLE" set without cluster
                                  #  - same for materialized views
                                  #"TABLE" can be omitted to specify all "TABLE" having used cluster.

create table ...                  #Cache ROW inserts, for speed
 with (buffering = on|off|auto)   #If auto (def): when INDEX size > ENVVAR effective_cache_size
                                  #For gist INDEX only

create table ...                  #If on (def), faster writes, but slower reads
 with (fastupdate = on|off)       #For gin INDEX only


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          EFFICIENCY           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


PARTITIONS ==>                    #Parts (sets of rows) of a TABLE, used for improved performance (when querying, altering or deleting a
                                  #whole partition (e.g. drop "TABLE" is faster than delete "TABLE" where BOOL)).
                                  #There is:
                                  #  - an empty parent TABLE
                                  #  - partitions are children TABLE... with:
                                  #    - same "COL"...
                                  #    - a check CONSTRAINT to restrict to a specific set of row
                                  #    - an INDEX on the COL on which the CONSTRAINT is based.
                                  #  - a trigger FUNC that redirects data inserted in the parent TABLE to the correct child
                                  #  - Partitions should not overlap, and should together cover the whole data.

prepare PREP([TYPE...])           #Parse COMMAND to make it faster to use later, if complex and often used COMMAND.
as COMMAND                        #Must be used with execute PREP(...):
execute PREP(...)                 #  - Each TYPE can be specified in COMMAND as positional argument $NUM
                                  #  - execute PREP(...) supply those arguments
                                  #  - last TYPE... can be "unknown", meaning "anyelement" (can still be used as $NUM), providing it
                                  #    can be determined runtime
                                  #  - no overloading
                                  #COMMAND must be select|insert|update|delete|values
                                  #No problem of caching: PREP will be reparsed if:
                                  #  - used TABLE (including COLs) change types
                                  #  - search_path changes
deallocate PREP|all               #Delete a PREP.
                                  #deallocate all is automatically done at end of each session.

LARGEOBJECT ==>                   #Efficient way to manipulate big VAL (based on a file):
                                  #  - can manipulate only through OID
                                  #  - can read/write/seek (see online doc) like in C
lo_import(STR)                    #Creates a LARGEOBJECT from file at path STR, and returns its OID
lo_export(OID, STR)               #Creates a file at path STR with LARGEOBJECT with OID
lo_unlink(OID)                    #Needs to unlink LARGEOBJECT after use
                                 ##Instead of unlinking manually, could create a TFUNC executing lo_manage(COL_OID) on TABLE containing
                                 ##LARGEOBJECT as OID, before update or delete, for each row. Should delete * from table before dropping
                                 ##a TABLE to keep the trigger.
                                 ##Postgres extension 'lo'
                                 ##Command-line vacuumlo DATABASE (with connection options) can also be used.

explain([verbose,]                #Display the query tree of COMMAND:
 [analyze, [buffers,]             #  - nodes can be:
 [timing false,]]                 #     - Sort: order by ...
 [costs false,]                   #     - Limit: offset|fetch
 [format text|xml|json|yaml])     #     - Aggregate: AFUNC
 COMMAND                          #     - GroupAggregate: group by
                                  #     - HashAggregate: some AFUNC
                                  #     - WindowAgg: WFUNC
                                  #     - Filter: where TEST (or having)
                                  #     - Join: can be:
                                  #        - Nested loop, with a Join Filter: normal one
                                  #        - Hash, with a Hash Cond: involves an extra Hash step (compare hashes)
                                  #        - Merge join, compare both TABLE next to each other (must be sorted)
                                  #     - bottom only:
                                  #        - sequential scan: linear read of TABLE
                                  #        - index scan: using an INDEX, then visiting the TABLE
                                  #          - index-only scan: using an INDEX, and no need to visit the TABLE to answer the query
                                  #        - bitmap scan:
                                  #           - using an INDEX with first a Bitmap Index Scan on the INDEX
                                  #           - then fetching the TABLE with a Bitmap Heap Scan
                                  #           - difference with index scan: fetch all INDEX, then all TABLE, and not row by row INDEX
                                  #             then TABLE (index scan)
                                  #           - if using several INDEX, will do a BitmapAnd or BitmapOr
                                  #        - values scan: values(...)
                                  #  - each node include the cost|resources of its children
                                  #Options:
                                  #  - analyze: show the actual time (unless timing false is used) and memory consumed
                                  #    Actually execute the COMMAND (otherwise, it is not) (can put in a transaction with rollback if
                                  #    don't want the execution to persist)
                                  #    - buffers: show info about buffer hits, which shows which parts are I/O intensive
                                  #  - costs (def: true):
                                  #    - show the resources taken, in a cost-based approach according to ENVVAR:
                                  #       - seq_page_cost (def: 1): sequential disk page fetch (used in sequential scan)
                                  #       - random_page_cost (def: 4): non-sequential disk page fetch (used in INDEX retrieval)
                                  #         Put at 2-3 if fast disks.
                                  #       - cpu_tuple_cost (def: 0.01): CPU cost for processing a row
                                  #       - cpu_index_tuple_cost (def: 0.005): CPU cost for processing a row in an INDEX
                                  #       - cpu_operator_cost (def: 0.0025): CPU cost for processing a FUNC
                                  #    - values are:
                                  #       - cost: first is initial cost, second is final cost
                                  #       - rows: number of rows manipulated
                                  #       - width: average size (in bytes) of a row
                                  #Advice:
                                  #  - use real data close to real environment, not test ones.
                                  #  - run analyze first if lot of change since last time autovacuum did (because based on pg_statistic)

create tablespace "TABLESPACE"    #Create a TABLESPACE, i.e. a group of DATABASE, TABLE, MATERIALIZED VIEW and INDEX:
 [owner ROLE]                     #  - located on the disk at a specific location STR (must be empty dir)
 location STR                     #  - owned by ROLE (def: current ROLE)
                                  #Must be a superuser to do it.
                                  #Goal:
                                  #  - Unlike SCHEMA, can't be used for permissions.
                                  #    Only permission is create, i.e. possibility to assign a newly created VAR to TABLESPACE
                                  #  - is used to control the physical locations of database objects, in order to:
                                  #     - optimize performance, e.g. putting heavily used INDEX on fast storage
                                  #     - optimize space, e.g. put heavy space DATABASE on high-volume storage, with possibility to move
                                  #       to another is space is not enough anymore
                                  #Is cluster-wide, so can be assigned to objects of different DATABASE.
                                  #Each new VAR has as a TABLESPACE (unless explicity mentionned):
                                  #  - if cluster-wide object, pg_global
                                  #  - otherwise the default TABLESPACE of the database.
                                  #    It is inherited from its template (pg_default for template0|1), but can be overriden by:
                                  #     - if TEMP or INDEX on TEMP, ENVVAR_ARR temp_tablespace: if used as an ARR, allocate randomly
                                  #       accross TABLESPACE...
                                  #     - otherwise, ENVVAR default_tablespace
                                  #Symlinks to DIR of user-created TABLESPACE can be found in DATADIR/pg_tblspc
drop tablespace "TABLESPACE"      #Can only be done if empty

create table|materialized view ...
 tablespace "TABLESPACE" ...
create index ...
 tablespace "TABLESPACE"
 [where ...]
create database
[with] tablespace [=] "TABLESPACE"#Set ENTITY TABLESPACE on creation

create table ...
 exclude|unique|primary key ...
 using index tablespace "TABLSPAC"#Set TABLESPACE of CONSTRAINT's INDEX

alter ENTITY "ENTITY" ...         #Set TABLESPACE of one ENTITY. Moves the data files.
 set tablespace "TABLESPACE"      #For ENTITY: table, materialized view, index, database

alter ENTITY                      #Set TABLESPACE2 of all ENTITYs in a given TABLESPACE
 all in tablespace "TABLESPACE"   #For ENTITY: table, materialized view, index
 [owned by ROLE,...]              #Only ones owned by ROLE,...
 set tablespace "TABLESPACE2"
 [nowait]                         #All ENTITYs are locked.
                                  #If nowait, uses lock ... nowait, i.e. fail if cannot lock right away

create table ...                  #Keep 1-INT% additional free space on the page storing TABLE
 with (fillfactor = 10-100)       #Def: 100, i.e. none
                                  #Goal: faster memory allocation if lots of updates

WRITING ==>                       #Best way to write a big amount of data fast:
                                  #  - put in only one transaction/statement
                                  #  - use copy or (if copy not possible) prepare, if possible on an empty TABLE
                                  #  - create the INDEX and foreign keys constraints after the data has been put into
                                  #     - when doing so, increasing ENVVAR maintenance_work_mem INT, max. memory used by vacuum,
                                  #       create INDEX and foreign key constraint creation (def: '16MB')
                                  #  - less checkpoints (increasing ENVVAR checkpoint_segments and checkpoint_timeout)
                                  #  - temporarily disabling WAL or replication
                                  #Should run analyze afterwards.

PERFORMANCE ==>                   #Can:
                                  #  - disable durability, by:
                                  #      - putting fsync and full_page_writes off (risky)
                                  #      - putting synchronous_commit off (more durable and almost same performance gain)
                                  #  - less checkpoints (see below)

PERFORMANCE TUNING ==>            #ENVVAR:
                                  #  - work_mem (def: 1MB): max memory used by a single command for each of its sort operations and hash
                                  #    tables, before writing temp files to disk.
                                  #    Average total memory taken will be average_number_of_hash/sort_operations_by_command *
                                  #    number_of_connections * work_mem. Should not be more than RAM taken by:
                                  #      kernel + other applications + shared_buffers + let memory for kernel buffer
                                  #  - maintenance_work_mem (def: 16MB): max memory used by vacuum, create index and add foreign key.
                                  #    Usually not a lot of those operations are run concurrently, so can be set higher (256MB is good)
                                  #  - effective_cache_size (def: '128MB'): hint of the amount of cache available for queries
                                  #    (doesn't change the actual cache size). Should be 50-75% of the available free+cached HDD memory
                                  #  - wal_buffers (def: -1, which auto-select a value): memory used for caching WAL, i.e. number of
                                  #    WAL segments (16MB) that can be cached for all sessions before flushing them.
                                  #    If high number of transactions, might consider increasing for better performance.
                                  #    Best is 16MB.
                                  #  - max_stack_depth (def: 2MB):
                                  #     - higher can provoke stack overflow (crashing the server) if higher than the kernel limit, with
                                  #       a safety margin of 2MB
                                  #       current OS limit can be seen with ulimit -s (8MB)
                                  #     - lower can cancel complex queries requiring more stack.
                                  #  - temp_file_limit (def: -1, unlim): max memory for temp files, in KB
                                  #  - max_files_per_processes (def: 1000): max opened files per session (see limit with ulimit -S|H -n)
                                  #    Def on Linux: 1024, so that's good.
                                  #  - effective_io_concurrency: when using several disks at same time (e.g. RAID), number of disks that
                                  #    can write at same time
                                  #  - shared_buffers (def: 128MB): memory for shared buffers (def: 128MB).
                                  #    Good value is 25% of RAM (if > 1GB total RAM)
                                  #Look at amount of memory taken with pgcluu or pgbadger
pgtune -i FILE                    #Checks postgresql.conf FILE, and prints an optimized version (mostly for performance ENVVAR)
                                  #Can do -o FILE2, but should pipe it to diff - FILE, to see differences.
-M NUM                            #Total memory in bytes (def: guess it)
-c NUM                            #Number of connections expected (change max_connections and work_mem)
-T WORD                           #Type of application, among DW (OLAP), OLTP, Web or Desktop. Def is Mixed (-> unspecified)
                                  #Desktop assumes lower cache, mem and connections, DW moderate, and Web and OLTP very high.

HARDWARE ==>                      #  - more RAM -> more cache
                                  #  - good hard drives. RAID0 or RAID1 is good idea
                                  #  - CPU less important, but still important for complex functions

pgbench                           #Does a benchmark, to compare machines or server conf speed.
                                  #Must first do a pgbench -i to initialize it (creates four pgbench_* tables), with following options
                                  #while initializing:
-F NUM                            #Percentage of not-null in pgbench_* tables (def: 100)
-s NUM                            #Multiply default number or rows in pgbench_* tables. Should be at least >= -c NUM
--[index-]tablespace=TABLESPACE   #Use a custom TABLESPACE for tables or indexes (to do if used in production)
--unlogged-tables                 #Create pgbench_* as unlogged tables
                                  #While not initializing:
                                  #  - tps is transactions per seconds.
                                  #  - has following options:
-h -p -U                          #Connection options (see psql)
-c NUM                            #Number of concurrent connections. Should be close to average in real production.
-t NUM                            #Number of transactions per client. Higher gives more precision.
                                  #Should be high enough to run few minutes
-j NUM                            #Number of threads
-n -f FILE                        #Execute SQL FILE, instead of default one (simple update, select and insert statements)
                                  #Can include commands:
                                  #  - \setrandom "INT" MIN MAX
                                  #  - \setshell "INT" COMMAND ARGS
-S                                #Perform only select statements
-r                                #Show execution time for clients, per statements.

OTHERS ==>                        # - TABLE fillfactor, fastupdate


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:     USERS AND PRIVILEGES      :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


ROLES ==>                         #ROLE are users or group of users for a given cluster.
                                  #Difference between OS_USER (OS-specific) and ROLE (cluster-specific).
                                  #Default installation creates a OS_USER "postgres", with group "postgres", often used as owner of
                                  #clusters.
                                  #Each cluster has a superuser ROLE:
                                  #  - defined as the owner OS_USER (user that created the cluster using initdb)
                                  #  - should have OS permissions over the DATADIR of the cluster
                                  #By default, client connects as ROLE using OS_USER, but can use flags to do otherwise.
                                  #  - so anyone that can login as the owner OS_USER of a cluster on a local computer can be superuser
                                  #    ROLE too.
                                  #ROLE own VAR they create.

create role ROLE                  #Create a ROLE:
[superuser]                       #  - superuser: creates another superuser ROLE (must be superuser ROLE)
[createdb|role]                   #    Cannot drop the initial superuser ROLE.
[[encrypted] password STR]        #    readonly ENVVAR is_superuser ('on|off') is available.
[login] [replication]             #  - createdb|role|login|replication: gives createdb|role|login|replication privilege (see PRIVILEGE)
[connection limit INT]            #  - password STR:
[noinherits]                      #     - either plaintext or "md5STR" where STR is a md5 hash.
[valid until TIMTMPTZ]            #     - If encrypted is specified, STR must be plaintext -> it is converted to a "md5STR".
[in role ROLE2...]                #     - can be null for no password.
[role passwordcheck ROLE2...]     #     - only useful with authentication methods with passwords (i.e. "password" and "md5")
[admin ROLE2]                    ##     - will cancel if password is weak.
                                 ##       Must also put '$libdir/passwordcheck' in shared_preload_libraries.
                                 ##       Will not work on md5 hashes, only plaintext.
                                 ##       It is recommended to rebuild the module by modifying the Makefile to enable CrackLib
                                 ##       (better weak password recognition). Must be enabled at buildtime anyway.
                                 ##     - report password failure after ENVVAR auth_delay.milliseconds (def: 0), to avoid bruteforce
                                 ##       (but makes DDoD easier).
                                 ##       Must put auth_delay in shared_preload_libraries
                                 ##        - Postgres extension 'auth_delay'
                                  #  - valid until TIMESTAMPTZ: validity of the password
                                  #  - in role ROLE2...: grants ROLE as a member of ROLE2... (prefer using grant|revoke)
                                  #  - role ROLE2...: inverse
                                  #  - admin ROLE2...: same as role ROLE2, but ROLE2 are added with admin_option
                                  #  - connection limit: how many connections at same time (def: -1, unlim)
                                  #  - noinherits: see grant|revoke
alter role ROLE ...               #Can be all options of create role but:
                                  #  - can use no..., e.g. nosuperuser
                                  #  - no in role, role or admin
alter ENTITY "ENTITY"             #Set owner
 owner to ROLE                    #ROLE can be current_role, current_user or session_user
                                  #Not for ENTITY: extension, group, index, policy, role, rule,
                                  #text search parser|template, trigger, user, user mapping
                                  #Also for pseudo-ENTITY: large object OID
drop role ROLE...                 #Drop ROLE and cluster-specific objects owned by ROLE.
                                  #Doesn't work if ROLE own database-specific objects (use reassign|drop owned by ROLE first) or
                                  #privileges.
                                  #If client connection, doesn't stop it.
drop owned by ROLE...             #Drop all objects (except cluster-specific objects) owned by ROLE, and
[restrict|cascade]                #revoke privileges given to ROLE.
reassign owned
by ROL... to ROLE2                #Change ownership.

drop role ...                     #Can only be done if not used by any DATABASE

set [local] role ROLE             #Same syntax as set, but here change current ROLE
                                  #If not superuser, must be a ROLE that the session_user is member of (but not inverse, not other
                                  #members of same ROLE), directly or indirectly.
                                  #There are two types of users:
                                  #  - current user: current ROLE. Used for permission checking.
                                  #  - session user: ROLE that (usually) started the session.
                                  #    Used to switch roles with set role and set session authorization.
                                  #    So for a session, can switch back and forth between same possible ROLE (as long as set
                                  #    session authorization is not called)
                                  #VAR session_user (one that started the session) and current_user are available.
                                  #If ROLE is none, reset to current session_user.
                                  #ROLE can be written as STR
                                  #  - local: same as set local ...
set [local] session               #Same but:
authorization ROLE                #  - for both session_user and current_user
                                  #  - must be superuser
                                  #  - use default to reset to initial session_user

grant PRIVILEGE...                #Gives permissions PRIVILEGE... on VAR... to ROLE...:
on [TYPE] VAR...                  #  - TYPE:
to ROLE...                        #     - is table (def)|sequence|database|domain|function|language|schema|tablespace|type|
[with grant option]               #       large object|foreign data wrapper|foreign server
                                  #         - table include VIEW and FOREIGNTABLE
                                  #     - [TYPE] VAR can be all TYPEs in schema SCHEMA for table|sequence|function
                                  #  - PRIVILEGE:
                                  #     - can be:
                                  #        - on table:
                                  #           - insert (a): insert or copy from
                                  #           - delete (d): delete
                                  #           - truncate (D): truncate
                                  #           - references (x): needed on both TABLE to use foreign key
                                  #           - trigger (t): create trigger
                                  #        - on table|sequence|large object:
                                  #           - select (r):
                                  #              - select, copy or using VAR in update|delete
                                  #              - sequence: same + currval()
                                  #              - large object: being read
                                  #           - update (w)
                                  #              - update, select for share|update
                                  #              - sequence: same + nextval|setval()
                                  #              - large object: being written
                                  #        - on sequence|domain|foreign data wrapper|foreign server|language|schema|type:
                                  #           - usage (U):
                                  #              - language:
                                  #                - create function for this PL/* language
                                  #                - careful if functions can access OS (e.g. Bash)
                                  #              - schema: reading VAR in SCHEMA (without permission can still look up VAR names in
                                  #                SCHEMA)
                                  #              - sequence: currval() + nextval()
                                  #              - type|domain: using it in creation of any VAR (including FUNC() and TABLE)
                                  #              - foreign data wrapper: create server using FDW
                                  #              - foreign server: create foreign table using FSERVER
                                  #        - on database:
                                  #           - connect (c): can start client session
                                  #           - temp (T): create temp
                                  #        - on database|schema|tablespace:
                                  #           - create (C):
                                  #             - database: create schema
                                  #             - schema: create any VAR inside SCHEMA, and rename (must be owner too)
                                  #             - tablespace: create table|index|temp in it, and use TABLESPACE in create database
                                  #        - on function:
                                  #           - execute (X): executing *FUNC() (including TFUNC())
                                  #        - on all:
                                  #           - all privileges
                                  #     - Other PRIVILEGE which can be obtained differently:
                                  #        - drop|alter:
                                  #           - no way to grant them to others:
                                  #              - drop or alter definition of VAR:
                                  #        - grant|revoke:
                                  #           - grant PRIVILEGE ... with grant|admin option:
                                  #              - grant for PRIVILEGE for the specific PRIVILEGE and TYPE
                                  #              - admin for ROLE membership
                                  #        - createrole:
                                  #           - create|alter role ... createrole:
                                  #              - create role (or drop|alter)
                                  #              - To do so on superuser ROLE, must be superuser.
                                  #              - implies admin option
                                  #              - can create roles with higher permissions or memberships, so can be dangerous
                                  #        - createdb:
                                  #           - create|alter role ... createdb:
                                  #              - create database (or drop|alter)
                                  #        - login:
                                  #           - create|alter role ... login:
                                  #              - ROLE can initiate a client session (e.g. with psql)
                                  #                Without it (def) ROLE can only be assigned with set role ROLE
                                  #        - replication:
                                  #           - create|alter role ... login:
                                  #             - ROLE can use pg_basebackup
                                  #     - PRIVILEGE can be PRIVILEGE("COL"...) for select|insert|update|references
                                  #     - Def. PRIVILEGE is all for TABLE owner and superuser.
                                  #       They can revoke their own privileges though.
                                  #     - Permissions are optimistic: has privileges in following cases:
                                  #        - granted at table-level but revoked at column-level
                                  #        - granted to ROLE2 to which is member, but revoked to the specific ROLE
                                  #     - SQL only has VAR, not VAR...
                                  #  - ROLE:
                                  #     - if ROLE2 is a member of ROLE (directly or indirectly), it is targeted too:
                                  #         - generally ROLE is just a group name, and ROLE2 real users, or subgroups
                                  #         - but could also copy and extend|restrict permissions of another user
                                  #         - inherit:
                                  #           - by def., ROLE2 inherit privileges of ROLE (except "Other PRIVILEGE")
                                  #           - with noinherits, can still use set role ROLE (but then loses its inital PRIVILEGE)
                                  #     - can be public:
                                  #        - meaning all current and future ROLE.
                                  #        - cannot be member of a ROLE.
                                  #        - has default privilege: connect, temp, usage and create on SCHEMA public, execute, usage on
                                  #          LANGUAGES. Can be revoked.
                                  #     - If current user is superuser or can grant thanks to membership or "with grant option", looks
                                  #       like PRIVILEGE has been granted by VAR owner
                                  #Access controls:
                                  #  - are recorded in the database objects they are attached (using system catalogs) as ACLITEM_ARR,
                                  #    i.e. [ROLE]=LETTER.../ROLE2, where ROLE is the granted (def: public), ROLE2 the granter and
                                  #    LETTER shown above between parenthesis for each PRIVILEGE.
                                  #  - Each LETTER can be followed by * for "with grant option"
                                  #  - don't show default PRIVILEGE
revoke [grant|admin               #Inverse.
option for] PRIVILEGE...          #"with grant|admin option" is revoked too. If "grant|admin option for", only "with grant|admin option"
on [TYPE] VAR...                  #is removed.
from ROLE...                      #Revoke privileges granted to others by ROLE2 too: if restrict, command will fail if there are some
[restrict|cascade]                #ROLE can only revoke ROLE2 for PRIVILEGE it previously personnally granted the other or a ROLE the
                                  #other is member of.

alter default privileges          #Change default PRIVILEGE for ROLE2 (in ...) of all VAR (write TYPEs, not TYPE VAR) that will be
[for ROLE...]                     #created in the future by ROLE (must be current user (def) or a ROLE3 that ROLE is member of), in
[in schema SCHEMA]                #SCHEMA (if specified)
grant|revoke...                   #Only for TABLE, SEQUENCE, FUNC or TYPE.

grant ROLE... to ROL2...          #
[with admin option]               #
revoke [admin option
for] ROL... from ROL2...          #Grant|revoke ROLE2... as members of ROLE...
[restrict|cascade]                #Gives|revokes associated PRIVILEGE too.

security label [for PROVIDER]
 on VAR is STR                    #Used to implement SE-Linux (see online doc)

has_TYPE_privilege                #TYPE can also be:
 ([ROLE, ]VAR, PRIVILEGE)         #  - any_column
                                  #  - column: adds a "COL" arg after VAR
pg_has_role
 ([ROLE, ]ROLE2, PRIVILEGE)       #With membership


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:        AUTHENTICATION         :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


pg_hba.conf                       #File under a cluster DATADIR controlling:
                                  #  - who can connect (host address, OS_USER)
                                  #  - to which database
                                  #  - with which connection method
                                  #  - under which ROLE
                                  #Have five whitespaces-separated fields (can contain whitespace if double-quoted) (with #Comment):
                                  #  - type (protocol):
                                  #    - local: local connection (Unix sockets)
                                  #    - host: TCP/IP
                                  #    - host[no]ssl: TCP/IP with|without SSL. For SSL:
                                  #       - must set ENVVAR ssl to "on" (def: "off") at server start
                                  #       - must have been enable when installing|building PostgreSQL
                                  #  - database:
                                  #    - connect to which DATABASE... (comma-separated)
                                  #    - sameuser means DATABASE with same name as ROLE
                                  #    - samerole means DATABASE with same name as ROLE or a member of ROLE
                                  #    - replication: special DATABASE used by pg_basebackup
                                  #    - @FILE... means list of DATABASE is available under DATADIR/FILE (if relative) or FILE (if abs.)
                                  #    - can be all
                                  #  - user:
                                  #    - under which ROLE... (comma-separated) can connect
                                  #    - +ROLE means any member of ROLE
                                  #    - @FILE... means list of ROLE is available under DATADIR/FILE (if relative) or FILE (if abs.)
                                  #    - can be all
                                  #  - address:
                                  #    - which IPv4|6 addresses (along the netmask range) can connect
                                  #    - can also be a hostname (can be slow)
                                  #      - including a .DOMAINNAME for hosts under DOMAINNAME
                                  #    - can be all
                                  #    - samehost: any of the machine own IPs
                                  #    - samenet: any of the machine own subnet
                                  #  - netmask (optional):
                                  #    - IPv4|v6 netmask
                                  #  - auth. method:
                                  #    - trust|reject: always accept|refuse
                                  #    - ident [map=MAP]:
                                  #      - use MAP in pg_ident.conf (ENVVAR ident_file) to determine which ROLE correspond to OS_USER
                                  #      - def: ROLE = OS_USER
                                  #    - password|md5: ask for password (md5 hashes it but not crypto-secure)
                                  #      - libpq variable password:
                                  #         - To use if is demanded. Def: PGPASSWORD
                                  #         - Can also use a FILE PAGPASSFILE (def: ~/.pgpass), which should contain lines with format:
                                  #             host:port:database:user:password (first four field can be *)
                                  #           Permission must be 0600
                                  #    - SSL:
                                  #      - libpq variables:
                                  #        - sslmode: priority of SSL over non-SSL (def: PGSSLMODE):
                                  #          - disable: non-SSL
                                  #          - prefer (def): first SSL, then non-SSL
                                  #          - require: SSL. If root CA, verify certificate
                                  #          - verify-ca: SSL. Always verify certificate
                                  #          - verify-full: SSL. Verify certificate, and that hostname match in certificate
                                  #        - sslcert: certificate FILE (def: ~/.postgresql/postgresql.crt or PGSSLCERT)
                                  #        - sslkey:
                                  #          - Secret key (def: ~/.postgresql/postgresql.key or PGSSLKEY).
                                  #          - Can also be OpenSSL engines, as ENGINE:KEY
                                  #        - sslrootcert: CA certificate FILE (def: ~/.postgresql/root.crt or PGSSLROOTCERT)
                                  #        - sslcrl: CA revocation list FILE (def: ~/.postgresql/root.crl or PGSSLCRL)
                                  #    - krb5: Kerberos5
                                  #      - libpq variable krbsrvname: Kerberos server name (def: PGREALM or PGKRBSRVNAME)
                                  #    - GSSAPI:
                                  #      - libpq variable gsslib: on Windows, set to "gssapi" to use GSSAPI instead of SSPI
                                  #        (def: PGGSSLIB)
                                  #  - auth. method options (optional):
                                  #    - as VAR=VAL ...
                                  #    - see above
                                  #Default settings:
                                  #  - host and local connections: initdb --auth-host|local=STR (or -A STR for both)
                                  #  - default password: initdb -W|--pwfile=FILE, from stdin or from first line of FILE (if using
                                  #    password authentication)
                                  #Only the first matching line is chosen. Put most likely first for efficiency.
                                  #Location can be changed by ENVVAR hba_file
                                  #Read on server startup, or when receiving a SIGHUP.

requirekeeper                     #LIBPQ variable: OS_USER behind the server process must match STR.
                                  #Avoid another OS_USER starting the server while legit one is rebooting it.


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:         LOCALIZATION          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


ENCODING ==>                      #Sets within a cluster with initdb -E STR, which sets client_encoding ENVVAR, encoding of templates:
                                  #  - can be many, among 'LATIN1', 'UTF8' and 'SQL_ASCII'
                                  #  - Def. is locale (UTF8 in Linux) or SQL_ASCII if no locale.
                                  #If client has different encoding, a conversion is performed according to pg_conversion
                                  #(see online doc).
                                  #Available conversions from UTF8 should be enough. Otherwise can do:
                                  #  - create conversion CONVERSION for STR to STR2 from FUNC
                                  #Encoding is sometimes specified as INT: use pg_encoding_to_char(INT) to get it as a STR
                                  #server_encoding ENVVAR is available

LOCALES ==>                       #Use ENVVAR lc_*, that are usually set at cluster creation with initdb --lc-*=LOCALE.
                                  #lc_collate|ctype (unless using COLLATION) and encoding can't be changed after database creation
                                  #Def. is "", i.e. locale (en_US.UTF-8 e.g.) or SQL_ASCII if no locale.
                                  #Locales are server-dependent, not client-dependent.
                                  #Non-C locales allow local-dependent on some operations:
                                  #  - sorting: order by, < > >= <=
                                  #  - case: upper, lower, initcap, regexps
                                  #  - [[:...:]] in regexps
                                  #  - to_char()
                                  #C locale is faster and the only one that can use INDEX on like operator.

convert(STR, STR2, STR3)          #Encoding conversion. STR is string to convert.
convert_to|from(STR, STR2)        #Same, but assumes the dest|original encoding to be the current system's encoding
pg_client_encoding()              #Current encoding


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           COLLATION           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


COLLATION ==>                     #Combination of lc_collate and lc_ctype, specified as "lang_LANG[.ENCODING]":
                                  #  - are used by doing:
                                  #     - VAL collate "..." (e.g. "fr_FR")
                                  #     - TYPE collate "..."
                                  #  - cannot mix different COLLATION in same statement
                                  #  - prefer without ENCODING, which then let pg_collation use current ENCODING
                                  #Creating COLLATION:
                                  #  - available can be seen with pg_collation
                                  #  - populated by initdb with available locales on the OS
                                  #  - using create collation ...
create collation COLLATION
 ([locale = LOCALE]
 [, lc_collate|ctype = LOCALE])   #LOCALE is a shortcut for both lc_collate and lc_ctype
create collation
 COLLATION from COLLATION2        #

collation for (STR)               #Returns COLLATION

create table "TABLE"
 ("COL" TYPE collate COLLATION)   #
create table ...
 partition by ... ("COL"|(REXPR)
 collate COLLATION ...)           #


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          EXTENSIONS           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


create extension                  #Activate an EXTENSION, i.e. a collection of objects (library), except DATABASE, ROLE, INDEX and
EXTENSION                         #TABLESPACE, for a specific DATABASE.
[schema SCHEMA]                   #STR is the version (def: the one in the default_version)
[version STR]                     #SCHEMA is for objects defined in EXTENSION (default: current SCHEMA)
                                  #Some EXTENSIONs are already present in the default compilation of PostgreSQL, or personalized
                                  #compilations (but usually not activated).
                                  #Permissions are the ones required in executing the underlying SQL file.
                                  #Files must already be present in SHAREDIR/extensions/:
                                  #  - a SQL file "EXTENSION--VERSION.sql" defining new ROW, FUNC, etc.:
                                  #     - implicitly inside a transaction, so cannot use transaction statements
                                  #     - do select pg_extension_config_dump(STR, STR2); for a TABLE named STR used for users to
                                  #       personalize the extension.
                                  #       It will make the TABLE backupable, as opposed to rest of EXTENSION.
                                  #       STR is a filter, e.g. 'where BOOL' or ''.
                                  #     - should include protective lines:
                                  #       -- complain if script is sourced in psql, rather than via CREATE EXTENSION
                                  #       \echo Use "CREATE EXTENSION pgrowlocks" to load this file. \quit
                                  #  - an ASCII text file "EXTENSION.control" defining metadata as VAR = VAL ..., with #comment possible:
                                  #     - default_version STR: current version
                                  #     - relocatable BOOL (def: false): if SCHEMA can be changed after create extension
                                  #     - comment STR: description
                                  #     - directory STR: DIR of the SQL file (def: same as *.control file)
                                  #     - encoding STR (def: client's encoding): to be defined in no ASCII characters
                                  #     - module_pathname STR:
                                  #       - can be used as MODULE_PATHNAME in the *.sql file
                                  #       - can use $libdir, e.g. '$libdir/myextension'
                                  #     - requires STR...: other extensions this one depends on
                                  #     - superuser BOOL (def: true): if only superuser can create extension
                                  #     - schema STR: def. SCHEMA (only if non-relocatable)
                                  #  - additional EXTENSION--VERSION.control with same format but for a specific VERSION can be defined
                                  #  - additional EXTENSION--VERSION--VERSION2.sql are executed to go through VERSION to VERSION2 with
                                  #    alter extension update
alter extension EXTNSIN
add|drop TYPE VAR                 #

load STR                          #Loads a shared library located at STR, in order:
                                  #  - an absolute path
                                  #  - or look into ENVVAR dynamic_library_path, which a colon-separated list (def: $libdir),
                                  #    where items can start with $libdir (def: /usr/lib/postgresql/9.3/lib/)
                                  #    (can be seen with pg_config --pkglibdir)
                                  #If not superuser, must be inside $libdir/plugins/
                                  #STR path convention is OS-specific.
                                  #Not useful if only functions definitions because they are loaded automatically with create function...
                                  #Can also use ENVVAR shared_preload_libraries (comma-separated list), without the extension .so

create foreign data               #Creates a FDW, i.e. functions that permits using another DBMS inside PostgreSQL.
wrapper FDW                       #Can be slow and not optimized.
[handler FUNC]                    #Based on a standard implemented by other DBMS, including noSQL.
[validator FUNC2]                 #FUNC and FUNC2: see doc. on how to create them.
[options (VAR STR ...)]           #Must be superuser.
                                  #Available ones (as EXTENSION):
                                  #  - postgres_fdw: for PostgreSQL to other DBMS
                                  #     - FSERVER options (can also use libpq variables)
                                  #        - host STR
                                  #        - dbname STR
                                  #        - port STR
                                  #     - user mapping options:
                                  #        - user STR
                                  #        - password STR
                                  #        - client_encoding STR (def: ENVVAR client_encoding)
                                  #     - FTABLE options:
                                  #        - schema|table|column_name STR: if name is different
                                  #     - FSERVER or FTABLE options!
                                  #        - updatable BOOL (def: true): read-write
                                  #     - details:
                                  #        - transaction read committed -> repeatable read
                                  #  - file_fdw: for CSV file (or other formats of copy COMMAND), read-only:
                                  #     - FTABLE options:
                                  #        - filename STR: absolute path
                                  #        - ...: same options as copy COMMAND, except force* and oids
alter foreign data wrapper FDW
[no handler|handler FUNC]         #
[no validator|validator FUNC]     #
options
 ([add|set|drop] VAR VAL ...)     #

create server FSERVER [type STR]
[version STR2]                    #Creates a FSERVER, i.e. a connection to a specific DATABASE using a FDW.
foreign data wrapper FDW          #STR are all FDW-dependent options. They usually specify the connection details
[options (VAR STR3...)]           #(host and port, database name, etc.)
alter server FSERVER
[version STR]
[options
 ([add|set|drop] VAR STR2...)]    #

create user mapping
for ROLE|current_user
server FSERVER                    #Specify authentication details on FSERVER for ROLE.
[options (VAR STR ...)]           #STR are all FDW-dependent options.
alter user mapping ...
[options ([add|set|drop] ... )]   #

create foreign table "FTABLE"
 ("COL" TYPE
 [options (VAR STR ...)]
 CONSTRAINT|not null|
 default VAL ...)                 #Creates a FTABLE (can be used as a TABLE) while connected to a FSERVER.
server FSERVER                    #TABLE, COL, TYPE, CONSTRAINT, etc. should be same as on FSERVER, unless specified in the options.
[options (VAR STR2 ...)]          #But can only select some of the foreign COL.

alter foreign table "FTABLE"
 rename "COL" to "COL2"           #

alter foreign table "FTABLE"
 add COL_ARG                      #

alter foreign table "FTABLE"
 drop [if exists] "COL"
 [restrict|cascade]               #

alter foreign table "FTABLE"
 alter "COL" type TYPE            #

alter foreign table "FTABLE"
 alter "COL" set|drop
 not null|default [VAL]           #Same as alter table ...

alter foreign table "FTABLE"
 [alter "COL"] options
 ([add|set|drop] VAR VAL ...)     #

                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:      SYSTEM COLS/TABLES       :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


SYSTEM COLS ==>                   #Hidden COL... defined for every TABLE
                                  #ctid, etc. are used for MVCC
"TABLE".tableoid                  #OID of the TABLE
"TABLE".oid                       #ID row, doesn't change with update, but created by insert.
                                  #Table-specific: cross join with tableoid to have real IDs.
                                  #Creation:
                                  #  - ENVVAR default_with_oids = true (def: false)
                                  #  - create table ... with[out] oids
                                  #  - alter table TABLE set with[out] oids
                                  #Is actually a cycling number incrementing from 1, database-wise.
"TABLE".ctid                      #Same but change avec committed update or insert
                                  #Is actually a cycling number incrementing from 1, table-wise.
"TABLE".cmin|cmax                 #Same but change avec uncommitted update or insert (put back to 0 when ctid changes)
                                  #Is actually the numero of the statement inside the transaction.
"TABLE".xmin                      #ID of the transaction inserting (table-wise, not client-wise)
"TABLE".xmax                      #ID of the transaction deleting or updating this row by another non committed transaction.

SYSTEM CATALOGS ==>               #TABLE used by the system. Can also be VIEW (system views)
                                  #Are sometimes readonly. Anyway, should not modify them directly unless good reasons (e.g. creating a
                                  #new INDEX_METHOD).
                                  #Are database-specific unless on cluster-specific VAR
INFORMATION SCHEMA ==>            #Same but is SQL standard: more portable but does not contain all information.
                                  #Is in SCHEMA information_schema.*, written is_* below
                                  #Most of them not written here, look at online doc if needed

pg_database                       #All DATABASE, including:
                                  #  - datistemplate BOOL: can be used in create database template DATABASE
                                  #  - datallowconn BOOL: if false, no one can connect to it

pg_class                          #All TABLE-like elements: TABLE, VIEW, INDEX, SEQUENCE, MVIEW and ROW, including:
                                  #  - relisshared BOOL: if cluster-wide
pg_tables                         #All TABLE
pg_views                          #All VIEW
pg_matviews                       #All MVIEW
pg_index                          #All INDEX
pg_indexes                        #Same but with other infos, like the query that created it.
is.sequences                      #All SEQUENCE
pg_attribute                      #All COL, including:
                                  #  - attisdropped BOOL: dropped COL but physically kept
pg_attrdef                        #Default values for COL that have some
pg_constraint                     #All CONSTRAINT
pg_inherits                       #Inheritance between TABLE

pg_[sh]depend                     #Relations between [cluster-wide] objects, to avoid conflicts when dropping an object.
pg_locks                          #All currently held locks

pg_proc                           #All FUNC
pg_aggregate                      #All AFUNC
pg_trigger                        #All TFUNC
pg_event_trigger                  #All EFUNC
pg_operator                       #All OPERATOR
pg_rewrite                        #All RULE
pg_rules                          #Same, but more for user-defined RULE

pg_type                           #All TYPE, including:
                                  #  - typispreffered BOOL: if true, is used as the TYPE for the whole typecategory with
                                  #    overloading functions (def: text for STR, and real for numeric)
pg_enum                           #All ENUM_TYPEs
pg_range                          #All RANGE
is.domains                        #All DOMAIN

pg_authid|roles                   #All ROLE, including:
                                  #  - rolcatupdate BOOL (def: false): if false, all ROLE, including superuser ROLE, cannot write on
                                  #    system catalogs.
                                  #pg_roles blanks out the password
pg_auth_members                   #ROLE memberships, including:
                                  #  - roleid|member|grantor OID: means ROLE2 is a member of ROLE, which has been granted by ROLE3.
                                  #    Refer to pg_authid.oid
pg_default_acl                    #All default privileges.

pg_namespace                      #All SCHEMA
pg_tablespace                     #All TABLESPACE

pg_extension                      #Activated EXTENSION
pg_available_extensions           #Possible EXTENSION for their current version
pg_available_extension_
versions                          #Possible EXTENSION for all versions
pg_language                       #All activated LANGUAGE, including:
                                  #  - lanpltrusted BOOL: can not access filesystem (so non-superuser can create function)
                                  #    Is false for C, R and SH but true to SQL and PL/PGSQL
pg_pltemplate                     #All LANGUAGE

pg_ts_config[_map]                #All REGCONF
pg_ts_dict                        #All DICTIONARY
pg_ts_template                    #All TEMPLATE
pg_ts_parser                      #All PARSER

pg_collation                      #All COLLATION
pg_conversion                     #All CONVERSION

pg_cursors                        #All CURSOR
pg_prepared_statements            #All PREP
pg_prepared_xacts                 #All "prepare transaction STR"

pg_foreign_data_wrapper           #All FDW
pg_foreign_server                 #All FSERVER
pg_foreign_table                  #All FTABLE
pg_user_mapping[s]                #All USERMAPPING. With s, leaves out the option field when user should not see it

pg_am                             #All INDEX_METHOD: what they support (e.g. in create index ...) and the FUNC they use
pg_opclass                        #All OPCLASS
pg_opfamily                       #All OPFAMILY
pg_amop                           #OPERATOR used by OPFAMILY
pg_amproc                         #FUNC used by OPFAMILY

pg_largeobject
[_metadata]                       #All LARGEOBJECT

pg_[sh]description                #All COMMENT [on cluster-wide objects]

pg_settings                       #All ENVVAR, with also when is readonly, type, min|max value, unit
pg_db_role_setting                #All role and/or database-specific ENVVAR


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           DATABASE            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


MAIN STRUCTURE ==>                #  - Cluster: set of DATABASEs, managed by a single instance of a server daemon (postgres).
                                  #      - linked to a DATADIR
                                  #      - cluster-wide ENVVARs
                                  #      - cluster-specific objects:
                                  #         - DATABASE, including templates
                                  #         - ROLE
                                  #         - TABLESPACE
                                  #         - LANGUAGE
                                  #         - system catalogs on cluster-specific objects
                                  #  - Database: set of SCHEMAs. A client can connect only to one DATABASE at once.
                                  #     - max 4e9
                                  #  - Schema: set of SQL objects (TABLE, FUNC, etc.)
                                  #  - Session: client connection to the server for a specific database, e.g. interactive prompt session.
                                  #  - Transaction: set of statements that should executed all-or-nothing (concurrency)
                                  #  - Statement: SQL command individually sent to the server by the client.

create database DATABAS           #Create a DATABASE
[owner ROLE]                      #  - ROLE is current one by def
[template DATABASE2]              #  - DATABASE2 is the initial state of DATABASE:
[encoding WORD]                   #     - It is a default DATABASE2 called template1 by def. (created by initdb)
[lc_collate|ctype WORD]           #     - defines locales (see initdb)
[connection limit INT]            #     - template0 is the same as template1, but template1 can be modified to have specific initial
                                  #       state of DATABASE, while keeping template0 as the initial template if needed.
                                  #     - DATABASE2 cannot be accessed just before and during create database
                                  #  - encoding|lc_collate|ctype WORD: overrided default defined by template. Should be used only if
                                  #    DATABASE2 is template0.
                                  #  - connection limit: number of concurrent non-superuser client sessions max (def: -1, i.e. unlim)
                                  #Cannot be inside a transaction.
alter database DATABASE
connection limit INT              #

drop database ...                 #Cannot be done if currently connected to it
 [with force]                     #Terminate ongoing connections. Fail if could not


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            SERVER             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


INSTALLATION ==>                  #  - Server: postgresql
                                  #  - Client: postgresql-client, pgadmin3
                                  #  - Extensions: postgresql-contrib, postgresql-EXTENSION
                                  #  - Extension building: postgresql-server-dev
pg_config                         #Show compilation-time conf
--bin|doc|html|include|
pkginclude|lib|pkglib|            #Print DIR. By default, useful DIR (so without headers, docs, etc.) are:
locale|man|share|                 #  - /usr/lib/postgresql/VERSION/: bin and lib
sysconfdir                        #  - /usr/share/postgresql{,-common}/VERSION/
--includedir-server|pgxs          #  - /etc/postgresql-common/: few conf files
--configure                       #Print all configuration flags (usually to mimic another installation)
--cc|cppflags|
cflags[_sl]|
ldflags[_ex|sl]|libs              #Print makefile variables

REGRESSION ==>                    #Running the regression tests (to unsure installation is fine):
                                  #  - download source, configure and build it
                                  #     - after building, before installation: make check (must not be root)
                                  #     - after installation: make installcheck[-parallel] (localhost, unless PGPORT or PGHOST is used)
                                  #  - when failed:
                                  #     - check src/test/regress/expected/*.out to see the test and its expected output, and
                                  #       compare with diff on src/test/regress/results/*.out
                                  #     - or directly look at src/test/regress/regression.diffs
UPGRADING ==>                     #Only needs to care about upgrade incompatibilities for major upgrades (e.g. 9.3 to 9.4), every year.
                                  #How:
                                  #  - use pg_dumpall backup
                                  #  - use pg_upgrade -b OLDBINDIR -B NEWBINDIR -d OLDDATADIR -D NEWDATADIR. Flags are:
                                  #     -u USER
                                  #     -c dry-run
                                  #     -j NUM: multiprocess run
                                  #     -k: use hard links instead of copies. Faster.
                                  #     -p|P NUM: old|new port number (can also use PGPORTOLD|NEW)
                                  #    NEWBINDIR and NEWDATADIR must be a new install, with similar settings.
                                  #    OLD*DIR must be erased afterwards.
                                  #    Connects to OLDDATADIR -> might want to put authentication as trust temporarily
                                  #    Both servers must be down.
                                  #    Must use NEWBINDIR/pg_upgrade, not OLDBINDIR.
                                  #    Cannot upgrade a log shipping standby.

STARTING ==>                      #If DATADIR (e.g. /usr/local/pgsql/data), as postgres user:
                                  #  - initdb -D DATADIR: creates cluster
                                  #  - postgres -D DATADIR 2> LOG &: starts the server
                                  #  - createdb DATABASE (default "postgres" DATABASE could be used though)
                                  #  - psql [DATABASE]
                                  #Autostart at boot time are system-specific.
                                  #Have a lot of memory PC to avoid memory crash if big data.
STOPPING ==>                      #Terminate server:
                                  #  - Can send signals:
                                  #    - SIGTERM (15): doesn't accept new connections, but let current ones finish.
                                  #       - server process stops, but will redo uncaught statements when restarting
                                  #    - SIGINT (2, CTRL-C): close all connections with a SIGTERM: abort current statements but close
                                  #      server itself propertly
                                  #    - SIGQUIT (3, CTRL-\): close all connections with a SIGQUIT: abort statements and server.
                                  #  - to send a signal on Windows, use pg_ctl kill ...
                                  #  - PID of a cluster can be found in DATADIR/postmaster.pid (ENVVAR external_pid_file) (first line)
                                  #    or with pg_backend_pid().
                                  #Terminate a client session (superuser or same member, but not same user):
                                  #  - pg_terminate_backend(PID)
                                  #  - send SIGTERM (15)
                                  #  - can see client PID with pg_stat_activity (pid)
                                  #Terminate a client current statement (superuser or same member, but not same user):
                                  #  - pg_cancel_backend(PID)
                                  #  - send INT (2, CTRL-C)
LOCATIONS ==>                     #  - Each cluster has a DATADIR (must have permissions 0700)
                                  #  - SHAREDIR, e.g. /usr/share/postgresql/9.3/

initdb [-D DATADIR]               #Creates a cluster, i.e.:
                                  #  - populates or create DATADIR. Def: PGDATA
                                  #     - directory under which all data of the cluster are stored.
                                  #     - /usr/local/pgsql/data/ or /var/lib/pgsql/data/ are often used.
                                  #  - creates template0|1 and an empty database "postgres"
                                  #  - create cluster-specific system catalogs
                                  #  - initialize cluster-wide ENVVARs
                                  #User:
                                  #  - should have right to write in DATADIR
                                  #  - will use current OS_USER as the superuser ROLE (will create the ROLE in the cluster)
                                  #     - good idea to use a OS_USER which doesn't have any permissions on the filesystem apart from
                                  #       the directories used by the server.
                                  #        - A OS_USER "postgres" is created by def. installation for this purpose.
                                  #  - can't be root
-U ROLE                           #Name of the superuser ROLE (by def. the current OS_USER).
                                  #Change the ROLE name but not:
                                  #  - the fact that OS_USER will be superuser
                                  #  - nor the name of the default database "postgres" (but could rename it)
-E STR                            #See encoding in this doc.
--lc-collate|ctype|
messages|monetary|
numeric|time=LOCALE               #See locales in this doc.
--locale=LOCALE                   #Same but for all
--auth-host|local=STR             #
-A STR                            #
-W
--pwfile=FILE                     #Default authentification, see pg_hba.conf
-X DIR                            #Log DIR

LIBPQ VARIABLES ==>               #Used in several places in this doc.
host[addr]                        #Def is localhost or PGHOST[ADDR]. Can be an absolute path to a Unix socket.
                                  #With addr:
                                  #  - specifies IP address
                                  #  - avoid host name lookup, faster.
                                  #  - Can't be used with Kerberos, GSSAPI, SSPI or verify-full SSL
port                              #Def is PGPORT (5432)
dbname                            #Def: OS_USER or PGDATABASE
user                              #ROLE to use. Def: OS_USER or PGUSER
connect_timeout                   #In seconds. Def: 0 (unlim). Should not be <2. Def: PGCONNECT_TIMEOUT
client_encoding                   #Def: "auto" (defaults OS locales). Def: PGCLIENT_ENCODING
options                           #Set postgres flags at runtime, client-side. Def: PGOPTIONS
                                  #Can use -c ENVVAR=VAL to set ENVVAR.
[fallback_]                       #Name of the application (psql, pg_dump, etc.)
application_name                  #Used in logs (title of the client connection). Can be env. variable PGAPPNAME too.
                                  #If application_name or PGAPPNAME is blank, defaults to fallback_* (let users override it)
keepalives                        #1 to enable it (def). If connection seems lost, sends packet to check it actually is.
keepalives_                       #Send max *count packets, every *interval seconds. Start sending after non-activity from server for
[idle|iterval|count]              #*idle packets.
                                  #Can also use ENVVAR tcp_keepalives_*
OTHERS ==>                        #See Authentication section
service                           #Additional parameters (def: PGSERVICE[FILE])

postgres [-D DATADIR]             #Starts the server daemon for a specific cluster.
                                  #To start postgres on several clusters on same machine, use different ports.
                                  #Only one server can be launched for a given cluster. Each client session spawns a new process.
                                  #Should be logged as the same OS_USER who used initdb. It should have permissions to access files that
                                  #will be used:
                                  #   - DIR of TABLESPACE
                                  #   - FILE referenced by copy from|to, load STR or create function ... as STR
                                  #DATADIR is PGDATA by def (unset by def). Can also use ENVVAR data_directory, and PGDATA or -D DATADIR
                                  #will point to the directory containing the postgresql.conf.
                                  #Print log messages on stderr. Should be launched in the background.
                                  #Can call version(), ENVVAR server_version[_num] and also a file DATADIR/PG_VERSION.
                                  #Commands that started the server can be found under DATADIR/postmaster.opts
                                  #Connections are done using either:
                                  #  - Unix sockets ("local"), on a socket at DIR/.s.PSQL.PORT (created at server start), where
                                  #    DIR is designated by ENVVAR unix_socket_directories (def: /tmp or /var/lib/postgresql/),
                                  #    comma-separated list by order of preference. Can be "" to disallow "local" connections.
                                  #    OS_USER must (to avoid spoofing) have:
                                  #      - permissions on DIR, preferably only that user
                                  #      - socket itself will be owned by OS_USER and OS_GROUP_USER (can be changed with ENVVAR
                                  #        unix_socket_group)
                                  #      - socket itself will have permission ENVVAR unix_socket_permissions (def: 0777). Could set to
                                  #        0770 or 0700 (only OS_GROUP_USER+OS_USER or only OS_USER can connect)
                                  #    Client must connect by using DIR as host
                                  #  - TCP/IP ("host"), which uses socket designated by IP addresses specified in ENVVAR
                                  #    listen_addresses (comma-separated) with IPv4|6 addresses (def: "localhost"). Should be set at
                                  #    server start.
                                  #    "*" means all IPv4|6, "0.0.0.0" all IPv4, "::" all IPv6
                                  #If crash, sessions will restart automatically if ENVVAR restart_after_crash (def: on)
-p NUM                            #Port number (def: 5432).
                                  #Can also use ENVVAR port at server start.
-k STR                            #Sets ENVVAR unix_socket_directories.
-h STR                            #Sets ENVVAR listen_addresses
-i                                #Same as -h "*"
-N                                #Sets ENVVAR max_connections (def: 100), which is the number of superuser + normal users max
                                  #connections. The last ENVVAR superuser_reserved_connections (def: 3) are kept for superuser only.
                                  #Look at work_mem to see estimate of memory used by this configuration.
                                  #Lower max_connections means more connections denied, higher means more chance to crash server.
                                  #Look at real life usage to set this setting.
                                  #Can also sets database-wise with connection limit (see create database)
--single                          #Single-user mode: start both the daemon and a superuser client session
                                  #Must be put before -D DATADIR
                                  #Quits with EOF (C-D). No readline.
                                  #By default use newlines instead of semicolons. Use -j to use EOF instead (then there will be only one
                                  #command).
-l                                #Enable SSL connections

pg_isready                        #Returns (exit code) according to server up or down status:
                                  #  - 0: OK
                                  #  - 1: refusing connections
                                  #  - 2: no server response
                                  #  - 3: could not send request
-d -h -p -U -w|W                  #Connection options (see psql)
-t NUM                            #Timeout (in sec, def 3, 0 to disable)
-q                                #quiet

ENVVAR ==>                        #Environment variables. Can be specified with:
                                  #  - cluster-specific:
                                  #     - postgres -c VAR=VAL or postgres --VAR=VAL
                                  #     - editing DATADIR/postgresql.conf (ENVVAR config_file)
                                  #        - has lines VAR = VAL, and #comment
                                  #        - can have include[_if_exists] 'FILE' or include_dir 'DIR' (includes DIR/*.conf, by
                                  #        - alphabetical order)
                                  #        - can use pg_reload_conf() or send SIGHUP to server daemon postgres
                                  #        - can see load time with pg_conf_load_time()
                                  #     - PGOPTIONS
                                  #  - role-specific:
                                  #     - alter role ROLE ... set ENVVAR to VAL | from current
                                  #                           reset ENVVAR|all
                                  #  - database-specific:
                                  #     - alter role all in database DATABASE ... set ENVVAR from current
                                  #                                               reset ENVVAR|all
                                  #  - role-database-specific:
                                  #     - alter role ROLE in database DATABASE ... set ENVVAR to VAL | from current
                                  #                                                reset ENVVAR|all
                                  #  - session-specific:
                                  #     - set ...
                                  #     - setting PGOPTIONS with '-c VAR=VAL ...' before launching the client command
                                  #  - function-specific:
                                  #     - do create function ... set ENVVAR to VAL | from current:
                                  #        - from current: use current VAL as VAL
                                  #     - inside a function:
                                  #        - set local (if FUNC() used create function ... set ...)
                                  #  - transaction-specific:
                                  #     - set local ...
                                  #Some require superuser ROLE to write.
                                  #Some cannot be session-specific.
                                  #Are always STR. BOOL actually use 'on' and 'off'.
set [local] ENVVAR to VAL         #VAL can be default
                                  #For an ARR, write VAL...
                                  #Can also use set_config('ENVVAR', 'VAL', BOOL) (BOOL is is_local)
reset ENVVAR|all                  #Same as set ... to default
show ENVVAR|all                   #Print their values.
                                  #Can also use current_setting('ENVVAR')
                                  #Can also use postgres ... -C ENVVAR, which is done against a running server
alter TYPE VAR ... set ENVVAR
 to VAL|from current              #
alter TYPE VAR ...
 reset ENVVAR|all                 #For database, function or role

discard plans|temp|all            #Remove session-specific information:
                                  #  - plans: cached explain plans
                                  #  - temp: TEMP
                                  #  - all: cached explain plans, TEMP, session-specific ENVVAR, PREP, CURSOR, unlisten *,
                                  #    pg_advisory_unlock_all(), put session_user and current_user to default

pg_postmaster_start_
time()                            #
current_database()                #Can also use information_schema.information_schema_catalog_name.catalog_name
current_query()                   #Current executing statement
inet_client|server_
addr|port()                       #

statement_timeout                 #ENVVAR (in ms) after which client requests fail (def: 0).

FILESYSTEM ACCESS ==>             #
pg_ls_dir(STR)                    #Returns 'COL'. Must be relative path (.. not allowed)
pg_read[_binary]_file(STR)        #Returns as STR|BYTEA
pg_stat_file(STR)->TABLE          #Single row: size, access (atime), modification (mtime), change (ctime), creation (creation time, only Windows), isdir.
pg_file_write(STR, STR2, BOOL)   ##BOOL is append
                                 ##Postgres extension 'adminpack'
pg_file_read(STR, STR2, BOOL)    ##BOOL is append
pg_file_rename(STR, STR2)        ##
pg_file_unlink(STR)              ##
pg_file_length(STR)              ##

DATADIR ==>                       #  - base/: databases main data.
                                  #    Querying database|tables oids:
                                  #      - utility oid2name:
                                  #         - without option: database oid -> name
                                  #         - -H -p -U -P: usual connection flags
                                  #         - -d DATABASE: show table oid -> name
                                  #           - -S: include system catalogs, views and TOAST
                                  #         - -f|o NUM: for tables with filenode|oid NUM
                                  #         - -t STR: same with name
                                  #         - -i: include SEQUENCE and INDEX
                                  #         - -s: info about TABLESPACE
                                  #      - pg_relation_filenode|filepath(OID|STR)
                                  #    6MB for an empty database. Each file is a table with optionally:
                                  #      - a FILE_vm: Visibility Map
                                  #      - a FILE_fsm: Free Space Map
                                  #    TOAST are special subfiles when a file is too big.
                                  #  - global/: cluster-wide data.
                                  #  - pg_xlog/: WAL
                                  #  - pg_log/: logs (see log_directory)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            CLIENT             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


psql                              #Starts interactive commands while connecting to a DATABASE
                                  #Read from standard input, so <<<"STR" or <FILE are possible.
                                  #Use readline so can use a .inputrc
                                  #The five first options are connection-related, and shared by other commands. When available, can
                                  #also always use a STR argument instead with either:
                                  #  - VAR=VAL... as space-separated libpq variables
                                  #  - postgres://[USER:PASSWORD@][HOST][:PORT]/[DATABASE][?VAR=VAL] (VAR are libpq variables)
-d DATABASE                       #Def: "postgres"
-h HOST                           #Def: PGHOST or (if absent) local host.
-p PORT                           #Def: PGPORT or (if absent) default port.
-U USER                           #Def: PGUSER or (if absent) current OS user.
-w|W                              #Force to not use or use a password

-c STR
-f FILE                           #Redirect input from STR or FILE (non-interactive shell)
-o FILE                           #Redirect output to FILE
-L FILE                           #Prints queries to FILE (logging)

-X                                #Do not read init files (files read at session start containing any command that PSQL understands)
                                  #Init file can be:
                                  #  - systemwide (/etc/postgresql-common/psqlrc)
                                  #  - user-specific (shell variable PSQLRC, by def HOME/.psqlrc)
                                  #Can append -NUM[.NUM2[.NUM3]] to target only specific PostgreSQL versions.
-n                                #Don't use readline (useful when pasting)
-s                                #Ask for confirmation before each command
-1                                #Wrap commands in a transaction block. Commands should not contain transaction blocks themselves.
                                  #Disable all EFUNCs
-l                                #Does \list then exits

\COMMAND                          #psql can use special commands. Finished by newline not semicolon.
                                  #Can use \n \t \r \000 \x00 in 'STR'. Can do shell substitution with `COMMAND`
                                  #Can appear anywhere a SQL command can.
                                  #Some commands use SREGEXP:
                                  #  - . only means SCHEMA separation (otherwise current schema).
                                  #    For all objects outside current SCHEMA, do *.*
                                  #  - $ not present
                                  #  - ? and * are globbing
                                  #  - case-insensitive unless ""

\q                                #Exits
\h [COMMAND]                      #Help on SQL commands
\?                                #Help on PSQL commands
\! [COMMAND]                      #Execute a shell command according to the shell variable SHELL
\timing [on|off]                  #Show time taken by commands

\pset VAR [VAL]                   #If VAL, sets printing options, if not either toggle or print current value.
                                  #VAR [VAL] can be:
format STR                        #How things are printed. Can be unaligned, aligned (def), wrapped, html, latex[-long table], troff-ms.
                                  #  - Wrapped: like aligned but wrap long lines according to columns INT (if 0, only on terminal
                                  #    output, and uses shell env variable COLUMNS or detected screen size)
                                  #  - unaligned: can control separators with field|recordsep STR or field|recordsep_zero (use \0)
x [on|off|auto]                   #Put in expanded mode (switch cols and rows, good for table with long width). If auto, do it only for
                                  #wide tables.
t                                 #No footer nor headers
footer [on|off]                   #footer is command tag, etc.
title STR                         #Print STR in front of all tables
border INT                        #Column width
linestyle ascii|unicode           #
null STR                          #What to print for null strings (def: "")
numericlocale on|off              #Locale-specific NUM
pager on|off|always               #Using env variable PAGER (def: less)
tableattr STR                     #In HTML output format, HTML attributes of <table>

END OF LINE ==>                   #The seven following commands should be put at the end of a command (instead of ;):
\w FILE| |COMMAND                 #Print current input to FILE or pipe to COMMAND (don't execute it)
\p                                #Same as \w |cat
\g [FILE| |COMMAND]               #Redirect output like \o, but for current input only.
\r                                #Clears current input.
\e [FILE]                         #Edit current command (or if FILE, FILE) with editor (shell variable [PSQL_]EDITOR, i.e. vim), which
                                  #becomes the new command.
                                  #New command is only executed if terminated by ;
\ef [FUNC[(...)]]                 #Same but the command is a "create or replace function FUNC". If no FUNC, creates a empty definition.
\watch INT                        #Execute current input every INT seconds, until interrupted (or error).

\o [FILE| |COMMAND]               #Redirect stdout (not stderr) (def: to stdout)
\i[r] FILE                        #Execute command in FILE.
                                  #If r and non-interactive, relative path to script DIR, otherwise relative to PWD)
\copy ...                         #Like SQL copy but performed locally, not on the server.
                                  #Can use pstdin|out to avoid any stdin|stdout redirection (i.e. use terminal input|output)
\lo_export OID STR
\lo_import STR                    #Like lo_ex|import(...), but performed locally, not on the server.

\[q]echo [-n] VAL                 #Prints VAL (use q if \o has been used), without trailing newline if -n
                                  #Can appear anywhere in a SQL command.
\setenv VAR [VAL]                 #Sets shell environment variables

\d...[S][+] [SREGEXP]             #Show info about VAR specified in ... (S for also system ones, + for more info) among:
                                  #  - nothing (all table-like), t (table), v (view), i (index), m (materialized view), s (sequence)
                                  #  - u (ROLE), dp (default user privilege), p (all table-like with privileges)
                                  #  - d (constraint, operator*, rule, trigger)
                                  #  - n (SCHEMA)
                                  #  - b (tablespace)
                                  #  - L (LANGUAGE), x (EXTENSION)
                                  #  - T (TYPE), D (domain), C (cast)
                                  #  - O (COLLATION), c (conversion)
                                  #  - E|et (ftable), es (foreign server), eu (user mapping), ew (foreign data wrapper)
                                  #  - f[n|a|w|t] (func, afunc, wfunc, tfunc), y (efunc), o (OPERATOR)
                                  #  - F (REGCONF), Fd (DICTIONARY), Fp (PARSER), Ft (TEMPLATE)
                                  #  - l (large objects)
                                  #  - rds: ENVVAR, ROLE-specific (SREGEXP) and optionally database-specific too (use a second SREGEXP)
                                  #  - \l[+] (not \d): DATABASE
\sf [FUNC[(...)]]                 #Prints definition of FUNC

\c [DATABASE [USER]
[HOST] [PORT]]                    #Connect to different database. Def is current
\conninfo                         #Print current connection info
\cd [DIR]                         #Change PWD (def: HOME)

\[un]set INTVAR [VAL]             #Internal VAR. INTVAR is case-sensitive. Are not ENVVAR.
                                  #Can also use psql -v INTVAR[=[VAL]]
                                  #Can be created INTVAR. Substitution is done with:
                                  #  - :INTVAR: macro expansion of INTVAR
                                  #  - :'INTVAR': same but surround with '', unless already present (do with STR)
                                  #  - :"INTVAR": same with "" (do with VAR)
\gset [WORD]                      #Put at end of command (like \p, \r, etc.)
                                  #Command output is redirected to new INTVAR (one by column) called [WORD_]"COL".
                                  #Columns must be named. Null give unset variables, failing commands don't change variables
\prompt [-f] [STR]
INTVAR                            #Prompt for INTVAR, with message STR. Use terminal (no -f) or stdin/stdout (-f)

DBNAME                            #
HOST                              #
PORT                              #
USER                              #Connections info

ON_ERROR_STOP                     #When set, errors terminate script (non-interactive) or line (interactive)
                                  #ENVVAR exit_on_error is also available, where errors terminate whole session.
ON_ERROR_ROLLBACK                 #If on, errors in transactions are just ignored. If off (def), they abort the whole transaction.
on|interactive|off                #Interactive means on for interactive and off for non-interactive.
IGNOREEOF INT                     #Number of EOF (C-D) to send to terminate a session (def: 1)

PROMPT1|2|3                       #Prompt. Literal STR with possible sequences escaped by %: M (full host), m (short host), > (port),
                                  #n (user), / (database), ~ (database, but ~ if default one), # (# if superuser, > otherwise),
                                  #R (= if normal, ! if disconnected), x (transaction block), NNN (octal), `command`, :VAR:,
                                  #[ and ] (ansi escaping sequences). Def is %/%#
                                  #PROMPT1 is normal, PROMPT2 when continuing on a new line, PROMPT3 when reading from stdin
COMP_KEYWORD_CASE
[preserve-]lower|upper            #Completion case. If preserve, tries to keep current word case.
QUIET                             #Don't print welcome message
ECHO                              #When set to '' (def), do nothing.
                                  #When 'queries', print all input to output.
                                  #When 'all', same but only for non-interactive input.
ECHO_HIDDEN                       #When set, prints commands behind \ commands

HISTFILE                          #Def: ~/.psql_history. Written at exit.
                                  #Can for example use user, database-specific, etc. hist files
                                  #Can also use shell variable PSQL_HISTORY
                                  #Can also use \s [FILE] (always relative to PWD) (def: print to stdout)
HISTSIZE                          #Number max of commands (def: 500)
HISTCONTROL
ignoredups|space|both             #Like in Bash

AUTOCOMMIT on|off                 #By def (on), each individual command is wrapped in a single transaction. When off, a start
                                  #transaction is implicitly fired but needs to manually commit it
LASTOID                           #OID of last written object
FETCH_COUNT                       #Number of max rows in memory at once

PGADMIN3 ==>                      #GUI client. Can do almost anything that can be done with psql.
                                  #Installing/launching:
                                  #  - MaintenanceDB:
                                  #     - DATABASE where pgAdmin connects first (should use postgres)
                                  #     - should install adminpack extension
                                  #  - Should use the same OS_USER we would use for a normal psql session
                                  #Usage:
                                  #  - Is not refreshed automatically: needs to refresh it manually.
                                  #  - Some types of objects are hidden by default (e.g. AFUNC or TYPE): can change in options
                                  #  - Servers have names, and can be grouped.
                                  #Useful tools:
                                  #  - Easy access to objects, with properties and statistics, and conf files
                                  #  - Can open a psql session in a console
                                  #  - Edit/View data: simple spreadsheet.
                                  #    Read-only if no primary key.
                                  #    blank is null (needs to write '' for '')
                                  #  - Server status: current clients, locks, log (needs to edit path in options), transactions
                                  #Less useful tools:
                                  #  - Grant wizard (available when on a SCHEMA): generate SQL grant statements with GUI
                                  #  - Reports: generating HTML files for objects properties, statistics, dependencies.
                                  #  - Query tool: useless, use the console (unless needs a SQL debugger, which needs to be installed)

PGAGENT ==>                       #  - SQL "cron", inside pgadmin3
                                  #  - to install on a cluster:
                                  #     - connect to postgres
                                  #     - install plpgsql
                                  #     - as superuser ROLE, execute pgagent.sql (i.e. in pgadmin3 sharedir).
                                  #       It will create TABLE and FUNC used for storing/manipulating the jobs and schedules, in SCHEMA
                                  #       pagent
                                  #     - launch pgagent 'LIBPQ'
                                  #        - this daemon will look at those tables and determine if need to launch job
                                  #        - run as root
                                  #        - options:
                                  #           -s LOG_FILE
                                  #           -l1 (best verbosity)
                                  #           -t (poll time, def: 10 sec)
                                  #        - do no put password in 'LIBPQ' (use passfile instead)
                                  #        - automatically in background and detached from current terminal tab
                                  #        - should automatically launch it at startup
                                  #  - configure jobs using pgadmin, under "Jobs":
                                  #     - steps are:
                                  #         - SQL commands (will be executed as superuser ROLE)
                                  #         - or "batch" (shell commands, run as root, must start with #!/bin/bash)
                                  #     - schedules are when it is done
                                  #  - monitor with check_postgres

TEAMPOSTGRESQL ==>                #Alternative to pgAdmin3. Fewer functions, but is a web interface instead of a dekstop app.


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:              IPC              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


notify WORD[, 'STR']              #Sends a message 'STR' (def: "") on channel WORD. Also communicates the server PID.
                                  #Any client connected to the same server and listening to WORD will get a notification.
                                  #How this notification is handled depends on the client:
                                  #  - psql: print to stderr
                                  #If sends twice the same WORD + 'STR', might notify only once.
                                  #'STR' is max 8KB
                                  #pg_notify(STR, STR2) is also available: same but don't need to use constant 'STR'.
[un]listen WORD                   #WORD can be * for unlisten
                                  #listening is session-wise: unlisten * is executed at end of each session
pg_listening_channels()           #


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            LOGGING            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


LOGGING ==>                       #Controlled by several ENVVARs
log_destination                   #Where to put log messages (comma-separated list):
                                  #  - stderr (def)
                                  #  - csvlog:
                                  #     - with logging_collector, will output as CSV files
                                  #     - goal is to import them in tables with copy from
                                  #  - syslog:
                                  #     - prefer using the logging_collector
                                  #     - Needs to put local0.* /var/log/postgresql/ in syslog conf file
                                  #     - Can use ENVVAR syslog_facility, syslog_ident and event_source
logging_collector                 #When on, use the logging facility:
                                  #  - redirect stderr to file in ENVVAR log_directory too (can be relative to DATADIR) (def: pg_log).
                                  #      - files are named according to ENVVAR log_filename, which can use %... (data escape)
                                  #        (def: "postgresql-%Y-%m-%d_%H%M%S.log") for file creation time
                                  #      - a new file is created every ENVVAR log_rotation_age (def: 1d)
                                  #        or every time the file is more than ENVVAR log_rotation_size (def: 10MB)
                                  #        or when pg_rotate_file() is called
                                  #    If csvlog, will be in CSV format and use name ENVVAR application_name.
                                  #  - Files have permission ENVVAR log_file_mode (def: 0600, only server owner can read/write)

log|client_min_messages           #Between debug5-1, log, notice, warning, error, fatal, panic (def: notice for client, warning for log) for
                                  #either client messages or logging.
                                  #postgres -d NUM can set log_min_messages (from 0 to 5, def: 0), for DEBUG5-1
log_error_verbosity               #Verbosity of messages: default, verbose (include SQLSTATE error code) or terse (no defail, hint,
                                  #query nor context)
log_min_error_statement           #Same as log_min_message, but for logging the statements themselves (def: error).
log_statement                     #Which statements to log among none (def), all, ddl or mod (include ddl)
log_min_duration_                 #Logs time of statement execution, when it is higher than this limit (in ms, 0 to log all, -1 not to
statement                         #log it (def))
log_statement_stats               #If on, server prints to stderr the statements executed and the time it took
log_line_prefix                   #What to put in beginning of each log line. Can include %-escapes:
                                  #  - a: application_name
                                  #  - u: user
                                  #  - d: database
                                  #  - r: host+port
                                  #  - h: host
                                  #  - p: PID
                                  #  - t|m: timestamp (to seconds|ms). Timezone is controlled by ENVVAR log_timezone (def: 'localtime')
                                  #  - s: process start time
                                  #  - c: session id (process start time + PID)
                                  #  - i: command
                                  #  - e: error code
                                  #  - l: log number, session-wise
                                  #  - x|v: [virtual] transaction ID
log_checkpoints                   #Logs checkpoints (def: off)
log_[dis]connections              #Logs [dis]connections attempts (def: off)
log_lock_waits                    #Logs deadlocks (see deadlock_timeout)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          MONITORING           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


check_postgres                    #Performs several sanity monitoring tests, and outputs warnings.
-db -H -u -p                      #Connection options. Some actions requires several clusters/databases: then use STR...
--dbpass=STR...                   #Can also use STR... for any action to perform the check separately on several clusters/databases
                                  #(will return problem if any of them is wrong), or on master/slave
--output=STR                      #Output format (this doc only talks about nagios):
                                  #  - nagios (def):
                                  #     - compatible with NAGIOS (server network monitoring application)
                                  #     - one line with test name, then OK|WARNING|CRITICAL|UNKNOWN (and exit code 0 to 3 accordingly),
                                  #       followed by colon and description.
                                  #       UNKNOWN is when test cannot be performed, and WARNING|CRITICAL are set up according to
                                  #       -w|c VAL ("thresholds", depends on action). If warning = critical, turn off warnings.
                                  #     - can use option:
                                  #       --showperf=1|0: show performance at end of line (def: 1)
                                  #           --perflimit=NUM: limit --showperf to NUM items (def: 0, i.e. unlim)
                                  #           --showtime=1|0: show queries execution time (def: 1)
                                  #  - mrtg
                                  #     - compatible with MRTG (traffic load monitoring application)
                                  #     - four lines: NUM (usually main info), description (usually 0), blank and DATABASE
                                  #       (only when relevant)
                                  #     - can use option --mrtg=VAL to pass arguments to MRTG
                                  #     - usually don't issue warnings|critical
                                  #  - simple
                                  #     - like mrtg, but only first line (NUM)
                                  #     - can be followed by unit, e.g. --output=simple,MB
--action=STR...                   #Checks to perform, among:
                                  #Connections:
                                  #  - connection:
                                  #    Checks if server is up.
                                  #    CRITICAL + psql error description if no, OK + server version if yes.
                                  #  - backends:
                                  #    Checks if number of connections is more than threshold (NUM or % of max_connections) or if more
                                  #    than threshold connections are left (-NUM).
                                  #    Can only select --noidle connections.
                                  #    Look at --include below for how to specify per DATABASE.
                                  #  - pgbouncer_backends:
                                  #    Same but with pgBouncer (max_client_conn)
                                  #  - pgb_pool_maxwait|cl_active|waiting|sv_active|idle|used|tested|login:
                                  #    Checks if any pgBouncer pool has more than thresholds (see show pools in pgBouncer)
                                  #Space usage (look at --include below):
                                  #  - disk_space:
                                  #    Checks if any partition used by any data in the cluster (DATADIR, tablespaces, WAL dir, log dir)
                                  #    is using more than thresholds of memory (can use percentage, "MB", etc. units, and "and|or")
                                  #  - database|relation|index|table_size:
                                  #    Checks if any DATABASE|TABLE|INDEX is more than thresholds (can include "MB", etc.).
                                  #    Prints size in bytes (first line), and name (last line) of biggest one.
                                  #  - bloat:
                                  #    Checks if there are more than threshold (NUM (unit: 'KB', etc.) or % of TABLE size) dead rows
                                  #    in any TABLE|INDEX (only consider ones with > 10|15 pages)
                                  #  - wal_files:
                                  #    Checks if there are more than thresholds WAL files.
                                  #    Number of WAL files is usually comprised in a given range, unless there is a malfunction
                                  #    (long transaction, wrong archive_command, etc.), creating disk space usage risk.
                                  #Unusual state:
                                  #  - pgagent_jobs:
                                  #    Checks if all pgagent jobs since threshold (unit 's|m|h|d') have an exit code of 0
                                  #  - logfile:
                                  #    Checks if redirection to log file is happening correctly.
                                  #    Must provide log full path with --logfile=STR (can use "%Y|%m|%d|%H").
                                  #    Does not work if redirection to stderr without logging collector on.
                                  #  - commitratio:
                                  #    Checks if commit ratio (non-rollbacked transactions/transactions) is lower than thresholds.
                                  #  - disabled_triggers:
                                  #    Checks if number of disabled triggers is >= thresholds.
                                  #  - locks:
                                  #    Checks if number of locks held >= threshold.
                                  #  - txn_idle:
                                  #    Checks if there are more than thresholds idle current transactions (waiting for locks), and if
                                  #    any has lasted more than threshold (unit 's|m|h|d')
                                  #  - prepared_txns:
                                  #    Checks max. age of prepared transactions (not prepared statements).
                                  #Corruption:
                                  #  - sequence:
                                  #    Checks if sequence has been used more than threshold (%)
                                  #  - txn_wraparound:
                                  #    Checks if more than thresholds transactions have not been vacuumed, creating risk for
                                  #    xid wraparound. Wraparound happends every 2e9, so value should be e.g. 1.5e9
                                  #  - autovac_freeze:
                                  #    Checks if number of old transactions is more than threshold (%) of autovacuum_freeze_max_age
                                  #Performance (look at --include below):
                                  #  - query_runtime:
                                  #    Checks if queries specified by --queryname=STR (VIEW or FUNC) runs in more than time specified
                                  #  - txn|query_time:
                                  #    Same for running transactions|queries
                                  #  - hitratio:
                                  #    Checks if cache hit ratio is lower than thresholds.
                                  #  - last_[auto]analyze|vacuum:
                                  #    Checks if has been run (auto only checks autovacuum|analyze, other checks all) since threshold
                                  #    (in s|m|h|d, def: 1d for vacuum, 2d for analyze).
                                  #    Should exclude tables with no dead rows.
                                  #  - dbstats:
                                  #    For each DATABASE, print one line with backends (number of processes), commits|rollbacks
                                  #    (number since beginning), read|hit (number of blocks since beginning), ret|fetch|ins|upd|del
                                  #    (number of rows), dbname, idx..., seq...
                                  #    Cannot use alternate outputs.
                                  #Comparison:
                                  #  - same_schema:
                                  #    Compares two or more databases, schema-wise (not data-wise).
                                  #    If only one host: make a time-based comparaison: next time it will be executed, will compare
                                  #    with previous version.
                                  #    To do so, create a file at ./check_postgres.audit.port.PORT.db.DATABASE:
                                  #      - Use --replace to overwrite it.
                                  #      - can add .STR to the filename with suffix=STR
                                  #    Can exclude objects with:
                                  #      --filter=nouser|schema|table|view|index|sequence|constraint|trigger|perm|funcbody|function[='REGEXP']
                                  #      --filter=noposition: don't compare columns positions
                                  #  - settings_checksum:
                                  #    Compares two settings (ENVVAR...) for a given user.
                                  #    First use -c 0 to get checksum, then do -w|c=CHECKSUM
                                  #  - pgbouncer_checksum:
                                  #    Same but with pgBouncer
                                  #  - timesync:
                                  #    Checks if local time diff >= threshold (in sec., should not be <5)
                                  #Standbies (can all test standby mode with --assume-standby|prod-mode):
                                  #  - hot_standby_delay:
                                  #    Checks if delay between current database (master) and slave >= threshold (number of WAL lines)
                                  #  - replicate_row:
                                  #    Checks that updates of a single row takes no more than threshold to replicate using replication.
                                  #    Should choose column to change (should pick one not likely to be changed by another process),
                                  #    with --repinfo=TABLE,PKEY,PKEY_VAL(to select row),"COL",OLD_VAL,NEW_VAL
                                  #  - checkpoint:
                                  #    Checks if last checkpoint was run more than threshold ago (unit: 's|m|h|d').
                                  #    Meant to be run on a slave. Must supply --datadir DATADIR
                                  #Upgrades:
                                  #  - new_version_bc|cp|pg:
                                  #    Checks if new version of Bucardo|check_postgres|PostgreSQL is available.
                                  #    Only nagios. UNKNOWN if binary not here, CRITICAL is revision upgrade, WARNING is major upgrade.
                                  #  - version:
                                  #    Checks that server version is at least threshold
                                  #Custom:
                                  #  - custom_query:
                                  #    Checks a custom --query=STR, which returns a single column called "result", if any row value,
                                  #    depending on type of -w|c VAL:
                                  #      - NUM: >= NUM
                                  #      - NUM[KB, etc.]: >= NUM
                                  #      - STR's|m|h|d': older or same as STR
                                  #      - STR: same as STR
--in|exclude=STR...               #Limit the objects checked:
                                  #  - DATABASE: for backends, database_size, locks, query_time, txn_idle, txn_time
                                  #  - TABLE|INDEX: for bloat, index|table|relation_size, last_[auto]vacuum|analyze
                                  #  - FILESYSTEM: disk_space
                                  #include alone means "include only", but not alone means "include also" (to reinstate objects that
                                  #have been excluded with --exclude).
                                  #STR:
                                  #  - ending with . matches a schema
                                  #  - starting with ~ is a REGEXP (otherwise full VAR name)
--in|excludeuser=STR...           #Same for objects owned by 'ROLE'...
                                  #Works for relation|database_size, query|txn_time, last_[auto]vacuum|analyze.
-t NUM                            #Timeout (in secs, def: 10) after which returns UNKNOWN status, per cluster.
-v ...                            #Verbosity. Do several times to increase verbosity.
--debugoutput=LETTER...           #Prints also the psql output for a (all), c (critical), w (warning), o (ok), u (unknown)
--PGBINDIR=STR                    #psql directory (see man page on precautions to use)

pgbadger FILE[...]                #FILE... are the log files (stderr, csvlog (need Text::csv_xs module) or syslog format).
                                  #FILE can be - for stdin (not for csvlog).
                                  #Recognize compressed files from extensions .gz, .bz2 or .zip
                                  #Should put:
                                  #  - log_statement to 'none' (do not enable it)
                                  #  - log_min_duration_statement to 0
                                  #  - log_checkpoints|[dis]connections|lock_waits to 'on'
                                  #  - log_temp_files to 0
                                  #  - lc_messages to 'C'
                                  #If stderr:
                                  #  - log_line_prefix to '%t [%p]: [%l-1] user=%u,db=%d,host=%h,application=%a'
                                  #    Use pgbadger -p '%t ...' (same as above) -f stderr
                                  #Use latest release (3.3 is not)
                                  #Needs to put as much as possible in logs to get all graphs.
                                  #Can zoom it with shift button.
-f stderr|csvlog|syslog           #Def: stderr
                                  #For syslog:
                                  #  -i STR: Program name used as ident for syslog
-o FILE                           #Output file and format (among .html, .txt and .tsung). Def is output.html
                                  #Can also use -x text|html|tsung. Tsung is <sessions> tag for XML config file with most usual session.
-q                                #Quiet

-c HOST
-d DATABASE
-u USER
-N APPLICATION_NAME               #Filter for only this parameter (can be used several times)
-U USER                           #Filter for excluding USER (can be used several times)
-b|e DATE                         #Start|end time to be processed.
-l FILE                           #Only use logs starting from this log file.

-a NUM                            #Step (in min, def: 5) for the average number of query per second.
-s NUM                            #Number of sample queries (def: 3)
-t NUM                            #Number of top queries (def: 20)
--pie-limit NUM                   #Minimum percentage for pie chart slices

-S                                #Only analyze select queries
--exclude-query STR               #Exclude queries matching regexp STR
--exclude-file FILE               #Same but regexps are in FILE
--include-...                     #Inverse: include only.
-T                                #HTML <title> (def: "pgBadger")
-C                                #Remove /*comment*/ from queries
--disable-error|hourly|
type|session|temporary|
connection|query|lock|
autovacuum|checkpoint             #Remove a specific part in the report

-j|J NUM                          #Multiprocessing. Cannot be used with compressed files, csvlog or on Windows.
                                  #j is number of jobs/log file, J is number of log files in same time.

pgcluu_collectd DIR               #GUI that gives info on resource and space usage (similar to pgbadger, but gives some different stats).
                                  #pgcluu_collectd is the daemon collecting stats, pgcluu the tool creating reports
                                  #Should be run as the OS_USER owning the cluster, on a DIR owned by this OS_USER.
                                  #Good idea is to put inside DATADIR, with same permissions as other folders.
                                  #psql, sar (from package sysstat) should be installed. Their path should be given with -P|s STR if not
                                  #in /usr/bin/
                                  #Can find a sar file and several CSV files in DIR/
-d -h -p -U                       #Connection options
-D                                #Run as daemon. Can be killed with pgcluu_collectd -k
-i NUM                            #Frequency in seconds (def: 60)
-f FILE                           #PID FILE (def: /tmp/pgcluu_collectd.pid)
--stat-type all                   #Includes also system catalogs stats.
-m STR                            #Restrict data collection with a comma-separated list of metrics to perform (list can be found with
                                  #pgcluu_collectd --list-metric)
--pgbouncer-args=STR              #If pgbouncer (connection pooling utility) is used, arguments to pass to it (e.g. connection options)

pgcluu DIR                        #Creates report. DIR is the pgcluu_collectd DIR
                                  #Should be run as same OS_USER as pgcluu_collectd
                                  #sadf (from package sysstat) should be installed. Its path should be given with -s STR if not
                                  #in /usr/bin/
                                  #Can zoom in graphs
-b|e DATETIME                     #Begin|end time when to report.
-d DATABASE                       #Filter for only DATABASE (can be used several times)
-T TABLE                          #Same for TABLE (don't seem to work)
-t                                #Per table stats (don't seem to work)
-p DEVICE                         #Filter I/O info for only DEVICE (can be used several times)
-o DIR                            #DIR to create the HTML files (def: $PWD)

pg_top [NUM]                      #Show info about running PostgreSQL clients and servers in realtime, tables|indexes read|write.
                                  #psql is shown as "postgresql" command.
                                  #Must be run as the OS_USER owning the server.
                                  #If NUM, only show NUM first processes.
                                  #Accepts the following keystrokes:
                                  #  C-L: refresh
                                  #  R|X: switch with table|index stats
                                  #    t: show cumulative, not instant stats
                                  #  i: toggle display of idle processes
                                  #  k: kill
                                  #  o: change sorting
                                  #  Q: show current query
                                  #  u: show only specific user
                                  #Also available for smartphones/tablets.
-I                                #Do not display idle processes.
-o FIELD                          #Sorts according to FIELD
-z USER                           #Filter for only USER
-x [NUM]                          #Prints NUM first processes (def: "all"), then exits.
-c                                #Show command name instead of full command line
-s NUM                            #Delay in seconds (def: 5)
-r                                #Connects to a remote database. Needs to use -h -p -U -W connection options.

DETAILED MONITORING ==>           #Usually not needed, because there are higher-level monitoring tools:
                                  #  - ps auxww | grep ^postgres: see individual processes and description:
                                  #     - postgres master process
                                  #     - several master background processes: checkpoints, WAL, autovacuum, statistics collector
                                  #     - each client connection has one process with description showing CLIENT DATABASE HOST ACTIVITY
                                  #       (autoupdate can be turned on|off by ENVVAR update_process_title)
                                  #  - statistic collector:
                                  #     - daemon that fill in pg_stat* system views
                                  #     - used to collect statistics on activity
                                  #     - controlled by several ENVVAR BOOL:
                                  #        - track_activities (def: 'on') (COMMAND executed and time of execution)
                                  #           - track_activity_query_size (size of tracks in track_activities, def: 1024). Can only be
                                  #             set at server start.
                                  #        - track_counts (def: 'on') (general activity). Also allows explain.
                                  #        - track_io_timing (def: 'off') (I/O timing). Can be slow.
                                  #        - track_functions (def: 'none') (FUNC calls). Can also be 'pl' (PL/*) or 'all' (PL/*, SQL
                                  #          and C functions)
                                  #     - temp stats are stored in ENVVAR DATADIR/stats_temp_directory (def: 'pg_stat_tmp').
                                  #       Putting it in a RAM disk can improve performance.

pg_stat_activity                  #Server processes, with names, usernames, start|last time, addresses and command activity.
pg_stat_bgwriter                  #Background writer process's activity, e.g. for checkpoints.
pg_stat_replication               #WAL sender processes.
pg_stat_database                  #DATABASE, with number of servers/clients, transactions, temp files, tuples manipulated
                                  #(fetch|select|insert|update|delete), blocks read|hits, time spent on I/O read|write, deadlocks.
pg_stat_database_
conflicts                         #DATABASE, with query cancelled due to recovery on standby servers.
pg_stat[io]_[xact_]               #TABLE, with:
all|sys|user_tables               #  - not io: number of sequential|indexed scans (and tuples they fetched), tuples manipulated
                                  #    (insert|update|delete), number of rows (live|dead), [auto]vacuum|analyze activity
                                  #  - io: disk read|hits for all, index-only, TOAST and TOAST index
                                  #Can be for only system catalogs (sys) or not (user).
                                  #If xact_, take the current transaction into account.
pg_stat[io]_                      #INDEX, with:
all|sys|user_indexes              #  - not io: number of scan (with tuples fetched: bitmap + simple index scan, or simple index scan
                                  #    only)
                                  #  - io: index blocks read|hits (efficient if low read/hits %)
pg_statio_all_sequences           #SEQUENCE, with number of blocks read|hits
pg_stat_[xact_]user_              #FUNC, with number of calls and total time (only FUNC, or FUNC called by it too).
functions                         #ENVVAR track_functions must be on.

pg_stat_statements                #VIEW for all queries (query, time, number of rows, I/O).
                                  #Must put pg_stat_statements in ENVVAR shared_preload_libraries and use EXTENSION pg_stat_statements.
                                  #Can be reset with pg_stat_statements_reset().
                                  #Can use ENVVAR pg_stat_statementsmax (def: 1000)

OBJECT SIZES ==>                  #Can also look at pg_class.relpages (a page is 8KB)
pg_column_size(VAL)               #
pg_database_size(OID|STR)         #
pg_tablespace_size(OID|STR)
pg_indexes_size(OID|STR)
pg_relation_size(OID|STR[, STR2]) #Size in bytes. Can be a TABLE, INDEX or TOAST.
                                  #STR2 can be 'main' (def), 'vm' of 'fsm'
pg_total_relation_size(OID|STR)   #Same but with INDEX included
pg_table_size(OID|STR)            #Same with INDEX excluded and only for TABLE
pg_size_pretty(UINT)              #Convert a bytes size into human readable STR.


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:         MAINTAINANCE          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


vacuum([full, ][freeze, ]         #Options:
 [verbose, ][analyze])            #  - analyze: do analyze ... too
 ["TABLE"[("COL"...)]]            #  - full:
                                  #     - make database size shrink to its minimum (while non-full keep same size, but let rows space
                                  #       be used by further writes)
                                  #     - require exclusive lock
                                  #     - slower and should be avoided
                                  #  - verbose: print details
                                  #Goal:
                                  #  - With MVCC deleted rows are actually hidden so that other transactions can read them.
                                  #    Once they are not used anymore, those are "dead rows".
                                  #    Delete them, so optimize disk storage and thus speed (garbage-collection)
                                  #  - update visibility map: 1 and 0 map for rows that are not committed yet.
                                  #    Used to optimize index-only scans queries.
                                  #  - protect losing very old data due to xid (xmin or xmax) wraparound:
                                  #     - rows that will be wraparound but are still not committed can be "frozen" (frozenxid at the
                                  #       TABLE-level), so that their xid is skipped in the wraparound
                                  #        - vacuum freeze rows that are older than ENVVAR vacuum_freeze_max_age transactions or
                                  #          2e9 - ENVVAR vacuum_freeze_min_age (def: 5e7) transactions
                                  #            - if problems of wraparound, increase vacuum_freeze_max_age or decrease
                                  #              vacuum_freeze_min_age
                                  #        - force vacuuming freeze rows if "freeze" is used (can violate MVCC)
                                  #        - TABLE with no "dead rows" will not be checked for frozenxid removal unless it is older
                                  #          than ENVVAR vacuum_freeze_table_age (def: 1.5e8)
                                  #     - 2e9 xid, so need to vacuum once every 1e9 transactions
                                  #     - if there are wraparound risk, the server will not accept any new command
                                  #Def. TABLE is all TABLE that current ROLE has permissions. Def. "COL" is all "COL".
                                  #Cannot be done inside a transaction.
                                  #Requires share update exclusive lock, and makes database slower during vacuuming.

AUTOVACUUM ==>                    #Daemon automatically doing vacuum [analyze] on individual TABLE... according to how many rows are
                                  #changed. Better than doing it manually.
                                  #Enabled by ENVVAR autovacuum (def: 'on')
                                  #  - do vacuum every time:
                                  #     - a vacuum freeze is needed
                                  #       (can set its own ENVVAR autovacuum_freeze_* to override vacuum_freeze_*)
                                  #     - or ENVVAR autovacuum_vacuum_threshold (def: 50) +
                                  #       (number of inserted|deleted|updated rows) * ENVVAR autovacuum_vacuum_scale_factor (def: 0.2)
                                  #  - do vacuum analyze similary according to ENVVAR autovacuum_analyze_threshold (def: 50)
                                  #    and autovacuum_analyze_scale_factor (def: 0.1)
                                  #  - ENVVAR:
                                  #     - autovacuum_naptime INT: min. time (def: '1min') * number of databases before two launches
                                  #     - autovacuum_max_workers: numbers of DATABASEs that can be vacuumed at same time (def: 3)
                                  #  - doesn't vacuum TEMP
                                  #Can set autovacuum_* at the TABLE-level with create table ... with (autovacuum_* = VAL)
create table ...
 with (autovacuum_* = VAL)        #Set ENVVAR autovacuum_* for this TABLE

analyze [verbose]                 #Fill in pg_statistic.
 ["TABLE"[("COL"...)]]            #Parameters are like for vacuum.
                                  #Requires only an access share lock.
                                  #FOREIGNTABLE are analyzed only when explicitly specified, and not always supported.

pg_statistic                      #Stats used by the planner to optimize queries (only indexed COL).
                                  #Not exact stats, because only a random sample of the rows is chosen for efficiency purpose.
                                  #Example of statistics: number of entries, distinct entries, histograms, size (number of disk blocks)
                                  #ENVVAR default_statistics_target (def: 100, from 0 to 10000) decides the sample size.
                                  #Can be set column-wise with alter table "TABLE" alter "COL" set statistics INT (-1 means default)
                                  #(same for FTABLE and materialized views).
                                  #  - starelid OID: of the TABLE. Refers to pg_class.oid
                                  #  - staatnum UINT: COL index. Refers to pg_attribute.attnum.
                                  #  - stainherit BOOL: all COLs have false + (if inherited COL) a row with true, with inherited
                                  #    version of the TABLE
                                  #  - stanullfrac FLOAT: percentage of null values
                                  #  - stawidth INT: average size of null values
                                  #  - stadistinct FLOAT: number of repetitions: -NUM if repetitions (UNIQUE/TOTAL, closer to 0 if
                                  #    many repetitions), +NUM means no repetitions (UNIQUE), 0 means unknown
                                  #  - for NUM statistics:
                                  #     - stakindNUM INT: subtype of the statistic (code number)
                                  #     - staopNUM OID: FUNC used. Refers to pg_operator.oid
                                  #     - stanumbersNUM FLOAT_ARR: stats as FLOAT, or null if COL is not numerical
                                  #     - stavaluesNUM ARR: stats as the same type as the COL
pg_stats                          #User-friendly version of pg_statistic


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:      RECOVERY & BACKUPS       :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


DURABILITY ==>                    #PostgreSQL has durability: write operations will succeed even after a crash.
                                  #A crash will lead to:
                                  #  1) an inconsistent state if transaction was half written because of:
                                  #     - cache:
                                  #        - ENVVAR fsync (def: 'on'): don't use cache, i.e. flush WAL records as they are written.
                                  #          Can be disabled at server startup with postgres -F
                                  #        - ENVVAR wal_sync_method tells which OS command to use to flush cache (when using fsync):
                                  #          open_datasync, fdatasync, fsync, fsync_writethrough or open_sync (def: fdatasync). Best one
                                  #          can be determined with:
                                  #             pg_test_fsync -f FILE (FILE must be on same filesystem than DATADIR)
                                  #        - HDD cache on Linux:
                                  #           - queried with: hdparm -I /dev/FILE | grep "Write cache" (* at beginning if cache enabled)
                                  #           - disabled with: hdparm -W 0 /dev/FILE
                                  #        - Filesystem caching through journaling: disable it with mount options (e.g. data=writeback
                                  #          on ext3).
                                  #     - partial writes, controlled by ENVVAR full_page_writes (def: 'on').
                                  #       Putting to 'off' can improve performance.
                                  #  2) lost transactions (but no inconsistency) because of:
                                  #     - no synchronous commit: doesn't wait for the WAL to be written to report success of operation.
                                  #       ENVVAR synchronous_commit can be activated (local|remote_write|on (def)) or not ('off')
                                  #     - WAL is written after ENVVAR commit_delay (def: 0ms) in hope several operations will happen in
                                  #       the delay, which will then use a single flush. Best value is half the time of a single
                                  #       8kB write, as reported by last line of pg_test_fsync
                                  #       Only happens when min. ENVVAR commit_siblings (def: 5) transactions are currently opened.
                                  #     - ENVVAR wal_writer_delay (INT in ms, def: 200) too high: delay between each WAL writes
                                  #1) is dangerous: database could not be restared without a restore.
                                  #2) gives similar performance gain without that problem.
                                  #Putting DATADIR in a RAM disk is hardcore non-durable, and limits space to RAM space, but highly
                                  #efficient.

BACKUP VS HIGH                    #Backup strategy (saving data) is different from, but should be combined with high availability
AVAILABILITY ==>                  #strategy (quick restore of system if a node falls down)

BACKUPS ==>                       #Either:
                                  #  - pg_dump: more stable from one PostgreSQL version to another, or from one architecture to another.
                                  #  - WAL archiving: provides continuous archiving and PITR
                                  #Best: do both too (do a pg_dumpall after each base backup).
                                  #Good idea to compress backups
                                  #Backups methods are all hot backups.

pg_dump [DATABASE]                #Def DATABASE: PGDATABASE or OS_USER
                                  #Must be connect as superuser ROLE (for both backups and restores).
                                  #Unless "all", doesn't backup cluster-specific information. Remember then to restore them before
                                  #psql <FILE.
                                  #template1-specific information are backuped too: remember to restore from template0.
                                  #"INT" ON_ERROR_STOP should be set.
                                  #Recommendations for restore:
                                  #  - psql --single can be used to make everything rollback if error
                                  #  - Make sure tablespace DIR are good
                                  #  - should analyze restored databases.
-F p|c|d|t                        #Format of the output:
                                  #  - p (def): sql command in text format
                                  #  - c: custom compressed format (must be restored with pg_restore)
                                  #  - d -f DIR: put in a directory DIR (must be restored with pg_restore) with one file by TABLE, and a
                                  #    table of content file
                                  #  - t -f DIR: same but use tar (not compressed). Limit of GB per table.
-a                                #Don't save SCHEMAs (save only data)
-s                                #Save only SCHEMAs (not data)
-n SREGEXP                        #Only VAR... in SCHEMA matching SREGEXP (see psql). Can be specified several times.
                                  #Caution: doesn't dump VAR of other SCHEMA2... that SCHEMA might depend on.
-N                                #Inverse: SCHEMA not matching SREGEXP
-t SREGEXP                        #Same for TABLE matching SREGEXP. Incompatible with -n or -N
-T SREGEXP                        #Inverse: TABLE not matching SREGEXP.
--exclude-table-data=
SREGEXP                           #Same but only exclude TABLE data, not definition
-b                                #Include large objects, which is the default unless -n, -s or -t is used
-o                                #Includes OID
-O                                #Don't save ROLE ownership (with -F p). Will be able to restore backups without being superuser, but
                                  #restorer will get ownership of all objects.
-x                                #Don't save privileges (grant/revoke)
--no-tablespaces                  #Save everything in same, default tablespace.
--no-unlogged-table-data          #Don't save content of unlogged TABLEs
--no-security-labels              #Don't save seLINUX labels (when using it)
-c                                #Put cleaning commands first (drop VAR before trying to create it)
-C                                #Create the database in the beginning (otherwise need to create it).
--[column-]inserts                #Use insert instead of copy (slower). With column, put "COL" names instead of using positions. Is
                                  #much slower.
--serializable-deferrable         #Execute command in a serializable deferrable transaction (useful only when dumping to clone to
                                  #another machine)
--disable-dollar-quoting          #Use standard SQL quoting ' ' instead of $$ $$
--disable-triggers                #Create commands (with -F p) which disable triggers on tables before dump is restored.
-E STR                            #Encoding (def: PGCLIENTENCODING)
-j NUM                            #Use several threads in same time (faster but uses more resources). Make sure ENVVAR max_connections
                                  #is high enough. Doesn't work if any exclusive lock is being requested meanwhile.
--lock-wait-timeout=NUM           #Wait for NUM seconds when asking for locks (def: unlim)
-d -h -p -U -w|W                  #Connection options (see psql)
--role=ROLE                       #ROLE when getting the dump data

pg_dumpall                        #Same as pg_dump, but for the whole cluster (except template0)
                                  #Use same options as pg_dump, except ones that are irrelevant, and selection options (like -T).
                                  #All databases must already exist.
-g                                #Only saves cluster-wide objects
-t                                #Only saves tablespaces
-r                                #Only saves ROLE

pg_restore [FILE]                 #Restore a backup produced by pg_dump -F (except for normal format, which should be restored with psql).
                                  #Def FILE is stdin. If no -d DATABASE is specified, print a text version of the restoration instead.
-a
-c
-C
-F c|d|t
-j NUM
-n SCHEMA
-O
-s
-S ROLE
-t SREGEXP
-x
--disable-triggers
--no-tablespaces
--no-security-labels
-d -h -p -U -w|W                  #Like pg_dump
-e                                #Sets ENVVAR exit_on_error
-1                                #Put in only one transaction
-L FILE                           #Restore only objects present in FILE (can be produced with pg_restore -l, then manipulated)

WAL ==>                           #Write-ahead logs. Logs that store every operation on the cluster before they are performed.
                                  #Goal:
                                  #  - when starting the server, if the last operations of the WAL have not been applied to the data
                                  #    (i.e. if the DATADIR data don't match the WAL), last operations are performed.
                                  #    Goal is to recover from crash.
                                  #  - can also be used for backups (see below)
                                  #Only WAL log are garanteed to be flushed (faster), not real operations, to ensure durability.
                                  #Structure:
                                  #  - Use 16MB segments. A log "line" is a "record".
                                  #    Every write on the cluster adds a new record on the last segment.
                                  #    New segments are automatically added and rotated.
                                  #    Are in DATADIR/pg_xlog/ but could be moved to a faster storage using symlinks.
                                  #Checkpoints are when operations recorded by WAL are flushed to the disk (as opposed to flushing
                                  #the WAL itself, which is controlled by fsync, etc.):
                                  #  - last one is where to restart in crash recovery
                                  #  - are performed at min. time between ENVVAR checkpoint_segments (number of segments, def 3) and
                                  #    checkpoint_timeout (time between checkpoints, def '5min').
                                  #    Increasing it will improve performance but increase crash recovery time (values between 32 to 256
                                  #    are often used for checkpoint_segments, and checkpoint_timeout can be one day)
                                  #    If ENVVAR checkpoint_warning (def: '30s') is less than the time between checkpoints, but more
                                  #    than checkpoint_timeout, a warning will be issued to the server log.
                                  #  - can also issue SQL command checkpoint to do it
                                  #  - flushes performed by a checkpoints are spread to the next checkpoint. The spread is
                                  #    ENVVAR checkpoint_completion_target, i.e. percentage of size spread for the free time allowed
                                  #    between checkpoints (def: 0.5, best is 0.9). Can go up to 0.9 will improve performance, but
                                  #    increase recovery time. Can only be set at server start.
pg_xlogdump [FILE]                #Show a WAL file in human readable format
                                  #When in DATADIR, can also use FILE FILE2 to go from FILE to FILE2
pg_resetxlog                      #To use when WAL is corrupted. Look at online doc
pg_controldata DATADIR            #Show debug info for WAL

create unlogged table|sequence ...#TABLE|SEQUENCE is not written to WAL
select ... into unlogged table ...#Faster, but truncated on unclean shutdown
                                  #Also, cannot use replication to standby servers

SEQUENCE.log_cnt                  #0-32 (def: 0). Decrements at each setval|nextval() then cycles to 32.
                                  #When at 0, writes SEQUENCE to WAL.
                                  #I.e. only every 32 new value of SEQUENCEs are written to WAL, for performance

WAL ARCHIVING /                   #  - goals:
ONLINE BACKUP ==>                 #     - "continuous archiving". Just need to archive new WAL segments.
                                  #     - point in time recovery (PITR): instead of single snapshots, can recover to specific time in
                                  #       past
                                  #  - enabled by ENVVAR wal_level to 'archive|hot_standby' (def: 'minimal') and archive_mode to 'on'
                                  #  - backing up WAL segments continuously, and DATADIR at regular times:
                                  #     - backup in different folders, let's call them DIR1 and DIR2
                                  #     - events since the last DATADIR since the crash are then restored thanks to the archived WAL
                                  #       segments
                                  #  - backup of WAL segments:
                                  #     - each time a new WAL segment is about to be erased (because of rotation), ENVVAR
                                  #       archive_command STR is fired to back it up:
                                  #        - can include %p for its path and %f for its filename, e.g.:
                                  #            '[ ! -f "DIR1/%f" ] && cp -a "%p" "DIR1/%f"'
                                  #        - should give exit code != 0 if error, so that it retries it
                                  #        - should not allow overwritting files
                                  #        - on Linux, use sh, not Bash
                                  #        - should be faster than the speed at which WAL segments appear
                                  #        - check permissions of server daemon to execute command
                                  #     - new segments are automatically made. But can be created manually by:
                                  #        - running pg_switch_xlog()
                                  #        - can be made every max. every ENVVAR archive_timeout (def: 0, in seconds). Should not be
                                  #          under 60s.
                                  #          Goal is for databases with low traffic: new segments are rarely created but still want to
                                  #          archive the little traffic.
                                  #     - archived WAL segments before the last "base backup" can be erased to save space, up until when
                                  #       we want to do a PITR
                                  #     - Can also use command pg_receivexlog -D DIR, which archive WAL segments to DIR, according to
                                  #       connection options (see psql) -d -h -p -U -w|W
                                  #  - backup of DATADIR ("base backups"):
                                  #     - manually, steps are:
                                  #        - connect to any DATABASE of the cluster and fire pg_start_backup(STR) as superuser.
                                  #          STR should be the number of this unique backup
                                  #           - creates a text file DATADIR/pg_xlog/FILE.*.backup, where FILE is the last WAL segment
                                  #             archived, with information used by the recovery process (e.g. last WAL segment of
                                  #             current DATADIR)
                                  #           - creates DATADIR/backup_label, which is a very similar file
                                  #        - backup DATADIR with any command (such as cp -a) to DIR2:
                                  #           - don't include postmaster.* nor pg_xlog/*
                                  #           - don't forget directories that might be elsewhere, e.g. tablespaces or directories using
                                  #             symlinks postgresql.conf, pg_hba.conf, pg_ident.conf could also be put somewhere else
                                  #             with ENVVAR config|hba|ident_file
                                  #           - copy might issue warnings because DATADIR files change on the fly (since cluster is
                                  #             running): it's fine
                                  #        - fire pg_stop_backup() as superuser.
                                  #           - removes backup_label file
                                  #        - utilities (not necessarily needed):
                                  #           - pg_is_in_backup(), pg_backup_start_time()
                                  #           - pg_start|stop_backup() returns the WAL segment as STR: to translate into filenames:
                                  #              - pg_xlogfile_name[_offset](STR)
                                  #              - pg_xlog_location_diff(STR, STR2)
                                  #     - pg_basebackup:
                                  #        - automate all this. Options are:
                                  #            -h -p -U -w      Connection options
                                  #            -D DIR           DIR to copy to. Can be - (stdout) for tar mode
                                  #            -F p|t           If p, do a simple copy. Files pointed by symlinks (such as tablespaces),
                                  #                             will be copied to the destination using the same absolute path
                                  #                             If t, will tar it under the filename base.tar (symlinks files are tar'd
                                  #                             too, under their abs. path)
                                  #                             Can also use -z to gzip it and -Z 1-9 for the compression level (def: 6)
                                  #            -R               Put a recovery.conf sample if the backup
                                  #            -X s             Includes first WAL segment in the backup (def: doesn't include any WAL
                                  #                             segment).
                                  #                             Will use two clients in max_wal_senders
                                  #            -l STR           Label used in backup_label (def: 'pg_basebackup base backup')
                                  #            -c fast|spread   Change the checkpoint_completion_target (def: spread)
                                  #            -P               Progress bar
                                  #        - use same privileges as streaming replication (max_wal_senders, replication privilege, etc.)
                                  #     - in all cases, need to be done regularly, e.g. with a cron script
                                  #        - more regular base backups require more storage, but make faster recoveries
                                  #  - recovery:
                                  #     - steps:
                                  #        - stop server
                                  #        - replace DATADIR by DIR2, but keeping the WAL segments:
                                  #           - move DATADIR/* to temporary DIR3 (including tablespaces, etc., see above)
                                  #           - copy DIR2/* to DATADIR (including tablespaces, etc., see above), with right ownership
                                  #             and permissions
                                  #           - replace DATADIR/pg_xlog/* by DIR3/pg_xlog/*, with right ownership|permissions
                                  #             (in case some WAL segments were not archived but still present in DATADIR)
                                  #        - copy archived WAL segments from DIR1 to DATADIR:
                                  #           - create DATADIR/recovery.conf (its presence instructs server start to be in recovery mode)
                                  #              - can copy template SHAREDIR/recovery.conf.sample
                                  #              - must set variables:
                                  #                 - restore_command STR: just like archive_command, but to copy the WAL segments from
                                  #                   DIR1 to DATADIR/pg_xlog/
                                  #                   Should overwrite existing ones.
                                  #                   Will emit warnings because try to copy files that might not exist.
                                  #                   Ex: 'cp -a "DIR1/%f" "%p"'
                                  #              - can recover to a specific time (PITR):
                                  #                 - by setting (in recovery.conf) any of:
                                  #                    - recovery_target_time TIMESTAMP
                                  #                    - recovery_target_xid STR: the transaction ID
                                  #                    - recovery_target_name STR: STR is a restore point, which must have been
                                  #                      previously created by pg_create_restore_point(STR)
                                  #                 - time must be after the creation time of DIR2/*
                                  #                 - recover just before|after according to variable (in recovery.conf)
                                  #                   recovery_target_inclusive (def: true, i.e. after)
                                  #                 - will stop (unless variable pause_at_recovery_target is set to false or if
                                  #                   hot_standby mode), so we can check if the state is fine. Can resume by firing
                                  #                   pg_xlog_replay_resume()
                                  #                 - must remove WAL segments that have been archived after that time, to restart
                                  #                   archiving them normally
                                  #           - start the server in single user mode
                                  #           - recovery will happen: when done, recovery.conf will be recovery.done
                                  #        - make sure everything is ok, then restart the server normally
                                  #     - timelines:
                                  #        - each time a recovery suceeds, it increments the first number of the WAL segment files, e.g
                                  #          00...00100..0034 to 00...00200..0034
                                  #        - the first number is the timeline ID. Goal it that following WAL archives doesn't overwrite
                                  #          previous WAL archives created between the recovery and the crash, in case we want to come
                                  #          back to that point.
                                  #        - by default, recover to the timeline that was used during the base backup, but can specify
                                  #          recovery_target_timeline STR with "latest" in recovery.conf, or with the specified
                                  #          timeline ID

HIGH AVAILABILITY ==>             #Can use:
                                  #  - log shipping: master ships WAL to a DIR, then standby gets it from DIR
                                  #  - streaming replication: ships directly WAL from master to slave. Probably better.
                                  #     - async. (better performance) or sync. (better availability)
                                  #Any standby can also be a hot standby (makes more sense for a streaming replication one) to improve
                                  #load balancing (watch out precautions)

LOG SHIPPING /                    #  - Goal: not backup (but can be combined with backup) but to maintain a copy of the master server, so
WARM STANDBY ==>                  #    a switchover to the standby can happen quickly if there is a problem with the master
                                  #  - Idea: the standby machine keeps on reading the WAL archive (master must do WAL archiving) and
                                  #    applies them right away.
                                  #  - How:
                                  #     - start a cluster with a base backup, with a recovery.conf file in it.
                                  #       recovery.conf variable standby_mode should be on.
                                  #     - will continuously call recovery.conf variable restore_command (same format as archive_command)
                                  #       to copy WAL archive DIR1 to its own pg_xlog/, e.g. 'cp -a "DIR1/%f" "%p"'
                                  #        - will show error messages for next WAL segment, and .history file -> it's normal
                                  #     - Put recovery_target_timeline to "latest" (to stay sync. with the timeline chosen by the master)
                                  #     - If don't want to use DIR1 for backup purpose, clean every WAL archive that has been copied by
                                  #       setting variable archive_cleanup_command:
                                  #        - %r is the filename (not path) of the first WAL file to keep
                                  #        - pg_archivecleanup is a command line often used:
                                  #            - pg_archivecleanup "DIR" "%r"
                                  #            - flags are -d (verbose), -x STR (use it if WAL segments have this extension,
                                  #              e.g. -x .gz) and -n (dry-run)
                                  #     - Can stop standby mode and become a master:
                                  #        - by creating file specified by recovery.conf variable trigger_file, or firing
                                  #          pg_ctl promote.
                                  #           - change recovery.conf to recovery.done
                                  #        - never two masters at same time:
                                  #           - should turn off former master shortly before
                                  #           - before restarting, former master should become the new slave
                                  #        - good idea to prepare already the slave to become a master by setting up WAL archiving, etc.
                                  #        - recovery_end_command STR will be fired (%r is the same as archive_cleanup_command)
                                  #        - automatic failover is only possible using external packages.
                                  #  - Precautions:
                                  #     - DIR1 should not be on the master machine.
                                  #     - WAL segments are sent async (don't wait for shipping to execute), so there's a window for data
                                  #       loss, that can be reduce by lowering archive_timeout
                                  #     - standby and master should have similar config:
                                  #        - logically, e.g. symlinks (including table spaces)
                                  #        - software-wise
                                  #        - hardware wise. CPU architecture must be same.
                                  #     - switchover is manual: should have own mechanism to notify when the primary server is down, and
                                  #       to automatically failover

ASYNC. STREAMING                  #  - Goal: like log shipping, but smaller delay between master and slave state (still small one)
REPLICATION ==>                   #  - Idea: like log shipping, but doesn't use WAL archive DIR1 (nor restore_command,
                                  #    recovery_target_timeline, archive_cleanup_command), but directly get WAL from the server (over
                                  #    TCP connection).
                                  #  - How:
                                  #     - Set recovery.conf variable primary_conninfo (as "VAR=VAL ...", using libpq variables) for how
                                  #       to connect to the master.
                                  #     - Same as above for recovery_target_timeline
                                  #     - Must have privileges:
                                  #        - to connect to "replication" virtual DATABASE (in pg_hba.conf)
                                  #        - replication and login privileges (better to create a ROLE than to set up as superuser).
                                  #        - max number of connections is ENVVAR max_wal_senders (def: 0).
                                  #     - slave must keep up with the pace:
                                  #        - can increase ENVVAR wal_keep_segments on the master (number of segments that should be
                                  #          recycled but are kept, def: 0)
                                  #        - can use log shipping in parallel.
                                  #        - If fall behind, can redo a base backup.
                                  #        - Can tell by:
                                  #           - comparing pg_current_xlog_[insert_]location() on the master (current WAL),
                                  #             pg_last_xlog_receive|replay_location|timestamp() on the slave
                                  #           - use pg_stat_replication system view
                                  #        - Connection waits only for ENVVAR wal_receiver_timeout (def:60s) from slave to master, and
                                  #          wal_sender_timeout (def: 0, turned off) from master to slave.
                                  #     - Cascading replication:
                                  #        - Just use replication from downstream to upstream servers.
                                  #        - Goal: to reduce cost for master, but introduces more delay for other standbies.
                                  #        - sync. replication doesn't work for downstream servers.

SYNC. STREAMING                   #  - Goal: like async. streaming replication, but reduces data loss window to nothing (at expense of
REPLICATION ==>                   #    performance): every write transaction returns only after WAL is sent to standby ("2-safe
                                  #    replication").
                                  #  - How:
                                  #     - Master must set ENVVAR synchronous_standby_names with standbies:
                                  #        - comma-separated-list, only picks the first connected in the list
                                  #        - names must match application_name in primary_conninfo
                                  #           - can be * for any application_name
                                  #        - def is walreceiver
                                  #     - Actually waits according to ENVVAR synchronous_commit:
                                  #        - on (received and flushed to disk on slave), remote_write (only received) or local|off
                                  #          (nothing).
                                  #        - Makes it possible to set synchronous_commit specific values for databases, users or
                                  #          transactions, for different durability/performance tradeoff.
                                  #  - Precautions:
                                  #     - If last standby loses connection, will wait forever
                                  #        - if last standby needs to be down, must first put synchronous_commit to off in a
                                  #          pg_start|stop_backup() block

HOT STANDBY ==>                   #  - Goal: use a standby server (streaming replication or log shipping) for readonly queries (load
                                  #    balancing).
                                  #  - How:
                                  #     - Must set ENVVAR hot_standby to on on standby and ENVVAR wal_level to hot_standby for master
                                  #     - Must start with a new base backup (if switching from non hot standby to hot standby)
                                  #  - Precautions:
                                  #     - Watch out for the delay between master write and ability to read it in standby. If an arriving
                                  #       WAL archive is conflicting with a current query (e.g. if master dropped a table while standby
                                  #       is querying it), it will wait ENVVAR max_standby_archive|streaming_delay (for streaming
                                  #       replication mode or not) (def: 30000 ms, -1 for unlim) then cancel
                                  #        - low value provokes more cancels, but standby and master are more in sync: good if goal is
                                  #          more High availability, bad if goal is more load balancing
                                  #        - could be set at approx max time of queries.
                                  #        - Can also increase ENVVAR vacuum_defer_cleanup_age if lot of vacuum-related conflicts.
                                  #          Cancels can be seen on system view pg_stat_database_conflicts.
                                  #     - Hot standby stops at startup when standby tries to catch up servers WAL segments. During that
                                  #       period, there might be seemingly weird behavior.
                                  #       pg_is_in_recovery() will return true.
                                  #     - those ENVVAR must be superior or equal on the standby than the master: max_connections,
                                  #       max_prepared_transactions, max_locks_per_transaction
                                  #     - advisory locks can't be shared between master and slave
                                  #     - isolation level serializable not available


repmgr                            #Must have rsync, pg_ctl and pg_config in $PATH. Must be installed from source (see online doc).
                                  #Actions can be:
                                  #  - standby clone "NODE": make it possible to put as standby (do a base backup).
                                  #  - master|standby register: put as master|standby (master should be done first)
                                  #  - standby promote|follow: in case of a failover, automatical new master to promoted, and followers
                                  #    will replicate from it. Automatical or manual???
-d -h -p -U                       #Connection options
-D DATADIR                        #Cluster to target
-f DIR                            #repmgr.conf DIR (def: same as executable).
                                  #repmgr has three lines: cluster STR, node number INT, libpq_conninfo STR
--force                           #Do with standby clone when a master is up again after having being down, to get back the changes
                                  #since then from the new master.

repmgrd                           #Daemon doing automatic failover.
                                  #Needs to do all the standby register first.
-f DIR                            #


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:     CLUSTERING AND POOLING    :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


pgbouncer PGBFILE                 #Does connection pooling: maintains a single connection to be reused for each DATABASE+USER pair.
                                  #Goal is to lower connection time.
                                  #Can be much faster when connection time is important (small sessions).
                                  #Disadvantages:
                                  #  - requires more fds, so might needs lower max_client_conn than PostgreSQL's server
                                  #  - hides original host+port information in logs (all traffic goes though pgbouncer)
                                  #  - cannot implement all authentication method
                                  #Act as layer of abstraction: connection to pgbouncer DATABASE can be redirected to DATABASE of
                                  #other names, or of different clusters/machines.
                                  #Should be run as same OS_USER as the server.
                                  #Should be installed:
                                  #  - on database server, if lot of web servers connect to it (because it is the center of all
                                  #    connections that should be pooled)
                                  #  - on web server, if connects to lot of database servers
                                  #Each pool (DATABASE+USER) has:
                                  #  - clients (to pgBouncer) and servers (connection of pgBouncer to PostgreSQL).
                                  #    1 client = 0|1 server: 0 server when client just connected (session pool_mode) or is not issuing
                                  #    a request (transaction pool_mode)
                                  #  - cl_active (from show pool, see below) is number of clients on a pool.
                                  #    If more than pool size, clients will be cl_waiting instead until cl_active is lower.
                                  #    Pool size is determined by:
                                  #      - [default_]pool_size: cluster-wide and database-specific pool size.
                                  #      - min_pool_size: at first client, opens at least NUM idle servers, to make it more responsive
                                  #        in the first requests.
                                  #      - reserver_pool_size: extra pool size used for clients waiting (cl_waiting) for more than
                                  #        reserve_pool_timeout
                                  #  - max_client_conn is max number of cl_active for all pools together.
                                  #    When reached, clients don't wait, they crash.
                                  #  - Optimize limits:
                                  #     - number of file descriptors used = 2 + 1 per client (max_client_conn) + 1 per server
                                  #       (pool_size * number of users * number of databases)
                                  #         - pool_size should be at max without creating more servers than PostgreSQL's max_connections
                                  #         - max_client_conn should be max number of servers + expected number of idle clients
                                  #         - total should not exceed max number of file descriptors
                                  #Pool mode:
                                  #  - when server is not used anymore, returns back to pool (sv_active -> sv_idle|used)
                                  #  - it is done according to pool_mode, either after each session (def), transaction or query (avoid).
                                  #    transaction doesn't support session states, i.e. [re]set ENVVAR, listen|notify, with hold CURSOR,
                                  #    PREP, load, user-defined volatile FUNC
                                  #    Use transaction if lot of idle times in sessions, or if long queries.
                                  #Look at check_postgres for monitoring.
-d                                #Run in background.
                                  #Needs to give pidfile = FILE in [pgbouncer] in PGBFILE (FILE is created with the PID)
-R                                #Online restart: closes current running pgbouncer and inherits its connections without interrupting
                                  #anything (current running pgbouncer will be closed). Useful to upgrade without interrupting anything.
-q                                #Quiet mode
-v                                #Verbosity (can do several times)

PGBFILE ==>                       #Usually called pgbouncer.ini
                                  #Has two parts, each started with [databases], then [pgbouncer] on a single line, and separated by
                                  #blank line.
                                  #Each part has VAR = VAL ... (STR don't have any quoting)

                                  #[databases]:
DATABASE                          #STR, libpq string, but with only:
                                  #  - dbname: def. is same as DATABASE
                                  #  - host: def. is using Unix socket.
                                  #  - port: def. 5432
                                  #  - user: def. is same user
                                  #  - password
                                  #When client asks PgBouncer to connect on DATABASE, will use STR to connect to server.
                                  #Can also specify:
                                  #  - pool_size: Per-database pool size
                                  #  - connect_query: query done at connection start.
                                  #    For connection end (not DATABASE-specific), use server_reset_query (def: "discard all")
                                  #Can use * DATABASE to mean "any other database"

                                  #[pgbouncer]:
listen_port                       #Proxy port (which client should connect to in order to reach server)
listen_addr                       #Same for proxy address. Can be *
unix_socket_dir|mode|             #Like PostgreSQL ENVVAR unix_socket_directories|permissions|group
group                             #Def. are /tmp, 0777 and ""
auth_type                         #Similar as in pg_hba.conf. Can be md5 (def), plain (like password in pg_hba.conf), trust or any.
                                  #any is like trust, except that users are not even remembered which means:
                                  #  - all DATABASE must specify user=VAL in their libpq STR
                                  #  - control with admin_users is not effective
auth_file                         #"USER" "PASSWORD" ...
                                  #Necessary (only USER with a line in it will be able to connect)
admin_users                       #USER... (pgBouncer USER) allowed to connect to pgBouncer and issue statements on it.
stats_users                       #Same but can only use show ENVVAR (except show fds)

logfile                           #Redirect stderr to FILE, without stopping stderr
log_[dis]connections              #Logs them (def: 1)
log_pooler_errors                 #Logs errors sent to client (def: 1)
stats_period                      #Logs stats every NUM seconds (def: 60)
syslog[_ident|facility]           #

pool_mode                         #See above (def: session)
                                  #If transaction, server_reset_query should be ""
max_client_conn                   #(def: 100)
default_pool_size                 #(def: 20)
min_pool_size                     #(def: 0)
reserve_pool_size|
timeout                           #(def: 0 and 5 seconds)

server_check_delay                #After NUM seconds (def: 30), goes from sv_idle to sv_used, i.e. run sanity check query on server
                                  #connections when going from idle to active.
server_lifetime                   #Closes server connections opened for more than NUM seconds (def: 3600)
server_idle_timeout               #Same but for idle server connections (def: 600)
server_connect_timeout            #Same but for connecting time (def: 15)
client_login_timeout              #If client connects but does not login before NUM seconds (def: 60), drops it.
autodb_idle_timeout               #Closes pools (using * in [databases]) that have been unused for more than NUM seconds (def: 3600)

server_login_retry                #Waits NUM seconds (def: 15) after each failed authentification.
dns_max_ttl                       #DNS (host resolution) cache time in seconds (def: 15)
max_packet_size                   #Max packet size between PostgreSQL and pgBouncer, in bytes (def: 2GB)

server_round_robin                #If 0 (def), reuse connections in LIFO manner. If 1, in a random manner (better if TCP round-robin
                                  #distributing load between servers)

pgbouncer DATABASE ==>            #Virtual DATABASE, where only show ENVVAR is allowed, with some commands:
reload                            #Reload PGBFILE (can also use SIGHUP)
pause [DATABASE]                  #Safest way to stop pgBouncer: wait for clients to complete. Can also use SIGINT (CTRL-C)
shutdown                          #Like pause, but exit pgBouncer completely. Can also use SIGTERM
suspend                           #Drop clients, but flush buffers
kill DATABASE                     #Least saft way to stop DATABASE
resume [DATABASE]                 #Resume from pause|resume

                                  #Can also show the following ENVVAR:
lists                             #Snapshot of all other info
databases                         #DATABASE: connection+pool_size
stats                             #DATABASE:
servers                           #
clients                           #
pools                             #
fds                               #File descriptors
users                             #All users in auth_file
config                            #PGBFILE info
dns_hosts
dns_zones                         #Host resolution


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            TESTING            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


PGTAP UNITS ==>                  ##Needs to be installed.
                                 ##Tested database must enable PL/PGSQL.
                                 ##Idea is to create assertions (see below for list) in a separate test unit SQL file. Usually put in a
                                 ##tests/ folder
                                 ##Usually do test manipulation on the database between assertions, so in the end should rollback:
                                 ##  - put in a transaction block that rollbacks.
                                 ##  - put "INT" ON_ERROR_ROLLBACK and ON_ERROR_STOP
                                 ##For best formatting:
                                 ##  - put "INT" ECHO to nothing, QUIET to 1
                                 ##  - \pset format unaligned, pager on, t true
                                 ##  - if using psql, use -X to bypass init files
                                 ##Each assertion produce a TAP format line (common text format for test results, that is runned and
                                 ##parsed by "test harnesses")
                                 ##Postgres extension 'pgtap'
select plan(NUM)                 ##Starts a unit with exactly NUM assertions. If not sure use select * from no_plan() instead (avoid).
select * from finish()           ##Completes a test unit

PGTAP XUNIT TESTS ==>            ##Same as normal pgTap units (same output and assertions) but:
                                 ##  - use functions, not files. Functions just execute the assertions functions, and returns them as a
                                 ##    STR_ARR:
                                 ##      create or replace function SCHEMA.FUNC()
                                 ##      returns setof text as
                                 ##      $$begin
                                 ##          return next ASSERTION_FUNC(ARGS)...
                                 ##        end$$
                                 ##      language pgsql
                                 ##  - don't need anything to start|finish the unit but needs to run the unit with:
                                 ##      select * from runtests([STR][, STR2])
                                 ##    where STR is SCHEMA, and STR2 is a regular expression to match the FUNC to choose.
                                 ##    Since STR and STR2 are both optional (def: 'public' and '^test') cast to name if using only STR
                                 ##     - Use transaction on all tests as a whole, then on each individual test (including fixture
                                 ##       functions)
                                 ##  - can use fixture functions (same definition as above), special FUNC used at specific moments.
                                 ##    Each set run in alphabetical order. FUNC name must start with the name of the phase:
                                 ##     - startup, once before all tests
                                 ##     - setup, once before each test
                                 ##     - teardown|shutdown: same as setup|startup, but after tests
                                 ##    Watch out to exclude the fixture functions in runtests(). Good practice is to use a SCHEMA, and
                                 ##    '^test' for tests.

pg_prove [DIR|FILE...]           ##Test harness for pgTap (executes tests).
                                 ##Like doing psql, but better output, and don't need to set \pset and "INT"
                                 ##(but should still put in a transaction block)
                                 ##For DIR, recognize test files according to extension ".pg"
                                 ##Same for xUnit-style tests, but:
                                 ##  - don't use FILE... but -R, which fires runtests()
                                 ##  - use -s SCHEMA and -x REGEXP to specify arguments to runtests(STR, STR2)
-d -U -h -p                      ##Connection options
-P|S VAR=VAL                     ##Does \[p]set VAR VAL
--ext STR                        ##With DIR, use extension STR, not ".pg"
-r                               ##With DIR, recursive

--shuffle|reverse                ##Modify test execution order
--state STR,...                  ##Which tests to run:
                                 ##  - last: same as last time
                                 ##  - all: in normal order
                                 ##  - failed|passed: only ones that failed|passed
                                 ##  - hot: most recent failure first
                                 ##  - todo: only test with todos
                                 ##  - slow|fast: in speed order
                                 ##  - new|old: in mtime order
                                 ##  - fresh: only the ones that have been modified
                                 ##  - save: save state in a file ./.pg_prove (must be done first to be able to do --state next time)

-f                               ##Print failed tests
-q|Q                             ##Quiet, or even quieter
--verbose                        ##Outputs full TAP format
--no-comments                    ##Don't show diag() messages
--directives                     ##Only show skip() messages and todo() tests
-D                               ##Dry-run
-t                               ##Show time of execution of each test

-j NUM                           ##Number of jobs in parallel
-b FILE                          ##PSQL location

PGTAP ASSERTIONS ==>             ##They are FUNC that all come with an optional (but recommended) last arg STR for error message
                                 ##(def: '').
                                 ##They print the result of the assertion as a STR

GENERAL ASSERTS ==>              ##
ok(BOOL)                         ##Asserts that BOOL is true.
                                 ##Prefer other function when possible, e.g. is(VAL, VAL2) over ok(VAL = VAL2), because more descriptive
                                 ##output.
pass|fail()                      ##Like ok(true|false) (avoid them)
is[nt](VAL, VAL2)                ## is [not] distinct from
[i]matches(VAL, VAL2)            ## ~[*]
doesnt_[i]match(...)             ## !~[*]
[un][i]alike(VAL, VAL2)          ## [not] [a]like
cmp_ok(VAL, 'OP', VAL2)          ## VAL OP VAL2
isa_ok(VAL, STR)                 ## pg_type(VAL) = STR

SQL QUERIES RESULTS==>           ##Asserts results of sql select ...:
'SQL'                            ##Means SQL statement STR (either as is, or name of a PREP (recommended)).
                                 ##A PREP with arguments needs to be written as is, i.e. not 'PREP' but 'execute PREP(ARGS)'
throws_ok('SQL'[, STR2 [, STR3]])##Asserts that 'SQL' throws an exception, with errcode STR2 and errmessage STR3 (each can be null
                                 ##(def) for all errcode|errmessage)
lives_ok('SQL')                  ##Inverse of throws_ok('SQL')
throws_[i]like|matching
 ('SQL'[, STR2])                 ##Same as throws_ok('SQL', null, STR2), but STR2 needs to match with [i]like or ~[*], not = <>
performs_ok('SQL', INT)          ##Asserts that 'SQL' performs in less than INT ms.
results_eq|ne('SQL'|CURSOR,      ##Asserts that both queries compare with = <>
 'SQL2'|ARR|CURSOR2)             ##Is row-wise, so make sure they are ordered the same.
                                 ##CURSOR iterates over all rows (must be STR casted as refcursor)
                                 ##ARR represents a single-column (values ... could also be used for several columns)
bag|set_eq|ne('SQL',             ##Same but compares not row-wise, but the whole set of values together (so order doesn't matter).
'SQL2'|ARR)                      ##set removes duplicates, bag doesn't.
bag|set_has[nt]('SQL', 'SQL2')   ##Same as bag|set_eq|ne, but only for subset, i.e. asserts that 'SQL' includes 'SQL2'
is[nt]_empty('SQL')              ##Asserts number of rows = <> 0
row_eq('SQL', "ROW")             ##Same as results_eq, but for a single row

SCHEMA CONFORMANCE ==>           ##Asserts that current variables are exactly this.
schemas|tablespaces|roles
 |languages|casts_are(STR_ARR)   ##
tables|views|sequences|functions
 |opclasses|types|domains|enums
 |operators_are                  ##Can restrict to a SCHEMA, otherwise use search_path.
 (['SCHEMA', ]STR_ARR)           ##Functions are only the name, without arguments.
columns|indexes|triggers
 |rules_are
 (['SCHEMA', ]'TABLE', STR_ARR)  ##

SCHEMA EXISTENCE ==>             ##Asserts that variable exist.
has[nt]_schema|role|language(STR)##
has[nt]_table|view|sequence
 |foreign_table|type|composite
 |domain|enum|opclass|relation
 (['SCHEMA', ]STR)               ##relation is table|view|sequence|ctype
has[nt]_index(['SCHEMA',]
 'TABLE', 'INDEX'[, 'COL'[_ARR]])##'COL'[_ARR] not with hasnt.
has[nt]_trigger|rule
 (['SCHEMA', ]'TABLE', STR)      ##
has[nt]_function(['SCHEMA',]
 'FUNC'[, 'ARGSTYPE'_ARR])       ##
has[nt]_cast('TYPE', 'TYPE2'
 [, 'SCHEMA'][, 'FUNC'])         ##
has_operator('TYPE'[, 'SCHEMA'],
 'OP', 'TYPE2'[, 'RETURNTYPE'])  ##
has_left|rightop(['SCHEMA'],
 'OP', 'TYPE'[, 'RETURNTYPE'])   ##
has[nt]_tablespace(STR[, STR2])  ##Can use a STR2 as tablespace location (not with hasnt).

COL ATTRIBUTES ==>               ##
has[nt]_column
 (['SCHEMA', ]'TABLE', 'COL')    ##
col_not|is_null|
has[nt]_default|pk|fk|
unique|check(['SCHEMA',]
 'TABLE', 'COL'_[ARR])           ##pk is primary key, fk foreign key constraint.
is_clustered|
index_is_unique|primary
 (['SCHEMA', ]['TABLE', ]'INDEX')##Asserts properties for an index COL
has[nt]_unique|check|pk|fk
 (['SCHEMA', ]'TABLE')           ##TABLE has at least those constraints.
col_default_is(['SCHEMA',]
 'TABLE', 'COL', VAL)            ##
fk_ok(['SCHEMA', ]'TABLE',
 'COL'[_ARR], 'TABLE2',
 'COL2'[_ARR])                   ##Asserts that COL references COL2

TYPES ==>                        ##
col_type_is(['SCHEMA', ]'TABLE',
 'COL', ['SCHEMA2', ]'TYPE')     ##
index_is_type(['SCHEMA',]
 ['TABLE', ]'INDEX', 'TYPE')     ##'TYPE' is 'btree', 'hash', etc.
domain_type_is[nt](['SCHEMA',]
 'DOMAIN', ['SCHEMA2', ]'TYPE')  ##'TYPE' is 'btree', 'hash', etc.
enum_has_labels(['SCHEMA', ]
 'ENUM_TYPE', 'VAL'_ARR)         ##

FUNCTIONS ==>                    ##
can(['SCHEMA', ]'FUNC'_ARR)      ##Same as has_function, but without 'ARGSTYPE'_ARR, and with FUNC_ARR
function_lang_is
 (['SCHEMA', ]'FUNC'
 [, 'ARGSTYPE'_ARR], 'LANGUAGE') ##
function_returns
 (['SCHEMA', ]'FUNC'
 [, 'ARGSTYPE'_ARR], 'TYPE')     ##
volatility_is
 (['SCHEMA', ]'FUNC'
 [, 'ARGSTYPE'_ARR], STR)        ##
function_is_definer|
strict|aggregate(['SCHEMA',]
 'FUNC', ['ARGSTYPE'_ARR])       ##
cast_context_is
 ('TYPE', 'TYPE2', STR)          ##STR can be 'implicit', 'assignment', 'explicit'
trigger_is
 (['SCHEMA', ]'TABLE', 'TFUNC',
 ['SCHEMA2', ] 'FUNC')           ##Asserts that TFUNC executes FUNC
rule_is_instead
 (['SCHEMA', ]'TABLE', 'RULE')   ##
rule_is_on(['SCHEMA',]
 'TABLE', 'RULE', 'EVENT')       ##

ROLES AND SECURITY ==>
db|schema|tablespace|
 language_owner_is(STR, 'ROLE')  ##
table|view|sequence|composite
 |foreing_table|relation|opclass
 |type_owner_is
 (['SCHEMA', ]STR, 'ROLE')       ##
index_owner_is(['SCHEMA',]
 'TABLE', 'INDEX', 'ROLE')       ##
function_owner_is(['SCHEMA', ]
 'FUNC', 'ARGSTYPE'_ARR, 'ROLE') ##
*_privs_are                      ##Same as *_owner_is(...), but asserts PRIVILEGE[_ARR] for ROLE. Differences:
 (..., 'PRIVILEGE'[_ARR])        ##  - db -> database
                                 ##  - no relation, view, composite, foreign_table, index, opclass, type
                                 ##  - there is also:
                                 ##     - column*(..., 'TABLE', 'COL', ...) and any_column*(..., 'TABLE')
                                 ##     - fdw|server(FDW|'FSERVER', ...)

is[nt]_superuser(ROLE)           ##
is_member_of
 ('ROLE', 'ROLE2'[_ARR])         ##
language_is_trusted('LANGUAGE')  ##

UTILITIES ==>                    ##
diag(STR...)                     ##Returns STR (separated by newline), in front of a #, to add comments to the output.
skip(STR[, INT])                 ##Skip the next INT (def: 1) PGTAP functions, with explanation STR.
                                 ##To put in a conditional branch (e.g. case when ...) when a test might provoke the whole unit test
                                 ##to throw an exception (language or function not available).
collect_tap(ASSERT_FUNC(...)...) ##Do several PGTAP assertions functions at once.
                                 ##Useful when can't be put several COMMAND; but only one, for example in a SQL case when
todo(STR[, INT])                 ##Same, but instead of skipping, just declares that tests are expected to fail, because still on the
                                 ##todo list.
todo_start|end(STR)              ##Do todo() for all tests between start and end.
in_todo()                        ##Returns true if in a todo_start|end block.
os_name()                        ##e.g. 'linux'

OWN ASSERTION_FUNC ==>           ##Just create a plpgsql function that returns text, with a last optional text argument, and which
                                 ##returns ok() if test passes, or returns error message if not.

datafiller.py [FILE]              #Script printing commands filling randomly some TABLE...
                                  #FILE (def: stdin) is a list of DDL commands creating the TABLE.
                                  #Hints on how to fill are provided with --comments:
                                  #  - syntax:
                                  #     -- df [MACRO]: VAR[=VAL]
                                  #       - with MACRO, can do elsewhere use=DIRECTIVE to repeat all the VAR[=VAL]...
                                  #          - some predefined MACRO:
                                  #             words: word=/etc/dictionaies-common/words
                                  #       - VAL can use '' for STR and TIMESTAMP
                                  #     - can also use -- df T=TABLE A="COL": ... to target a TABLE or "COL" on a separate line
                                  #       after it. TABLE cannot use skip=FLOAT.
                                  #     - to specify a VAR, I write $VAR, but it should be written VAR
                                  #  - supported VAR:
                                  #     - all TABLE (put comment on a line by itself)
                                  #        - size, offset, mangle, null, seed: see below
                                  #     - TABLE (put comment after the opening parenthesis of creation):
                                  #        - size=INT: number of tuples to fill.
                                  #          Can only be on TABLE, not COL (except for gen=serand)
                                  #        - mult=INT: multiply $size for this TABLE
                                  #          mult (def: 1) should be done on each TABLE (relative size with each other)
                                  #          size (def: 100) only once for all TABLE (to scale it)
                                  #        - skip=FLOAT: divide $size for this TABLE.
                                  #          As opposed to mult, actually produce the rows, but randomly don't output them
                                  #        - nogen, null=FLOAT: same as below
                                  #     - COL (put comment after it):
                                  #        - all:
                                  #           - type=TYPE: generate another TYPE, then casted to the actual type
                                  #           - nogen: no random data (use only default values)
                                  #           - null=FLOAT: percentage of nulls
                                  #           - seed=INT: set random seed (def: use OS (usually depends on current time))
                                  #        - BOOL:
                                  #           - rate=FLOAT: percentage of true (def: 0.5)
                                  #        - INT (integer, not int)|DATE|TIMESTAMP|INTERVAL|INET|CIDR|MAC:
                                  #           - gen=STR: distribution, among:
                                  #              - serial: counter, increments $step (def: 1, must not be divider of $size) from
                                  #                $shift (def:0), then modulo $size, then adds $offset (def: 1)
                                  #                If $mangle, choose random $shift and $step
                                  #              - uniform: uniform distribution, from $offset to $offset + $size - 1
                                  #              - serand: serial up to $size1, then uniform to $size2 - $size1 ($size1 and $size2
                                  #                are the COL-level, and TABLE-level $size)
                                  #              - for other distributions: just use type=float, then use float distributions
                                  #           - offset, shift, step, size, mangle: see above
                                  #        - FLOAT:
                                  #           - gen=WORD: distribution, among:
                                  #              - uniform, gauss|norm, log (lognormal), beta, gamma, weibull, vonmises: use $alpha and
                                  #                $beta
                                  #              - exp, pareto: use $alpha
                                  #           - alpha|beta: see above
                                  #        - STR, followed by:
                                  #           - nothing: prefix followed by repetition of number, separated by _
                                  #              - prefix=STR (def: "COL")
                                  #              - length|lenvar=NUM: average length and diff from average of STR (def: 12 and 3)
                                  #           - chars=STR: choose random characters among a dictionary built with random words using
                                  #             characters in STR
                                  #              - cgen=MACRO: specifies INT parameters (to be used like use=) to specify how selection
                                  #                is done
                                  #              - length and lenvar: see above
                                  #           - text: can use INT parameters, choose from list of words
                                  #              - word=FILE|:STR,...: list of words, of 'size' words
                                  #              - length and lenvar: see above
                                  #           - word=FILE|:STR,...: same as above, but length to 1 and lenvar to 0. Can support unique.
                                  #        - DATE|TIMESTAMP|INTERVAL:
                                  #           - start|end=...
                                  #           - prec=NUM: in days for DATE, in seconds for TIMESTAMP
                                  #        - TIMESTAMP:
                                  #           - tz=STR
                                  #        - INTERVAL:
                                  #           - unit=s|m|h|d|mon|y (def: s)
                                  #        - BYTEA:
                                  #           - length and lenvar: see above
                                  #        - INET|CIDR:
                                  #           - network=STR
                                  #        - MAC
                                  #COL can't be unique for FLOAT, STR chars|text and BYTEA.
                                  #Uniqueness is tried 10 times (can be changed with datafiller.py --tries=NUM)
--[no-]filter                     #Output also FILE (commands creating the TABLE...), before commands filling the TABLE...
--drop                            #Output also commands dropping the TABLE...
--truncate                        #Sale for truncating
--size|offset|seed INT
--null FLOAT
--mangle                          #Sets VAR
-T                                #Put in a single transaction (normal isolation level)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            OTHERS             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


comment on ... is STR             #Add a comment STR, that can be read with:
                                  #  - col_description(TABLEOID, NUM)
                                  #  - [sh]obj_description(OID, DATABASE): shobj is for cluster-wide objects
                                  #  - a psql command \d* under "description"
                                  #... is TYPE followed by the definition, e.g. table "TABLE", trigger TFUNC on "TABLE", column "TABLE"."COL"
                                  #cast (TYPE as TYPE2), aggregate AFUNC(...), etc.
                                  #TYPE can be any object that can be used with create TYPE ...
                                  #If STR is null, remove the comment.
                                  #To write must be owner or superuser

TO DO ==>                         #In online doc:
                                  #  - Clients all rely on a backend protocol.
                                  #  - libpq is a C library that implement it and often used by clients.
                                  #    Large objects are a specific type handled by libpq.
                                  #  - Embedded SQL is a preprocessor that allows to write SQL in C code (then processed to libpq)
                                  #  - C can be used to write functions: see online doc, including background worker processes, SPI,
                                  #    creating new types, writing a PL/* handler, writing a FDW


      
   PG  
      


VERSION ==>                       #3.6.2

PG                                #Installation requires libpq

new PG.Client([STR|OBJ],          #Connect to the database specified by STR|OBJ, then fire FUNC.
 FUNC(ERROR, CLIENT,FUNC2(ERROR)))#FUNC2 must be fired when all operations are done to close connection.
                                  #STR is "[connectionname://][user[:password]@][host[:port]][/database]"
                                  #(all defaults if no first arg) or a IPC socket folder path.
                                  #Connectionname can be anything, it just differentiate sessions. OBJ has members :
                                  #  - user (def: process.env.USER)
                                  #  - database (def: process.env.USER)
                                  #  - password (def: null)
                                  #  - port (def: 5432)
                                  #  - host (def: null): if not URL, use DIR/.s.PGSQL.PORT
                                  #  - ssl (def: false)
                                  #Defaults are in PG.defaults.VAR
                                  #Other defaults:
                                  #  - PG.defaults.parseInt8:
                                  #     - PSQL bigint (such as result of count()) is too big for JavaScript INT.
                                  #     - If false (def), bigint -> STR. If true, bigint -> INT
                                  #Returns CLIENT, but should only be used for events. Use CLIENT in callback for connect|end()
CLIENT.connect
([FUNC(ERROR, CLIENT)])           #
CLIENT.end()                      #


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            QUERIES            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


CLIENT.query(STR[, VAL_ARR]       #Returns a QUERY from PostgreSQL command STR.
 [, FUNC(ERROR, OBJ)])            #If FUNC, also execute it and event handlers of QUERY cannot be used (so QUERY is useless then).
                                  #OBJ is same as in QUERY end event handler.
                                  #If VAL_ARR, each "$1", "$2", etc. in STR will be replaced by those VAL, providing it does not
                                  #point to a TABLE, a COL or a SCHEMA. It is slower but it prevents SQL injections (VAL_ARR are
                                  #properly escaped instead of using risky STR concatenation).
CLIENT.query(OBJ[, FUNC])         #Same but OBJ can have members :
                                  #  - text: same as STR
                                  #  - values: same as VAL_ARR
                                  #  - name STR3:
                                  #     - make it PREP: but using PSQL Extended Protocol, so same effect (skip parsing phase when
                                  #       calling came query with same name (will use same text|values)), but not actual PREP
                                  #     - parsing is only done when values VAL_ARR is used, so only useful then

QUERY.on("row", FUNC(OBJ))        #Execute QUERY and fire event handler for each row OBJ: {VAR: VAL}...
QUERY.on("end", FUNC(OBJ))        #Execute QUERY and fire event handler for all rows. OBJ has members :
                                  #  - command STR : SQL command
                                  #  - rowCount UINT
                                  #  - oid DOUBLE
                                  #  - rows OBJ_ARR: {VAR: VAL}...
                                  #  - fields OBJ_ARR:
                                  #     - name STR
                                  #     - format 'TYPE'
                                  #     - tableID DOUBLE
                                  #     - columnID DOUBLE
                                  #     - dataTypeID DOUBLE
                                  #     - dataTypeSize UINT
                                  #     - dataTypeModifier UINT
QUERY.on("error", FUNC(ERROR))    #

CLIENT.query
 (new PG-QUERY-STREAM(STR))       #Like CLIENT.query(STR) but returns as ISTREAM.
CLIENT.query
 (new PG-CURSOR(STR)[, VAL_ARR])  #Like CLIENT.query(STR[, VAL_ARR]) but returns a CURSOR (version 0.2.0).
CURSOR.read
 (UINT, FUNC(ERROR, OBJ_ARR))     #OBJ_ARR is {VAR: VAL}... or [] if no more rows
CLIENT.copyFrom|To(STR)           #COPY...FROM|TO statement must use this instead of CLIENT.query().
                                  #Returns a I|OSTREAM (must execute I|OSTREAM.end()).
                                  #Can use stdin (not stdout) in STR if writing|reading from I|OSTREAM
CLIENT.pause|resumeDrain()        #Stops|resumes emission of drain events (useful when async operations need to complete first)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:       OTHER OPERATIONS        :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/



CLIENT.on("drain", FUNC())        #Fired each time all queries have been executed
CLIENT.on("error", FUNC(ERROR))   #
CLIENT.on                         #Fired with listen/notify SQL statements
 ("notification", FUNC(OBJ))      #OBJ:
                                  #  - name "notification"
                                  #  - channel STR
                                  #  - payload STR
                                  #  - length NUM
                                  #  - processId NUM
CLIENT.on("notice", FUNC(STR))    #Fired with warning messages (otherwise printer in stdout)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            POOLING            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


PG.pools.getOrCreate([OBJ])       #Returns POOL (from GENERIC-POOL) of CLIENT that has extra method:
                                  #  - connect(FUNC(ERROR, CLIENT, FUNC2(ERROR2))): acquire a CLIENT and fires FUNC()
                                  #Created with params (either OBJ or PG.defaults):
                                  #  - name: OBJ stringified
                                  #  - max <- poolSize
                                  #  - idleTimeoutMillis <- poolIdleTimeout
                                  #  - reapIntervalMillis <- reapIntervalMillis
                                  #  - log <- poolLog
                                  #Other OBJ passed to new PG.CLIENT(OBJ)
                                  #If no POOL used, would use one new connection for each query.
PG.pools.all                      #POOL_OBJ

PG.connect(OBJ, FUNC)             #Like new PG.CLIENT(OBJ, FUNC).connect() but uses PG.pools.getOrCreate(OBJ)
PG.on
 ("error", FUNC(ERROR, CLIENT))   #
PG.end()                          #Close all CLIENT, even if currently querying.


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           PGMODELER           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


PGMODELER ==>                     #GUI modelling tool:
                                  #  - goal is to create/modify the DDL of a database, using a GUI.
                                  #     - can import DDL from existing database (of objects the user has permissions to query).
                                  #  - outputs SQL commands (or send to a database) or PNG image.
                                  #  - can validate DDL and issue warnings (requires connection to a database)
                                  #  - most DDL is available except foreign wrapper, etc., materialized views, event triggers,
                                  #    dictionaries, unlogged|temp tables, reference to VIEW COL
                                  #  - relationships: generalization is inherits, copy is create table like, others are foreign keys (with proper uniqueness)
                                  #  - there is a tree to go through object on the right panel
