
                                  ┏━━━━━━━━━━━━━━┓
                                  ┃   POSTGRES   ┃
                                  ┗━━━━━━━━━━━━━━┛

TODO:
  - continue going through this doc, refreshing it. Stopped at `psql`
  - go through all `???` in this doc
  - read full official docs, and compare with this doc
     - stopped at https://www.postgresql.org/docs/current/creating-cluster.html (for 15.3)

                                  ┌─────────────┐
                                  │   VERSION   │
                                  └─────────────┘

VERSION ==>                       #15.3

ARCHITECTURE ==>                  #RDBMS with focus on standard compliance and extensibility.
                                  #Conform to SQL:2016 for most of it
                                  #Client (psql, pgadmin, etc.) / server (postgres) architecture

pg_config|postgres --version
ICONF.server_version[_num]
version()->STR                    #Postgres full version, including OS

DATADIR|DBDIR/PG_VERSION          #Postgres version used by a CLUSTER|DATABASE

                                  ┌─────────────┐
                                  │   SUMMARY   │
                                  └─────────────┘

DATABASE DESIGN ==>               #Modelling:
                                  #  - create tables with right:
                                  #     - columns
                                  #     - constraints: pkey, fkey, default, check, not null, unique, exclude
                                  #     - properties: inherits
                                  #  - using:
                                  #     - normal types (NUM, BOOL, STR, BSTR, BYTEA, DATE|TIME, ENUM) and arrays, ranges
                                  #     - special types (net, dictionary, xml, json, hstore, ltree, geometry) and created types (ctype, domain)
                                  #     - id vs uuid
                                  #     - views for encapsulation, or security restriction per column
                                  #     - [event] triggers
                                  #     - sequences
                                  #     - schemas
                                  #     - foreign tables (including file_fdw for CSV files)
                                  #     - listen|notify for clients communication
                                  #  - pgModeler
                                  #Security:
                                  #  - roles and privileges
                                  #  - authentication
                                  #  - PCONF.unix_socket_directories
                                  #  - FUNC definition (leakproof, security definer)
                                  #Multithread-safety (transactions, locks)
                                  #Watch out for:
                                  #  - null
                                  #  - SQL injection

PERFORMANCE ==>                   #  - on design:
                                  #     - materialized views instead of views
                                  #     - rules instead of triggers
                                  #     - index
                                  #     - cursors
                                  #     - partitions
                                  #     - prepared statements
                                  #     - large objects
                                  #     - tablespaces
                                  #  - CONF tunning:
                                  #     - disabling durability, decreasing checkpoints frequency, using RAM disks
                                  #     - setting right resources needed for SCONF.work_mem, SCONF.maintenance_work_mem, SCONF.effective_cache_size,
                                  #       PCONF.wal_buffers, ZSCONF.max_stack_depth, ZSCONF.temp_file_limit,
                                  #       PCONF.max_files_per_processes, SCONF.effective_io_concurrency, PCONF.shared_buffers,
                                  #       PCONF.max_connections, SCONF.statement_timeout
                                  #     - using pgtune
                                  #  - optimizing queries with explain
                                  #  - pgbench
                                  #  - for big data write, see below best practices
                                  #  - connection pooling (pgBouncer)
                                  #  - upgrading hardware
                                  #  - FUNC definition (volatility, cost, rows)
                                  #  - TABLE fillfactor, fastupdate
                                  #  - autovacuum tunning

SETUP FOR END USERS               #  - create [A|W]FUNC (possibily from PL/* languages), prepared statements, comments
 AND FUTURE MAINTENANCE ==>       #  - logging
                                  #  - [hot] standby with [a]sync. streaming replication
                                  #  - pgagent for regular tasks:
                                  #     - pgbadger and pgcluu reports creation
                                  #     - check_postgres
                                  #        - good idea to merge pgbadger, pgcluu and check_postgres into one HTML file with a script
                                  #     - pg_dumpall
                                  #  - if durability, check proper cache usage (HCONF.wal_sync_method, HDD|filesystem cache)

TESTING ==>                       #  - random filling (datafiller.py)
                                  #  - unit testing (pgTap)
                                  #  - load testing (Tsung)

MAINTENANCE ==>                   #  - monitoring:
                                  #     - use pgadmin, with Server status window, and opening a psql within pgadmin (create proper .psqlrc), or use teamPostgreSQL
                                  #     - resource (should not exceed PCONF.max_connections and SCONF.work_mem), space usage or other problems:
                                  #        - pgbadger and pgcluu
                                  #        - pg_top
                                  #        - check_postgres
                                  #  - data update (should create functions):
                                  #     - partitionning
                                  #     - copy "TABLE" from
                                  #  - cluster|reindex (ask for exclusive lock)
                                  #  - check PostgreSQL upgrades, and use pg_upgrade
                                  #  - create restore points with pg_create_restore_point(STR) after critical operations

                                  ┌─────────────┐
                                  │   UPGRADE   │
                                  └─────────────┘

pg_upgrade                        #Upgrade a CLUSTER to a new major release of Postgres
                                  #Should make a backup first
                                  #Cannot be done on a log shipping standby
                                  #Servers must be down
                                  #DATABASEs cannot use TYPE reg*, except regclass|regrole|regtype

ENVVAR PGBINOLD
--old-bindir|-b OLD_BINDIR
ENVVAR PGBINNEW
--new-bindir|-B NEW_BINDIR
ENVVAR PGDATAOLD
--old-datadir|-d OLD_DATADIR      #NEW*DIR must be the new install, with similar settings
ENVVAR PGDATANEW                  #OLD*DIR must be erased afterwards
--new-datadir|-D NEW_DATADIR      #Must use NEW_BINDIR/pg_upgrade

ENVVAR PGPORTOLD
-p OLD_PORT
ENVVAR PGPORTNEW
-P NEW_PORT                       #
PGSOCKETDIR
--socketdir|-s DIR                #DIR with Unix sockets

--old-options|-o STR
--new-options|-O STR              #`postgres` CLI flags

ENVVAR PGUSER
--username|-u ROLE                #Initial session ROLE

--link|-k                         #Use hard links instead of copies. Faster.
                                  #Must be on the same filesystem
                                  #Cannot access old server afterwards
--clone                           #Same but using reflinks. Even faster.
                                  #Must be on the same filesystem
--jobs|-j NUM                     #Use multiple processes

--no-sync|-N                      #Like initdb

--retain|-r                       #Do not cleanup logs

--check|-c                        #Dry run

                                  ┌────────────┐
                                  │   SYNTAX   │
                                  └────────────┘

COMMAND;                          #"Statement"
CLAUSE ==>                        #Part of a COMMAND attached to keywords
                                  #E.g. WHERE BOOL

WHITESPACES ==>                   #Ignored

CASE-SENSITIVITY ==>              #Case-insensitive for:
                                  #  - keywords (usually uppercase)
                                  #  - VARs (usually lowercase)
"VAR"
U&"VAR2"                          #Make VAR case-sensitive

-- COMMENT ...
/* COMMENT */                     #

(VAR [= VAL], ...)                #OPTS. Used in many SQL statements for named parameters.
                                  #VAL is only optional if either:
                                  #  - it has a default value
                                  #  - it has no value, i.e. it is implicitly a BOOL
                                  #Some commands allow specifying OPTS both in (...) and as keywords
                                  #  - prefer (...) as keywords tend to be deprecated
(VAR [VAL], ...)                  #ZOPTS. Same without = sign
pg_options_to_table
 ('VAR=VAL'_ARR)->ROW_SET         #Parses as ROW: option_name 'VAR', option_value 'VAL'

DDL                               #"Data Definition Language"
                                  #Statements operating on entities themselves
                                  #E.g. create, alter, drop, truncate, comment, etc.
DML                               #"Data Manipulation Language"
                                  #Statements operating on entities contents
                                  #E.g. select, insert, update, delete, explain, etc.
DCL                               #"Data Control Language"
                                  #Statements operating on authorization
                                  #E.g. grant, revoke, etc.
TCL                               #"Transaction Control Language"
                                  #Statements operating on transactions
                                  #E.g. commit, rollback, savepoint, etc.

OUTPUT ==>                        #Some statements return the NUM of ROWs manipulated.
                                  #This is separate from the ROW_SET returned by a SUBQUERY, and is not printed by default
                                  #For: select|insert|update|delete|merge|move|fetch|copy|create table as

.sql                              #File extension for SQL
application/sql                   #MIME type for SQL

                                  ┌──────────┐
                                  │   NAME   │
                                  └──────────┘

name                              #TYPE of a "VAR" name

ICONF.max_identifier_length       #63. Max size of a "VAR"

NAME[NUM]                         #'CHAR'

VAR                               #Any identifier
                                  #[[:alnum:]_]+
                                  #Max 63 chars
"VAR"                             #Allows reserved keywords, case-sensitive, and do not trim whitespaces
                                  #"" to escape "
as VAR                            #Some COMMANDs allows optional `as`.
                                  #This allows reserved keywords, but remains case-insensitive unless quoted
SCONF.quote_all_identifiers       #BOOL (def: false). Quote all "VAR" in output

"..."                             #Notation in my doc to mean a VAR (with|without quoting)
                                  #Including "TABLE", "COL", etc.

TEXT <-> NAME
VARCHAR|BPCHAR <=-> NAME          #Type casting

pg_get_keywords()->ROW_SET        #All SQL keywords
ROW.word                          #'KEYWORD'
ROW.catcode                       #CHAR among:
                                  #  - 'U': can be used by any NAME
                                  #     - due to being used only in unambiguous places
                                  #     - e.g. any ENTITY
                                  #  - 'C': cannot be used as TYPE|FUNC NAME
                                  #     - due to already being a TYPE|FUNC
                                  #  - 'T': cannot be used as COL NAME
                                  #     - due to ambiguity in SELECT query
                                  #  - 'R': cannot be used as COL|TYPE|FUNC NAME
ROW.catdesc                       #Like catcode, but as longer STR
ROW.barelabel                     #BOOL. If false, requires `as VAR`
ROW.baredesc                      #Like barecode, but as longer STR

                                  ┌────────────┐
                                  │   SCHEMA   │
                                  └────────────┘

create schema "SCHEMA"            #Creates a SCHEMA, i.e. namespace inside a DATABASE
                                  #Dependency parent of the ENTITYs it contains

create schema "SCHEMA"            #Combine create schema + create ENTITYs within that SCHEMA
 create ENTITY ... [,...]         #ENTITY: table, view, index, sequence, trigger
create schema "SCHEMA"
 grant ... [,...]                 #Same for `grant ...`
alter ENTITY "ENTITY"
 set schema "SCHEMA"              #For all ENTITYs that can have a SCHEMA

[SCHEMA.]"NAME"                   #"NAME"s are namespaced by SCHEMA

SCONF.search_path                 #'SCHEMA,...' used as default. Leftmost has priority.
                                  #Def: '"$user", public'
current_schemas(BOOL)             #Show SCONF.search_path
 ->'SCHEMA'_ARR                   #If false, do not include pg_catalog and pg_temp*

SEARCH PATH ATTACK ==>            #Creating ENTITYs in a non-rightmost SCHEMA to in order to shadow ENTITYs in other SCHEMAs
                                  #Can prevent by either:
                                  #  - not specifying shared SCHEMAs in SCONF.search_path
                                  #     - i.e. using only ROLE-specific ("$user") or session-specific (pg_temp) SCHEMAs
                                  #  - use only one shared SCHEMA, and as rightmost
                                  #  - restrict `create` PRIVILEGE on shared SCHEMAs

set schema 'SCHEMA,...'           #Same as: set SCONF.search_path to 'SCHEMA,...'

DEFAULT CREATE SCHEMA ==>         #When creating a new ENTITY, use the leftmost SCHEMA of SCONF.search_path, except "$user"
current_schema
current_schema()->'SCHEMA'        #Default write schema. null if none

pg_ENTITY_is_visible(OID)->BOOL   #True if ENTITY's SCHEMA is within SCONF.search_path

"$user"                           #Can be used in SCONF.search_path, replaced by current "ROLE" name
                                  #This SCHEMA must be manually created
                                  #Meant for user-specific data

public                            #SCHEMA automatically created, initially empty
                                  #Meant for non-user-specific data
                                  #`public` ROLE has `usage` PRIVILEGEs

pg_namespace                      #TABLE with all SCHEMAs
pg_namespace.oid                  #OID
pg_namespace.nspname              #NAME of "SCHEMA"

regnamespace                      #TYPE to cast pg_namespace.oid as "SCHEMA" name

pg_type.typnamespace              #REGNAMESPACE of TYPE
pg_class.relnamespace             #REGNAMESPACE of RELATION
pg_constraint.connamespace        #REGNAMESPACE of CONSTRAINT
pg_ts_parser.prsnamespace         #REGNAMESPACE of PARSER
pg_ts_template.tmplnamespace      #REGNAMESPACE of TEMPLATE
pg_ts_dict.dictnamespace          #REGNAMESPACE of DICTIONARY
pg_ts_config.cfgnamespace         #REGNAMESPACE of REGCONF
pg_conversion.connamespace        #REGNAMESPACE of CONVERSION
pg_collation.collnamespace        #REGNAMESPACE of COLLATION
pg_opfamily.opfnamespace          #REGNAMESPACE of OPFAMILY
pg_opclass.opcnamespace           #REGNAMESPACE of OPCLASS
pg_seclabels.objnamespace         #REGNAMESPACE|null of SECURITY_LABEL
pg_proc.pronamespace              #REGNAMESPACE of FUNC
pg_operator.oprnamespace          #REGNAMESPACE of OP
pg_statistic_ext.stxnamespace     #REGNAMESPACE of STATISTICS
pg_tables.schemaname              #"SCHEMA" name of TABLE
pg_indexes.schemaname             #"SCHEMA" name of INDEX
pg_views.schemaname               #"SCHEMA" name of VIEW
pg_matviews.schemaname            #"SCHEMA" name of MVIEW
pg_sequences.schemaname           #"SCHEMA" name of SEQUENCE
pg_stats.schemaname               #"SCHEMA" name of analyzed TABLE
pg_policies.schemaname            #"SCHEMA" name of POLICY
pg_rules.schemaname               #"SCHEMA" name of RULE
pg_publication_tables.schemaname  #"SCHEMA" name of PUB's TABLE
pg_stats_ext[_exprs]
 .statistics_schemaname           #"SCHEMA" name of STATISTICS
pg_stats_ext.schemaname           #"SCHEMA" name of STATISTICS's TABLE

                                  ┌────────────────┐
                                  │   PG_CATALOG   │
                                  └────────────────┘

pg_catalog                        #SCHEMA for system data. "System catalogs"
                                  #Contains all pg_* TABLE|VIEWs and builtins FUNC|TYPEs
                                  #Prepended to SCONF.search_path
                                  #  - can be explicitly added to SCONF.search_path to override priority order
                                  #Sometimes readonly. Should avoid modifying.
                                  #DATABASE-specific unless on cluster-specific ENTITY
                                  #  - dependency child of DATABASE

PRIVILEGES ==>                    #Owned by CLUSTER|DATABASE owner
                                  #Most TABLEs are read-only to `public`
                                  #pg_settings is read-write
                                  #A few TABLEs can only be seen by superuser

postgres -O
ZSCONF.allow_system_table_mods    #BOOL (def: false). Allow modifying pg_catalog

pg_node_tree                      #Internal serialized information TYPE, specific to pg_catalog.*
                                  #Is internally like a STR
pg_get_expr(PG_NODE_TREE,         #Converts PG_NODE_TREE to STR
 TABLE.oid[, BOOL])->STR          #TABLE.oid can be 0 if PG_NODE_TREE does not contain variables
                                  #BOOL (def: false) is prettify

                                  ┌────────────────────────┐
                                  │   INFORMATION SCHEMA   │
                                  └────────────────────────┘

information_schema                #SCHEMA for system data
                                  #Unlike pg_catalog, is standard SQL
                                  #Does not contain Postgres-specific information
                                  #Are all VIEWs over pg_catalog.*
                                  #To document ???

DOMAIN TYPES ==>                  #The following are DOMAIN_TYPEs used only by information_schema
                                  #All use not null
sql_identifier                    #NAME_TYPE, COLLATION "C"
yes_or_no                         #VARCHAR(3)_TYPE, 'YES|NO', COLLATION "C"
character_data                    #VARCHAR_TYPE, COLLATION "C"
cardinal_number                   #INT4_TYPE, >= 0
time_stamp                        #TIMESTAMPTZ_TYPE, default current_timestamp

                                  ┌────────────┐
                                  │   ENTITY   │
                                  └────────────┘

ENTITY                            #Entity that can be created with `create ENTITY ...`
                                  #E.g. table, collation, function, etc.

"ENTITY"                          #Notation depends on entity. It can be one of the following.
VAR,...                           #For most ENTITYs
VAR                               #For access method, collation, conversion, database, event trigger, language,
                                  #subscription, tablespace, text search *
VAR(...),...                      #For function|procedure|routine|aggregate
VAR(TYPE|none, TYPE2|none),...    #For operator
(TYPE as TYPE2)                   #For cast
VAR on "TABLE"                    #For policy, trigger, rule
VAR using ACCESS_METHOD           #For operator class|family
for TYPE language LANG            #For transform
for RPROLE server SERVER          #For user mapping

ENTITY_CATALOG                    #pg_* TABLE listing ENTITYs of a given kind

ENTITY ID ==>                     #The following three properties are often used to identify any ENTITY
class[o]id                        #REGCLASS of the ENTITY_CATALOG
obj[o]id                          #OID of the ENTITY within its ENTITY_CATALOG
objsubid                          #INT4. "COL" number. 0 if classid is not pg_class

pg_describe_object
 (classid, objid, objsubid)->STR  #'ENTITY NAME [of RELATION NAME2]'
pg_identify_object
 (classid, objid, objsubid)->ROW  #
ROW.type                          #'ENTITY'
ROW.schema                        #'SCHEMA'|null
ROW.name                          #'NAME'|null
ROW.identity                      #'SCHEMA.NAME[.COL]'
pg_identify_object_as_address
 (classid, objid, objsubid)->ROW  #
ROW.type                          #'ENTITY'
ROW.object_names                  #{SCHEMA,NAME[,COL]}
ROW.object_args                   #STR_ARR. Arguments passed to some ENTITYs
pg_get_object_address('ENTITY',
 {SCHEMA,NAME[,COL]},STR_ARR)->ROW#ROW: classid, objid, objsubid

alter ENTITY ... "ENTITY" ...     #Sets ENTITY options after creation
                                  #Not for ENTITY: access method, cast, transform
                                  #Several ENTITYs allow combining several `alter ...` into a single statement
                                  #  - faster than doing individual statements serially
                                  #  - for most actions of:
                                  #     - alter [foreign] table, materialized view, type "ROW"
                                  #     - alter function|procedure|routine

alter ENTITY "ENTITY"             #Rename an ENTITY.
 rename to "VAR"                  #Not for ENTITY: extension, operator, user mapping

create or replace ENTITY ...      #If "ENTITY" already exists, drop it first.
                                  #For ENTITY:
                                  #  - view, rule, trigger
                                  #  - function|procedure|aggregate
                                  #  - language, transform
create ENTITY if not exists ...   #If "ENTITY" already exists, noop but no error
                                  #For ENTITY: collation, extension, foreign table, index, materialized view, schema,
                                  #sequence, server, statistics, table, user mapping
alter ENTITY if exists ...        #Fail if "ENTITY" does not exist
                                  #For ENTITY: foreign table, index, materialized view, sequence, table, view

create ENTITY ... with (OPTS)     #Common syntax found in multiple ENTITYs
                                  #If OPTS.VAR VAL optional, then also optional in alter ...
                                  #When present the following are available too
alter ENTITY ... set (OPTS)       #Sets OPTS after creation
alter ENTITY ...                  #Sets OPTS to default value
 reset (OPTS.VAR,...)             #Not with ENTITY: publication|subscription

drop ENTITY "ENTITY"              #Delete an ENTITY
drop ENTITY if exists "ENTITY"    #Unless set, fails if exists

                                  ┌──────────────────┐
                                  │   DEPENDENCIES   │
                                  └──────────────────┘

drop ENTITY ... restrict|cascade  #If there are dependency child objects
                                  #  - 'restrict' (def): fail
                                  #  - 'cascade': drop them, recursively
                                  #     - not allowed for database|tablespace|role|user mapping

pg_[sh]depend                     #TABLE with child|parent dependencies between [cluster-wide] ENTITYs
pg_[sh]depend.classid
pg_[sh]depend.objid
pg_[sh]depend.objsubid            #ENTITY
pg_[sh]depend.refclassid
pg_[sh]depend.refobjid
pg_[sh]depend.refobjsubid         #ENTITY it depends on
pg_shdepend.dbid                  #pg_database.oid of DATABASE
pg_depend.deptype                 #'CHAR' for the type of dependency among:
                                  #  - 'n' ("normal"): delete child with `cascade`
                                  #  - 'a' ("auto"): delete child with `cascade|restrict`
                                  #  - 'i' ("internal"): like 'a', except if child is dropped due to another parent being
                                  #    deleted, its initial parent is deleted too
                                  #  - 'P|S' ("partition primary|secondary"): partition CHILD_TABLE
                                  #  - 'e' ("extension"): EXTENSION direct child
                                  #  - 'x' ("auto extension"): EXTENSION indirect child
pg_shdepend.deptype               #'CHAR' for the type of dependency among:
                                  #  - 'o' ("owner"): ROLE owner child
                                  #  - 'a' ("ACL"): ROLE mentioned in ACL
                                  #  - 'r' ("policy"): ROLE mentioned in POLICY
                                  #  - 't' ("tablespace"): TABLESPACE parent of a TABLE

                                  ┌─────────────┐
                                  │   COMMENT   │
                                  └─────────────┘

comment on ENTITY "ENTITY"        #Add a comment
 is 'COMMENT'                     #Child auto-dependency of ENTITY
comment ... is null               #Delete a comment

obj_description
 (OID, 'ENTITY_CATALOG')
 ->STR|null                       #Get DATABASE-wide ENTITY's comment
shobj_description
 (OID, 'ENTITY_CATALOG')
 ->STR|null                       #Get cluster-wide ENTITY's comment
col_description
 (TABLE_OID, COL_NUM)->STR|null   #Get COL's comment

\d*                               #Print comments under `description` column

pg_description                    #TABLE with all COMMENTs on DATABASE-wide ENTITYs
pg_description.classoid
pg_description.objoid
pg_description.objsubid           #ENTITY
pg_description.description        #'COMMENT'

pg_shdescription                  #TABLE with all COMMENTs on cluster-wide ENTITYs
                                  #Same COLs except no objsubid

                                  ┌─────────────────────┐
                                  │   TYPE DEFINITION   │
                                  └─────────────────────┘

create type TYPE                  #Without YOPTS, creates a new "shell TYPE", i.e. TYPE declared but not implemented yet
                                  #Can be used only to type a FUNC's arguments or return value
                                  #Useful when creating a TYPE used in its own YOPTS.*

create type TYPE(YOPTS)           #Creates a new "base TYPE", based on C functions
                                  #Must be superuser

YOPTS.category                    #'CHAR' among:
                                  #  - 'B': BOOL
                                  #  - 'N': NUM (or OID-like)
                                  #  - 'S': STR|NAME
                                  #  - 'Z': char, pg_node_tree
                                  #  - 'V': BSTR
                                  #  - 'D': date|time[stamp][tz]
                                  #  - 'T': INTERVAL
                                  #  - 'A': ARR_TYPE
                                  #  - 'G': point|line|lseg|box|polygon|path|circle
                                  #  - 'I': inet|cidr
                                  #  - 'E': ENUM_TYPE
                                  #  - 'R': [MULTI]RANGE_TYPE
                                  #  - 'C': ROW_TYPE
                                  #  - 'P': pseudo-type
                                  #  - 'X': unknown
                                  #  - 'U' (def): user-defined
                                  #     - including tid|cid|xid|xid8, bytea, EXTENSION TYPEs like json, etc.

YOPTS.default                     #VAL assigned as default value

YOPTS.like                        #TYPE2

YOPTS.input                       #FUNC(CSTR[, OID, TYPEMOD_INT4])->TYPE_VAL
                                  #Converts 'UNKNOWN' to TYPE
                                  #OID: of TYPE, or of TYPE[*] if ARR_TYPE
                                  #Must be `strict`
YOPTS.output                      #FUNC(TYPE_VAL)->CSTR
                                  #Converts TYPE to 'UNKNOWN'

YOPTS.receive                     #FUNC(INTERNAL[, OID, TYPEMOD_INT4])->TYPE_VAL
                                  #Converts binary representation to TYPE
                                  #INTERNAL is pointer towards bytes
                                  #Must be `strict`
YOPTS.send                        #FUNC(TYPE_VAL)->BYTEA
                                  #Converts TYPE to binary representation

YOPTS.typmod_in                   #FUNC(CSTR_ARR)->TYPEMOD_UINT
                                  #"Type modifier", i.e. arbitrary arguments passed to TYPE
                                  #Usually for variable-bounded length, e.g. bpchar(NUM)
                                  #Arguments are converted to a single UINT
                                  #  - passed to YOPTS.input|receive and cast FUNCs
                                  #  - as TYPEMOD_INT4, -1 if no TYPEMOD
YOPTS.typmod_out                  #FUNC(TYPEMOD_UINT)->CSTR
                                  #Def: returns '(UINT)'

pg_type                           #TABLE with all TYPEs
pg_type.oid                       #OID
pg_type.typname                   #"TYPE" name
pg_type.typtype                   #'CHAR' among:
                                  #  - 'b': base TYPE (typcategory 'B|N|S|Z|V|D|T|A|G|I|U')
                                  #  - 'e': ENUM_TYPE (typcategory 'E')
                                  #  - 'r': RANGE_TYPE (typcategory 'R')
                                  #  - 'm': MULTIRANGE_TYPE (typcategory 'R')
                                  #  - 'd': DOMAIN_TYPE (uses underlying TYPE's typcategory)
                                  #  - 'c': ROW_TYPE (typcategory 'C')
                                  #  - 'p': pseudo-type (typcategory 'P|X')
pg_type.typcategory               #'CHAR' of YOPTS.category
pg_type.typdefault                #STR of YOPTS.default. Can be:
                                  #  - null: none
                                  #  - VAL: if `create type` was used
                                  #  - 'EXPR': with DOMAIN_TYPE
pg_type.typinput                  #REGPROC of YOPTS.input
pg_type.typoutput                 #REGPROC of YOPTS.output
pg_type.typreceive                #REGPROC of YOPTS.receive. 0 if none.
pg_type.typsend                   #REGPROC of YOPTS.send. 0 if none.
pg_type.typmodin                  #REGPROC of YOPTS.typemod_in. 0 if none.
pg_type.typmodout                 #REGPROC of YOPTS.typemod_out. 0 if none.
pg_type.typanalyze                #REGPROC of YOPTS.analyze. 0 if none.
pg_type.typisdefined              #BOOL. Temporarily set to false while `create type` is ongoing.

regtype                           #TYPE to cast pg_type.oid as "TYPE" name
format_type
 (TYPE_OID, TYPEMOD_UINT|null)
 ->'TYPE'                         #

                                  ┌────────────┐
                                  │   DOMAIN   │
                                  └────────────┘

create domain "TYPE" [as] TYPE2   #Creates a TYPE based on TYPE2 but with additional CONSTRAINTs

create domain ... default VAL     #Default VAL (def: null)
                                  #Can be `default`
alter domain "TYPE"
 set default VAL                  #
alter domain "TYPE" drop default  #

create domain ... [not] null      #
alter domain "TYPE"
 set|drop not null                #

create domain ...
 check(BOOL_REXPR)                #Can use `value` to refer to the new value

create domain ...
 constraint "CONSTRAINT" ...      #Set name of "CONSTRAINT" underlying [not] null or check()
alter domain "TYPE"
 rename constraint
 "CONSTRAINT" to "CONSTRAINT2"    #

alter domain "TYPE"
 drop constraint
 [if exists] "CONSTRAINT"
 [restrict|cascade]               #

pg_type.typbasetype               #REGTYPE of underlying TYPE of DOMAIN_TYPE. 0 if not DOMAIN_TYPE
pg_type.typtypmod                 #TYPEMOD_INT4 passed to underlying TYPE of DOMAIN_TYPE
                                  #0 if not DOMAIN_TYPE, or if no TYPEMOD
pg_attribute.atttypmod            #Same for COL
pg_type.typndims                  #INT4. Number of dimensions of underlying ARR_TYPE of DOMAIN_TYPE
                                  #0 if not DOMAIN_TYPE, or if underlying TYPE is not ARR_TYPE
pg_attribute.attndims             #Same for COL
pg_type.typdefaultbin             #PG_NODE_TREE of the default value, if using DOMAIN_TYPE
pg_type.typnotnull                #BOOL. `not null` on DOMAIN_TYPE. 0 if not DOMAIN_TYPE

pg_constraint.contypid            #REGTYPE of CONSTRAINT's DOMAIN.
                                  #0 if CONSTRAINT is on a TABLE instead

                                  ┌──────────────────┐
                                  │   TYPE CASTING   │
                                  └──────────────────┘

pg_typeof(VAL)->REGTYPE           #

cast(VAL as TYPE)
VAL::TYPE                         #Explicit casting
TYPE '...'                        #Explicit casting, but UNKNOWN '...' only

ASSIGNMENT CASTING ==>            #Automatic casting when:
                                  #  - inserting a value in a COL
                                  #  - assigning|returning a value inside a FUNC
                                  #Always implies explicit casting too

IMPLICIT CASTING ==>              #Automatic casting when passing arguments to a FUNC
                                  #Always implies explicit + assignment casting too

TYPE -> TYPE2                     #Means can do implicit casting
TYPE => TYPE2                     #Means can do assignment casting
TYPE ~> TYPE2                     #Means can do explicit casting
TYPE <=-> TYPE2                   #Means TYPE2 => TYPE, TYPE -> TYPE2

create cast (TYPE as TYPE2)       #Creates a type casting FUNC
 with function FUNC(...)          #Must be FUNC(TYPE1_VAL[, TYPEMOD_INT4[, BOOL]])->TYPE2_VAL
                                  #BOOL is true if explicit cast
                                  #Current ROLE must own TYPE[2]
create cast (TYPE as TYPE2)       #Create a type cast that does:
 with inout                       #  - TYPE1_VAL -> 'TYPE1_UNKNOWN'
                                  #  - 'TYPE1_UNKNOWN' -> TYPE2_VAL
                                  #I.e. uses YOPTS.output|input
create cast (TYPE as TYPE2)       #Create a type cast when TYPE[2] are binary-equivalent.
 without function                 #I.e. uses YOPTS.send|receive

create cast ... as assignment
create cast ... as implicit       #Assignment|implicit casting (def: explicit)

pg_cast                           #TABLE with implicit|explicit type casting
pg_cast.oid                       #OID
pg_cast.castsource|casttarget     #REGTYPE of source|target TYPE
pg_cast.castfunc                  #REGPROC of FUNC used for conversion
pg_cast.castcontext               #Casting:
                                  #  - 'e': explicit
                                  #  - 'a': assignment
                                  #  - 'i': implicit
pg_cast.castmethod                #How to cast, among:
                                  #  - 'f': `with function`
                                  #  - 'i': `with inout`
                                  #  - 'b': `without function`

YOPTS.preferred                   #BOOL (def: false). Each YOPTS.category has a single true, which is the preferred type cast.
pg_type.typispreferred            #Also used as the preferred TYPE in:
                                  #  - overloaded FUNCs
                                  #  - anycompatible*
                                  #For:
                                  #  - NUM -> FLOAT8
                                  #  - STR -> TEXT
                                  #  - BSTR -> VARBIT
                                  #  - date|time[stamp][tz] -> TIMESTAMPTZ
                                  #  - REG* -> OID
                                  #  - inet|cidr -> INET

                                  ┌─────────────────┐
                                  │   LARGE TYPES   │
                                  └─────────────────┘

FIXED LENGTH TYPES ==>            #Types that do not have a variable length

VARIABLE BOUNDED LENGTH TYPES     #One of:
 ==>                              #  - numeric(...)
                                  #  - varchar|bpchar(...)
                                  #  - bit(...)
                                  #  - time[stamp][tz]|interval(...)

VARIABLE UNBOUNDED LENGTH TYPES   #One of:
 ==>                              #  - numeric
                                  #  - text
                                  #  - bit varying, bytea
                                  #  - pg_node_tree, pg_snapshot
                                  #  - [MULTI]RANGE_TYPE
                                  #  - ARR_TYPE
                                  #  - ROW_TYPE
                                  #  - any other TYPE built from variable '...': json[b]|jsonpath, xml, hstore,
                                  #    ltree|l[txt]query, query_int, path|polygon, inet|cidr, tsvector|tsquery

PHYSICAL SIZE ==>                 #Additional 1|4|18 bytes, max 1GB (see TOAST)

SIZING CAST ==>                   #Type cast to same type
                                  #Used to enforce size of variable bounded length TYPEs
                                  #  - failing if too large
                                  #  - padding or truncating
                                  #Usually implicit casting

YOPTS.internallength              #INT2. Number of bytes of a TYPE.
                                  #Can be `variable` for variable bounded|unbounded TYPE
pg_type.typlen                    #INT2 of YOPTS.internallength. Can be:
                                  #  - -2: cstring|unknown
                                  #  - -1: variable bounded|unbounded TYPE
pg_attribute.attlen               #Same for COL

pg_column_size(VAL)->INT4         #Size of VAL, in bytes, including:
                                  #  - additional 1|4|8 bytes
                                  #  - TOAST
                                  #  - compression

YOPTS.alignment                   #'CHAR' specifying how many bytes to align the values when stored, i.e. padding them if necessary.
pg_type.typalign                  #Can be:
                                  #  - 'c' (1 byte, i.e. no alignment)
                                  #  - 's' (2 bytes)
                                  #  - 'i' (4 bytes)
                                  #  - 'd' (8 bytes, usually)
                                  #Usually same as YOPTS.internallength for fixed-length TYPEs except:
                                  #  - no alignment: cstring|unknown, name, uuid
                                  #  - 2 bytes: tidd
                                  #For variable length TYPEs:
                                  #  - ARR|RANGE_TYPE: uses underlying TYPE's alignment
                                  #  - 8 bytes: ROW_TYPE, PATH|POLYGON
                                  #  - 4 bytes: all others
pg_attribute.attalign             #Same for COL

YOPTS.passedbyvalue               #BOOL. Whether the TYPE is passed by value or by reference.
pg_type.typbyval                  #Builtin TYPEs: true if fixed length of 1-8 bytes, except macaddr[8] and tid
pg_attribute.attbyval             #Same for COL

                                  ┌───────────┐
                                  │   TOAST   │
                                  └───────────┘

TOAST ==>                         #Large variable length TYPE values are split in several ~2KB chunks
                                  #Goals:
                                  #  - fit in a single 8KB heap page, so that computation can happen in-memory only, which is faster
                                  #  - compression, to save space
                                  #Not used by non-persisted data ("on-disk TOAST"), except in few specific cases ("in-memory TOAST").
IN-LINE TOAST ==>                 #Keeps data as is but possibly compress it
                                  #Requires 1 (if <127 bytes) or 4 additional bytes
                                  #Used if <2005 bytes
OUT-OF-LINE TOAST ==>             #Replace data with 18 bytes pointer to pg_toast_OID TABLE
                                  #Used if >=2005 bytes
pg_class.reltoastrelid            #REGCLASS of the RELATION's pg_toast_OID "TABLE". 0 if none
pg_toast.*                        #SCHEMA with out-of-line data
pg_toast.pg_toast_OID             #"TABLE" with TOAST out-of-line data
pg_toast.pg_toast_OID.chunk_id    #Data ID
pg_toast.pg_toast_OID.chunk_seq   #Data chunk serial NUM
pg_toast.pg_toast_OID.chunk_data  #BYTEA with the data
pg_toast_temp_NUM.*               #Same with TEMP TABLEs
                                  #Same special behavior as pg_temp_NUM

ICONF.segment_size                #1.3e6 (i.e. 1GB). Max amount of heap pages in a TOASTED type.
                                  #I.e. max size of any TYPE value, especially variable unbounded length ones.

SCONF.default_toast_compression   #Compress TOASTed values (in-line or out-of-line) among:
                                  #  - 'pglz' (def): Postgres-specific LZMA-like, optimized for speed (not space)
                                  #  - 'lz4': optimized for space
                                  #     - requires compiling with --with-lz4 (is the case with Ubuntu)
create table "TABLE"
 ("COL" TYPE compression ENUM,...)
alter table "TABLE"
 alter [column] "COL"
 set compression ENUM             #Sets compression, like SCONF.default_toast_compression
pg_attribute.attcompression       #'CHAR' of compression among '\0' (default_toast_compression), 'p' (pglz), 'l' (lz4)
pg_column_compression(VAL)->STR   #Returns compression 'pglz|lz4' or null

alter [foreign] table "TABLE"     #Sets TOAST behavior among:
 alter [column] "COL"             #  - plain
 set storage ENUM                 #     - no out-of-line nor compression
                                  #     - only possible value for fixed length TYPEs
                                  #  - extended:
                                  #     - both out-of-line and compression
                                  #     - built-in TYPEs: for variable length TYPEs
                                  #  - external:
                                  #     - out-of-line but no compression
                                  #     - i.e. faster computation but more space
                                  #  - main:
                                  #     - no out-of-line but compression
                                  #     - might still be out-of-line, but only as last resort after extended|external ones
                                  #     - built-in TYPEs: numeric, inet|cidr
pg_attribute.attstorage           #'CHAR' for TOAST behavior for the COL
                                  #Can be 'p|x|e|m' for plain|extended|external|main
YOPTS.storage
pg_type.typstorage                #Same for a TYPE, i.e. setting default value for COLs using it

TOPTS.toast_tuple_target          #UINT. Do not use out-of-line nor compression for values < UINT bytes
                                  #Min: 128, max: 8160, def: 2040 (which is usually good)

OPTS.process_toast                #BOOL (def: true). Whether `vacuum` applies to TOAST_TABLEs too
                                  #Always `on` if `vacuum full`

                                  ┌───────────────────┐
                                  │   LARGE OBJECTS   │
                                  └───────────────────┘

LARGEOBJ                          #VAL that is persisted as its own file
                                  #Meant for large values
                                  #  - always on-file, not in-memory
                                  #  - conceptually like a file path or file descriptor
                                  #  - i.e. low memory but slow read|write
                                  #Split into 2KB chunks
LARGE OBJECT                      #"ENTITY" name

OID                               #When specifying as argument of LARGEOBJ creation, allows specifying its OID
                                  #Can be 0|-1 to ask for a new one

lo_import('PATH'[, OID])->OID     #Creates a LARGEOBJ from a file
                                  #Must be superuser
lo_export(OID, 'PATH')            #Creates a file from a LARGEOBJ
                                  #Must be superuser

lo_creat(OID)->OID                #Creates an empty LARGEOBJ
lo_from_bytea(OID, BYTEA)->OID    #Creates a LARGEOBJ from BYTEA
lo_unlink(OID)                    #Delete LARGEOBJ from database. Must be done after use
                                  #Does not remove from files, if imported from files

lo_get(OID[, INT8, INT4])->BYTEA  #Reads LARGEOBJ
                                  #If INT8, only from that byte, with a length of INT4 bytes
lo_put(OID, INT8, BYTEA)          #Writes LARGEOBJ

pg_largeobject_metadata           #TABLE with all LARGEOBJ metadata
pg_largeobject_metadata.oid       #OID of LARGEOBJ

pg_largeobject                    #TABLE with all LARGEOBJ data
                                  #Visible only to superuser
pg_largeobject.loid               #pg_largeobject_metadata.oid of LARGEOBJ
pg_largeobject.data               #BYTEA with contents
pg_largeobject.pageno             #INT 0-based index, if BYTEA split into several chunks

log_manage("COL")                 #Calls lo_unlink() on all LARGEOBJ OIDs that have been removed|changed since last call
                                  #Should be done as a TFUNC: before update or delete, for each row
                                  #Must `delete * from TABLE` before `drop|truncate table` to ensure TFUNC is called
                                  #Trusted postgres extension 'lo'

lo                                #TYPE that abstracts LARGEOBJ
                                  #Must be used as log_manage() "COL" TYPE

vacuumlo DATABASE...              #CLI. Remove LARGEOBJs which OIDs does not exist in DATABASE anymore
--limit|-l NUM                    #Max of LARGEOBJs to remove (def: 1000). Meant for performance
                                  #Can be 0
--dry-run|-n                      #
--host|-h HOST
--port|-p PORT
--username|-U USER
--no-password|-w
--password|-W                     #LIBPQ connection

                                  ┌───────────┐
                                  │   EQUAL   │
                                  └───────────┘

operator([SCHEMA.]OP)             #Another way to write OP
                                  #Default SCHEMA: pg_catalog

OPERATORS ==>                     #Operators shared by all TYPEs, except a few documented as such

OPERAND ORDER ==>                 #The evaluation order of FUNC|OPs arguments is not defined. It might be reordered by query planner.
                                  #E.g. with select VALS,... or with or|and chains

(VAL)                             #Parenthesis to override operator order

VAL = VAL2
VAL != VAL2
VAL <> VAL2                       #BOOL

VAL [not] in (VAL2,...)           #BOOL. Whether VAL = <> any VAL2

case [LVAL]
  when TVAL then RVAL
  [...]                           #Switch statement. Substitutes to RVAL where LVAL = TVAL
  [else RVAL]                     #Def LVAL: true, i.e. can use TVAL BOOLs, like an if statement
end                               #Def RVAL: null

                                  ┌─────────────┐
                                  │   COMPARE   │
                                  └─────────────┘

VAL > >= < <= VAL2                #BOOL

VAL [not] between [symmetric]     #BOOL. Same as VAL >= VAL2 and VAL <= VAL3
 VAL2 and VAL3                    #If VAL3 < VAL2:
                                  #  - if symmetric: swap them
                                  #  - otherwise: returns false

greatest|least(VAL...)->BOOL      #Using > <

min|max(SET)->VAL                 #AFUNC

                                  ┌─────────────┐
                                  │   UNKNOWN   │
                                  └─────────────┘

unknown                           #Unknown TYPE
                                  #Has no operators, but is usually implicitly transtyped based on operators
                                  #Cannot be used in an ARR_TYPE
                                  #Also called "string"
unknown -> VAL                    #Possible with any TYPE, except any*
VAL ~> unknown                    #Never possible, except with unknown itself

'...'                             #UNKNOWN
                                  #'' to escape a '
                                  #Otherwise can include any character, including \, newlines and Unicode codepoints.
                                  #Cannot include \0
                                  #  - must use BYTEA with '\x00'
                                  #Internally encoded using server ENCODING
                                  #Used for the literal value of all TYPEs, meant to be cast
                                  #  - noted as TYPE_UNKNOWN, meaning UNKNOWN that can be cast to TYPE
                                  #  - type casting is TYPE-specific, and not specified in pg_cast
$[TAG]$...$[TAG]$                 #Like '...' but can include '
E'...'                            #Like '...' but can use backslash escape sequences
                                  #\b \f \n \r \t \v \\ \' \NNN \xNN \uNNNN \UNNNNNNNN
U&'...'                           #Like '...' but can also include \NNNN or \+NNNNNN codepoint
U&'...' uescape 'CHAR'            #Set escape CHAR (def: \)

unistr(STR)->STR                  #Converts \uNNNN \UNNNNNNNN \NNNN \+NNNNNN to characters

any*                              #TYPE. "Polymorphic type".
                                  #Used in FUNCs to represent generic types
                                  #  - all any* in a given FUNC call's argument|return have same TYPE
                                  #  - including anyarray|any[multi]range, but using their underlying TYPE
anycompatible*                    #Like any* but polymorphic TYPEs can use implicit casts, not just be identical
unknown -> any*                   #Not possible
anyelement
anycompatible                     #Most general any* TYPE, i.e. matches anything

cstring                           #TYPE. null-terminated STR
                                  #Similar to unknown, but meant to use inside FUNCs
                                  #Does not have any OPs (not even =), not used in FUNCs|COLs, but can be cast
CSTR <~=> STR                     #

void                              #TYPE of FUNC with no return value
                                  #Different from null, which is a value

internal                          #Pointer TYPE, for C FUNCs
                                  #When used, cannot be called from SQL
                                  #  - i.e. only meant for internal FUNCs
                                  #Should be used both for arg and return types

PSEUDO-TYPE ==>                   #TYPEs meant for FUNCs, not SQL
                                  #Any of: any*, unknown, record, cstring, void, [event_]trigger, internal, *_handler, pg_ddl_command

                                  ┌──────────┐
                                  │   NULL   │
                                  └──────────┘

null                              #Missing data
                                  #Can be any TYPE (def: unknown)
                                  #Often avoided
                                  #  - e.g. with not null CONSTRAINTs

VAL OP null
FUNC(..., null, ...)              #Always return null, except statements below

null = <> < <= > >= null          #null
null [not] in (null)              #null
VAL is [not] distinct from VAL2   #Like VAL = <> VAL2 but null = null
VAL is [not] null
VAL isnull|notnull                #Same as VAL is [not] distinct from null, except deep with ROW
BOOL is [not] BOOL2               #Same as BOOL is [not] distinct from BOOL2
BOOL is [not] unknown             #Same as BOOL is [not] distinct from null

null or false                     #null
null and true                     #null
null or true                      #true
null and false                    #false
not null                          #null

case null when null then ... end  #Does not match

nullif(VAL, VAL2)->VAL|null       #null if VAL = VAL2. Otherwise VAL
coalesce(VAL,...)->VAL            #First VAL not null
num_[non]nulls(VAL,...)->INT4     #Number of [not] null VALs

concat(STR,...)->STR2             #See below
quote_nullable(VAL)->STR          #See below

ARR = <> ARR2                     #null = null, i.e. can be compared
                                  #null is also distinct from missing item
ARR is [not] distinct from null
ARR is [not] null                 #True if ARR itself is [not] null (not deep)
ARR < <= > >= ARR2                #Missing item < present item < null
ARR @> <@ && ARR2                 #Error if contains null

ROW = <> < <= > >= ROW2           #null if contains any null
ROW is [not] distinct from null   #True if ROW itself is [not] null (not deep)
ROW is [not] null                 #True if ROW itself is [not] null, or if each COL is [not] null

[not] null                        #COL_CONSTRAINT. See below

unique nulls [not] distinct
create unique index ...           #If `nulls distinct` (def), ignore nulls
 nulls [not] distinct             #I.e. can have multiple nulls

exclude()                         #Ignore nulls

references "TABLE2"("COL2")       #null ROWs are ignored in both COL and COL2
 match simple|full                #For multicolumn foreign keys:
                                  #  - match simple (def): ignore ROW if at least one COL null
                                  #  - match full:
                                  #     - ignore ROW if all COLs null
                                  #     - fail if some COLs null but not others

check (BOOL_REXPR)
policy ... using (BOOL_REXPR)
policy ... with check (BOOL_REXPR)#null -> true

where BOOL_REXPR                  #null -> false
                                  #For: select, insert on conflict, update, delete, exclude, copy, AFUNC filter, PUB, etc.
having BOOL_REXPR                 #null -> false
join ... on BOOL_REXPR            #null -> false
                                  #I.e. ROWs with nulls are usually:
                                  #  - ignored by inner join
                                  #  - kept as single ROWs by outer join
if BOOL ...                       #null -> false (PL/PGSQL)
JSONPATH JBEXPR                   #null -> false

distinct
union|intersect|except distinct
AFUNC(distinct)                   #null = null
group by
over (partition by)               #null = null
BTREE DEDUPLICATION ==>           #null = null

order by ... nulls first|last
create index ...
 (...  nulls first|last,...)      #Def: nulls first for desc, nulls last for asc
pg_index_column_has_property
 (REGCLASS, COL_INT,
 'nulls_first|last')->BOOL        #

create|alter function ... strict  #Returns null directly if any argument is null
                                  #For variadic argument, whole variadic ARR must be null, not just an item
create|alter function ...
 returns null on null input       #Same as `strict`
create|alter function ...
 called on null input             #Same as not `strict`

AFUNC(...)                        #Ignores nulls
                                  #  - except: *agg(...), count(*), *rank(), cume_dist()
                                  #Returns null if empty SET
                                  #  - except: count()
greatest|latest(VAL,...)          #Ignores nulls

                                  ┌─────────────┐
                                  │   BOOLEAN   │
                                  └─────────────┘

bool[ean]                         #TYPE

BOOL => STR                       #Cast as 'true|false'
BOOL <~> INT4                     #Cast as 0|1

true|false
t|f
on|off
yes|no
y|n
1|0                               #BOOL_UNKNOWN

BOOL or BOOL2                     #
BOOL and BOOL2                    #
not BOOL                          #

bool_or(BOOL_SET)->BOOL           #AFUNC. BOOL or
bool_and|every(BOOL_SET)->BOOL    #AFUNC. BOOL and

BOOL > >= < <= BOOL2              #true > false

                                  ┌────────────┐
                                  │   NUMBER   │
                                  └────────────┘

NUM                               #INT|FLOAT|money
INT                               #int2|4|8
FLOAT                             #float4|8|numeric

smallint|int2                     #TYPE. Signed 2 bytes integer
integer|int|int4                  #TYPE. Signed 4 bytes integer
bigint|int8                       #TYPE. Signed 8 bytes integer

real|float4|float(1-24)           #TYPE. 4 bytes float
double precision|float8
 |float(25-53)                    #TYPE. 8 bytes float

numeric|decimal[(NUM[, NUM2])]    #TYPE. Fixed precision integer with NUM digits including NUM2 decimals
                                  #NUM2 can be negative: NUM2 last integer digits are zeros
                                  #Def NUM,NUM2: unbounded
                                  #Def NUM2: 0
                                  #Max NUM[2]: 1e3
                                  #Min NUM2: -1e3
                                  #Max value: 1e130000, min epsilon: 1e-16000
                                  #Rounded nearest, then towards [-]Infinity
                                  #0.5 bytes per digit, plus 3-8 bytes
                                  #Slower than other NUMs

INT2 <=-> INT4 <=-> INT8
 <=-> NUMERIC                     #When cast as smaller TYPE, fails if beyond max size.
 <=-> FLOAT4 <=-> FLOAT8          #When cast from FLOAT to INT, rounds nearest, then towards 0

money                             #TYPE. Fixed point INT8
                                  #NUM of decimlals depends on lc_monetary, but is often 2
                                  #Max value: 1e17
                                  #Avoid because 2 decimals is usually not enough
'NUM'                             #MONEY_UNKNWON can include currency signs and thousands separator
                                  #Depends on lc_monetary
MONEY <=> NUMERIC
INT4|8 => MONEY                   #Type cast

NUM                               #Literal NUM
NUMe...                           #TYPE:
                                  #  - numeric: decimals, NUMe... or >= 2**63
                                  #  - int8: >= 2**31
                                  #  - int4: otherwise
-0                                #Same as +0

'NaN'
'[-]Inf[inity]'                   #FLOAT_UNKNOWN. Case-insensitive

SCONF.extra_float_digits          #NUM of decimals to show when printing FLOAT4|8
                                  #If > 0 (def), unlimited
                                  #If <= 0, use 6|15 + NUM with FLOAT4|8

to_hex(INT)->STR                  #Hexadecimal, lowercase, without 0x prefix

generate_series(NUM, NUM2[, NUM3])
 ->NUM4_SET                       #From NUM to NUM2, with step NUM3 (def: 1)

                                  ┌───────────────────────┐
                                  │   NUMBER FORMATTING   │
                                  └───────────────────────┘

to_char(NUM, 'FORMAT')->STR       #
to_number(STR, 'FORMAT')->NUMERIC #Inverse. Casting can sometimes be an alternative.
                                  #Skips currency and TH|th

9                                 #Digit, space if none
0                                 #Digit, 0 if none
RN                                #Roman numeral, I-ICCCC

PR                                #[] if negative, not localized
SG                                #+|-, not localized, not shifted right
S                                 #+|-, localized (lc_numeric).
                                  #Shifted right if separated to digits by spaces|zeroes
                                  #If PR|SG|S|PL|MI not used, S is prepended to FORMAT with to_char()
PL                                #+ if positive, not localized, not shifted right
MI                                #- if negative, not localized, not shifted right

L                                 #Currency, localized (lc_monetary)
,                                 #Thousands separator, not localized
G                                 #Thousands separator, localized (lc_numeric)
.                                 #Decimal point, not localized
D                                 #Decimal point, localized (lc_numeric)

EEEE                              #e... exponent
                                  #Must be at the end. Can only use digits and decimal points
V                                 #Multiply by NUM that follows V
                                  #Cannot use decimal point
...TH|th                          #Suffix, for ordinal number

FM...                             #Remove leading 0|spaces

                                  ┌──────────┐
                                  │   MATH   │
                                  └──────────┘

NUM + - / * NUM2                  #
-NUM                              #

sum(NUM_SET)->NUM                 #AFUNC
avg(NUM_SET)->NUM                 #AFUNC

INT & | # << >> INT2
~INT                              #Bitwise operations
INT # INT2                        #xor

power(FLOAT, FLOAT)->FLOAT
FLOAT ^ FLOAT                     #

mod(NUM, NUM2)->NUM3
NUM % NUM2                        #

div(NUMERIC, NUMERIC2)->NUMERIC3  #trunc(NUMERIC/NUMERIC2)

|/ FLOAT8                         #Square root
cbrt(FLOAT8)->FLOAT8
||/ FLOAT8                        #Cube root

factorial(INT8)->NUMERIC          #

exp(FLOAT)->FLOAT                 #
ln(FLOAT)->FLOAT                  #
log10(FLOAT)->FLOAT               #
log(FLOAT[, INT4])->FLOAT         #Def: 10

abs(NUM)->NUM
@ NUM                             #
sign(FLOAT)->-1|0|1               #

ceil[ing](FLOAT)->FLOAT           #
floor(FLOAT)->FLOAT               #
trunc(FLOAT[, INT4])->FLOAT       #Def INT4: 0
round(FLOAT[, INT4])->FLOAT       #Def INT4: 0

trim_scale(NUMERIC)->NUMERIC      #Trim trailing fractional zeroes
scale(NUMERIC)->INT4              #Number of fractional digits
min_scale(NUMERIC)->INT4          #Number of fractional digits, excluding trailing zeroes

gcd(NUM, NUM2)->NUM3              #Greatest common divisor
lcm(NUM, NUM2)->NUM3              #Least common multiple

[a]cos|sin|tan[d|h]               #If `d`, in degrees instead of radians
 (FLOAT8)->FLOAT8                 #If `h`, hyperbolic
                                  #If `a`, inverse
cot[d](FLOAT8)->FLOAT8            #
atan2[d](FLOAT8, FLOAT8)->FLOAT8  #
degrees|radians(FLOAT8)->FLOAT8   #Conversion
pi()->FLOAT8                      #

                                  ┌─────────────┐
                                  │   STRINGS   │
                                  └─────────────┘

STR                               #varchar|bpchar|text (not char|name)
'...'                             #Personal notation meaning a STR
                                  #Including 'TABLE', 'COL', etc.
'STR'                             #Notation meaning a literal STR value

STRINGS ==>                       #Unless specified otherwise, operations are done Unicode codepoint-wise
                                  #  - including astral
                                  #  - "character" usually means "Unicode codepoint"
                                  #Unicode-aware, e.g. case
                                  #1-based indices

varchar|character varying[(NUM)]  #TYPE. STR with NUM max Unicode codepoints (def: unlim)
                                  #Max NUM: 1e7
bpchar[(NUM)]
char[acter](NUM)                  #TYPE. Like varchar, but pads with spaces (slower and takes more space)
text                              #TYPE. Like varchar, but cannot specify NUM

BPCHAR -> VARCHAR|TEXT            #Type cast removes padded spaces
VAL -> STR                        #For all TYPEs
                                  #Usually looks like '...' TYPE_UNKNOWN
                                  #  - e.g. row(VAL,...) -> '(VAL,...)'

'...'                             #STR_UNKNOWN

string_agg(STR_SET, 'DELIM')->STR #AFUNC. Joins to STR

ascii('CHAR')->UINT               #Unicode codepoint
chr(UINT)->'CHAR'                 #Inverse

[char[acter]_]length(STR)->INT    #In Unicode codepoints
bit|octet_length(STR)->INT        #In server ENCODING bits|bytes

strpos(STR2, STR)->UINT
position(STR in STR2)->UINT       #Index of STR inside STR2. 0 if not found.

STR ^@ STR2
starts_with(STR, STR2)->BOOL      #

left|right(STR, UINT)->STR2       #UINT first|last characters
substr(STR, UINT[, UINT2])->STR2
substring
 (STR [from UINT] [for UINT2])
 ->STR2                           #UINT2 characters (def: all) from index UINT (def: 1)
overlay(STR placing STR2
 from UINT [for UINT2])->STR3     #Replace substring(STR from UINT [for UINT2]) by STR2

STR || STR2                       #Concatenation
STR || VAL                        #Same as STR || VAL::text
concat(STR,...)->STR2             #Same as STR || ... but ignores nulls
concat_ws(STR, STR2...)           #Same but with separator STR

repeat(STR, UINT)->STR2           #
reverse(STR)->STR2                #

replace(STR, STR2, STR3)->STR4    #Replace each occurence of STR2 by STR3 in STR
translate
 (STR, 'CHAR...', 'CHAR2...')
 ->STR2                           #Replace each CHAR in STR by CHAR2
split_part(STR, STR2, INT)
 ->STR3|null                      #Split STR by delimiter STR2 and returns item number INT (can be negative)

lower|upper(STR)->STR2            #
initcap(STR)->STR2                #Titleize. upper() to first character, and characters after a non-letter|digit
                                  #lower() otherwise

trim([trailing|leading|both]
 [STR] from STR2)->STR3           #Remove (def: both) characters among STR (def: ' ') from STR2
ltrim|rtrim|btrim(STR2, STR)->STR3#Same as trim(trailing|leading|both STR from STR2)
l|rpad(STR, UINT[, STR2])->STR3   #Pads STR with STR2 (def: ' ') to length UINT.
                                  #If lower length, truncates.

                                  ┌──────────┐
                                  │   CHAR   │
                                  └──────────┘

"char"                            #TYPE. Like char(1) except:
                                  #  - no \0 delimiter, i.e. only 1 byte
                                  #  - no ENCODING (always ASCII)
                                  #TYPE itself must be double-quoted, otherwise it is interpreted as BPCHAR's TYPE

'CHAR'                            #CHAR_UNKNOWN

CHAR <~> INT4                     #Type cast from first digit, e.g. '2' <~> 2
CHAR <=-> TEXT
CHAR <=> VARCHAR|BPCHAR           #Type cast. Truncate first Unicode codepoint

                                  ┌──────────────┐
                                  │   ESCAPING   │
                                  └──────────────┘

quote_ident(STR)->STR             #Escape STR to use as SQL "VAR"
                                  #Wrap in "" if needed, and escape "
quote_literal(VAL)->STR           #Escape STR to use as SQL STR
                                  #Wrap in '', and escape ' \
                                  #If not STR, stringify
quote_nullable(VAL)->STR          #Same as quote_literal(VAL), but if VAL is null, returns 'NULL', not null

parse_ident(STR[, BOOL])          #Inverse of quote_ident()
 ->STR2_ARR                       #Can contain SCHEMA, returning 2 items then
                                  #If BOOL true, ignore characters after last VAR
                                  #  - useful with FUNC names that include ARGs at the end

format(STR[, VAL...])->STR        #Similar to sprintf(). Can use following %-sequences.
%I                                #quote_ident()
%s                                #quote_literal() without the outside ''
%L                                #quote_nullable()
%NUM$TYPE                         #Use VAL at index NUM, instead of next one
%NUMTYPE                          #Space-padding with width NUM
%*TYPE                            #Space-padding with width from next VAL
%*NUM$TYPE                        #Space-padding with width from VAL at index NUM
%-...TYPE                         #Right padding instead of left

                                  ┌──────────────┐
                                  │   GLOBBING   │
                                  └──────────────┘

'GLOB'                            #Only two special characters: % (like *) and _ (like ?)
                                  #No file expansion
                                  #Full match

STR [not] [i]like 'GLOB'          #BOOL. True if matches
 [escape 'CHAR']                  #i if case-insensitive
                                  #'CHAR' is escape character (def: '\')
STR [!]~~[*] 'GLOB'               #Alternative syntax for [not] [i]like

                                  ┌─────────────┐
                                  │   GREGEXP   │
                                  └─────────────┘

'GREGEXP'                         #"SQL REGEXP", mixing:
                                  # - GLOB: _ %
                                  # - REGEXP: | * + ? {} () [] \-sequence
                                  #Full match

STR [not] similar to 'GREGEXP'    #BOOL. Like `like` but with GREGEXP
 [escape 'CHAR']                  #'CHAR' is escape character (def: '\').

substring(STR similar 'GREGEXP'   #Returns first match
 escape 'CHAR')->STR2|null        #If there is an outer set of \"...\", return that part only

                                  ┌────────────┐
                                  │   REGEXP   │
                                  └────────────┘

'REGEXP'                          #"POSIX REGEXP"
                                  #REGEXP types:
                                  #  - literal STR
                                  #  - basic
                                  #     - no | + ? * { }
                                  #     - no \-escapes
                                  #     - (...) -> \(...\)
                                  #  - extended (def)
                                  #Specifying REGEXP type:
                                  #  - flags: q b e
                                  #  - prefix: '***=...' (literal) '***:...' (extended)
                                  #Can use (?:...)
                                  #  - makes FUNCs that use outer sets of parenthesis ignore that sets of parenthesis
                                  #\-escapes:
                                  #  - can use \a \b \e \f \n \r \t \v \0 \NN \NNN \xNNN \uNNNN \UNNNNNNNN
                                  #  - some standard \-sequences are renamed:
                                  #     - \< \> -> \m \M or [[:<:]] [[:>:]]
                                  #     - \b \B -> \y \Y
                                  #Greediness:
                                  #  - can use non-greedy symbol `?`
                                  #  - cannot use greedy symbol `+`, but greedy by default
                                  #Additional flags for default modes:
                                  #  - c: as opposed to i flag
                                  #  - s: as opposed to n|p|w flags
                                  #  - t: as opposed to x flag
                                  #Does not have:
                                  #  - modifiers (\u \l ...)
                                  #  - [...&&--...]
                                  #  - (?<GROUP>)
                                  #  - \p{PROP}
                                  #Use locales|Unicode for case and [[:...:]]
                                  #Partial match

STR [!]~[*] 'REGEXP'              #BOOL. True if matches
                                  #* if case-insensitive
regexp_like
 (STR, 'REGEXP'[, 'FLAGS'])->BOOL #True if matches

regexp_substr(STR, 'REGEXP'[, INT #Returns INT2-th match (def: 1)
 [, INT2[, 'FLAGS'[, INT3]]]])    #INT (def: 1) is search character start
 ->STR2|null                      #INT3 (def: 1) selects which outer set of parenthesis
substring(STR from 'REGEXP')      #Returns first match
 ->STR2|null                      #If there is an outer set of parenthesis, return that part only
regexp_match                      #Returns first match
 (STR, 'REGEXP'[, 'FLAGS'])       #ARR are parenthesis matches (if none, single item)
 ->STR_ARR|null                   #Cannot use FLAG 'g'
regexp_matches                    #Returns first match (or all if FLAG 'g')
 (STR, 'REGEXP'[, 'FLAGS'])       #If no match, empty SET
 ->ARR_SET                        #ARR are parenthesis matches (if none, single item)

regexp_instr(STR, 'REGEXP'[, INT  #Returns character position of match
 [, INT2[, INT5[, 'FLAGS'         #Same syntax as regexp_substr(...)
 [, INT3]]]]])->INT4              #If INT5 1 (def: 0), returns position of character after end of match instead

regexp_count
 (STR, 'REGEXP'[, INT[, 'FLAGS']])#Returns number of matches
 ->INT4                           #INT is search character start (def: 1)

regexp_replace(STR, 'REGEXP', STR2#Replace INT2-th (def: 1, or all if 'g') match by STR2
 [, INT[, INT2]][, 'FLAGS'])->STR3#INT is search character start (def: 1)
                                  #STR2 can use \NUM \&

regexp_split_to_array
 (STR, 'REGEXP'[, 'FLAGS'])       #Split STR using REGEXP delimiter.
 ->STR_ARR                        #If delimiter not found, returns {STR}
regexp_split_to_table(...)
 ->STR_SET                        #Same but as a SET

                                  ┌──────────┐
                                  │   ENUM   │
                                  └──────────┘

ENUM_TYPE                         #Each enum has its own TYPE
anyenum                           #TYPE. Any ENUM_TYPE

'...'                             #ENUM_VAL_UNKNOWN. Max 63 chars
ENUM_VAL                          #Stored as 4-byte long

create type "ENUM_TYPE"
 as enum(ENUM_VAL...)             #Arguments list decides ordering

alter type "ENUM_TYPE" add value
 [if not exists] ENUM_VAL
 [before|after ENUM_VAL2]         #
alter type "ENUM_TYPE"
 rename value
 ENUM_VAL to ENUM_VAL2            #

ENUM_VAL < <= > >= ENUM_VAL2      #BOOL. Using ordering

enum_first|last(ENUM_VAL)         #First|last ENUM_VAL of the same type
 ->ENUM_VAL2                      #null::ENUM_TYPE can be used as argument
enum_range(ENUM_VAL)              #All ENUM_VALs of the same type
 ->ENUM_VAL_ARR                   #null::ENUM_TYPE can be used as argument
enum_range(ENUM_VAL, ENUM_VAL2)   #From ENUM_VAL to ENUM_VAL2
 ->ENUM_VAL_ARR                   #null::ENUM_TYPE can be used to represent start|end

pg_enum                           #TABLE with all ENUM_VALs
pg_enum.oid                       #OID
pg_enum.enumlabel                 #NAME of ENUM_VAL
pg_enum.enumsortorder             #UINT. Sort position
pg_enum.enumtypid                 #REGTYPE of ENUM_TYPE

                                  ┌──────────┐
                                  │   BITS   │
                                  └──────────┘

BSTR                              #BIT|VARBIT
                                  #Unlike STR, meant for binary data, not textual data:
                                  #  - can include \0
                                  #  - not impacted by ENCODING
                                  #     - faster
                                  #     - can include sequences forbidden by ENCODING
                                  #  - not impacted by locales

bit[(NUM)]                        #TYPE. BIT, i.e. like STR, but bit-wise
                                  #NUM is exact length
                                  #Def NUM: 1
                                  #Max NUM: 1e8
                                  #0-based indices, left-to-right, LSB rightmost

varbit[(NUM)]                     #TYPE. VARBIT, i.e. same but variable length (unless NUM)
bit varying[(NUM)]                #NUM is max length
                                  #Def NUM: unlimited

BIT <-> VARBIT                    #Type cast. Truncates last bits if needed.
BIT <~> INT4|8                    #Type cast. Fails if larger than max INT

B'...'                            #BIT with 0|1s
X'...'                            #BIT with hex chars

BSTR & | # << >> BSTR2            #
~BSTR                             #

bit_and|or|xor(INT|BIT_SET)
 ->INT|BIT                        #AFUNC. Bitwise and|or|xor

get_bit(BSTR, UINT)->0|1          #
set_bit(BSTR, UINT, 0|1)->BSTR    #

bit_count(BSTR)->INT8             #Number of 1 bits

BSTR || BSTR2
bit|octet_length(...)
overlay(...)
position(...)
substring(...)                    #Same as STR but for BSTR
length(BSTR)->INT4                #Like bit_length()

                                  ┌───────────┐
                                  │   BYTEA   │
                                  └───────────┘

bytea                             #TYPE. Like BSTR but byte-wise
                                  #0-based indices, left-to-right

'...'                             #BYTEA_UNKNOWN
                                  #Can use either:
                                  #  - character as is, if [[:print:]]
                                  #  - octal \NNN
                                  #  - '' for '
                                  #  - \\ for \
'\x...'                           #BYTEA_UNKNOWN
                                  #Only hex characters
                                  #Case insensitive
                                  #Ignore whitespaces between bytes
                                  #Faster

encode(BYTEA, STR)->STR2          #Converts to format STR:
                                  #  - 'escape': like '...'
                                  #  - 'hex': like '\x...', but without leading '\x'
                                  #  - 'base64': newline every 76 chars
decode(STR, STR2)->BYTEA          #Inverse

SCONF.bytea_output                #Output format among: 'hex' (def) or 'escape'

string_agg
 (BYTEA_SET, DELIM_BYTEA)->BYTEA  #AFUNC. Joins to BYTEA

get_byte(BYTEA, UINT)->0-255      #
set_byte(BYTEA, UINT, 0-255)
 ->BYTEA                          #

md5(STR|BYTEA)->STR2              #
sha224|256|384|512(BYTEA)->BYTEA2 #

BYTEA || BYTEA2
bit|octet_length(...)
overlay(...)
position(...)
substring(...)
get_bit(...)
set_bit(...)
bit_count(...)                    #Like BSTR but for BYTEA
length(BYTEA)->INT4               #Like octet_length()
length(BYTEA, 'ENCODING')->INT4   #Like char_length()

[b|r|l]trim(...)
substr(...)                       #Like STR but for BYTEA

                                  ┌────────────────────┐
                                  │   INTEGER ARRAYS   │
                                  └────────────────────┘

INT4_ARR                          #Trusted postgres extension 'intarray' adds more methods for INT4_ARR
                                  #They must not contain any nulls
                                  #1-based indices

INT4_ARR @> INT4_ARR2             #BOOL. Is superset|equal
INT4_ARR <@ INT4_ARR2             #BOOL. Is subset|equal
INT4_ARR && INT4_ARR2             #BOOL. True if any INT = any INT2

query_int                         #TYPE
QUERY_INT                         #'INT' which can use & | ! () e.g. 'INT & !(INT2 | INT3)'
INT4_ARR @@ QUERY_INT
QUERY_INT ~~ INT4_ARR             #BOOL. Whether it matches

icount(INT4_ARR)->NUM             #Number of elements, including duplicates
idx(INT4_ARR, INT2)->UINT         #Index of first element with value INT2
                                  #0 if none

subarray(INT4_ARR, INT2[, INT3])  #Slice from INT2 (included) to INT3 (excluded, def: end)
 ->INT4_ARR                       #INT2|3 can be negative to be index from end

INT4_ARR + INT4[_ARR]2            #Concatenate
INT4_ARR | INT4[_ARR]2            #Concatenate. Remove duplicates and sort.
INT4_ARR & INT4_ARR2              #Intersection. Remove duplicates and sort.
INT4_ARR - INT4[_ARR]2            #Difference. Remove duplicates and sort.

sort(INT4_ARR[, 'desc'])->INT4_ARR#
uniq(INT4_ARR)->INT4_ARR          #Remove duplicates. Must be first sorted

                                  ┌───────────────┐
                                  │   DATE/TIME   │
                                  └───────────────┘

date                              #TYPE. 4 bytes-long

'YYYY-MM-DD'                      #DATE_UNKNOWN. Can use:
                                  #  - delimiter - / or none
                                  #  - YYYY or YY
                                  #  - different order for YYYY|MM|DD
                                  #  - MM: January, Jan or 01
                                  #  - MM|DD: 01 or 1
                                  #Also:
                                  #  - 'YYYY.DDD'
                                  #  - Julian date: J followed by NUM of days since 4713 BC
make_date
 (YEAR_INT4, MONTH_INT4, DAY_INT4)
 ->DATE                           #

time [without time zone] [(NUM)]  #TYPE. 8 bytes-long
                                  #NUM is number of sub-seconds decimals (min: 0, def|max: 6, i.e. microsecs)
make_time(HOUR_INT4, MONTH_INT4,
 SEC_FLOAT8)->TIME                #

'HH:MM[:SS[.SSSSSS]]'             #TIME_UNKNOWN. Can use:
                                  #  - no delimiter
                                  #  - am|pm

timestamp [without time zone]
 [(NUM)]                          #TYPE. 8 bytes-long
'DATE TIME'                       #TIMESTAMP_UNKNOWN
make_timestamp
 (YEAR_INT4, MONTH_INT4, DAY_INT4,
 HOUR_INT4, MIN_INT4, SEC_FLOAT8)
 ->TIMESTAMP                      #

TIME[TZ] <= TIMESTAMP[TZ]         #Type cast, removing DATE
DATE <=-> TIMESTAMP[TZ]           #Type cast, removing TIME or filling it with midnight

ENVVAR PGDATESTYLE                #'OUTPUT, INPUT'
SCONF.DateStyle                   #Def: based on lc_time, or 'ISO, MDY'
                                  #OUTPUT:
                                  #  - how to print DATE[TZ]|TIME[STAMP][TZ]
                                  #  - 'ISO': YYYY-MM-DD HH:MM:SS.SSSSSS
                                  #  - 'SQL': DD/MM/YYYY HH:MM:SS.SSSSSS
                                  #  - 'Postgres': Thu May DD HH:MM:SS.SSSSSS YYYY
                                  #INPUT:
                                  #  - how to read ambiguous DATEs (day is from 1 to 12)
                                  #  - can be: "DMY", "MDY" or "YMD"

'[-]infinity'                     #DATE|TIMESTAMP_UNKNOWN
isfinite
 (DATE|TIMESTAMP[TZ]|INTERVAL)
 ->BOOL                           #Whether [-]Infinity

'epoch'                           #DATE|TIMESTAMP_UNKNOWN
to_timestamp(FLOAT8)->TIMESTAMPTZ #Epoch, in secs

'yesterday|today|tomorrow'        #DATE|TIMESTAMP_UNKNOWN (midnight)
'allballs'                        #TIME_UNKNOWN (midnight)

'now'                             #DATE|TIME|TIMESTAMP_UNKNOWN
                                  #Beginning of transaction
now()->TIMESTAMPTZ
transaction_timestamp()
 ->TIMESTAMPTZ
current_time[stamp][(NUM)]        #Same but directly DATE|TIMETZ|TIMESTAMPTZ[(NUM)] instead of UNKNOWN
current_date                      #Beginning of transaction
localtime[stamp][(NUM)]           #Same but using current TZ
statement_timestamp()
 ->TIMESTAMPTZ                    #Beginning of statement
clock_timestamp()->TIMESTAMPTZ
timeofday()->'TIMESTAMPTZ'        #Beginning of FUNC call

DATE + - NUM                      #DATE
DATE - DATE2                      #NUM

DATE + - TIME[TZ]                 #TIMESTAMP[TZ]

(DATE|TIME[STAMP][TZ],
 INTERVAL|DATE|TIME[STAMP][TZ]2)
 overlaps (DATE|TIME[STAMP][TZ]3,
 INTERVAL|DATE|TIME[STAMP][TZ]4)  #BOOL. Like RANGE [...) && [...)

extract(PERIOD
 from TIME[STAMP][TZ]|INTERVAL)   #PERIOD: millenium, century, decade, [iso]year, quarter, month, week, day, [iso]dow (day of week),
 ->NUMERIC                        #doy, hour, minute, second, milli|microseconds, timezone[_hour|minute], epoch
date_part('PERIOD',
 TIME[STAMP][TZ]|INTERVAL)->FLOAT8#Same. Less precise, but allows PERIOD to be a STR
date_trunc('PERIOD',
 TIMESTAMP[TZ]|INTERVAL[, 'TZ'])  #Truncates until PERIOD
 ->TIMESTAMP[TZ]|INTERVAL         #PERIOD cannot be isoyear, [iso]dow, doy, timezone*, epoch

date_bin(INTERVAL, TIMESTAMP[TZ], #TIMESTAMP[TZ] modulo INTERVAL (starting at TIMESTAMP[TZ]2), i.e. rounds it down
 TIMESTAMP[TZ]2)->TIMESTAMP[TZ]   #E.g. '1 month', '2020-06-12', '2000-01-15' -> '2020-05-15'

generate_series
 (TIMESTAMP[TZ], TIMESTAMP[TZ]2,
 INTERVAL)->TIMESTAMP[TZ]_SET     #From TIMESTAMP[TZ] to TIMESTAMP[TZ]2, with step INTERVAL

moddatetime("COL")                #TFUNC which sets TABLE."COL" = current_timestamp
                                  #Must be `before update` + `for each row`
                                  #Part of spi EXTENSION

                                  ┌────────────────┐
                                  │   TIME ZONES   │
                                  └────────────────┘

LOCALES ==>                       #Used, including current timezone, unless specified otherwise

timetz|time with time zone[(NUM)] #TYPE. 12 bytes. Usually preferred over time
'TIME[TZ]'                        #TIMETZ_UNKNOWN. TZ is [NAME|ABBREV][-|+NUM]

timestamptz
 |timestamp with time zone[(NUM)] #TYPE. 8 bytes. Usually preferred over timestamp and timetz
'TIMESTAMP[TZ]'                   #TIMESTAMPTZ_UNKNOWN
make_timestamptz
 (YEAR_INT4, MONTH_INT4, DAY_INT4,
 HOUR_INT4, MIN_INT4, SEC_FLOAT8
 [, 'TZ'])->TIMESTAMPTZ           #

TIME <=-> TIMETZ
TIMESTAMP <=-> TIMESTAMPTZ        #Type cast, using local TZ

ENVVAR [PG]TZ                     #Def: system one
SCONF.TimeZone                    #Used in:
                                  #  - input only if:
                                  #     - TYPE without timezone
                                  #     - TYPE with timezone, but omitted
                                  #  - output

pg_timezone_names                 #TABLE with TZs by names
pg_timezone_names.name            #STR, e.g. 'America/New_York'
pg_timezone_names.abbrev          #STR, e.g. 'PST'
pg_timezone_names.utc_offset      #INTERVAL
pg_timezone_names.is_dst          #BOOL. Daylight saving time

pg_timezone_abbrevs               #TABLE with TZs by abbreviation
pg_timezone_abbrevs.abbrev
pg_timezone_abbrevs.utc_offset
pg_timezone_abbrevs.is_dst        #

SCONF.timezone_abbreviations      #Override list of available TZs. Def: 'Default'

TIMESTAMPTZ at time zone 'TZ'     #TIMESTAMP
TIMESTAMP at time zone 'TZ'       #TIMESTAMPTZ
TIMETZ at time zone 'TZ'          #TIMETZ

                                  ┌──────────────┐
                                  │   INTERVAL   │
                                  └──────────────┘

interval [PERIOD [to PERIOD2]]    #TYPE. 16-byte long
 [(NUM)]                          #PERIOD is year|month|day|hour|minute|second (def: any)
                                  #NUM is like time(NUM)

TIME <=-> INTERVAL                #Type cast

'...'                             #INTERVAL_UNKNOWN.
                                  #Like any SCONF.IntervalStyle format
                                  #Can use full words: year, months, minutes, seconds, milliseconds, microseconds
                                  #Can use: decade, century, millenium
                                  #Can be NUM alone, for seconds
                                  #NUM can be FLOAT
make_interval([YEAR_INT4
 [, MONTH_INT4[, WEEKS_INT4
 [, DAY_INT4[, HOUR_INT4
 [, MIN_INT4[, SEC_FLOAT8]]]]]]])
 ->INTERVAL                       #

SCONF.IntervalStyle               #INTERVAL format using in output:
                                  #  - 'postgres' (def): '[NUM year NUM mons] [NUM days HH:MM:SS.SSSSSS]'
                                  #  - 'postgres_verbose': '@ [NUM year NUM mons] [NUM days NUM hours NUM mins NUM.SSSSSS secs [ago]]'
                                  #     - `ago` negates whole INTERVAL
                                  #  - 'sql_standard': '[Y-M] [D HH:MM:SS.SSSSSS]'
                                  #  - 'iso_8601': 'P[...Y...M][...DT...H...M....SSSSSS]'

DATE + - INTERVAL                 #TIMESTAMP
TIME[STAMP][TZ] + - INTERVAL      #TIME[STAMP][TZ]
TIME[STAMP][TZ] - TIME[STAMP][TZ]2#INTERVAL
INTERVAL + - INTERVAL             #INTERVAL
age
 ([TIMESTAMP[TZ],] TIMESTAMP[TZ]2)#Same as TIMESTAMP[TZ] - TIMESTAMP[TZ]2, but justifies months|days|hours
 ->INTERVAL                       #Def: TIMESTAMP[TZ]: current_date

INTERVAL * / NUM                  #
-INTERVAL                         #

sum|avg(INTERVAL_SET)->INTERVAL   #AFUNC

justify_days(INTERVAL)->INTERVAL  #Modulo on days, e.g. 35 days -> 1 month 5 days
                                  #Always use 1 month = 30 days
justify_hours(INTERVAL)->INTERVAL #Modulo on hours, e.g. 30 hours -> 1 day 6 hours
justify_interval
 (INTERVAL)->INTERVAL             #justify_days() + justify_hours()

                                  ┌──────────────────────────┐
                                  │   DATE/TIME FORMATTING   │
                                  └──────────────────────────┘

to_char(TIMESTAMP[TZ]|INTERVAL,
 'FORMAT')->STR                   #

to_timestamp(STR, 'FORMAT')       #Inverse. Casting can sometimes be an alternative.
 ->TIMESTAMPTZ                    #Any punctuation|space can match any character that is punctuation|space
to_date(STR, 'FORMAT')->DATE      #Skips day of weeks and quarter

ESCAPING ==>                      #"-quotes for sequence chars
                                  #\-escape for: " \

I*                                #Use "ISO 8601 week-numbering year", i.e. first days (until Wednesday) are last year's

J                                 #"Julian Date", days since November 24, 4714 BC

CC                                #Century, 00-21
Y|I[Y|YY|YYY|,YYY]                #Year
BC|AD|bc|ad|B.C.|A.D.|b.c.|a.c.   #
Q                                 #Quarter, 1-4
WW|IW                             #Week of year, 01-53
[I]DDD                            #Jay of year, 001-366|371

MM                                #Month, 01-12
RM|rm                             #Month, I-XII
MONTH|Month|month                 #Month, full, space-padded to 9 chars
MON|Mon|mon                       #Month, 3 chars
W                                 #Week of month, 1-5
DD                                #Day of month, 01-31
D                                 #Day of week, 1 (Sunday) to 7
ID                                #Day of week, 1 (Monday) to 7
DAY|Day|day                       #Day of week, full, space-padded to 9 chars
DY|Dy|dy                          #Day of week, 3 chars

SSSS[S]                           #Secs since midnight, 0–86399
HH[12]                            #Hour, 01-12
HH24                              #Hour, 00-23
AM|PM|am|pm|A.M.|P.M.|a.m.|p.m.   #
MI                                #Minutes, 00–59
SS                                #Secs, 00–59
MS                                #Millisecs, 000–999
US                                #Microsecs, 000000–999999
FF1|2|3|4|5|6                     #Sub-secs with NUM digits

TZ|tz                             #Time zone abbreviation
OF                                #Time zone offset
TZH                               #Time-zone offset hours
TZM                               #Time-zone offset minutes

FM...                             #Remove leading 0|spaces
FX...                             #With to_timestamp|to_date() only
                                  #Unless set:
                                  #  - ignore leading|trailing|duplicate spaces
                                  #  - 1 punctuation|space can match empty string
                                  #  - empty string can match n punctuation|spaces
TM...                             #Localized, with name of month or day of week
...TH|th                          #Appends th, for ordinal number, localized

                                  ┌───────────┐
                                  │   SLEEP   │
                                  └───────────┘

pg_sleep(FLOAT8)                  #Sleeps FLOAT8 seconds
                                  #Time resolution is OS-specific, often 10ms
pg_sleep_for(INTERVAL)
pg_sleep_until(TIMESTAMPTZ)       #Same

                                  ┌─────────┐
                                  │   OID   │
                                  └─────────┘

oid                               #TYPE for an ID of any ENTITY
                                  #Internally like an INT4
                                  #32 bits, i.e. only use for uniqueness if:
                                  #  - TABLE-scoped
                                  #  - either:
                                  #     - serial on <2e9 items
                                  #     - random on <2e3 items
OID <-=> INT4|8
OID <- INT2                       #Type cast

reg*                              #TYPE for an ID of specific ENTITYs
                                  #Internally like an OID
                                  #Allows transtyping a OID from|to a 'NAME' instead
                                  #E.g. pg_namespace.oid::regnamespace -> "SCHEMA"
                                  #Also creates dependencies
                                  #  - e.g. default CONSTRAINT using REGCLASS depends on that RELATION
REG* <-> OID                      #Type cast
REG* <-> 'NAME'                   #Type cast
                                  #Can quote using '"NAME"'
to_reg*(TEXT)->REG*               #

                                  ┌────────────┐
                                  │   RANDOM   │
                                  └────────────┘

random()->FLOAT8                  #From 0 (included) to 1 (excluded)
                                  #Cycle of 3e14 numbers
                                  #PRNG not crypto-secure
set seed FLOAT8
setseed(FLOAT8)                   #FLOAT is from -1 (included) to 1 (included)

normal_rand(INT, FLOAT, FLOAT2)   #INT random variables following N(FLOAT, FLOAT2)
 ->INT_SET                        #Trusted postgres extension 'tablefunc'

                                  ┌────────────┐
                                  │   CRYPTO   │
                                  └────────────┘

pgcrypto                          #FUNCs for: MD5|SHA hash, HMAC, crypt, Blowfish|DES|AES, PGP
                                  #Trusted EXTENSION 'pgcrypto'
                                  #Not fully documented yet

gen_random_bytes(INT4)->BYTEA     #Crypto-secure randomness
                                  #Max INT4: 1024

digest(STR|BYTEA, 'TYPE')->BYTEA2 #Hash
                                  #'TYPE' can be 'md5' or 'sha1|224|256|384|512'
hmac(STR|BYTEA, 'KEY', 'TYPE')
 ->BYTEA2                         #HMAC

pgsodium                          #FUNCs for many crypto FUNCs, using libsodium C library
                                  #Untrusted EXTENSION 'pgsodium'
                                  #Always in SCHEMA 'pgsodium'
                                  #Not fully documented yet

                                  ┌──────────┐
                                  │   UUID   │
                                  └──────────┘

uuid                              #TYPE. 16-byte long

'nnnn-nnnn-nnnn-nnnn-nnnn-        #UUID_UNKNOWN. Dashes all optional
 nnnn-nnnn-nnnn'                  #Case-insensitive

gen_random_uuid()->UUID           #UUID v4

uuid-ossp                         #Trusted postgres extension, required for the following

uuid_generate_v1[mc]()->UUID      #UUID v1
                                  #If mc, uses a random multicast MAC address
uuid_generate_v3|5                #UUID v3|5
 (uuid_ns_*(), STR)->UUID         #* is dns|url|oid|x500
uuid_generate_v4()->UUID          #UUID v4

uuid_nil()->UUID                  #Only 0 bits

                                  ┌──────────┐
                                  │   JSON   │
                                  └──────────┘

json                              #TYPE. Including scalar types.
                                  #Must be well-formed.
                                  #Cannot use = <> < <= > >=, but can cast

jsonb                             #TYPE. Like json, but stored as binary format
                                  #Slower to parse|serialize, but faster for other operations
                                  #Does not preserve whitespaces, key order, nor duplicate keys
                                  #Does not preserve equivalent NUMs, e.g. 1e1 -> 10
                                  #Cannot use \u0000 nor \u... with invalid codepoints
                                  #Usually preferred over json

'JSON'                            #JSON_UNKNOWN
KEY                               #UINT|STR

JSONB <=> JSON                    #Type cast
JSONB ~> BOOL|NUM|STR             #Type cast. Fail if top-level value is not BOOL|NUM|STR|null
                                  #null is cast to null::text
jsonb_pretty(JSONB)->STR          #Type cast, prettified

json[b]_typeof(JSON[B])->STR      #'string|number|boolean|null|object|array'

CONVERSION ==>                    #ARR <-> ARR|SET
                                  #OBJ <-> ROW
                                  #STR|NUM|BOOL <-> STR|NUM|BOOL
                                  #Use json type casting if exists for a given TYPE
                                  #Otherwise serialize as STR

to_json[b](VAL)->JSON[B]          #

array_to_json
 (ARR[, BOOL])->ARR_JSON          #BOOL (def: false) is prettify
json[b]_build_array
 (VAL,...)->ARR_JSON[B]           #
json[b]_agg(SET)->ARR_JSON[B]     #AFUNC. Converts to ARR_JSON[B]

row_to_json(ROW)->OBJ_JSON        #BOOL (def: false) is prettify
json[b]_object
 ('KEY'_ARR, 'VAL'_ARR)
 ->OBJ_JSON[B]                    #
json[b]_object
 ({'KEY', 'VAL'}_ARR)->OBJ_JSON[B]#
json[b]_object
 ({'KEY', 'VAL',...})->OBJ_JSON[B]#
json[b]_build_object
 (KEY, VAL,...)->OBJ_JSON[B]      #
json[b]_object_agg
 ('KEY'_SET, VAL_SET)->OBJ_JSON[B]#AFUNC. Converts to OBJ_JSON[B]

json[b]_array_elements
 (ARR_JSON)->JSON[B]_SET          #Converts ARR_JSON to JSON[B]_SET
json[b]_array_elements_text
 (ARR_JSON)->STR_SET              #Converts ARR_JSON to STR_SET
json[b]_array_length
 (ARR_JSON[B])->UINT              #ARR.length

json[b]_to_record
 (OBJ_JSON[B])->ROW               #ROW is untyped, i.e. must cast or assign a ROW_ALIAS
json[b]_to_recordset
 (OBJ_ARR_JSON[B])->ROW_SET       #Same with ROW_SET
json[b]_populate_record           #Same as json[b]_to_record[set](OBJ[_ARR]_JSON[B]) but using ROW_TYPE of ROW2
 (ROW2, OBJ_JSON[B])->ROW         #OBJ keys not in ROW_TYPE are omitted
json[b]_populate_recordset        #ROW2 contains default value for each COL
 (ROW2, OBJ_ARR_JSON[B])->ROW_SET #  - it can be null::ROW_TYPE, i.e. default values are null

json[b]_each
 (OBJ_JSON[B])->ROW_SET           #Each OBJ entry -> ROW with COLs: key STR, value JSON[B]
json[b]_each_text
 (OBJ_JSON[B])->ROW_SET           #Same but with COLs: key STR, value STR
json[b]_object_keys
 (OBJ_JSON[B])->'KEY'_SET         #

JSONB ? STR                       #BOOL. Check if:
                                  #  - OBJ: key exists
                                  #  - ARR: value exists
                                  #  - STR|NUM|BOOL|null: identical
JSONB ?& STR_ARR                  #Same as JSONB ? STR and ...
JSONB ?| STR_ARR                  #Same as JSONB ? STR or ...

JSONB @> JSONB2                   #BOOL. Is superset|subset
JSONB <@ JSONB2                   #With OBJ|ARR:
                                  #  - deeply
                                  #     - OBJ: against another OBJ2
                                  #     - ARR: against either another ARR2, or an ARR item
                                  #  - unordered
                                  #  - ignore duplicates
                                  #With STR|NUM|BOOL|null: must be identical

JSONB['KEY'|NUM]                  #OBJ['KEY'|NUM] as JSON[B]2|null
JSON[B]->'KEY'|NUM                #Non-OBJ|ARR JSONB return null
                                  #  - including null, i.e. can do multiple ['KEY'|NUM]
                                  #  - with `update set`, creates empty OBJ|ARR
                                  #NUM is for ARR index
                                  #  - 0-based
                                  #  - can be negative
                                  #  - if NUM too low|high, extends with null
json[b]_extract_path
 (JSON[B], 'KEY|NUM',...)
 ->JSON[B]2|null
JSON[B]#>'KEY|NUM'_ARR            #Same but with multiple successive KEY|NUMs
JSON[B]->>'KEY'|NUM
json[b]_extract_path_text
 (JSON[B], 'KEY|NUM',...)
 ->STR|null
JSON[B]#>>'KEY|NUM'_ARR           #Same but returns as STR|null

jsonb_set(OBJ|ARR_JSONB,          #Sets OBJ|ARR_JSONB['KEY'|NUM]... = JSONB2
 'KEY|NUM'_ARR, JSONB2[, BOOL])   #If BOOL false (def: true), noop if last KEYs does not already exist
 ->OBJ|ARR_JSONB                  #Noop if any non-last KEY does not exist
                                  #NUM can be negative
                                  #If NUM too low|high, prepends|appends
                                  #If JSONB2 null, returns null
jsonb_set_lax                     #Same as jsonb_set(...) except if JSONB2 null, depending on STR:
 (...[, STR])->OBJ|ARR_JSONB      #  - 'use_json_null' (def): set value as null
                                  #  - 'delete_key'
                                  #  - 'return_target': noop
                                  #  - 'raise_exception'
jsonb_insert(OBJ|ARR_JSONB,       #Like jsonb_set(..., true) except if value is ARR item, appends|prepends instead of setting.
 'KEY|NUM'_ARR, JSONB2[, BOOL])   #BOOL is whether appended (true) or prepended (false, def)
                                  #Also, fails if not ARR item and last KEY already exists

JSONB || JSONB2                   #JSONB3. If:
                                  #  - ARRs: shallow concatenate
                                  #  - OBJs: shallow merge
                                  #  - otherwise: [JSONB, JSONB2]

ARR_JSONB - 'VAL'[_ARR]           #ARR_JSONB2. Omit VALs
ARR_JSONB - INT4                  #ARR_JSONB2. Omit index
OBJ_JSONB - 'KEY'[_ARR]           #OBJ_JSONB2. Omit KEYs
JSONB #- 'KEY|NUM'_ARR            #JSONB2. Omit OBJ KEY or ARR index at JSONB#>ARR
json[b]_strip_nulls
 (JSON[B])->JSON[B]               #Omit OBJ VALs that are null, recursively

                                  ┌──────────────┐
                                  │   JSONPATH   │
                                  └──────────────┘

jsonpath                          #TYPE
                                  #0-based indices
                                  #Also called "SQL/JSON"

'...'                             #JSONPATH_UNKNOWN
JVAL                              #Value in JSONPATH

'lax|strict ...'                  #Whether lax (def) or not
                                  #If strict:
                                  #  - fails if:
                                  #     - OBJ_JVAL.VAR2 missing
                                  #     - ARR_JVAL[INTL] out-of-bound
                                  #  - no automatic cast of [NON_]ARR_JVAL
                                  #?(JBEXPR) and exists(VAL) are always `lax`
jsonb_path_*(..., BOOL)           #Forces lax (true) or strict mode (false).
                                  #`true` also allows invalid operations:
                                  #  - invalid type, e.g. 5 / "5"
                                  #  - errors, e.g. 5 / 0
                                  #Always true with @? and @@

$                                 #Top-level JVAL

OBJ_JVAL.VAR2
OBJ_JVAL."VAR2"                   #Get OBJ field
OBJ_JVAL.*                        #Get all OBJ fields
OBJ_JVAL.**                       #Include all of: leaves, branches, roots
OBJ_JVAL.**{[INTL to] INTL2}      #Same but only specific depth levels
                                  #INTL means INT or `last`

ARR_JVAL[INTL]                    #Get ARR item
ARR_JVAL[*]                       #
ARR_JVAL[INTL to INTL2]           #Slice
ARR_JVAL -> ARR_JVAL[*]           #Automatic cast when needed, e.g. ARR_JVAL.VAR2
                                  #With **, this creates duplicate values
NON_ARR_JVAL -> [ARR_JVAL]        #Automatic cast when needed, e.g. OBJ_JVAL[0]
+ARR_JVAL
-ARR_JVAL
ARR_JVAL.FUNC(...)                #Applied on each ARR item

ARR ?(JBEXPR)                     #Filter when JBEXPR evaluates to false
@                                 #Each ARR item, inside JBEXPR

BOOL FUNCTIONS ==>                #FUNC|OPs returning BOOL:
                                  #  - inside JBEXPR: required, and applied on each item
                                  #  - outside JBEXPR: applied only on first item

STR|NUM|BOOL|null                 #Must use JSON syntax, not SQL
                                  #Can only use ARR|OBJ through $ @ or $VAR

VAL == <> < <= > >= VAL2          #BOOL, or null if different types
VAL is unknown                    #BOOL. VAL is result of FUNC|OP with wrong argument types
                                  #E.g. (5 > "5") is unknown
exists(VAL)->BOOL                 #BOOL. VAL <> undefined
JVAL.type()->STR                  #json_typeof(VAR)

BOOL && || BOOL2                  #
!BOOL                             #

NUM_JVAL + - / * % NUM            #
'NUM'|NUM_JVAL.double()->NUM      #Cast to NUM
NUM_JVAL.ceiling|floor|abs()->NUM #ceil|floor|abs(NUM)

STR starts with STR2              #Like starts_with(STR, STR2)
STR like_regex "REGEXP"           #Like STR ~ REGEXP
 [flags "FLAGS"]                  #Flags: i s m q

JVAL.size()->INT                  #json_array_length(ARR), or 1 if not ARR

OBJ_JVAL.keyvalue()->OBJ2_ARR     #Iterates over entries, as OBJ2: key 'KEY', value JSONB, id NUM (unique ID for that OBJ)

STR_JVAL.datetime(['TEMPLATE'])
 ->[DATE][TIME][TZ]               #to_timestamp(STR)

jsonb_path_query
 (JSONB, JSONPATH)->JSONB_SET     #Evaluates JSONPATH, with JSONB as $
jsonb_path_query_array
 (JSONB, JSONPATH)->ARR_JSONB     #Same but returns as ARR_JSONB
jsonb_path_query_first
 (JSONB, JSONPATH)->JSONB         #Same but only returns first element

JSONB @? JSONPATH
jsonb_path_exists
 (JSONB, JSONPATH)->BOOL          #True if does not evaluate to undefined

JSONB @@ JSONPATH
jsonb_path_match
 (JSONB, JSONPATH)->BOOL          #True if evaluates to true

jsonb_path_*(..., OBJ_JSONB)      #{ VAR: VAL, ... } allowing to use $VAR inside JSONPATH
                                  #Only used as value, not variable names (e.g. no $.$VAR)

jsonb_path_*_tz(...)              #Parses ambiguous TIME[STAMP]_UNKNOWN (with no time zone specified) as TIME[STAMP]TZ

                                  ┌─────────┐
                                  │   XML   │
                                  └─────────┘

xml                               #TYPE
                                  #Must be well-formed
                                  #Does not check DTD
                                  #Cannot use = <> < <= > >=, but can cast
                                  #Not fully documented yet ???
                                  #  - https://www.postgresql.org/docs/current/functions-xml.html

DOCUMENT VS CONTENT ==>           #Allows both:
                                  #  - "documents": 1 top-level element
                                  #  - "contents"/"fragments": 1+ top-level elements

'XML'                             #XML_UNKNOWN
                                  #XML encoding declaration is ignored
                                  #  - i.e. ENCODING must match client's

STR <=~> XML                      #Type cast
                                  #Same as xmlparse|xmlserialize()
SCONF.xmloption                   #When casting, whether to use 'CONTENT' (def) or 'DOCUMENT'
xmlparse(document|content STR)
 ->XML                            #
xmlserialize(document|content XML
 as [var]char|text)->STR          #

XML is document                   #BOOL

SCONF.xmlbinary                   #'base64' (def) or 'hex'. How to show binary data (e.g. BYTEA) in XML

xmlagg(XML_SET)->XML              #AFUNC. Concatenates

                                  ┌────────────┐
                                  │   HSTORE   │
                                  └────────────┘

hstore                            #TYPE. OBJ where keys are identifiers
                                  #Conceptually like a JavaScript MAP
                                  #Trusted postgres extension 'hstore'
                                  #Cannot use < <= > >=
VAL                               #'VAL'|null

STR ~> HSTORE                     #Type cast, using 'KEY=>VAL,...'
HSTORE ~> JSON[B]                 #Type cast, using { KEY: VAL, ... }

'KEY=>VAL,...'                    #HSTORE_UNKNOWN
                                  #"" to escape KEY|VAL for whitespace , = >
hstore(['KEY', VAL]_ARR)->HSTORE  #
hstore(['KEY', VAL, ...])->HSTORE #
hstore('KEY'_ARR, VAL_ARR)
 ->HSTORE                         #

HSTORE->'KEY'                     #VAL
HSTORE->'KEY'_ARR                 #VAL_ARR

HSTORE ? 'KEY'                    #BOOL. True if HSTORE->'KEY' exists
defined(HSTORE, 'KEY')->BOOL      #True if HSTORE->'KEY' exists and is not null
HSTORE ?& 'KEY'_ARR               #BOOL. True if all of HSTORE->'KEY' exists
HSTORE ?| 'KEY'_ARR               #BOOL. True if any of HSTORE->'KEY' exists

HSTORE @> HSTORE2                 #BOOL. HSTORE is superset of HSTORE2 (including equal)
HSTORE <@ HSTORE2                 #BOOL. Same with subset (or equal)

akeys(HSTORE)->'KEY'_ARR          #
avals(HSTORE)->VAL_ARR            #
%# HSTORE                         #['KEY', VAL]_ARR
%% HSTORE                         #['KEY', VAL, ...]

HSTORE || HSTORE2                 #Merge. HSTORE2 has priority
HSTORE - HSTORE2                  #Substract. Only for HSTORE2 entries with same key + value
HSTORE - 'KEY'[_ARR]              #Omit
slice(HSTORE, 'KEY'_ARR)->HSTORE2 #Pick
                                  #If 'KEY' not found, ignored.

hstore(ROW)->HSTORE               #Using COL names as KEYs
ROW #= HSTORE                     #ROW2. Set ROW values using HSTORE

skeys(HSTORE)->'KEY'_SET
svals(HSTORE)->VAL_SET            #Same as akeys|avals() but as SET
each(HSTORE)->ROW_SET             #With COLs: key STR, value STR

HSTORE ~> JSON[B]                 #Type cast, similar to hstore_to_json()
hstore_to_json(HSTORE)->OBJ_JSON  #OBJ values are all STR|null
hstore_to_json_loose(HSTORE)
 ->OBJ_JSON                       #Same but OBJ values can also be NUM or BOOL (with VAL 't|f')

                                  ┌───────────┐
                                  │   LTREE   │
                                  └───────────┘

ltree                             #TYPE. Array of VARs representing a reference
                                  #0-based indices
                                  #Trusted postgres extension 'ltree'

'VAR.VAR2....'                    #LTREE_UNKNOWN
                                  #VAR is [[:alpha:]_], max 256 characters.
                                  #Max 65e3 VARs
                                  #Can be empty ''

LTREE < <= >= > LTREE2            #Compare first VAR, then second, etc.
                                  #Missing VAR is less

LTREE @> LTREE2                   #BOOL. Is parent of equal.
LTREE <@ LTREE2                   #BOOL. Is child of equal.
LTREE_ARR @> <@ LTREE2
LTREE @> <@ LTREE2_ARR            #BOOL. Same but "any of"
LTREE_ARR ?@> ?<@ LTREE2          #LTREE|null. First LTREE that @> <@ LTREE2

LTREE || LTREE2                   #LTREE3. Concatenate as 'LTREE.LTREE2'

nlevel(LTREE)->UINT               #Number of VARs

index(LTREE, LTREE2[, INT])       #If LTREE2 is inside LTREE, indice of VAR where it starts
 ->INT2                           #Otherwise, returns -1
                                  #Ignore first INT VARs (def: 0).
                                  #INT can be negative to specify from end

subltree(LTREE, UINT, UINT2)
 ->LTREE2                         #Sliced from VAR at index UINT (included) to UINT2 (excluded)
subpath(LTREE, INT[, INT2])       #Same but:
 ->LTREE                          #  - negative INT[2] is indice from the end
                                  #  - otherwise INT2 is number of VARs (def: all)

lca(LTREE_ARR)->LTREE2
lca(LTREE...)->LTREE2             #Common prefix ('' if none)

                                  ┌────────────┐
                                  │   LQUERY   │
                                  └────────────┘

lquery                            #TYPE. Globbing-like query against a LTREE (full match)

'VAR.VAR2...'                     #LQUERY_UNKNOWN
                                  #Same syntax as LTREE with following additional ones
*                                 #Any multiple VARs
*{[NUM],[NUM2]}                   #NUM (def: 0) to NUM2 (def: any) multiple VARs
VAR*                              #Any suffix
VAR%                              #Matches _-separated parts
VAR@                              #Case insensitive
VAR|VAR2                          #Or
!VAR                              #Not

LTREE[_ARR] ~ LQUERY
LQUERY ~ LTREE[_ARR]              #BOOL. Whether [any] LTREE fully matches LQUERY
LTREE[_ARR] ? LQUERY_ARR
LQUERY_ARR ? LTREE[_ARR]          #BOOL. Whether [any] LTREE fully matches any LQUERY

LTREE_ARR ?~ LQUERY               #LTREE|null. First LTREE that ~ LQUERY

                                  ┌───────────────┐
                                  │   LTXTQUERY   │
                                  └───────────────┘

ltxtquery                         #TYPE. Like lquery but partial match

'...'                             #LTXTQUERY_UNKNOWN
                                  #Single VAR. Also following syntax.
VAR*
VAR%
VAR@
VAR | VAR2
!VAR                              #Like LQUERY
VAR & VAR2                        #And

LTREE[_ARR] @ LTXTQUERY
LTXTQUERY @ LTREE[_ARR]           #BOOL. Whether [any] LTREE partially matches LTXTQUERY

LTREE_ARR ?@ LTXTQUERY            #LTREE|null. First LTREE that @ LTXTQUERY

                                  ┌──────────┐
                                  │   INET   │
                                  └──────────┘

inet                              #TYPE for an IP address
                                  #10 (IPv4) or 22 bytes-long (IPv6)
'IP[/NNUM]'                       #INET_UNKNOWN
                                  #Cannot omit last 0 bits
                                  #Can include non-0 bits in host identifier
                                  #Def NNUM: max

cidr                              #TYPE for a IP subnet
                                  #10 (IPv4) or 22 bytes-long (IPv6)
'IP[/NNUM]'                       #CIDR_UNKNOWN
                                  #Can omit last 0 bits
                                  #Must include only 0 bits in host identifier
                                  #Def NNUM is max of:
                                  #  - number of non-omitted bits (e.g. max if none)
                                  #  - IP class

text(INET)->STR
INET => STR                       #Type cast
host(INET)->STR                   #Type cast, without 'NNUM'
abbrev(INET)->STR                 #Type cast, without 'NNUM' if max

CIDR => STR                       #Type cast
abbrev(CIDR)->STR                 #Type cast, without host identifier

CIRD -> INET                      #Type cast
network(INET)->CIDR
INET => CIDR                      #Type cast. Fills host identifier with 0s

INET|CIDR < INET2|CIDR2           #IPv4 always < IPv6

INET >> >>= << <<= INET2          #Network prefix is superset|subset [or equal]

INET | & INET2
~INET                             #Bitwise
INET + - INT8                     #Bitwise
INET - INET2                      #INT8. Bitwise

family(INET)->4|6                 #
inet_same_family
 (INET, INET2)->BOOL              #

masklen(INET)->NNUM               #
set_masklen(INET|CIDR, NNUM)
 ->INET|CIRD                      #
netmask(INET)->INET2              #Subnet mask
hostmask(INET)->INET2             #Host mask

broadcast(INET)->INET2            #Broadcast IP

inet_merge(INET, INET2)->CIDR     #Smallest CIDR that is >> INET[2]

                                  ┌─────────┐
                                  │   MAC   │
                                  └─────────┘

macaddr                           #TYPE. 6-byte long
'NN:NN:NN:NN:NN:NN'               #MACADDR_UNKNOWN
                                  #Delimiter can be none : . -
                                  #Can delimit 2|4|6
                                  #Case-insensitive

macaddr8                          #TYPE. 8-byte long
'NN:NN:NN:NN:NN:NN:NN:NN'         #MACADDR8_UNKNOWN. Same as MACADDR_UNKNOWN otherwise.

MACADDR <-> MACADDR8              #Type cast

MACADDR[8] | & MACADDR[8]2
~MACADDR[8]                       #Bitwise operations

trunc(MACADDR[8])->MACADDR[8]     #Put second half as 00

macaddr8_set7bit
 (MACADDR8)->MACADDR8             #Sets 7th bit to 1 (EUI-64)

                                  ┌──────────────┐
                                  │   GEOMETRY   │
                                  └──────────────┘

= <> < <= > >=                    #Cannot be used. But can cast to STR

point                             #TYPE. 16-byte long
'(NUM,NUM2)'
'NUM,NUM2'                        #POINT_UNKNOWN
POINT[0|1]                        #NUM[2]

line                              #TYPE. Infinite LINE. 24-byte long
'[(NUM,NUM2),(NUM3,NUM4)]'
'((NUM,NUM2),(NUM3,NUM4))'
'(NUM,NUM2),(NUM3,NUM4)'
'NUM,NUM2,NUM3,NUM4'              #LINE_UNKNOWN
'{NUM,NUM2,NUM3}'                 #LINE_UNKNOWN as NUMx + NUM2y + NUM3
LINE[0|1|2]                       #NUM[2|3]

lseg                              #TYPE. Segment LINE. 32-byte long
'[(NUM,NUM2),(NUM3,NUM4)]'
'((NUM,NUM2),(NUM3,NUM4))'
'(NUM,NUM2),(NUM3,NUM4)'
'NUM,NUM2,NUM3,NUM4'              #LSEG_UNKNOWN
LSEG[0|1]                         #POINT

box                               #TYPE. Rectangle. 32-byte long
'((NUM,NUM2),(NUM3,NUM4))'
'(NUM,NUM2),(NUM3,NUM4)'
'NUM,NUM2,NUM3,NUM4'              #BOX_UNKNOWN (diagonal)
'{(...);...}'                     #BOX_ARR_UNKNOWN must use ;
BOX[0|1]                          #POINT

path                              #TYPE. 16 bytes * (length + 1)
polygon                           #TYPE. Like closed PATH
'((NUM,NUM2),...)'
'(NUM,NUM2),...'
'(NUM,...,NUMn)'
'NUM,...,NUMn'                    #Closed PATH_UNKNOWN
'[(NUM,NUM2),...]'                #Open PATH_UNKNOWN

circle                            #TYPE. 32-byte long
'<(NUM,NUM2),NUM3>'
'((NUM,NUM2),NUM3)'
'(NUM,NUM2),NUM3'
'NUM,NUM2,NUM3'                   #CIRCLE_UNKNOWN

POINT <~ LSEG <~ BOX
 <~> CIRCLE <~> POLYGON           #Type casts
POINT => BOX
BOX => POLYGON
PATH <=> POLYGON                  #Type casts

cube                              #TYPE. N-dimensional cube
                                  #Trusted postgres extension 'cube'
'(NUM...), (NUM2...)'             #CUBE_UNKNOWN diagonal

GEOMETRY OPERATORS ==>            #Many operators for shift, rotation, scaling, getting points|distance like center, positions, etc. exist
                                  #Including for cube
                                  #Not documented yet
                                  #  - see https://www.postgresql.org/docs/current/functions-geometry.html

                                  ┌───────────┐
                                  │   RANGE   │
                                  └───────────┘

RANGE ==>                         #Like an ARR of size 2 indicating start and end

int4range                         #RANGE TYPE of INT4
int8range                         #RANGE TYPE of INT8
numrange                          #RANGE TYPE of NUMERIC
daterange                         #RANGE TYPE of DATE
ts[tz]range                       #RANGE TYPE of TIMESTAMP[TZ]
any[compatible]range              #TYPE. Any RANGE TYPE

create type "RANGE_TYPE"
 as range(OPTS)                   #New RANGE TYPE
OPTS.subtype                      #TYPE of start|end
                                  #Must be supported by btree ACCESS_METHOD
OPTS.multirange_type_name         #'TYPE' of MULTIRANGE
                                  #Def: replace 'range' by 'multirange', or append '_multirange'

OPTS.subtypediff                  #FUNC(VAL, VAL2)->UINT, computing distance
                                  #Def: VAL2 - VAL, which is usually slower
                                  #Meant for gist|spgist ACCESS_METHODs

OPTS.canonical                    #FUNC2(VAL)->VAL (def: noop) transforming each VAL
                                  #Used to normalize:
                                  #  - [VAL, VAL2] to [VAL, VAL2+1) (or the other way around)
                                  #  - if TYPE is discrete
                                  #     - such as INT|DATE, but not FLOAT|TIMESTAMP[TZ]

'[VAL, VAL2]'                     #RANGE_UNKNOWN. Square brackets include, parenthesis exclude.
'[VAL, VAL2)'                     #Def VAL[2]: null
'(VAL, VAL2]'                     #  - noted as empty, not `null`
'(VAL, VAL2)'                     #Escaping of VALs: like ARR_UNKNOWN but { } -> ( ) [ ]
RANGE_TYPE(VAL, VAL2[, STR])
 ->RANGE                          #Same. STR is '[)' (def), '(]', '[]' or '()'

null                              #As VAL[2]: like [-]Infinity
lower|upper_inf(RANGE)->BOOL      #Whether null

'empty'                           #Empty RANGE. VAL[2] are both null, but not handled like Infinity
isempty(RANGE)->BOOL              #

lower|upper(RANGE)->VAL[2]        #
lower|upper_inc(RANGE)->BOOL      #Whether [] or ()

RANGE @> VAL|RANGE2               #BOOL. Is superset|equal
VAL|RANGE <@ RANGE2               #BOOL. Is subset|equal
RANGE && RANGE2                   #BOOL. Whether overlaps

RANGE << RANGE2                   #BOOL. Whether RANGE end before RANGE2 start
RANGE >> RANGE2                   #Same as RANGE2 << RANGE
RANGE &< RANGE2                   #BOOL. Whether RANGE start before RANGE2 start, and RANGE end before RANGE2 end
RANGE &> RANGE2                   #Same as RANGE2 &< RANGE
RANGE -|- RANGE2                  #BOOL. Whether RANGE end adjacent to RANGE2

RANGE + RANGE2                    #RANGE3. Union. Must overlap or be contiguous.
range_merge(RANGE, RANGE2)->RANGE3#Union. If does not overlap nor contiguous, fill the gap.
RANGE - RANGE2                    #[RANGE.begin, RANGE2.begin]
                                  #If RANGE2.begin < RANGE.begin:
                                  #  - if RANGE2.end > RANGE.end, returns [RANGE.begin, RANGE.end]
                                  #  - otherwise returns empty
RANGE * RANGE2                    #RANGE3. Intersection. Empty if none.

range_agg
 ([MULTI]RANGE_SET)->[MULTI]RANGE #AFUNC. Union
range_intersect_agg
 ([MULTI]RANGE_SET)->[MULTI]RANGE #AFUNC. Intersection

pg_range                          #TABLE with all RANGEs
pg_range.rngtypid                 #REGTYPE of RANGE_TYPE
pg_range.rngsubtype               #REGTYPE of OPTS.subtype
pg_range.rngmultitypid            #REGTYPE of MULTIRANGE TYPE
pg_range.rngcanonical             #REGPROC of OPTS.canonical. 0 if none
pg_range.rngsubdiff               #REGPROC of OPTS.subtypediff. 0 if none
pg_range.rngcollation             #REGCOLLATION of OPTS.collation. 0 if none
pg_range.rngsubopc                #pg_opclass.oid of OPTS.subtype_opclass

                                  ┌────────────────┐
                                  │   MULTIRANGE   │
                                  └────────────────┘

MULTIRANGE ==>                    #Combination of multiple RANGEs
                                  #Behaves like a RANGE with potential gaps
                                  #Normalizes overlapping RANGEs to a single one
                                  #Empty RANGEs are ignored

int4multirange
int8multirange
nummultirange
datemultirange
ts[tz]multirange
any[compatible]multirange         #MULTIRANGE TYPEs

RANGE ~> MULTIRANGE               #Type cast

'{RANGE,...}'                     #MULTIRANGE_UNKNOWN
MULTIRANGE_TYPE([RANGE,...])
 ->MULTIRANGE                     #Same

OPERATORS ==>                     #All FUNCs and operators for RANGE work with MULTIRANGE too
                                  #Can mix RANGE and MULTIRANGE arguments, except for + - *

range_merge(MULTIRANGE)->RANGE    #Convert to single RANGE, filling any gap
multirange(RANGE)->MULTIRANGE     #Inverse

unnest(MULTIRANGE)->RANGE_SET     #

                                  ┌───────────┐
                                  │   ARRAY   │
                                  └───────────┘

TYPE[]                            #TYPE2 with 0-n values of same TYPE
_TYPE                             #Dimensions are defined at write-time
                                  #1-based indices
                                  #Max length 1.3e8
array
any[compatible]array              #TYPE. Any TYPE2[]
any[compatible]nonarray           #TYPE.

TYPE[NUM]
array[NUM]                        #Same as TYPE|array[], i.e. NUM is only for documentation

array[VAL...]                     #ARR literal value.
'{VAL,...}'                       #ARR_UNKNOWN
                                  #VAL can be null
                                  #Escaping of VALs:
                                  #  - " or \ for:
                                  #     - { } , whitespaces
                                  #     - empty STR, "null" STR
                                  #  - \ for: " \
'[INT[:INT2]]...={VAL,...}'       #Same but with specific:
                                  #  - lower bound INT (included)
                                  #     - def: 0
                                  #  - upper bound INT2 (included)
                                  #     - def: INT
                                  #     - must be INT + ARR.length - 1, i.e. cannot truncate|extend
                                  #Both can be negative
                                  #One [...] per dimension

array[[...],...]
'{{...},...}'                     #Underlying TYPE can be another ARR for multidimensional ARRs

_TYPE '...'                       #When type casting with this syntax, must use _TYPE instead of TYPE[]

array_agg(SET)->ARR               #AFUNC. Converts to ARR

ARR[INT]                          #VAL. null if out-of-bound, or if ARR|INT null
ARR[INT:INT2]                     #ARR2, from INT (included) to INT2 (included)
                                  #Uses max(INT2, ARR.length)
                                  #Empty if INT2 < INT, or if INT > ARR.length
ARR[INT:]                         #Same as ARR[INT:ARR.length]
ARR[:INT2]                        #Same as ARR[0:INT2]
ARR[...]                          #Can be set, e.g. with `update`
                                  #If out-of-bound, fills with nulls

ARR = <> ARR2                     #BOOL. Done deeply
ARR < <= > >= ARR2                #BOOL, with first item compared first, etc.

VAL OP any|some (ARR)             #BOOL. Whether VAL OP any ARR item
VAL OP all (ARR)                  #BOOL. Whether VAL OP all ARR item

ARR @> ARR2                       #BOOL. Is superset|equal
                                  #Ignores duplicates
ARR <@ ARR2                       #BOOL. Is subset|equal
                                  #Ignores duplicates
ARR && ARR2                       #BOOL. Overlaps, i.e. at least one item equal
                                  #Ignores duplicates

array_ndims(ARR)->UINT|null       #NUM of dimensions. null if empty ARR
array_dims(ARR)->'[INT:INT2]...'  #Each dimensions lower|upper bound
array_lower(ARR, UINT3)->UINT     #Dimension UINT3 lower bound
array_upper(ARR, UINT3)->UINT2    #Dimension UINT3 upper bound
array_length(ARR, UINT3)->UINT    #array_upper - array_lower
cardinality(ARR)->INT4            #NUM of items in any dimension

ARR || VAL
array_append(ARR, VAL)->ARR       #Append
VAL || ARR
array_prepend(ARR, VAL)->ARR      #Prepend
ARR || ARR2
array_cat(ARR, ARR2)->ARR         #Concatenates

array(SSUBQUERY)->ARR             #
unnest(ARR)->SET                  #Flattens ARR and returns as SET
unnest(ARR,...)->ROW_SET          #Same but each ARR becomes a COL
                                  #Smaller COLs are filled with null
                                  #Must be in a FROM

array_to_string                   #Cast each ARR item to STR, then join with 'DELIM'.
 (ARR, 'DELIM'[, 'NULL'])->STR    #If 'NULL' specified, nulls are transformed to it. Otherwise, they are ignored.
string_to_array                   #Inverse
 (STR, 'DELIM'|null[, 'NULL'])    #If DELIM is null, split each character.
 ->STR_ARR                        #If DELIM is '', returns STR as ARR with single item
string_to_table(...)->STR_SET     #Like string_to_array(...) but returning a STR_SET

array_position
 (ARR, VAL[, UINT2])->UINT|null   #Find first VAL index, starting at index UINT2 (def: 1), using `is not distinct from`
array_positions
 (ARR, VAL)->UINT_ARR             #Find all VAL indices

generate_subscripts               #Indices from min|max for dimension UINT3
 (ARR, UINT3[, BOOL])->INT4_SET   #If BOOL true (def: false), in reverse

width_bucket(VAL, ARR)->INT4      #1-based index of VAL inside sorted ARR
                                  #Returns 0 if < first ARR value
                                  #Returns ARR.length + 1 if >= last ARR value
width_bucket
 (FLOAT, FLOAT2, FLOAT3, INT4)
 ->INT4                           #Same using an ARR of length INT4 going from FLOAT2 to FLOAT3

array_fill                        #ARR where all values are VAL
 (VAL, INT_ARR[, INT_ARR2])->ARR  #Number of dimensions is INT_ARR[2].length
                                  #INT_ARR are upper bounds, INT_ARR2 lower bounds (def: {1,...})

trim_array(ARR, INT4)->ARR        #Remove last INT4 items
array_remove(ARR, VAL)->ARR       #Filter out any element is not distinct from VAL
                                  #ARR must be one-dimensional
array_replace(ARR, VAL, VAL2)->ARR#Same but replace with VAL2

YOPTS.subscript                   #FUNC(INTERNAL)->INTERNAL implementing VAL[NUM] for any given TYPE
pg_type.typsubscript              #Common ones:
                                  #  - array_subscript_handler: ARR_TYPEs
                                  #  - raw_array_subscript_handler: NAME, POINT|LINE|LSEG|BOX
                                  #  - jsonb_subscript_handler: JSONB
                                  #  - hstore_subscript_handler: HSTORE
                                  #Not fully documented yet

YOPTS.element                     #Underlying TYPE of an ARR_TYPE, if it is an ARR_TYPE
pg_type.typelem                   #Not set if underlying type is not known (e.g. JSONB|HSTORE)

pg_type.typarray                  #pg_type.oid of a TYPE, i.e. inverse of pg_type.typelem. 0 if none

YOPTS.delimiter                   #'CHAR' (def: ',') used in '{...}' ARR_UNKNOWN for a given TYPE
pg_type.typdelim                  #Builtin TYPEs: ',' for all except ';' for BOX

                                  ┌─────────┐
                                  │   ROW   │
                                  └─────────┘

ROW_TYPE                          #Conceptually like a tuple ARR (ordered, item-specific types)
                                  #where each item has an optional name
                                  #Also called "composed type" or "ctype"
                                  #Values are also called "tuples"
                                  #Max 1600 COLs
record                            #TYPE of any ROW_TYPE

table(VAR TYPE,...)               #ROW_SET_TYPE
                                  #Can only be used in FUNC return TYPEs

ROW                               #ROW_TYPE value
COL                               #"Column", i.e. ROW property
                                  #Ordered
                                  #Named. Can have duplicate names
                                  #  - e.g. select 1 as a, 2 as a;
                                  #  - but (ROW)."COL" fails

CONTAINER TYPE ==>                #ARR_TYPE|ROW_TYPE|RANGE_TYPE

create type "ROW"
 as ("COL" TYPE,...)              #Create a new ROW_TYPE

alter type "ROW"
 add attribute "COL" TYPE
 [restrict|cascade]               #cascade or restrict (def): when "ROW" is a "TABLE", whether to modify the "TABLE" too
alter type "ROW"
 drop attribute
 [if exists] "COL" TYPE
 [restrict|cascade]               #
alter type "ROW"
 alter attribute "COL" type TYPE
 [restrict|cascade]               #
alter type "ROW"
 rename attribute "COL" to "COL2"
 [restrict|cascade]               #

[row](VAL,...)                    #ROW
                                  #COL names: fNUM
                                  #"row" is necessary only if only one VAL
'(VAL,...)'                       #Same as ROW_UNKNOWN
                                  #Can cast to ROW_TYPE but not to record
                                  #VAL can be omitted (i.e. null)
                                  #Escaping of VALs: like ARR_UNKNOWN but { } -> ( )

ROW."COL"
"COL"(ROW)                        #VAL

ROW."FUNC"                        #"Virtual COL". Same as FUNC(ROW)
                                  #I.e. can be used to emulate a dynamic COL

ROW.*                             #Expanded to ROW."COL", ROW."COL2", ...
                                  #Only expanded in `select VALs`, `returning`, `values()`, `row()`
                                  #Otherwise, same as just `ROW`
                                  #  - but can be used to avoid ambiguity, making it clear it is a ROW
                                  #When expanded, ROW is evaluated once per COL
                                  #  - e.g. (FUNC()->ROW).* evaluates FUNC() multiple times
                                  #  - can put FUNC() as a FROM instead to prevent this

(ROW)."COL"                       #Parenthesis often needed to avoid ambiguity, e.g.:
(ROW)."FUNC"                      #  - anywhere a ROW_ALIAS is also valid
(ROW).*                           #     - even if none defined with that name
                                  #  - when ROW is return value of a FUNC

ROW = <> ROW2                     #BOOL. Done deeply
                                  #Must have same amount of COLs, but names do not need to match
ROW < <= > >= ROW2                #BOOL, with first COL compared first, etc.
ROW OP (SUBQUERY)                 #BOOL. Like ROW OP ROW2, using ROW2 returned by SUBQUERY
                                  #Fails if SUBQUERY does not return exactly one ROW2
ROW *= *<> *< *<= *> *>= ROW2     #Like ROW = <> < <= > >= ROW2 except does binary equality instead of logical equality
                                  #E.g. -0 = 0 but -0 *<> 0
                                  #Intended for ROW with TYPEs missing = or < OPs
                                  #Requires record_image_ops OPCLASS

pg_type.typrelid                  #REGCLASS of a ROW_TYPE. 0 if ROW_TYPE is not related to a RELATION

                                  ┌─────────┐
                                  │   SET   │
                                  └─────────┘

setof TYPE                        #SET. Like ARR except OPs|FUNCs automatically iterate over each item
                                  #Always top-level
SCALAR                            #Opposite of SET

SCALAR_FUNC(SET)->SET             #Iterates over SET items
SCALAR_FUNC(SET, SCALAR)->SET     #Same but repeats SCALAR
                                  #If SCALAR is returned by a FUNC(), re-evaluate it each time
SCALAR_FUNC(SET, SET2)->SET       #Same but fills smaller SET with nulls

SCALAR_OP SET
SET SCALAR_OP SCALAR
SET SCALAR_OP SET2
SET_OP SCALAR                     #Same with operators

select SET ...
select SET, SCALAR ...
select SET, SET2 ...              #`select VAL,...` behaves like SCALAR_FUNC

SET_FUNC(SCALAR)                  #Fails

                                  ┌──────────────┐
                                  │   SUBQUERY   │
                                  └──────────────┘

SUBQUERY                          #ROW_SET that is the result of select, values, table or execute
                                  #I.e. not returned by a FUNC()
                                  #Can only be used when explicitly documented as such
SSUBQUERY                         #SUBQUERY returning a single COL
ZSUBQUERY                         #SUBQUERY returning a single COL + ROW

REXPR                             #Expression which:
                                  #  - is evaluated once per ROW
                                  #     - except if it does not reference the ROW
                                  #  - can refer to the ROW
                                  #Can also use any (ZSUBQUERY), with same ROW behavior

exists(SUBQUERY)->BOOL            #Whether SUBQUERY has at least one ROW
                                  #Since SUBQUERY values are not used, `select 1 ...` is often used

ROW OP any|some SUBQUERY          #BOOL. Whether ROW OP any SUBQUERY_ROW
ROW OP all SUBQUERY               #BOOL. Whether ROW OP all SUBQUERY_ROW
ROW [not] in SUBQUERY             #Same as ROW =|<> any SUBQUERY

                                  ┌──────────────┐
                                  │   RELATION   │
                                  └──────────────┘

RELATION ==>                      #ENTITYs with COLs
                                  #I.e. TABLE, INDEX, SEQUENCE, [M]VIEW, ROW_TYPE, FTABLE

pg_class                          #TABLE with all RELATIONs
pg_class.oid                      #OID
pg_class.relname                  #"TABLE" name
pg_class.relkind                  #'CHAR' among:
                                  #  - r: TABLE
                                  #  - i: INDEX
                                  #  - p: partitioned TABLE
                                  #  - I: partitioned INDEX
                                  #  - S: SEQUENCE
                                  #  - t: TOAST_TABLE
                                  #  - v: VIEW
                                  #  - m: MVIEW
                                  #  - c: ROW_TYPE created through `create type`
                                  #  - f: FTABLE
pg_class.reltype                  #REGTYPE of ROW_TYPE
                                  #0 for INDEX|SEQUENCE|TOAST_TABLE
pg_class.relrewrite               #REGCLASS. When a RELATION is copied to a new one, old RELATION's REGCLASS.
                                  #Set to 0 after the change. Since those operations are atomic, this is always 0 from user perspective

regclass                          #TYPE to cast pg_class.oid as "NAME"

oid2name                          #List DATABASE|RELATION|TABLESPACEs by OID|name
                                  #By default, prints all DATABASE OID|names
-H|p|U|P                          #Connection flags
--filenode|-f REGCLASS_OID        #Print relation "NAME" using its relfilenode
--oid|-o REGCLASS_OID             #Same using its OID
--table|-t NAME_GLOB              #Inverse
-d DATABASE                       #Select DATABASE.
                                  #Also, by default, prints all its RELATIONs
--indexes|-i                      #Also print SEQUENCE|INDEXs
--system-objects|-S               #Also print system catalogs and TOAST_TABLEs
--tablespaces|-s                  #Prints all TABLESPACEs
--quiet|-q                        #Do not print header
--extended|-x                     #Also print OID, SCHEMA and TABLESPACE

                                  ┌───────────┐
                                  │   TABLE   │
                                  └───────────┘

TABLE                             #ROW_SET with a known ROW_TYPE, that is persisted
                                  #Unlimited ROWs
                                  #ROWs order is not defined unless explicitly sorted (e.g. using `order by`)
                                  #Max 1e9 per DATABASE

"TABLE"                           #Can be used as ROW_TYPE value
                                  #  - CONSTRAINTs are stripped
                                  #But not as a:
                                  #  - "ROW_TYPE" variable
                                  #  - ROW[_SET] value

create
 [temp|unlogged]
 table "TABLE"
 [of "ROW_TYPE"]
 [partition of ...]
 ([COL_ARG,...])
 [for values ...]
 [inherits ...]
 [partition by ...]
 [using ...]
 [with (TOPTS)]
 [on commit ...]
 [tablespace ...]
 [as SUBQUERY ...]                #Creates a TABLE

create table ... of "ROW_TYPE"    #ROW_TYPE of (COL_ARG,...)
                                  #"COL" TYPE ... -> "COL" [with options] ...
                                  #  - with options: noop
                                  #Cannot use: inherits, like "TABLE|ROW_TYPE", compression, collate
alter table "TABLE" of "ROW_TYPE" #
alter table "TABLE" not of        #

create table ...                  #Populates values with SUBQUERY
 as SUBQUERY                      #(COL_ARG,...):
                                  #  - only "COL"
                                  #  - optional
                                  #Cannot use:
                                  #  - of "ROW_TYPE"
                                  #  - inherits
                                  #  - partition by
                                  #  - if not exists
 [with [no] data]                 #Whether to copy values (def) or only ROW_TYPE

select VALS,...                   #Same as `select ...` but creates "TABLE" instead of returning ROW_SET
 into [table] "TABLE" ...         #Prefer `create table as SUBQUERY` as it has more features and is more standard

create table ... with (TOPTS)     #"Table storage options"
pg_class.reloptions               #'VAR=VAL'_ARR of TOPTS

pg_tables                         #TABLE with all TABLEs
pg_tables.tablename               #"TABLE" name

pg_class.reloftype                #REGTYPE of ROW_TYPE when `of ROW_TYPE` was used
                                  #0 if none, or if not TABLE

"ROW_ALIAS".tableoid              #REGCLASS of TABLE. System COL

crosstab('SUBQUERY')->ROW_SET     #With SUBQUERY returning ROW2_SET: row_name 'ROW', category 'COL', value VAL
                                  #I.e. each ROW2 is a specific ROW+COL's value in ROW_SET
                                  #Trusted postgres extension 'tablefunc'

                                  ┌─────────────┐
                                  │   COLUMNS   │
                                  └─────────────┘

SYSTEM COLS ==>                   #Hidden COLs defined for every TABLE ROW: tableoid, ctid, cmin|cmax, xmin|xmax

alter table "TABLE" set
 alter [column] "COL" set(COPTS)  #"Column storage options"

pg_attribute                      #TABLE with all COLs, including system COLs
pg_attribute.attrelid             #REGCLASS of the RELATION
pg_attribute.attname              #"COL" name
pg_attribute.attnum               #INT2. COL's index (1-based)
                                  #Negative for system COLs
pg_attribute.attcacheoff          #INT4. COL's byte offset inside its RELATION
                                  #Only set when ROWs are being copied. Otherwise -1
pg_attribute.atttypid             #REGTYPE of "COL". 0 if COL was deleted
pg_attribute.attoptions           #'VAR=VAL'_ARR of COPTs
pg_attribute.attisdropped         #BOOL. Whether COL was deleted but physically kept.
pg_attribute.atthasmissing        #BOOL. Whether COL is currently being added.
pg_attribute.attmissingval        #ARR (of length 1). Default VAL of the COL being added, when atthasmissing is true. null otherwise

pg_class.relnatts                 #INT2. Number of COLs, excluding system COLs

                                  ┌────────────────┐
                                  │   CONSTRAINT   │
                                  └────────────────┘

CONSTRAINT                        #Condition validating udpates, and making them fail if false
                                  #Auto-dependency child of its COLs
COL_CONSTRAINT                    #Single-COL CONSTRAINT

alter table "TABLE" add COL_ARG   #

"COL" TYPE [COL_CONSTRAINT...]    #COL_ARG. Define a new COL
alter table "TABLE"
 add [column] "COL" TYPE [...]    #
alter table "TABLE"
 rename [column] "COL" to "COL2"  #
alter table "TABLE"
 alter [column] "COL"
 [set data] type TYPE             #
 [using VAL]                      #VAL used when casting (def: COL value)
alter table "TABLE"
 drop [column] [if exists] "COL"
 [restrict|cascade]               #

check(BOOL_REXPR) ...
unique("COL",...) ...
primary key("COL",...) ...
foreign key("COL",...) references
 "TABLE"("COL2",...) ...          #COL_ARG. Multicolumn CONSTRAINTs

constraint "CONSTRAINT" COL_ARG   #Set "CONSTRAINT" name
                                  #Not with: like "TABLE|ROW_TYPE"
alter table "TABLE"
 rename constraint "CONSTRAINT"
 to "CONSTRAINT2"                 #
alter table "TABLE"
 drop constraint [if exists]
 "CONSTRAINT" [restrict|cascade]  #

pg_constraint                     #TABLE with all CONSTRAINTs, excluding `not null`, including triggers
pg_constraint.oid                 #OID
pg_constraint.conname             #"CONSTRAINT" name
pg_constraint.contype             #'CHAR' among:
                                  #  - 'c': check()
                                  #  - 'x': exclude()
                                  #  - 'u': unique
                                  #  - 'p': primary key
                                  #  - 'f': foreign key
                                  #  - 't': trigger
pg_constraint.conrelid            #REGCLASS of TABLE. 0 if DOMAIN CONSTRAINT.
pg_constraint.conindid            #REGCLASS of INDEX. 0 if check|trigger
pg_constraint.conkey              #ARR of pg_attribute.attnum. COLs using the CONSTRAINT.

pg_get_constraintdef              #Returns 'CONSTRAINT' as it was created
 (CONSTRAINT_OID[, BOOL])->STR    #BOOL (def: false) is prettify

                                  ┌─────────────────────┐
                                  │   LAZY CONSTRAINT   │
                                  └─────────────────────┘

alter [foreign] table "TABLE"     #Perform CONSTRAINTs:
 add COL_ARG not valid            #  - not at creation time
alter domain "TYPE"               #  - but when using: alter ... validate constraint ...
 add ... not valid                #Goal: speed up time to perform this statement
                                  #Still perform those CONSTRAINTs on insert|update
                                  #Only for check() and foreign key CONSTRAINTs
alter [foreign] table "TABLE"
 validate constraint "CONSTRAINT"
alter domain "TYPE"
 validate constraint "CONSTRAINT" #Noop after being used at least once

pg_constraint.convalidated        #BOOL. Whether `not valid` and not validated yet on CONSTRAINT

pg_index.indimmediate             #BOOL. Whether `not valid` was not used on INDEX
pg_index.indisvalid               #BOOL. Whether `not valid` was used and not `validate ...` on INDEX

                                  ┌─────────────────────────┐
                                  │   DEFERRED CONSTRAINT   │
                                  └─────────────────────────┘

set constraints CONSTRAINT,...    #Check CONSTRAINT|TFUNCs at the end of the transaction, instead of end of the statement
 deferred                         #Does not apply to check() and `not null`
                                  #Cannot be done if marked as `not deferrable` (see below)
                                  #  - default for unique and exclude() CONSTRAINTs
                                  #Internally done through a TFUNC *_recheck() `for each row` on insert|update
set constraints CONSTRAINT,...
 immediate                        #Default behavior: check CONSTRAINTs at the end of each statement

set constraints all ...           #Same for all CONSTRAINTs

"COL" TYPE ...
 [[not] deferrable]
 [initially deferred|immediate]   #Same for a specific COL_ARG (including multicolumn)
alter table "TABLE"
 alter constraint "CONSTRAINT"
 [[not] deferrable]
 [initially deferred|immediate]   #Same for foreign key CONSTRAINT
alter table "TABLE"
 add unique|primary key ...
 [[not] deferrable]
 [initially deferred|immediate]   #Same for unique|primary key CONSTRAINT
create ... trigger ...
 [[not] deferrable]
 [initially deferred|immediate]   #Same for a TFUNC

pg_constraint.condeferrable       #BOOL. Whether CONSTRAINT is deferrable
pg_constraint.condeferred         #BOOL. Whether CONSTRAINT is deferred by default

                                  ┌───────────┐
                                  │   CHECK   │
                                  └───────────┘

check(BOOL_REXPR)                 #COL_CONSTRAINT. Fails if BOOL false.
                                  #Def "CONSTRAINT" name: "TABLE_COL_check"
                                  #Must be purely functional

pg_class.relchecks                #INT2. Number of check() CONSTRAINTs in TABLE
pg_constraint.conbin              #PG_NODE_TREE representing check()'s BOOL_REXPR

                                  ┌──────────────┐
                                  │   NOT NULL   │
                                  └──────────────┘

not null                          #COL_CONSTRAINT
                                  #Same as check("COL" is not null)
null                              #COL_CONSTRAINT. Not having `not null` constraint (def)
alter table "TABLE"
 alter [column] "COL"
 set|drop not null                #

pg_attribute.attnotnull           #BOOL. Whether COL uses `not null`

                                  ┌────────────┐
                                  │   UNIQUE   │
                                  └────────────┘

exclude                           #COL_ARG
 ("COL"|(REXPR) with OP,...)      #Fails if NEW_ROW."COL" OP ANY_CURRENT_ROW2."COL"
                                  #Can also use REXPR
                                  #OP must be commutative
                                  #Creates a CONSTRAINT "TABLE_COL_excl"
 [where (BOOL_REXPR)]             #Do not fail new ROW if BOOL false

unique                            #COL_CONSTRAINT. Same as exclude("COL" with =) but faster
                                  #I.e. fails if any duplicate value.
                                  #Def "CONSTRAINT" name: "TABLE_COL_key"

primary key                       #COL_CONSTRAINT.
                                  #Same as unique + not null
                                  #Only one per TABLE
                                  #Def "CONSTRAINT" name: "TABLE_pkey"

create unique index ...           #Similar to `unique` or `exclude (... with =)` CONSTRAINTs
                                  #Makes INDEX faster
create table ...
 exclude|unique|primary key ...   #Those CONSTRAINTs use a btree INDEX, automatically created with the same name
alter table "TABLE" add           #Add the CONSTRAINT using an existing INDEX
 [constraint "CONSTRAINT"]        #Def "CONSTRAINT" name: same as "INDEX"
 unique|primary key using "INDEX" #INDEX must:
                                  #  - be `unique`
                                  #  - not use REXPR
                                  #  - not use `where` (partial INDEX)
                                  #  - not use `asc|desc`
                                  #  - not use `deferrable`

pg_constraint.conexclop           #REGOPERATOR_ARR of the CONSTRAINT's `with OP`

pg_index.indisexclusion           #BOOL. Whether INDEX is used as `exclude`
pg_index.indisunique              #BOOL. Whether INDEX is `unique`
pg_index.indnullsnotdistinct      #BOOL. Whether INDEX uses `nulls not distinct`
pg_index.indisprimary             #BOOL. Whether INDEX is used as `primary key`

                                  ┌─────────────────┐
                                  │   FOREIGN KEY   │
                                  └─────────────────┘

references "TABLE2"[("COL2")]     #COL_CONSTRAINT. "Foreign key"
                                  #Ensure every COL value references a COL2 value (but not inverse)
                                  #On added|removed|updated values (for both COL|COL2)
                                  #COL2 must be `unique` or `primary key`
                                  #Def COL2: TABLE2 primary key
                                  #Def "CONSTRAINT" name: "TABLE_COL_fkey"
                                  #Implemented using TFUNCs:
                                  #  - on TABLE insert|update
                                  #  - `for each row`
                                  #  - called RI_FKey_check_ins|upd()
                                  #COL can be null
                                  #  - with pg_catalog.*, usually allow 0s instead

references ... match full|simple  #See null section

references ... on delete ACTION   #When removing COL2 values, do ACTION:
                                  #  - no action (def): fails, deferrable
                                  #  - restrict: fails, not deferrable
                                  #  - set default ["COL",...]: set COL values (def: all) to default
                                  #  - set null ["COL,"...]: set COL values (def: all) to null
                                  #  - cascade: remove ROW
                                  #Implemented using a TFUNC:
                                  #  - on TABLE2 delete
                                  #  - `for each row`
                                  #  - called RI_FKey_noaction|restrict|setdefault|setnull|cascade_del()
references ... on update ACTION   #Same but when updating COL2 values
                                  #Cannot specify "COL",... with set default|null

pg_constraint.conf*               #Excludes foreign keys CONSTRAINTs in pg_catalog.*
pg_constraint.confrelid           #REGCLASS of foreign key's target TABLE2. 0 if none
pg_constraint.confkey             #ARR of pg_attribute.attnum. Foreign key's target COL2s
pg_constraint.confmatchtype       #'CHAR' of `match` among: 'f' (full) or 'u' (simple)
pg_constraint.confdeltype         #'CHAR' of `on delete ACTION` among:
                                  #  - 'a': no action
                                  #  - 'r': restrict
                                  #  - 'd': set default
                                  #  - 'n': set null
                                  #  - 'c': cascade
pg_constraint.confupdtype         #Same for `on update ACTION`
pg_constraint.conpfeqop           #REGOPERATOR_ARR of the = OPs used to compare current|foreign keys
pg_constraint.conppeqop           #Same with REGOPERATOR_ARR of the = OPs used to compare current keys with itself
pg_constraint.conffeqop           #Same with REGOPERATOR_ARR of the = OPs used to compare foreign keys with itself

pg_get_catalog_foreign_keys()
 ->ROW_SET                        #Returns all foreign key CONSTRAINTs in pg_catalog.*
ROW.fktable                       #REGCLASS of foreign key's TABLE
ROW.fkcols                        #Foreign key's "COL"_ARR
ROW.pktable                       #REGCLASS of foreign key's target TABLE2
ROW.pkcols                        #Foreign key's target "COL2"_ARR
ROW.is_array                      #BOOL. Whether last foreign key's "COL" is an ARR
ROW.is_opt                        #BOOL. Whether foreign key's "COL" can be 0s

check_primary_key()               #TFUNCs implementing foreign key. Not useful since can use foreign key CONSTRAINT
check_foreign_key()               #Part of spi EXTENSION

                                  ┌────────────────────┐
                                  │   COLUMN DEFAULT   │
                                  └────────────────────┘

default VAL                       #COL_CONSTRAINT. Value when omitted on insertion.
                                  #VAL is evaluated at insertion time.
alter table "TABLE"
 alter [column] "COL"
 set default VAL                  #
alter table "TABLE"
 alter [column] "COL"
 drop default                     #

pg_attribute.atthasdef            #BOOL. Whether COL has a default value or generated COL

pg_attrdef                        #TABLE with COL default values, including generated COLs
pg_attrdef.oid                    #OID
pg_attrdef.adbin                  #PG_NODE_TREE with default value
pg_attrdef.adnum                  #pg_attribute.attnum of COL
pg_attrdef.adrelid                #REGCLASS of TABLE

                                  ┌──────────────────────┐
                                  │   GENERATED COLUMN   │
                                  └──────────────────────┘

generated always as (VAL) stored  #COL_CONSTRAINT. "Generated COL". Value on insertion.
                                  #Readonly on write
                                  #  - but can use `default`
                                  #VAL is evaluated at insertion time.
                                  #Can refer to other non-generated "COL"s of same "TABLE"
                                  #VAL must be purely functional
alter table "TABLE"
 alter [column] "COL"
 drop expression [if exists]      #Remove generated COL_CONSTRAINT, not COL itself

pg_attribute.attgenerated         #CHAR. Whether COL is: 's' (generated) or '' (not)

                                  ┌──────────────────┐
                                  │   COLUMNS COPY   │
                                  └──────────────────┘

like "TABLE|ROW_TYPE"             #COL_ARG. Copy (not inherit) the ROW_TYPE as COLs.
                                  #Always copied: COL TYPE, not null
                                  #Never copied: references, where BOOL_REXPR
 [including COL_INFO]...          #Also copy COL_INFO:
                                  #  - defaults: default VAL
                                  #  - indexes: INDEX, primary key, unique, exclude()
                                  #  - constraints: check()
                                  #  - storage: TOPTS
                                  #  - generated: generated COL
                                  #  - identity: identity COL
                                  #  - compression: TOAST compression
                                  #  - statistics: STATISTICS
                                  #  - comments: comment on ... for COL|INDEX|CONSTRAINT
                                  #  - all: of the above
 [excluding COL_INFO]...          #Do not copy COL_INFO. Only useful when using: including all

                                  ┌─────────────────┐
                                  │   INHERITANCE   │
                                  └─────────────────┘

create [foreign] table ...        #"CHILD_TABLE" inherits from "PARENT_TABLE"
 inherits ("PARENT_TABLE",...)    #Can be deep inheritance
                                  #Can have multiple parents
                                  #CHILD_TABLE is child dependency of PARENT_TABLE

READING ROWS ==>                  #Reading parent ROWs also reads child ROWs, but not vice-versa
                                  #  - including `select`
                                  #This behaves like `union all` is performed
WRITING ROWS ==>                  #Writing parent|child ROWs only writes parent|child ROWs
                                  #  - including `insert`
                                  #  - can use rule to redirect parent inserts to child, if it has same COLs
UPDATING|DELETING ROWS ==>        #Updating|deleting:
                                  #  - on parent:
                                  #     - can read child ROWs, i.e. can update|delete them
                                  #     - however the write happens on the child only
                                  #  - on child:
                                  #     - the write happens on the child only
                                  #     - but parent can see result since it can read child ROWs

INHERITANCE STATEMENTS ==>        #This only applies to statements related to data
                                  #  - for: select|table, update|delete|truncate|merge and most of alter table
                                  #  - also: `lock` parent applies to child too, but not vice-versa
                                  #  - not for vacuum|analyze: i.e. must be done on each child TABLE
                                  #Can prevent inherit by using `only "PARENT_TABLE"`
                                  #  - can use "PARENT_TABLE*" to do the opposite, but it is default behavior

CHILD INHERITS AND CANNOT CHANGE  #  - COL TYPE
 ==>                              #  - generated COL
                                  #  - temp
                                  #  - compression
                                  #  - collate

CHILD INHERITS BUT CAN APPEND ==> #  - COLs
                                  #  - check()
                                  #     - unless check(BOOL_REXPR) no inherit
                                  #  - not null
                                  #  - grant and row security policies
                                  #     - when reading parent ROWs, not writing

CHILD INHERITS BUT CAN OVERRIDE
 ==>                              #Only: default

CHILD DOES NOT INHERIT ==>        #  - unique, primary key, exclude
                                  #     - constraint on parent|child only applies to that TABLE
                                  #  - foreign key, as a:
                                  #     - source
                                  #     - target, i.e. references "CHILD_TABLE" implicitly means "only (CHILD_TABLE)"
                                  #  - INDEX
                                  #  - identity COL
                                  #  - TFUNC, RULE, PUB
                                  #  - unlogged
                                  #  - create table ... with (TOPTS)
                                  #  - comments

"ROW_ALIAS".tableoid              #Can be used to distinguish parent|child

alter [foreign] table
 "CHILD_TABLE"
 [no] inherit "PARENT_TABLE"      #

pg_inherits                       #TABLE with all `inherits`
pg_inherits.inhrelid              #REGCLASS of "CHILD_TABLE"
pg_inherits.inhparent             #REGCLASS of "PARENT_TABLE"
pg_inherits.inhseqno              #INT4. Order of parent, if multiple parents
pg_inherits.inhdetachpending      #BOOL. True if child is about to be detached

pg_class.relhassubclass           #BOOL. True if is a "PARENT_TABLE" of some "CHILD_TABLE"

pg_attribute.attislocal           #BOOL. If "CHILD_TABLE", whether COL is inherited
pg_attribute.attinhcount          #INT4. If "PARENT_TABLE", number of "CHILD_TABLE"s inheriting this COL

pg_constraint.conislocal          #BOOL. If "CHILD_TABLE", whether CONSTRAINT is inherited
pg_constraint.coninhcount         #INT4. If "PARENT_TABLE", number of "CHILD_TABLE"s inheriting this CONSTRAINT

                                  ┌───────────────┐
                                  │   PARTITION   │
                                  └───────────────┘

PARTITIONING ==>                  #Split a TABLE ROWs into multiple child TABLEs ("partitions")
                                  #Child TABLEs ROWs should:
                                  #  - not overlap other children
                                  #  - while still cover all of it
                                  #Child TABLEs should have same COLs
                                  #Goals:
                                  #  - faster read|write, by only targeting one smaller child TABLE
                                  #  - faster bulk delete, by detaching then deleting child TABLE
                                  #Not goals: splitting data across multiple machines
                                  #Only worth on very large tables, at least larger than RAM

VIEW PARTITIONING ==>             #Partitioning using a VIEW:
                                  #  - parent VIEW uses `union all` to concatenate all child TABLEs
                                  #  - child TABLEs restrict ROWs with a check()
                                  #     - with an INDEX on the underlying CONSTRAINT
                                  #  - rule|trigger that redirects parent ROWs writes to the right child

INHERITANCE PARTITIONING ==>      #Partitioning using `create table ... inherits`:
                                  #Same as view partioning but with `inherits` and an empty parent TABLE

SCONF.constraint_exclusion        #If 'on', queries skip child TABLEs if `where BOOL_REXPR` does not match its check() CONSTRAINT
                                  #If 'partition' (def, usually best): only when appears to be a child TABLE
                                  #using inheritance partitioning

DECLARATIVE PARTITIONING ==>      #Partitioning using `create table ... partition of`
                                  #Uses inheritance partitioning under the hood
                                  #  - i.e. behaves similarly, except for notes below
                                  #Automatically managed:
                                  #  - check() for the partition key, and underlying INDEX
                                  #  - rule to redirect writes to children
                                  #Child TABLEs clone PARENT_TABLE's:
                                  #  - unique, primary key, foreign key
                                  #     - can only use normal expression, not REXPR
                                  #     - have the same issues as with `inherits` (see above)
                                  #  - INDEXs
                                  #  - TFUNCs
                                  #Parent TABLE cannot use:
                                  #  - exclude()
                                  #  - check(...) no inherit
                                  #  - with (TOPTS)
                                  #Child TABLE cannot override:
                                  #  - not null
PARTITION KEY ==>                 #COL_REXPRs used to decide which child TABLE to use
                                  #Max 32 COL_REXPRs
                                  #Must be included in any unique or primary key CONSTRAINT
                                  #COL_REXPRs should match the `where BOOL_REXPR` expected in queries
PARTITION METHOD ==>              #One of: list, range, hash
                                  #Should use the best one to:
                                  #  - spread ROWs evenly
                                  #  - make queries target as few TABLEs at once as possible
NUMBER OF PARTITIONS ==>          #If too high: slower due to bookeeping and query analyzing time
                                  #If too low: slower due to bigger TABLEs slower

SCONF.enable_partition_pruning    #"Partition pruning".
                                  #Queries skip child TABLEs if `where BOOL_REXPR` does not match its `for values ...`
                                  #Only with declarative partitioning
                                  #Compared to SCONF.constraint_exclusion: faster, and works on more complex `where BOOL_REXPR`

SCONF.enable_partitionwise_join   #"Partitionwise join".
                                  #Allow joins on partitioned TABLEs to directly join their child TABLEs
                                  #Join condition must include all partition keys
                                  #Partition keys must have the same TYPEs
                                  #Slow planning time, i.e. disabled by default
SCONF.                            #"Partitionwise aggregate".
 enable_partitionwise_aggregate   #Similar for `group by` and AFUNCs

create table "PARENT_TABLE"
 partition by METHOD
 ("COL"|(COL_REXPR),...)          #Declare parent TABLE's partition keys

create
 [foreign] table "CHILD_TABLE"
 partition of "PARENT_TABLE"      #Declare ROWs owned by child TABLE
 [(COL_ARG,...)]                  #COL_ARGS,...: same syntax as `of "ROW_TYPE"`
 for values ...                   #Values are evaluated once at TABLE creation time

create [foreign] table ...
 partition of ...                 #Child TABLE will own any ROWs not owned by other child TABLEs
 default                          #Not with `partition by hash`

alter table "PARENT_TABLE"
 attach partition "CHILD_TABLE"
 for values ...
alter table "PARENT_TABLE"
 attach partition "CHILD_TABLE"
 default                          #Mark a TABLE as a new child
alter table "PARENT_TABLE"
 detach partition "CHILD_TABLE"   #Unmark a TABLE as a child
alter index "PARENT_INDEX"
 attach partition "CHILD_INDEX"   #

alter table ... detach partition  #Use a weaker lock that allows concurrent read|writes
 ... concurrently                 #Cannot be done inside a transaction, nor if there is a `default` partition
alter table ... detach partition
 ... finalize                     #If a previous `concurrently` was canceled, finish it

create table ...
 partition by list ...            #Child TABLE owns ROWs where partition key's value is among VAL,...
create table ... for values       #Partition key must have only 1 COL_REXPR
 in (VAL,...)                     #VAL can be null, but only in one child TABLE

create table ...                  #Child TABLE owns ROWs where partition key's value is between VAL (included) and VAL2 (excluded)
 partition by range ...           #If partition key has multiple COL_REXPRs, there are multiple VAL[2],...
create table ... for values       #VAL[2] can be minvalue|maxvalue
 from (VAL,...) to (VAL2,...)     #  - following COL_REXPRs must then also be minvalue|maxvalue

create table ...                  #Child TABLE owns ROWs where partition key's value % UINT = UINT2
 partition by hash ...            #Usually UINT is number of child TABLEs and UINT2 is index of child TABLE
create table ... for values with  #Can then multiple UINT by 2 to increase number of child TABLEs
 (modulus UINT, remainder UINT2)  #  - can do it one child TABLE at a time
                                  #  - should detach child TABLE, split its data, then re-attach it as two child TABLEs

pg_partitioned_table              #TABLE with declared partioning
pg_partitioned_table.partrelid    #REGCLASS of "CHILD_TABLE"
pg_partitioned_table.partdefid    #REGCLASS of default "CHILD_TABLE". 0 if none
pg_partitioned_table.partstrat    #Strategy among 'l' (list), 'r' (range) or 'h' (hash)
pg_partitioned_table.partnatts    #NUM of COLs in partition key
pg_partitioned_table.partattrs    #INT2_ARR. Partition key "COL" indices. 0 if COL_REXPR instead
pg_partitioned_table.partexprs    #PG_NODE_TREE. Partition key COL_REXPR values. 0 if "COL" instead
pg_partitioned_table.partclass    #ARR of pg_opclass.oid. Partition key COL OPCLASSs
pg_partitioned_table.partcollation#REGCOLLATION_ARR. Partition key COL COLLATION

pg_class.relispartition           #BOOL. Whether RELATION is a partition's child TABLE
pg_class.relpartbound             #PG_NODE_TREE. If is partition's child TABLE, `for values`

pg_partition_tree                 #CHILD_TABLEs of PARENT_TABLE REGCLASS, including their own children
 (REGCLASS)->ROW_SET              #Empty SET if no partitioning
ROW.relid                         #Current REGCLASS
ROW.parentrelid                   #REGCLASS of PARENT_TABLE
ROW.level                         #INT4. Hierarchy level, 0 for root
ROW.isleaf                        #BOOL. Whether has no CHILD_TABLE
pg_partition_ancestors            #Ancestor PARENT_TABLEs of CHILD_TABLE, including itself
 (REGCLASS)->REGCLASS2_SET        #Empty SET if no partitioning
pg_partition_root
 (REGCLASS)->REGCLASS2            #Same only for root PARENT_TABLE

                                  ┌──────────┐
                                  │   VIEW   │
                                  └──────────┘

create view "VIEW" as SUBQUERY    #VIEW forward statements to SUBQUERY
                                  #Goal: encapsulation
                                  #Child dependency of anything mentioned in SUBQUERY (e.g. TABLEs)

create view "VIEW"
 with (VOPTS) ...                 #

create view "VIEW"(COL,...) ...   #Change "COL" names. Omitted COLs keep their names.
alter view "VIEW"
 rename [column] "COL" to "COL2"  #

alter view "VIEW"
 alter [column] "COL"
 drop|set default [VAL]           #Add a `default` CONSTRAINT, forwarded to underlying SUBQUERY

UPDATABLE VIEW ==>                #Possible unless SUBQUERY uses:
                                  #  - AFUNC|WFUNC
                                  #  - from EXPR (instead of from "TABLE")
                                  #  - join
                                  #  - distinct
                                  #  - group by, having
                                  #  - limit|offset
                                  #  - union|intersect|except
                                  #  - returning
                                  #  - top-level with
                                  #  - with (security_barrier)
                                  #Only `select "COL"` are updatable
                                  #  - but can mix with other `select VAL`, although those will be readonly

create view "VIEW" ...
 as SUBQUERY with                 #Reject inserts|updates that do not match VIEW's SUBQUERY, i.e. would not be visible in VIEW
 [cascaded|local] check option    #Does not work with: `recursive`, `instead of` TFUNCs and `instead` RULEs
VOPTS.check_option                #If "cascaded", check in parent VIEWs recursively

VOPTS.security_barrier            #Ensure ROWs are no visible in `where BOOL_REXPR`, RULEs, etc.
                                  #Slower
                                  #Cover channel attacks are still possible
                                  #  - using explain query plans, time of queries, etc.
                                  #  - e.g. to infer size of hidden rows

create recursive view ...         #Allows recursion like in `with recursive ...` CTE

pg_views                          #TABLE with all VIEWs
pg_views.definition               #'SUBQUERY', using pg_get_viewdef()
pg_views.viewname                 #"VIEW" name

pg_get_viewdef                    #Returns 'SUBQUERY' of [M]VIEW.
 ([M]VIEW_OID[, BOOL|INT4])->STR  #BOOL (def: false) is prettify. INT4 is terminal width for wrapping.

                                  ┌───────────────────────┐
                                  │   MATERIALIZED VIEW   │
                                  └───────────────────────┘

create materialized view "MVIEW"  #Readonly TABLE that is populated on-demand via a SUBQUERY
                                  #Child dependency of anything mentioned in SUBQUERY (e.g. TABLEs)
 [("COL",...)]                    #Like create view ...
 [with (TOPTS)]                   #Like create table ...
 as SUBQUERY                      #

refresh materialized view "MVIEW" #Re-populates TABLE

create|refresh
 materialized view "MVIEW"
 [with [no] data]                 #with data (def): populate at creation time
                                  #with no data: truncate and cannot query until next refresh materialized view

alter materialized view "MVIEW"
 rename [column] "COL" to "COL2"
alter materialized view "MVIEW"
 alter [column] "COL" set
 statistics|storage|compression
 ...
alter materialized view "MVIEW"
 cluster on "INDEX"
alter materialized view "MVIEW"
 set without cluster
alter materialized view "MVIEW"
 set access method ...            #Same as alter table ...

pg_matviews                       #TABLE with all MVIEWs
pg_matviews.definition            #'SUBQUERY'
pg_matviews.matviewname           #"MVIEW" name
pg_class.relispopulated
pg_matviews.ispopulated           #BOOL. Whether truncated. True if not MVIEW

                                  ┌───────────────┐
                                  │   TEMPORARY   │
                                  └───────────────┘

create temp[orary] table ...
select ...                        #Drop TABLE at end of session
 into temp[orary] [table] ...     #No autovacuum, but can manually run analyze
 [on commit ACTION]               #At the end of each successful transaction:
                                  #  - preserve rows (def): nothing
                                  #  - delete rows: truncate TABLE
                                  #  - drop: drop TABLE
SCONF.temp_buffers                #Max buffers increment size used (def: 8MB)

create temp[orary] view ...       #Drop VIEW at end of session

create temp[orary] sequence ...   #Drop SEQUENCE at end of session
                                  #Can't use any SCHEMA

pg_temp_NUM                       #SCHEMA with user-defined temporary TABLE|VIEW|SEQUENCEs
                                  #Always prepended to SCONF.search_path
                                  #  - can explicitly add it to override priority order
pg_temp                           #Alias to pg_temp_NUM of current session
pg_my_temp_schema()->REGNAMESPACE #pg_temp_NUM SCHEMA of current session
                                  #0 if none
pg_is_other_temp_schema
 (REGNAMESPACE)->BOOL             #Whether is of pg_temp_NUM of another session

pg_class.relpersistence           #'CHAR'. Whether RELATION is:
                                  #  - 'p': non-temporary|unlogged
                                  #  - 't': temporary
                                  #  - 'u': unlogged

DATADIR/base/pgsql_tmp            #DIR with TEMP data

SCONF.temp_tablespaces            #'TABLESPACE,...' used for TEMP data
                                  #If multiple, pick randomly one on each ENTITY creation

discard temp[orary]               #Discard TEMP data of current session

HCONF
 .remove_temp_files_after_crash   #BOOL (def: true). If false, keep TEMP data after a crash, for debugging

pg_ls_tmpdir([TABLESPACE_OID])    #Returns files in TEMP data DIR
 ->ROW_SET                        #ROW: name STR, size INT8, modification TIMESTAMPTZ
                                  #Def TABLESPACE: pg_default

                                  ┌──────────────┐
                                  │   SEQUENCE   │
                                  └──────────────┘

SEQUENCE                          #TABLE storing a streaming INT algorithm
SEQUENCE.last_value               #INT (def: not set)
SEQUENCE.is_called                #BOOL. Whether setval|nextval() has been called

setval(REGCLASS, INT[, BOOL])     #Sets SEQUENCE.last_value and is_called (def: true)
nextval(REGCLASS)->INT            #Generates and returns new SEQUENCE.last_value
currval(REGCLASS)->INT            #Returns most recent last_value set by setval|nextval(REGCLASS) in current session.
                                  #Fails if not called yet
lastval()->INT                    #Returns most recent last_value set by any setval|nextval() in current session.
                                  #Fails if not called yet

create sequence "SEQUENCE"
 [as int2|4|8]                    #INT TYPE
 [increment [by] INT]             #Def: 1. Added by each nextval()
 [no min|maxvalue]
 [min|maxvalue INT]               #Def: 1 and max value for INT TYPE
 [start [with] INT]               #Def: 1. First value
 [cache INT]                      #Def: 1. Cache next values in advance.
                                  #Cached values are used even if setval() is called
                                  #If >1, concurrent calls to setval|nextval() might jump some values (but still get unique ones)
 [[no] cycle]                     #When reaching maxvalue:
                                  #  - cycle: set to minvalue
                                  #  - no cycle (def): fail
 [owned by none]
 [owned by "TABLE"."COL"]         #Make SEQUENCE an auto-dependency child of "TABLE"."COL"

alter sequence "SEQUENCE" ...     #Same syntax as create sequence ...
 [restart [with] INT]             #Like setval()

"COL" serial[4]                   #COL_ARG with:
 COL_CONSTRAINT...                #  - TYPE int4
                                  #  - default nextval('SEQUENCE')
                                  #  - not null
                                  #SEQUENCE:
                                  #  - named "TABLE_COL_seq"
                                  #  - owned by "COL"
"COL" smallserial|serial2 ...     #Same with TYPE int2
"COL" bigserial|serial8 ...       #Same with TYPE int8

autoinc("COL", "SEQUENCE")        #TFUNC which sets TABLE."COL" = nextval(SEQUENCE)
                                  #Must be `before insert [or update]` + `for each row`
                                  #Unlike `serial` TYPE, works on `update`
                                  #Part of spi EXTENSION

discard sequences                 #Discard SEQUENCE cache for current session

pg_sequence                       #Lower-level TABLE with all SEQUENCEs
pg_sequences                      #Higher-level VIEW with all SEQUENCEs
pg_sequence.seqrelid              #REGCLASS of SEQUENCE
pg_sequences.sequencename         #"SEQUENCE" name
pg_sequence.seqtypid
pg_sequences.data_type            #REGTYPE of INT2|4|8 value
pg_sequences.last_value           #INT8. Last value
pg_sequences.increment_by
pg_sequence.seqincrement          #INT8. Increment
pg_sequences.start_value
pg_sequence.seqstart              #INT8. First value
pg_sequences.min|max_value
pg_sequence.seqmin|max            #INT8. Min|max value
pg_sequences.cache_size
pg_sequence.seqcache              #INT8. Cache size
pg_sequences.cycle
pg_sequence.seqcycle              #BOOL. Whether `cycle`

pg_get_serial_sequence
 ('TABLE', 'COL')->"SEQUENCE"     #COL's SEQUENCE or null if none

                                  ┌─────────────────────┐
                                  │   IDENTITY COLUMN   │
                                  └─────────────────────┘

generated always|by default       #COL_CONSTRAINT. "Identity COL". Same as "COL" *serial, with additional features, i.e. preferred
 as identity                      #COL TYPE must be int2|4|8.
                                  #nextval() is used:
                                  #  - `by default`: as default VAL
                                  #  - `always`: as `generated` VAL, i.e. readonly except when setting `default`
 [(...)]                          #Passed to `create sequence "SEQUENCE" ...`
alter table "TABLE"
 alter [column] "COL"
 add generated always|by default
 as identity
alter table "TABLE"
 alter [column] "COL"
 set generated always|by default
alter table "TABLE"
 alter [column] "COL"
 drop identity [if exists]        #Modify|remove identity COL_CONSTRAINT, not COL itself
alter table "TABLE"
 alter [column] "COL" set ...
alter table "TABLE"
 alter [column] "COL" restart ... #Passed to `alter sequence "SEQUENCE" ...`

insert into ...(...)
 overriding system value          #Make `generated always` behave like `generated by default` instead
 overriding user value            #Make `generated by default` behave like `generated always` instead
                                  #Except: inserted VALs are ignored instead of failing

pg_attribute.attidentity          #CHAR. Identity column on COL:
                                  #  - '': none
                                  #  - 'a': generated always
                                  #  - 'd': generated by default

                                  ┌────────────┐
                                  │   SELECT   │
                                  └────────────┘

select
[distinct ...]
[VAL,...]
[from ...]
[where ...]
[group by ...]
[having ...]
[window ...]
[union|intersect|except ...]...
[order by ...]
[limit ...]
[offset ...]                      #Order: from, where, select non-AFUNC, group by, having, window, select AFUNC,
[fetch ...]                       #distinct, union|intersect|except, order, offset, limit|fetch

select VAL[_SET],...              #Evaluates VALs and returns them as a ROW_SET
                                  #Each VAL[_SET] is returned as a different COL
                                  #  - select VAL,...: multiple COLs
                                  #  - select ROW: single COL with a ROW TYPE
select REXPR,...                  #Can be used
select                            #If no VAL[_SET],..., returned ROWs have 0 COLs
                                  #Does not change how many ROWs are returned

select VAL[_SET]                  #"COL_ALIAS" is COL name in:
 [[as] "COL_ALIAS"],...           #  - return value
                                  #  - REXPR
                                  #Def (in priority):
                                  #  - "FCOL_ALIAS"
                                  #  - "COL" name
                                  #  - "FUNC" name
                                  #  - "?column?"
COL_REXPR                         #REXPR which is often just "COL"
                                  #Can use 1-based COL_INDEX UINT too

table "TABLE"                     #Same as select * from "TABLE"

insert|update|delete ...          #Make statement return `select VAL,...` using inserted|updated|deleted ROWs as source
 returning VAL,...                #Can use `[as] COL_ALIAS`
MSUBQUERY                         #Means either a SUBQUERY or a `... returning VAL,...` (which cannot be used as SUBQUERY otherwise)

                                  ┌────────────┐
                                  │   VALUES   │
                                  └────────────┘

values (VAL,...),...              #Evaluates VALs and returns them as a ROW_SET
                                  #Each (VAL,...) is a ROW
                                  #All ROWs must have same TYPE, including number of COLs
                                  #"COL" name: "columnNUM"
                                  #VAL cannot be a SET
                                  #VAL can use (ZSUBQUERY)s
 [order by ...]
 [asc|desc|using OP]
 [limit ...]
 [offset ...]
 [fetch ...]                      #Same as select ...

                                  ┌──────────┐
                                  │   FROM   │
                                  └──────────┘

select ... from ROW_SET           #Evaluates once per ROW:
                                  #  - select VAL,...
                                  #  - REXPR
                                  #If select VAL,... results is a SET itself, do cartesian product
                                  #ROW_SET must be returned by a FUNC()
select ... from NON_SET           #Converts non-SETs to single-ROW SETs
select ... from NON_ROW_SET       #Converts non-ROWs to single-COL ROWs
                                  #By default, COL name is same as "ROW_ALIAS"

select ...                        #Uses SUBQUERY's ROW_SET return value
 from [lateral] (SUBQUERY)        #Only evaluated once
                                  #  - unless SUBQUERY uses a "ROW_ALIAS" from a previous FROM, i.e. with a join
select (SUBQUERY) from ...
select ... from ...
 where|having|order by (SUBQUERY) #SUBQUERY can also use "ROW_ALIAS" from a previous FROM, i.e. with a join
select ... from FROM ...          #"Anti-join". When using `not exists`.
 where not exists (SUBQUERY)      #Instead of adding cartesian product combinations, removes some.

select ... from "TABLE"           #Same as as `from (table "TABLE") as "TABLE"`

select ... from FROM              #Name of each ROW to use in:
 [[as] "ROW_ALIAS",...]           #  - REXPR
                                  #     - including as FUNC("ROW_ALIAS") argument
                                  #  - any next `from FROM`
                                  #(SUBQUERY) can use "ROW_ALIAS" defined by a previous FROM, but:
                                  #  - must specify `lateral`
                                  #  - i.e. will behave as a REXPR
                                  #Parent query cannot use "ROW_ALIAS" defined by a (SUBQUERY)
                                  #Def: FUNC(...) name
                                  #Required with `from (SUBQUERY)`
["ROW_ALIAS".]"COL"|*             #Like ROW.COL|*
                                  #"ROW_ALIAS" can be omitted if there is a single "COL" named like this among all FROMs

select ... [as]                   #Rename "ROW_ALIAS"."COL"
 "ROW_ALIAS"("FCOL_ALIAS",...)    #Omitted ones are not renamed

select ... from ROW_SET [as]
 "ROWALIAS"("FCOL_ALIAS" TYPE,...)#Define ROW_TYPE
select ... from ROW_SET as        #Each COL must be defined
 ("FCOL_ALIAS" TYPE,...)          #Not with `from (SUBQUERY)` nor `from "TABLE"`

select ... from ROW_SET
 with ordinality
select ... from rows from(...)    #Concatenates a COL named "ordinality"
 with ordinality                  #Its values is a bigserial starting with 1

                                  ┌────────────┐
                                  │   FILTER   │
                                  └────────────┘

select ... where BOOL_REXPR       #Returns no ROWs if BOOL is false
                                  #Conceptually like select ..., BOOL where:
                                  #  - BOOL COL is not returned
                                  #  - ROWs with BOOL false are not returned

                                  ┌──────────────┐
                                  │   DISTINCT   │
                                  └──────────────┘

select all|distinct ...           #If `distinct`, ignores any ROW if any previous ROW2 is =
 [on (COL_REXPR,...)]             #Computes the values used to compare

                                  ┌────────────┐
                                  │   SAMPLE   │
                                  └────────────┘

select ... from "TABLE"
 tablesample SAMPLE_METHOD(...)   #Removes ROWs randomly
 tablesample bernoulli(0-100)     #Percentage of ROWs to keep
                                  #Percentage is only average over multiple runs
                                  #Probability is applied ROW-wise, i.e. more precise with high number of ROWs
 tablesample system(0-100)        #Same but applied on whole heap pages
                                  #I.e. faster, but much less precise
 tablesample system_rows(NUM)     #Number of ROWs to keep
                                  #Use whole heap pages too
                                  #Trusted extension 'tsm_system_rows'
                                  #Does not support `repeatable`
 tablesample system_time(NUM)     #NUMms of time spend collecting ROWs
                                  #Use whole heap pages too
                                  #Trusted extension 'tsm_system_time'
                                  #Does not support `repeatable`
 [repeatable FLOAT]               #Random seed (def: different one for each call)

                                  ┌──────────┐
                                  │   SORT   │
                                  └──────────┘

select ... order by COL_REXPR     #Sort ROWs
                                  #COL_REXPR is the sort value
                                  #  - if union|intersect|except used, can only be "COL"|COL_INDEX
                                  #Unless used, ROWs are unordered
                                  #  - including union|intersect|except result
 [asc|desc]                       #Sorting order (def: asc)
pg_index_column_has_property
 (REGCLASS, COL_INT, 'asc|desc')
 ->BOOL                           #

select ... order by ...,...       #Multiple sort values

SCONF.enable_sort                 #"Explicit sort"
                                  #Usual sort method when using order by COL,...
                                  #As opposed to incremental sort and ordered scans
                                  #Following are the actual methods used, chosen by query planner
QUICKSORT ==>                     #Faster in most cases
TOP-N HEAPSORT ==>                #Faster when using `order by` + `limit`
EXTERNAL MERGE SORT ==>           #Slower but preferred when ROW_SET is too large to fit in-memory (according to SCONF.work_mem)

SCONF.enable_incremental_sort     #"Incremental sort".
                                  #When using order by COL,..., query planner sometimes sorts COL-by-COL instead of all COLs at once
                                  #This allows next COLs to sort groups of ROWs instead of all ROWs at once.
                                  #Pros:
                                  #  - with limit NUM, allows them to skip some ROWs
                                  #  - lower memory
                                  #  - more paralellism
                                  #Con: cost of splitting + iteration
                                  #  - small groups of ROWs are often grouped together to reduce this

ORDERED SCAN ==>                  #Some ACCESS_METHODs automatically sort
                                  #This allows `order by` or merge joins to use the INDEX
                                  #asc|desc and nulls first|last must match
                                  #Comparison:
                                  #  - sequential scan + sort: CPU cost of additional sort step, but uses few sequential I/O
                                  #  - ordered scan: I/O cost of using multiple random I/O calls
                                  #  - i.e. ordered scan can be slower on large amount of ROWs
                                  #  - i.e. useful for `order by` + `limit`
BACKWARD SCAN ==>                 #Some ACCESS_METHODs can query in backward order
                                  #This allows ordered scan to be either asc|desc except:
                                  #  - on multi-COLs with different asc|desc
                                  #  - when using asc nulls first or desc nulls last
create index ... ("COL"|(REXPR)
 asc|desc [nulls first|last],...)
create table ...
 exclude("COL"|(REXPR) asc|desc
 [nulls first|last],...) ...      #Specifies sorting order for ordered scans.

                                  ┌───────────┐
                                  │   SLICE   │
                                  └───────────┘

select ... offset UINT [row[s]]   #Ignores first UINT rows
                                  #Still sequentially scans those rows
                                  #  - i.e. more performant when combined with `where`
                                  #  - i.e. offset pagination vs cursor pagination

select ... limit UINT|all
select ... fetch first|next       #Only returns first UINT rows, after `offset` applied
 [UINT] row[s] only               #Def UINT: 1
                                  #first|next have the same behavior
select ...                        #Returns any following ROW if:
 fetch ... row[s] with ties       #  - its COLs targeted by `order by`
                                  #  - are = than the previous ROW

                                  ┌──────────────────────┐
                                  │   CONCATENATE ROWS   │
                                  └──────────────────────┘

select ... union SUBQUERY         #Concatenates ROWs of `select ...` and SUBQUERY
                                  #They must have the same ROW TYPEs
                                  #SUBQUERY "COL" names are not used
                                  #order by, offset, limit:
                                  #  - applied on the merged result
                                  #  - to apply on only SUBQUERY, use parenthesis around it

select ... intersect SUBQUERY     #Same as union, but only keeps ROWs that are = between `select ...` and SUBQUERY

select ... except SUBQUERY        #Same as union, but only removes ROWs that are = between `select ...` and SUBQUERY

select ...                        #Can be done multiple times
 [union|intersect|except ...]...  #Processed left-to-right, except intersect which have priority

select ... union|intersect|except
 distinct|all SUBQUERY            #If "distinct" (def), removes duplicate rows on merged result

SCONF.enable_parallel_append      #"Parallel append"
                                  #When combining multiple ROW_SETs, distribute producing each in multiple parallel workers

                                  ┌─────────────────────────┐
                                  │   CONCATENATE COLUMNS   │
                                  └─────────────────────────┘

select ...                        #Concatenates each SET as a COL
 from rows from(SET,...)          #Smaller SETs are filled with nulls

select ...
 from rows from(ROW_SET,...)      #ROW_SETs are concatenated as multiple COLs

select ...
 from rows from(RECORD_SET
 as ("FCOL_ALIAS" TYPE, ...),...) #RECORDs (i.e. no specific ROW_TYPE) must use `as (...)`

                                  ┌──────────────────┐
                                  │   JOIN COLUMNS   │
                                  └──────────────────┘

select ... from FROM              #Concatenates COLs of FROM and FROM2
 cross join FROM2                 #ROWs are cartesian product of FROM and FROM2
                                  #Parenthesis can be used to force order
select ... from FROM, FROM2       #Like `cross join` except right-side cannot refer to FROM if it uses a BOOL_REXPR
select ... from FROM
 [inner] join FROM2
 on BOOL_REXPR                    #Like `cross join` but ignores ROWs where BOOL is false

select ... from FROM              #Like `cross join` but:
 left [outer] join FROM2          #  - if a FROM ROW has BOOL false with every FROM2 ROW
 on BOOL_REXPR                    #  - it is kept as a single ROW, with nulls in FROM2 COLs
select ... from FROM
 right [outer] join FROM2
 on BOOL_REXPR                    #Like `left join` but with FROM2 ROWs instead
select ... from FROM
 full [outer] join FROM2
 on BOOL_REXPR                    #Like `left join` + `right join`

select ... from FROM              #Same as: on "ROW_ALIAS"."COL" = "ROW_ALIAS2"."COL" [and ...]
 [...] join FROM2 using("COL",...)#Also merges "ROW_ALIAS[2]"."COL" to a single COL
 [as "ROW_ALIAS3"]                #"ROW_ALIAS3" contains only the "COL",...
select ... from FROM
 natural [...] join FROM2         #Same as `using("COL",...)` with any "COL" common between FROM and FROM2

SELF JOIN ==>                     #Using twice the same FROM

                                  ┌──────────────────┐
                                  │   JOIN METHODS   │
                                  └──────────────────┘

SCONF.enable_nestloop             #"Nested loop join".
                                  #Read both FROMs sequentially as outer|inner loops
                                  #One FROM is the outer loop
                                  #  - i.e. only the inner loop can use INDEXs on the join condition
                                  #O(n^2) but efficient if outer loop is small
SCONF.enable_memoize              #If outer loops has duplicate values, only perform a single inner loop for all of them
                                  #Do it thanks to memoization, i.e. cost memory and CPU if no duplicate values
NESTED LOOP JOIN ON UNIQUE ==>    #If inner loop's join condition is `unique`, can skip each inner loop iterate after finding one match
PARALLEL NESTED LOOP JOIN ==>     #Distribute the outer loop values among parallel workers.
                                  #The inner loop is not parallelized

SCONF.enable_hashjoin             #"Hash join".
                                  #Build hash tables for each FROM, where the key is a hash of the join condition
                                  #Read sequentially one of the hash table, looking up the other
                                  #Hash table size (number of "buckets")
                                  #  - guessed automatically
                                  #  - if too large, done in several rounds, persisting data on-disk
                                  #O(n) but cost of:
                                  #  - hash computation
                                  #  - on-disk memory + I/O, if hash table too large due to too many ROWs
                                  #Only with OP =
SCONF.enable_parallel_hash        #"Parallel hash join"
                                  #Create the hash table in parallel workers

SCONF.enable_mergejoin            #"Merge join".
                                  #Sort each FROM on the join condition, then do a merge join
                                  #O(n log n) but reduced to O(n) when can skip sorting thanks to one of:
                                  #  - an `order by` on the same value as the join condition being used
                                  #  - FROMs using ordered scans
                                  #  - another merge join sorted the other FROMs
                                  #Only with OP =

SCONF.enable_material             #"Materialization".
                                  #When creating intermediate ROW_SETs (e.g. during joins),
                                  #persist it fully in-memory, as opposed to fetching it on-disk.
                                  #Sometimes faster, but requires memory.

                                  ┌───────────────────┐
                                  │   JOIN STRATEGY   │
                                  └───────────────────┘

JOIN STRATEGY ==>                 #When joining multiple FROMs decides:
                                  #  - in which order to join each pair
                                  #  - when to apply each `where|on` condition
                                  #  - which join method to use

JOIN EXHAUSTIVE SEARCH ==>        #Join strategy comparing the cost of each possible solution
                                  #Best execution time, but high planning time if many FROMs
SCONF.join_collapse_limit         #NUM (def: same as SCONF.from_collapse_limit)
                                  #Use left-to-right join order instead of doing a join exhaustive search if:
                                  #  - there are > NUM FROMs
                                  #  - that use `join` keyword (not commas)
                                  #Higher value allow planner to optimize better, but take longer planning time
                                  #Can be 1 (combined with `join` keyword) to force a specific join order

OUTER JOIN STRATEGY ==>           #Joins order chosen by planner:
                                  #  - cross|inner join:
                                  #     - might re-order parenthesis
                                  #     - e.g. FROM join (FROM2 join FROM3) -> (FROM join FROM2) join FROM3
                                  #  - comma-only join:
                                  #     - might re-order parenthesis, unless right-side refers to left-side in join condition
                                  #     - e.g. FROM, FROM2 join FROM3 on BOOL_REXPR -> BOOL_REXPR cannot refer to FROM
                                  #  - left|right outer join:
                                  #     - follows parenthesis order, but might re-order otherwise
                                  #     - e.g. FROM left join FROM2 left join FROM3 -> FROM left join (FROM2 left join FROM3) or (FROM left join FROM2) left join FROM3
                                  #     - e.g. FROM left join (FROM2 left join FROM3) -> kept as is
                                  #  - full outer join:
                                  #     - always joins both sides together directly
                                  #     - e.g. FROM full join FROM2 join FROM3 -> (FROM full join FROM2) join FROM3
SCONF.from_collapse_limit         #NUM (def: 8). Parenthesized sub-join ignore parentheses if:
                                  #  - has <= NUM FROMs
                                  #  - does not use full joins
                                  #E.g. FROM join (FROM2 join FROM3) -> FROM join FROM2 join FROM3
                                  #Higher value allow planner to optimize better, but take longer planning time

ENVVAR PGGEQO                     #BOOL (def: true)
SCONF.geqo                        #Enables the "GEnetic Query Optimizer"
                                  #Join strategy using a genetic algorithm
SCONF.geqo_threshold              #NUM (def: 12). Use GEQO when joining >= NUM FROMs
SCONF.geqo_effort                 #1-10 (def: 5). Higher value spend more time planning, but with better results
                                  #This only sets the values of SCONF.geqo_pool_size|generations|selection_bias
SCONF.geqo_pool_size              #NUM of solutions being evaluated in each round. Usually between 100-1000
                                  #Def: 0, i.e. uses geqo_effort
sCONF.geqo_generations            #NUM of rounds. Usually between 100-1000
                                  #Def: 0, i.e. uses geqo_effort
SCONF.geqo_selection_bias         #NUM deciding how many solutions to remove after each round
                                  #1-1/NUM are removed. Usually 1.5-2. Def: 2
SCONF.geqo_seed                   #GEQO randomness seed, from 0 to 1. Def: 0

                                  ┌────────────┐
                                  │   INSERT   │
                                  └────────────┘

insert into "TABLE"[("COL",...)]  #Adds ROWs to "TABLE" using SUBQUERY's ROW_SET return value
 SUBQUERY                         #SUBQUERY must match ("COL",...) arity and TYPEs
                                  #Def ("COL",...): all COLs

default                           #Default VAL, or null
                                  #Can be used within `values(...)` as SUBQUERY
                                  #Also used on missing values if:
                                  #  - ("COL",...): does not pick every "COL"
                                  #  - no ("COL",...): SUBQUERY shorter than amount of COLs
insert into "TABLE" default values#Single ROW with (default,...)

insert into "TABLE"               #Name of each ROW to use in other parts of insert ..., except SUBQUERY
 [as "ROW_ALIAS"] ...             #Def: "TABLE"

insert ... on conflict ...        #Configure behavior when inserted VAL fails an unique or exclude() CONSTRAINT
insert ... on conflict do nothing #Ignore ROW, instead of failing
insert ...                        #Updates current ROW instead of inserting a new one, i.e. upserts
 on conflict do update set ARG,...#ARG is same syntax as update ... set ARG,...
                                  #If new VALs still fail, do not repeat
                                  #Can use `excluded` as a "ROW_ALIAS" for the VALs being inserted
                                  #Only with unique CONSTRAINT, not `exclude()`
insert ...
 on conflict do update set ...
 where BOOL_REXPR                 #If false, ignore ROW instead

on conflict                       #Only apply for a specific unique|exclude CONSTRAINT
 on constraint "CONSTRAINT" ...   #Required when using `on conflict do update set`
on conflict ("COL",...)           #Same as `on constraint` but targeting CONSTRAINT through its COLs
on conflict (...)                 #Same as `on constraint` but targeting CONSTRAINT through its underlying INDEX
                                  #(...) is same `create index "INDEX"(...)`
                                  #  - including `(...) where BOOL_REXPR` for partial INDEXs

                                  ┌────────────┐
                                  │   UPDATE   │
                                  └────────────┘

update "TABLE" set                #Set values of current ROWs
 "COL" = VAL,...                  #Other COLs are kept as is
                                  #VAL can be `default`
                                  #VAL is evaluated once per ROW
 ("COL",...) = [row](VAL,...),... #`row` is required if only one COL
 ("COL",...) = (SUBQUERY),...     #SUBQUERY must return either:
                                  #  - a single ROW
                                  #  - no ROWs: converted to a ROW filled with nulls

update "TABLE" [as] "ROW_ALIAS"   #Name of each current ROW
 ...                              #To use in other parts of `update ...`, including in (SUBQUERY)
                                  #Def: "TABLE"
["ROW_ALIAS".]"COL"               #Like `select ...`

update ... from FROM,...          #Allows using FROMs inside other parts of update ...
                                  #Same syntax as `select ... from FROM,...`
                                  #`where BOOL_REXPR` is called with cross-join, i.e. each TABLE_ROW + FROMS_ROW
                                  #For any given TABLE_ROW, if `where BOOL_REXPR` filters in:
                                  #  - 0 ROW: no update is done
                                  #  - 1 ROW: `set ...` can use filtered FROMS_ROW
                                  #  - >1 ROWs: `set ...` uses an unspecified filtered FROMS_ROW (to avoid)

update ... where BOOL_REXPR       #Only sets values on ROWs with BOOL true

                                  ┌────────────┐
                                  │   DELETE   │
                                  └────────────┘

delete from "TABLE"
[[as] "ROW_ALIAS"]
[using FROM,...]                  #Same as `update ...` but deleting ROWs instead
[where BOOL_REXPR]                #Def BOOL_REXPR: true, i.e. delete all ROWs

                                  ┌───────────────────┐
                                  │   PG_SAFEUPDATE   │
                                  └───────────────────┘

pg_safeupdate                     #C addon, version 1.5 (2024-12-17)
                                  #Forbids `update|delete` without `where`
SCONF.safeupdate.enabled          #BOOL (def: true)

                                  ┌───────────┐
                                  │   MERGE   │
                                  └───────────┘

merge into "TABLE"                #Join both TABLEs
 using "TABLE2" on BOOL_REXPR     #  - using BOOL_REXPR as condition
 when [not] matched then ...      #Run ...:
                                  #  - `when matched` for each TABLE[2] ROW of the resulting join
                                  #  - `when not matched` for each TABLE2 ROW not in resulting join
                                  #     - i.e. when BOOL_REXPR always false
                                  #Multiple TABLE2 ROWs can match a single TABLE ROW
                                  #  - but each TABLE ROW can be updated|deleted at most once
                                  #Does not work on MVIEW, FTABLE, or TABLE with RULEs
merge into "TABLE"
 using (SUBQUERY) ...             #Same with SUBQUERY

merge ... when [not] matched
 and BOOL_REXPR ...               #Only apply that specific `when ...` when BOOL_REXPR true
merge ... when ...                #Can use multiple `when ...`
                                  #For each ROW of the resulting join, only executes first `when ...` with:
                                  #  - the correct `[not] matched`
                                  #  - `and BOOL_REXPR` true

merge ... when not matched then
 insert [("COL",...)]
 [overriding ...] values(...)     #Like `insert`

merge ... when matched then
 update set
 "COL" = VAL|default, ...
merge ... when matched then
 update set
 ("COL" = VAL|default, ...)       #Like `update`

merge ... when matched then delete#Like `delete`

merge ... when [not] matched then
 do nothing                       #Used to skip the next `when ...`

merge into "TABLE"
 [as] "ROW_ALIAS"[(...)]
merge ...
 using "TABLE2"|(SUBQUERY)
 as "ROW_ALIAS"[(...)]            #Specify ROW_ALIASs, like `select`

                                  ┌──────────────┐
                                  │   TRUNCATE   │
                                  └──────────────┘

truncate table "TABLE",...        #Delete all ROWs
                                  #Unlike `delete from` on all ROWs, delete any dead ROWs right away
                                  #  - pro: faster, and free memory to OS
                                  #  - con: breaks MVCC, i.e. no concurrent transactions should be using the TABLE
[restart|continue identity]       #If `restart` (def: `continue`): call `alter sequence "SEQUENCE" restart`
[restrict|cascade]                #If `cascade` (def: `restrict`): truncates any "TABLE2" depending on "TABLE" too
                                  #  - e.g. due to foreign keys

                                  ┌─────────────────────────────┐
                                  │   COMMON TABLE EXPRESSION   │
                                  └─────────────────────────────┘

with                              #"CTE". Same as: ... from (MSUBQUERY) as "ROW_ALIAS"[("FCOL_ALIAS",...)]
 "ROW_ALIAS"[("FCOL_ALIAS",...)]  #Except:
 as (MSUBQUERY)                   #  - MSUBQUERY, not just SUBQUERY
 ... from "ROW_ALIAS" ...         #  - evaluates MSUBQUERY once when used multiple times
                                  #  - simpler to read
                                  #The main COMMAND can be select|table|values, insert|update|delete or merge
                                  #MSUBQUERY can use `with ...` itself, but only with `select` sub-MSUBQUERYs

with "ROW_ALIAS" ... as (...),    #Can use multiple ones
  "ROW_ALIAS2" ... as (...), ...  #"ROW_ALIAS" can be used inside the next MSUBQUERYs
                                  #  - or the previous ones, if `recursive`

with recursive ...                #Allow using "ROW_ALIAS" inside its own MSUBQUERY.
                                  #MSUBQUERY must be:
                                  #  select ... union select ... from "ROW_ALIAS" ... where BOOL_REXPR
                                  #Recursion happens bottom-up:
                                  #  - first recursion skips `union ...`
                                  #  - next recursions are repeated until `union ...` returns no ROWs
                                  #     - usually when BOOL_REXPR false for all ROWs
SCONF.recursive_worktable_factor  #NUM (def: 10). Hint to the query planner of the average depth of a recursive CTE

with recursive "ROW_ALIAS"        #Set "ROW_ALIAS"."COL2" = NUM
 as (...) search breadth first    #  - initially 1
 by "COL",... set "COL2"          #  - each "COL",... values has own NUM
                                  #I.e. can be used to indicates depth level of recursion
with recursive ... depth first ...#Same but NUM is incremented in a depth first manner

with recursive "ROW_ALIAS"        #Set "ROW_ALIAS"."COL3" = ARR
 as (...) cycle "COL",...         #  - initially empty
 set "COL2" [to VAL default VAL2] #  - contains sets of all "COL" values
 using "COL3"                     #When "COL3" contains twice same value:
                                  #  - recursion stops (i.e. this prevents cycles)
                                  #  - set "ROW_ALIAS"."COL2" with VAL (def: true)
                                  #  - if not, set with VAL2 instead (def: false)

with "ROW_ALIAS"                  #If "ROW_ALIAS" is referenced in ..., whether (...) is evaluated:
 as [not] materialized (...) ...  #  - materialized: once for all references
                                  #     - i.e. faster due to less work
                                  #     - def when (...) referenced multiple times in ...
                                  #  - not materialized: once per reference
                                  #     - sometimes faster if query planner can optimize by knowing both (...) and its usage in ...
                                  #     - cannot be used with `recursive`, nor MSUBQUERYs with side effects
                                  #     - def when (...) referenced only once in ...

                                  ┌─────────────┐
                                  │   CURSORS   │
                                  └─────────────┘

declare "CURSOR" cursor           #Create a CURSOR, i.e. streams a SUBQUERY
 for SUBQUERY                     #Query is executed once during CURSOR creation
                                  #Iterates over that result, i.e. ignores writes
close "CURSOR"|all                #Delete a CURSOR (or all)

declare "CURSOR" ...              #If scroll (def: no scroll), allow backward iteration
 [no] scroll cursor ...           #This can sometimes be slower
                                  #Should avoid with `volatile` FUNCs
                                  #Not with `select ... for ...` ROW locking

START POSITION ==>                #Index 0. Before first ROW.
END POSITION ==>                  #Index -1. After last ROW.
START|END POSITION ==>            #Have no ROWs: return empty ROW_SET
                                  #Boundaries: cannot go further
                                  #Does not close, can still move forward|backward
move ... [from|in] "CURSOR"       #Move CURSOR

RELATIVE MOVES ==>                #
move INT ...                      #Move CURSOR by INT
move [next] ...                   #Move CURSOR by 1
move prior ...                    #Move CURSOR by -1
move 0 ...                        #Does not move CURSOR
move all ..                       #Move CURSOR to start|end position
move forward ...                  #Same as move ...
move backward ...                 #Same but backward relative moves

ABSOLUTE MOVES ==>                #Following ones.
                                  #Still traverse each ROW, i.e. O(n), except for absolute 0|-1 which is O(1)
move absolute UINT ...            #Move CURSOR to index UINT
move first|last ...               #Move CURSOR to first|last ROW
move relative ...                 #Same as move ...

fetch ... from "CURSOR"           #Does move ... from "CURSOR"
                                  #Returns ROW_SET with ROWs from last one (excluded) to current one (included)
                                  #If absolute move, only return current ROW

declare "CURSOR" ...              #If `without hold` (def):
 cursor with[out] hold ...        #  - `declare "CURSOR"` must be in a transaction
                                  #  - `close "CURSOR"` automatically done at end of transaction
declare "CURSOR" cursor           #Cannot be used with `scroll` or `with hold`
 for ... select for update|share  #Should use `for update` if `where current of`:
                                  #  - this ensures ROWs remain the same
                                  #  - this is required if SUBQUERY uses group by, order by or joins

declare "CURSOR" binary ...       #Make fetch ... return ROW_SET in Postgres-specific binary format

update|delete ...                 #Perform `update|delete` on current "CURSOR" ROW.
 where current of "CURSOR"        #Does not move CURSOR

pg_cursors                        #TABLE with all CURSOR
pg_cursors.name                   #'CURSOR'
pg_cursors.statement              #'SUBQUERY'
pg_cursors.is_scrollable          #BOOL
pg_cursors.is_holdable            #BOOL
pg_cursors.is_binary              #BOOL
pg_cursors.creation_time          #TIMESTAMPTZ

SCONF.cursor_tuple_fraction       #0-1 (def: .1). Hint to the query planner at how much percentage of ROWs of TABLEs
                                  #is usually retrieved by a single `fetch ... from "CURSOR"`

refcursor                         #TYPE storing a CURSOR
                                  #Can be manipulated in FUNCs, but not directly in SQL
                                  #Default value: random 'CURSOR' name ("unnamed")
'CURSOR_NAME'                     #REFCURSOR_UNKNOWN
REFCURSOR <-> STR                 #Type cast

                                  ┌──────────┐
                                  │   COPY   │
                                  └──────────┘

copy (MSUBQUERY) to SOURCE        #Export TABLE to a SOURCE. Append ROWs
copy "TABLE"[("COL",...)]         #SOURCE can be:
 to SOURCE                        #  - 'ABSOLUTE_PATH'
                                  #  - stdout
                                  #  - program 'PROGRAM'
                                  #     - piped to stdin
                                  #     - use current shell
                                  #Only export data, not schema (including TYPEs)
                                  #"TABLE" cannot be "VIEW", but TABLE can be (table "VIEW")
 [where BOOL_REXPR]               #Filter ROWs to export

copy "TABLE"[("COL",...)]         #Import SOURCE to a TABLE. Append ROWs
 from SOURCE                      #SOURCE can be:
                                  #  - 'RELATIVE|ABSOLUTE_PATH'
                                  #     - relative to server's process CWD
                                  #  - stdin
                                  #  - program 'PROGRAM'
                                  #     - using its stdout
                                  #     - use current shell

copy ... with ZOPTS               #
ZOPTS.format                      #Can be:
                                  #  - 'text' (def):
                                  #     - DSV
                                  #     - EOF is line can be '\.'
                                  #     - can use \b \f \n \r \t \v \\ \NNN \xNN \DELIM \NULL
                                  #  - 'csv'
                                  #  - 'binary': Postgres-specific binary format
                                  #TYPEs:
                                  #  - text|csv: serialize to STR
                                  #     - except BOOL, serialized to t|f
                                  #  - binary:
                                  #     - preserve most TYPEs
                                  #     - but cast some TYPEs close to each other, e.g. money|int8 or bpchar|varchar|text

ZOPTS.encoding                    #'ENCODING' (def: client encoding)
ZOPTS.freeze                      #BOOL (def: false). Do a `vacuum freeze` first

TEXT|CSV ONLY ==>
ZOPTS.delimiter                   #'CHAR'. COL delimiter
                                  #Def: '\t' (text) or ',' (csv)
ZOPTS.null                        #STR used for null values
                                  #Def: '\N' (text) or '' (csv)

CSV ONLY ==>                      #
ZOPTS.header                      #BOOL (def: false) or match.
                                  #Make first CSV row the "COL" names
                                  #If `match` (only with `copy from`), fail if CSV header does not match "COL" names
ZOPTS.quote                       #'CHAR' (def '"')
ZOPTS.escape                      #'CHAR' (def: '\')
ZOPTS.force_quote ("COL",...)|*   #Always quote specific COLs (except null values)
                                  #Only with `copy to`
ZOPTS.force_not_null ("COL",...)  #Cast nulls as STR, in specific COLs
                                  #Only with `copy from`
ZOPTS.force_null ("COL",...)      #Never cast nulls as STR, even if quoted, in specific COLs
                                  #Only with `copy from`

SCONF.DateStyle                   #Should be set to 'ISO'
SCONF.IntervalStyle               #Should not be set to 'sql_standard'

pg_stat_progress_copy             #TABLE with ongoing `copy` statements
pg_stat_progress_copy.command     #'COPY FROM|TO'
pg_stat_progress_copy.type        #'PIPE|FILE|PROGRAM' or 'CALLBACK' (used in logical replication)
pg_stat_progress_copy.relid       #REGCLASS of TABLE
pg_stat_progress_copy.datid       #pg_database.oid of DATABASE
pg_stat_progress_copy.datname     #NAME of "DATABASE"
pg_stat_progress_copy.pid         #BPID
pg_stat_progress_copy
 .bytes_processed                 #INT8
pg_stat_progress_copy.bytes_total #INT8
pg_stat_progress_copy
 .tuples_processed                #INT8. Rows processed
pg_stat_progress_copy
 .tuples_excluded                 #INT8. Rows excluded by `where BOOL_REXPR` so far

                                  ┌───────────┐
                                  │   GROUP   │
                                  └───────────┘

select ... group by COL_REXPR,... #Group ROWs that are equal by all of COL_REXPR,...
select ... group by (COLREXPR,...)#Can refer to "COL_ALIAS"s
                                  #Each ROW_SET group is reduced to a single ROW
                                  #If a COL uses AFUNC(), it:
                                  #  - reduces ROW_SET into a SCALAR
                                  #  - cannot be targeted by a COL_REXPR
                                  #Some COLs cannot be reduced:
                                  #  - if neither:
                                  #     - uses COL_REXPR, or a superset of it
                                  #        - e.g. if COL_REXPR is `a * 2`, using `a * 2 + 1`
                                  #     - uses AFUNC()
                                  #     - "functional dependency", i.e. a COL_REXPR:
                                  #        - is a "COL"
                                  #        - that is a primary key
                                  #        - of the same "TABLE"
                                  #  - then:
                                  #     - cannot use any "ROW_ALIAS"[."COL"]
                                  #     - all those COLs are computed in a single separate ROW_SET, combined with a cartesian product
select ... group by ()            #Single ROW_SET group
                                  #Default behavior

GROUP AGGREGATE ==>               #Sort all COL_REXPR,... to perform the grouping

SCONF.enable_hashagg              #"Hash aggregate". Alternative to group aggregate
                                  #Build a hash table with hashes of COL_REXPR,... as key to perform the grouping
                                  #Faster unless group aggregate can benefit from an ordered scan
                                  #Also used for:
                                  #  - over (partition by), AFUNC(distinct), distinct, union|intersect|except distinct
                                  #  - union|intersect|except all

select ... having BOOL_REXPR      #Like `where BOOL_REXPR` except:
                                  #  - after `group by`
                                  #  - can use AFUNC()

                                  ┌───────────────────┐
                                  │   GROUPING SETS   │
                                  └───────────────────┘

select ... group by grouping sets #Same as `select ... group by COL_REXPR` union all `select ... group by COL_REXPR2` ...
 (COL_REXPR,...)                  #I.e. COL_REXPRs:
                                  #  - are independent from each other
                                  #  - produce different ROWs merged with `union all`
                                  #In `select VALs`, each COL_REXPR is null in the other grouping sets
                                  #  - including if COL_REXPR is a sub-expression within `select VAL`
                                  #  - examples:
                                  #     - select a, b ... group by grouping sets(a, b):
                                  #        - first ROWs: `select a, null`
                                  #        - second ROWs: `select null, b`
                                  #     - select coalesce(a, VAL) ... group by grouping sets(a, b):
                                  #        - first ROWs: `select a`
                                  #        - second ROWs: `select VAL`
select ... group by grouping sets #Can use a (...) list.
 ((...),...)                      #I.e. like `select ... group by (...)` union all ...
                                  #It can be an empty (), i.e. like `select ... group by ()`

select ... group by               #Same as single grouping sets (...) with cartesian product
 grouping sets (...),             #Example:
 grouping sets (...)              #  select ... group by grouping sets((a, b), (c, d)), grouping sets((e, f), (g, h))
                                  #  -> grouping sets((a, b, e, f), (a, b, g, h), (c, d, e, f), (c, d, g, h))
select ... group by COL_REXPR,    #COL_REXPR is like grouping sets (COL_REXPR)
 grouping sets (...)              #Example:
                                  #  select ... group by a, grouping sets((b, c), (d, e))
                                  #  -> grouping sets((a, b, c), (a, d, e))
select ... group by distinct ...  #Ignore duplicate grouping sets produced by the cartesian product

select ... group by grouping sets
 (grouping sets(...), ...)        #Same as grouping sets(..., ...)

rollup(COL_REXPR,...)             #Same as: grouping sets ((COL_REXPR1, COL_REXPR2,...), ..., (COL_REXPR1, COL_REXPR2), (COL_REXPR1), ())
                                  #With each grouping set having one less COL_REXPR
                                  #Meant when a series of groups that are subsets of each other
cube(COL_REXPR,...)               #Same as: grouping sets ((COL_REXPR,...), ..., ())
                                  #With all possible combinations of COL_REXPR,... including all|none of them
rollup|cube((...),...)            #If using a (...) list, it is kept as as a list when translating to `grouping sets`,
                                  #then it is flattened.
                                  #E.g. `cube((a, b), (c, d))` -> `grouping sets((a, b, c, d), (a, b), (c, d), ())`

grouping(COL_REXPR,...)->UINT     #AFUNC. UINT indicates the COL_REXPRs used by the current ROW
                                  #UINT is a or'd bitwise flag:
                                  #  - 1 for last COL_REXPR, 2 for previous one, etc.
                                  #  - absence of bit means COL_REXPR is used

                                  ┌───────────────┐
                                  │   AGGREGATE   │
                                  └───────────────┘

AFUNC(SET, ...)->SCALAR           #"Aggregate function". Reduce a SET to a SCALAR
                                  #If SCALAR is passed as argument, it is handled like a SET with a single item.
                                  #Must be used inside a REXPR: select, distinct, having, order by
                                  #Cannot be used inside `where`, `on`, `check()` and POLICY (`using`, `with check`)

AFUNC(...)
 filter (where BOOL_REXPR)        #Filter SET values passed to AFUNC()

AFUNC(distinct|all ...)           #If `distinct`, ignore duplicate SET values

AFUNC(... order by ...)           #Sort SET. Same syntax as `select ...`

AFUNC(...)                        #Similar to AFUNC(ARG..., ...) except ARG... are sorted ("ordered-set AFUNC")
 within group (order by ARG,...)  #ARG... are "aggregated arguments" (evaluated once per ROW)
                                  #and ... are "direct arguments" (evaluated once for all ROWs)
                                  #`order by`: same syntax as `select ...`
ZSET                              #Notation that means this AFUNC() argument must be in `within group (order by ZSET)`

PARTIAL AGGREGATION ==>           #AFUNC which can compute its result in parallel divide-and-conquer, as a performance optimization
                                  #Cannot do so when using ZSET, grouping sets, AFUNC(distinct ...) nor AFUNC(... order by ...)
                                  #Most builtin AFUNCs allow partial aggregation, except for *agg and ones using ZSETs

                                  ┌────────────┐
                                  │   WINDOW   │
                                  └────────────┘

AFUNC(SET, ...)->SCALAR over (...)#WFUNC, "Window function"
                                  #Alternative to `group by`. Like `group by`:
                                  #  - specifies the ROW_SET group ("window") passed to AFUNC()
                                  #Unlike `group by`:
                                  #  - window is computed for each ROW and AFUNC()
                                  #  - does not reduce ROW_SET groups to single ROWs
                                  #  - does not restrict which values other COLs can use
                                  #Any AFUNC can be used as WFUNC
                                  #  - but some WFUNC cannot be used as AFUNC
AFUNC (...) over (...) ...        #When combined with `group by`:
 group by ...                     #  - `group by` and `having` are applied first, independently
                                  #     - i.e. WFUNC operates on ROWs after grouping
                                  #  - WFUNC have same "ROW_ALIAS"[."COL"] restrictions as other `select VALs`

AFUNC(...) filter (...) over (...)#Can be used, like a normal AFUNC()

AFUNC(distinct|all ...) over (...)
AFUNC(... order by ...) over (...)#Cannot be used, unlike a normal AFUNC()

AFUNC(ZSET, VAL, ...)             #Must be called with: AFUNC(...) over (... order by COL_REXPR)
                                  #ZSET is the window. VAL is COL_REXPR.

select ...
 AFUNC(...) over "WINDOW"
 ... window "WINDOW" as (WINDOW)  #Same as: `select ... AFUNC(...) over (WINDOW)`
select ...
 AFUNC(...) over ("WINDOW" ...)
 ... window "WINDOW" as (WINDOW)  #Same as: `select ... AFUNC(...) over (WINDOW ...)`

AFUNC(...) over                   #Define window as: the ROWs with same COL_REXPR,... as current ROW
 (partition by COL_REXPR,...)     #  - i.e. similar to `group by`
                                  #If not specified:
                                  #  - if `over (... order by COL_REXPR,...)`:
                                  #     - same as `partition by COL_REXPR,...`
                                  #     - but each window includes any previous ROW
                                  #  - otherwise: single window

AFUNC(...) over (... order by ...)#Sort window ROWs. Same syntax as `select ... order by ...`
                                  #"Peer ROWs" are the preceding|following ones with same sort value

AFUNC(...) over (... rows         #Only include specific range of ROWs in current window
 between FRAME and FRAME2)        #FRAME is start (included) and FRAME2 end (excluded)
                                  #FRAME[2] can be:
                                  #  - unbounded preceding: first ROW
                                  #  - unbounded following: last ROW
                                  #  - current row
                                  #  - NUM preceding: NUMth previous ROW (up to first ROW)
                                  #  - NUM following: NUMth next ROW (up to last ROW)
AFUNC(...) over (... rows FRAME)  #Same as `rows between FRAME and current row`
AFUNC(...) over (... groups ...)  #Same as `rows ...` except FRAME[2]:
                                  #  - current row: include peer ROWs
                                  #  - NUM preceding|following: peer ROWs are counting as 1
AFUNC(...) over (... range ...)   #Same as `rows ...` except FRAME[2]:
                                  #  - current row: include peer ROWs
                                  #  - NUM preceding|following:
                                  #     - NUM is based on the sort value
                                  #     - not based on ROW position within the window
AFUNC(...) over (... range
 between unbounded preceding
 and current row)                 #Default behavior

AFUNC(...) over                   #Exclude specific ROWs in current window, based on EXCLUDE:
 (... rows|groups|range           #  - no others (def): none
 ... exclude EXCLUDE)             #  - current row
                                  #  - ties: peers (except current row)
                                  #  - group: peers + current row

                                  ┌──────────┐
                                  │   RANK   │
                                  └──────────┘

count(SET)->INT8                  #AFUNC. Number of values, excluding nulls
count(*)->INT8                    #AFUNC. Number of values, including nulls

rank(ZSET, VAL)->INT8             #AFUNC. 1-based index of VAL in sorted ZSET
                                  #If equal value, same index, but increments index for next value
dense_rank(ZSET, VAL)->INT8       #Same as rank() but if equal value, does not increment index for next value
                                  #I.e. like removing duplicates first
percent_rank(ZSET, VAL)->FLOAT8   #Same as rank() but returns as 0-1 percentage
cume_dist(ZSET, VAL)->FLOAT8      #AFUNC. Cumulative distribution, i.e. rank() / count()

mode(ZSET)->VAL                   #AFUNC. Mode

percentile_cont
 (FLOAT8|INTERVAL_ZSET,           #AFUNC. Percentile value[s], with interpolation
 FLOAT8[_ARR])->VAL[_ARR]         #FLOAT is 0-1 percentage
percentile_disc
 (ZSET, FLOAT8[_ARR])->VAL[_ARR]  #AFUNC. Percentile value[s], without interpolation

                                  ┌─────────────────┐
                                  │   WINDOW RANK   │
                                  └─────────────────┘

row_number(SET)->INT8             #WFUNC. Current 1-based index within window

nth_value(SET, COL_REXPR, INT4)
 ->VAL|null                       #WFUNC. Returns COL_REXPR value at index INT4 within window
first|last_value(SET, COL_REXPR)
 ->VAL                            #WFUNC. Returns COL_REXPR value at first|last index within window

lead(SET, COL_REXPR, INT4[, VAL]) #WFUNC. Returns COL_REXPR value at index row_number() + INT4 within window
 ->VAL                            #If none, returns VAL (def: null)
lag(...)->VAL                     #Same as lead but using -INT4

ntile(SET, INT4)->INT             #Returns 1 for first index, INT4 for last index, and interpolated values in-between.
                                  #If SET length >= INT4, returns row_number() instead

                                  ┌────────────────┐
                                  │   STATISTICS   │
                                  └────────────────┘

variance|var_samp(NUM_SET)->FLOAT #AFUNC. Variance
stddev[_samp](NUM_SET)->FLOAT     #AFUNC. Standard deviation
covar_samp(NUM_SET)->FLOAT8       #AFUNC. Covariance
var_pop(NUM_SET)->FLOAT
stddev_pop(NUM_SET)->FLOAT
covar_pop(NUM_SET)->FLOAT8        #AFUNC. Same as above but using n instead of n-1

corr
 (FLOAT8_SET, FLOAT8_SET2)->FLOAT8#AFUNC. r
regr_r2
 (FLOAT8_SET, FLOAT8_SET2)->FLOAT8#AFUNC. r₂

regr_*(...)                       #AFUNC. Linear regression. Not documented yet

                                  ┌────────────────────────┐
                                  │   TEXT SEARCH PARSER   │
                                  └────────────────────────┘

create text search parser "PARSER"#Tokenizer. Split a STR into tokens ("lexemes")
 (OPTS)                           #Can produce overlapping tokens
                                  #  - both the compound token and its parts
                                  #  - this allows searching for both
                                  #Max TOKEN size: 2KB
                                  #Must be superuser.
                                  #OPTS.* FUNCs not documented yet
OPTS.start                        #FUNC called at start
OPTS.gettoken                     #FUNC that processes next token
OPTS.end                          #FUNC called at end
OPTS.lextypes                     #FUNC that lists token types
OPTS.headline                     #FUNC that summarizes token types

pg_catalog.default                #Default "PARSER", with following tokens
blank                             #Whitespace
asciiword                         #ASCII word
[num]word                         #Non-ASCII word with[out] digits
                                  #Uses locale-specific information, based on lc_ctype
[ascii|num]hword                  #Like *word but hyphenated, as a whole
hword_[ascii|num]part             #Like *word but hyphenated part
int                               #INT
uint                              #UINT
float                             #FLOAT
sfloat                            #FLOAT, as NUMe...
url                               #URL
protocol                          #SCHEME://
host                              #HOST
url_path                          #/PATH of URL
file                              #/PATH of file
email                             #Email address
version                           #X.Y.Z
tag                               #XML tag
entity                            #XML entity

pg_ts_parser                      #TABLE with all PARSERs
pg_ts_parser.oid                  #OID
pg_ts_parser.prsname              #"PARSER" name
pg_ts_parser.prsstart
pg_ts_parser.prstoken
pg_ts_parser.prsend
pg_ts_parser.prslextype
pg_ts_parser.prsheadline          #REGPROC of OPTS.*

ts_token_type('PARSER'|PARSER_OID)
 ->ROW_SET                        #Returns all token types
ROW.tokid                         #TOKEN_TYPE, as INT
ROW.alias                         #"TOKEN_TYPE" name
ROW.description                   #'TOKEN_TYPE_DESCRIPTION'

ts_parse('PARSER'|PARSER_OID, STR)
 ->ROW_SET                        #Tokenize a STR
ROW.token                         #STR value
ROW.tokid                         #TOKEN_TYPE

                                  ┌──────────────────────────┐
                                  │   TEXT SEARCH TEMPLATE   │
                                  └──────────────────────────┘

create text search                #Creates a TEMPLATE
 template "TEMPLATE"(OPTS)        #Must be superuser
                                  #Normalizes tokens produced by PARSER: removing|transforming them
                                  #Only defines the backbone of the normalization logic
                                  #  - each DICTIONARY instantiates it with specific arguments (e.g. words from a given language)
                                  #When handling a token, can choose to let next TEMPLATE handle it or not
                                  #  - "filtering": when doing so
                                  #  - final: when not doing it, i.e. must be last TEMPLATE
                                  #OPTS.* FUNCs not documented yet
OPTS.init                         #FUNC
OPTS.lexize                       #FUNC

pg_ts_template                    #Table with all TEMPLATEs
pg_ts_template.oid                #OID
pg_ts_template.tmplname           #'TEMPLATE' name
pg_ts_template.tmplinit
pg_ts_template.tmpllexize         #REGPROC of OPTS.*

SHAREDIR/tsearch_data/FILE.EXT    #File used by TEMPLATEs

simple                            #TEMPLATE removing common words
                                  #Also lowercases words
OPTS.stopwords                    #'FILE' of common words
                                  #Uses SHAREDIR/tsearch_data/FILE.stop
                                  #  - file with one word per line
OPTS.accept                       #BOOL. Whether it is a final TEMPLATE (true, def) or filtering (false)

synonym                           #Filtering TEMPLATE normalizing synonyms to a single form.
                                  #Can also be used to process words, keeping them as is
                                  #  - to avoid next TEMPLATEs from wrongly normalizing them
                                  #  - e.g. Paris -> Paris, to avoid stemmer to misrecognize it as a plural word
OPTS.synonyms                     #'FILE' of synonyms
                                  #Uses SHAREDIR/tsearch_data/FILE.syn
                                  #  - each line has two space-separated fields
                                  #  - second field can end with * to mean it is a prefix
                                  #     - i.e. ...* with TSQUERY
OPTS.casesensitive                #BOOL (def: false). Lowercases words.

thesaurus                         #Filtering TEMPLATE
                                  #Like synonym TEMPLATE but can:
                                  #  - match multiple tokens as input
                                  #     - if multiple choices, longest one is picked
                                  #  - return multiple tokens as output
OPTS.dictfile                     #'FILE' of substitutions
                                  #Uses SHAREDIR/tsearch_data/FILE.ths
                                  #  - each line has two colon-separated fields
                                  #  - first field can contain ? to mean a single token removed by OPTS.dictionary
                                  #  - second field can start with * to prevent next TEMPLATE from processing it
                                  #  - can have #COMMENT
OPTS.dictionary                   #DICTIONARY to apply first ("subdictionary")
                                  #Must end with a final TEMPLATE
                                  #Only used for matching purpose, not kept in final output

ispell                            #Filtering TEMPLATE using Ispell project
                                  #Stemmer like snowball:
                                  #  - more supported languages
                                  #  - based on word list, instead of generic grammar algorithm
                                  #     - i.e. more specific
                                  #     - if word is in list (but might not be), better output
                                  #     - should be followed by snowball
                                  #  - can breakdown compound words even without punctuation|space (e.g. German long words)
OPTS.stopwords                    #Like simple TEMPLATE
OPTS.dictfile                     #'FILE'
                                  #Uses SHAREDIR/tsearch_data/FILE.dict
                                  #Must be manually downloaded and converted to UTF-8
OPTS.afffile                      #'FILE'
                                  #Uses SHAREDIR/tsearch_data/FILE.affix
                                  #Must be manually downloaded and converted to UTF-8

snowball                          #Final TEMPLATE using Snowball project
OPTS.language                     #'LANG' (e.g. 'english').
                                  #Stems words, i.e. remove alternative forms:
                                  #  - lowercase
                                  #  - plural -> singular
                                  #  - conjugation -> infinitive
                                  #  - adjective|adverb suffix (e.g. '*ous', '*ly') -> removed
OPTS.stopwords                    #Like simple TEMPLATE

                                  ┌────────────────────────────┐
                                  │   TEXT SEARCH DICTIONARY   │
                                  └────────────────────────────┘

create text search                #Create a DICTIONARY, i.e. TEMPLATE with arguments
 dictionary "DICTIONARY"(OPTS)    #Parent dependency of TEMPLATE
OPTS.template                     #TEMPLATE
OPTS.*                            #Arguments to TEMPLATE

alter text search
 dictionary "DICTIONARY"(OPTS)    #

pg_ts_dict                        #TABLE with all DICTIONARYs
pg_ts_dict.oid                    #OID
pg_ts_dict.dictname               #'DICTIONARY' name
pg_ts_dict.dicttemplate           #pg_ts_template.oid of TEMPLATE
pg_ts_dict.dictinitoption         #'VAR = VAL,...' of TEMPLATE OPTS

regdictionary                     #TYPE to cast pg_ts_dict.oid as "DICTIONARY" name

ts_lexize(REGDICTIONARY, 'TOKEN') #Normalize 'TOKEN' according to DICTIONARY
 ->STR_ARR|null                   #'TOKEN' is produced by PARSER
                                  #Returns null if token is not transformed and passed to next TEMPLATE
                                  #Returns empty ARR if token is omitted

simple                            #DICTIONARY with simple TEMPLATE but no OPTS.stopwords (i.e. noop)

LANG_stem                         #DICTIONARY with snowball TEMPLATE, OPTS.language 'LANG', OPTS.stopwords 'LANG'

unaccent                          #DICTIONARY with its own TEMPLATE
                                  #Similar to synonym TEMPLATE, but focused on turning Unicode characters into ASCII
                                  #  - removing accent
                                  #  - symbols, e.g. © -> (C) or ʹ -> '
                                  #Trusted postgres extension 'unaccent'
OPTS.rules                        #'FILE' (def: 'unaccent') of fields with|without accent
                                  #Uses SHAREDIR/tsearch_data/FILE.rules
                                  #Default works well for Western languages
unaccent(['REGDICTIONARY', ]STR)
 ->STR                            #Applies unaccent to STR

dict_xsyn                         #DICTIONARY with its own TEMPLATE
                                  #Similar to synonym TEMPLATE, but spread word into several synonyms
                                  #Trusted postgres extension 'dict_xsyn'
OPTS.rules                        #'FILE' of synonyms
                                  #Uses SHAREDIR/tsearch_data/FILE.rules
                                  #  - space-separated fields
                                  #  - first field is input
                                  #  - next fields are output
                                  #  - can use #COMMENT
OPTS.keeporig                     #BOOL (def: true). Whether to keep input token in output.
OPTS.keepsynonyms                 #BOOL (def: true). Whether to keep synonyms in output.
OPTS.matchorig                    #BOOL (def: true). When OPTS.keeporig true, whether input token can be processed by next TEMPLATEs
OPTS.matchsynonyms                #BOOL (def: false). Same for OPTS.keepsynonyms

dict_int                          #DICTIONARY with its own TEMPLATE
                                  #Normalize long NUMs
OPTS.maxlen                       #NUM (def: 6). Truncate only first 6 digits of NUMs
OPTS.rejectlong                   #BOOL (def: false). Instead of truncating, omit long NUMs
OPTS.absval                       #BOOL (def: false). Ignore + - signs

                                  ┌────────────────────────┐
                                  │   TEXT SEARCH CONFIG   │
                                  └────────────────────────┘

create text search                #REGCONF, i.e. PARSER + list of DICTIONARYs (for given TOKEN_TYPEs)
 configuration "REGCONF"(OPTS)    #Should put:
                                  #  - most specific DICTIONARYs first
                                  #  - DICTIONARY with final TEMPLATE last
                                  #Parent dependency of PARSER|DICTIONARY
OPTS.parser                       #"PARSER"
OPTS.copy                         #"REGCONF2" to copy PARSER + mappings

alter text search
 configuration "REGCONF"
 add|alter mapping
 for "TOKEN_TYPE",...
 with DICTIONARY,...              #Apply DICTIONARY for given TOKEN_TYPEs
alter text search
 configuration "REGCONF"
 alter mapping
 [for "TOKEN_TYPE",...]
 replace DCTIONARY with DCTIONARY2#
alter text search
 configuration "REGCONF"
 drop mapping [if exists]
 for "TOKEN_TYPE",...             #

initdb
 --text-search-config|-T 'REGCONF'#Def: 'pg_catalog.LANG' (using lc_ctype)
SCONF.default_text_search_config  #Current REGCONF
get_current_ts_config()->REGCONFIG#

pg_catalog.simple                 #REGCONF. PARSER pg_catalog.default
                                  #DICTIONARYs:
                                  #  - ignore: blank, tag|entity, protocol
                                  #  - simple: others
pg_catalog.LANG                   #REGCONF. Same but also uses DICTIONARY:
                                  #  - LANG_stem: [ascii]word, hword_[ascii]part, [ascii]numhword

pg_ts_config                      #TABLE with all REGCONFs
pg_ts_config.oid                  #OID
pg_ts_config.cfgname              #"REGCONF" name
pg_ts_config.cfgparser            #pg_ts_parser.oid of PARSER

regconfig                         #TYPE to cast pg_ts_config.oid as "REGCONF" name

pg_ts_config_map                  #TABLE with all REGCONFs mappings
pg_ts_config_map.mapcfg           #REGCONFIG of REGCONF
pg_ts_config_map.mapdict          #pg_ts_dict.oid of DICTIONARY
pg_ts_config_map.maptokentype     #TOKEN_TYPE
pg_ts_config_map.mapseqno         #INT with priority order for a given TOKEN_TYPE

                                  ┌────────────────────────┐
                                  │   TEXT SEARCH VECTOR   │
                                  └────────────────────────┘

tsvector                          #TYPE. STR after:
                                  #  - PARSER tokenization
                                  #  - REGCONFIG normalization
                                  #  - duplicate merging
                                  #The last two are only done with *to_tsvector(), @@, ts_rank*(), ts_headline()
                                  #Max 1MB
                                  #  - i.e. might need to split documents into chunks
                                  #Max 2e19 TOKENs
TOKEN:POS,...                     #Specify a TOKEN's position inside STR
                                  #Min 1
                                  #Max 16383 (if more, set to 16383)
                                  #Used for relative position comparison
                                  #Must:
                                  #  - '-escape -> '
                                  #  - \-escape or '-quote -> : \
                                  #  - \-escape -> \
TOKEN:POSWEIGHT,...               #Specify a TOKEN's WEIGHT, i.e. importance (title, subtitle, etc.)
                                  #Each WEIGHT is A|B|C|D
                                  #Def: D
                                  #Duplicates with different POSWEIGHTs are merged
                                  #  - max 256 duplicates per TOKEN
                                  #POSWEIGHTs are parsed as TOKENs themselves

TSVECTOR <-> STR                  #Type cast

'...'                             #TSVECTOR_UNKNOWN

to_tsvector([REGCONFIG, ]STR)
 ->TSVECTOR                       #Type cast

to_tsvector
 ([REGCONFIG, ]OBJ_JSON[B])       #Like to_tsvector() but using all OBJ values (deeply) (STR values only), concatenated
 ->TSVECTOR                       #Positions are ordered with JSON, but unordered with JSONB
json[b]_to_tsvector([REGCONFIG, ] #Same but filter by STR:
 OBJ_JSON[B], STR[_ARR]_JSON[B])  #  - "string": STR values
 ->TSVECTOR                       #  - "numeric": NUM values
                                  #  - "boolean": BOOL values
                                  #  - "key": OBJ keys (deeply)
                                  #  - "all": keys + values

array_to_tsvector(STR_ARR)
 ->TSVECTOR                       #Join with space
tsvector_to_array(TSVECTOR)
 ->STR_ARR                        #Inverse

TSVECTOR || TSVECTOR2             #Concatenates

length(TSVECTOR)->INT4            #Number of TOKENs

strip(TSVECTOR)->TSVECTOR         #Removes POSWEIGHTs
setweight(TSVECTOR, 'WEIGHT'
 [, 'TOKEN'_ARR])->TSVECTOR       #Sets TSVECTOR WEIGHT on TOKENs (def: all)
to_filter(TSVECTOR, 'WEIGHT'_ARR)
 ->TSVECTOR                       #Only include TOKENs with specific WEIGHTs

to_delete(TSVECTOR, 'TOKEN'[_ARR])
 ->TSVECTOR                       #Exclude specific TOKENs

ts_debug([REGCONFIG, ]STR)
 ->ROW_SET                        #Return each individual TOKEN as a ROW, with before-normalization information
ROW.alias                         #'TOKEN_TYPE'
ROW.description                   #'TOKEN_TYPE_DESCRIPTION'
ROW.token                         #STR. Original input
ROW.dictionaries                  #'DICTIONARY'_ARR chosen
ROW.dictionary                    #Final 'DICTIONARY'|null
ROW.lexemes                       #STR_ARR. Final TOKENs

unnest(TSVECTOR)->ROW_SET         #Return each individual TOKEN as a ROW
ROW.lexeme                        #'TOKEN'
ROW.positions                     #INT2_ARR
ROW.weights                       #'WEIGHT'_ARR

ts_stat('SUBQUERY'[, 'WEIGHT...'])#With SUBQUERY returning TSVECTOR, return each grouped TOKEN as a ROW
 ->ROW_SET                        #If 'WEIGHT...', only include TOKENs with those
ROW.word                          #'TOKEN'
ROW.nentry                        #Number of matches
ROW.ndoc                          #Number of TSVECTORs

tsvector_update_trigger
 ('TSVECTOR_COL', 'REGCONF',      #TFUNC which sets a `TSVECTOR_COL = to_tsvector(STR) || ...` each time STR_COL changes
 'STR_COL',...)                   #Must be `before insert or update` + `for each row`
tsvector_update_trigger_column
 ('TSVECTOR_COL', 'REGCONF_COL',
 'STR_COL',...)                   #Same but storing REGCONF as a COL instead

                                  ┌───────────────────────┐
                                  │   TEXT SEARCH QUERY   │
                                  └───────────────────────┘

tsquery                           #TYPE. Query on a TSVECTOR.
                                  #Goes through tokenization + normalization + duplicates like TSVECTOR.
                                  #The last two are only done with *to_tsquery(), @@, ts_rank*(), ts_headline()
                                  #Max 4e9 TOKENs, max 3e4 TOKENS + OPs

TSQUERY <-> STR                   #Type cast

'...'                             #TSQUERY_UNKNOWN, with following syntax
                                  #Must:
                                  #  - '-escape -> '
                                  #  - \-escape or '-quote -> : \ < & | ( ) !
                                  #  - \-escape -> \
TOKEN                             #
TOKEN:WEIGHT...                   #Only if this WEIGHT
PREFIX:*                          #Allow matching from start
... & ...                         #And
... | ...                         #Or (not space)
(...)                             #
! ...                             #Not
... <-> ...                       #Must immediately follow ("phrase query"), using :POS
... <POS> ...                     #Must follow after exactly POS distance
                                  #<1> is same as <->
                                  #<0> is similar to &

tsquery_phrase
 (TSQUERY, TSQUERY2[, NUM])
 ->TSQUERY                        #Returns TSQUERY <-> TSQUERY2 or TSQUERY <NUM> TSQUERY2

to_tsquery([REGCONFIG, ]STR)
 ->TSQUERY                        #Type cast
plainto_tsquery([REGCONFIG, ]STR) #Same as to_tsquery() but:
 ->TSQUERY                        #  - ignores all operators
                                  #  - put & between each TOKEN
phraseto_tsquery([REGCONFIG, ]STR)#Same as to_tsquery() but:
 ->TSQUERY                        #  - ignores all operators
                                  #  - put <-> or <POS> between each TOKEN
websearch_to_tsquery              #Same as to_tsquery() but:
 ([REGCONFIG, ]STR)->TSQUERY      #  - ignores all operators
                                  #  - "..." -> put <-> or <POS> between each TOKEN
                                  #  - or -> |
                                  #  - - -> !

TSQUERY && TSQUERY2               #Applies &
TSQUERY || TSQUERY2               #Applies |
!! TSQUERY                        #Applies !
TSQUERY <-> TSQUERY2              #Applies <->

TSQUERY @> TSQUERY2               #BOOL. Is superset|equal
                                  #Only considers TOKENs, not operators
TSQUERY <@ TSQUERY2               #BOOL. Is subset|equal

numnode(TSQUERY)->INT4            #Number of TOKENs and operators

querytree(TSQUERY)->TSQUERY       #Remove any !(...)
                                  #Reason: it cannot be indexed
                                  #Can return empty STR

ts_rewrite
 (TSQUERY, TSQUERY2, TSQUERY3)
 ->TSQUERY                        #Change occurences of TSQUERY2 inside TSQUERY to TSQUERY3
ts_rewrite(TSQUERY, 'SUBQUERY')
 ->TSQUERY                        #Same with TSQUERY2|3 are computed by running SUBQUERY returning 2 COLs

                                  ┌───────────────────────┐
                                  │   TEXT SEARCH MATCH   │
                                  └───────────────────────┘

TSQUERY @@ TSVECTOR
TSVECTOR @@ TSQUERY               #BOOL. true if match
STR @@ TSQUERY                    #Same as ts_vector(STR) @@ TSQUERY

ts_rank_cd([FLOAT_ARR,]           #Counts number of matches with TSQUERY on TSVECTOR
 TSVECTOR, TSQUERY[, UINT])       #Often used with `order_by`
 ->FLOAT                          #FLOAT_ARR is multiplied to matches for WEIGHT D|C|B|A (def: 0.1, 0.2, 0.4, 1)
                                  #Ignores TOKENs without :POS
                                  #UINT computes following operations on return value:
                                  #  - 0 (def): n
                                  #  - 1: n/log(m+1)
                                  #  - 2: n/m
                                  #  - 4: n/x
                                  #  - 8: n/u
                                  #  - 16: n/log(u+1)*log(2)
                                  #  - 32: n/(n+1)
                                  #UINT is or'd flag, i.e. can combine several computations
                                  #With:
                                  #  - n: count of matches
                                  #  - m: count of TOKENs in TSVECTOR (must use :POS)
                                  #  - u: count of unique TOKENs in TSVECTOR
                                  #  - x: mean harmonic distance between matches
                                  #     - sum of each 1/(:POS difference) between each match and the next one
                                  #     - e.g. :1 :11 :111 -> 1/10 + 1/100 -> .11
ts_rank(...)->FLOAT               #Same as ts_rank() but n is first normalized from 0 to 1
                                  #  - using: 1-1/(.9 + 1.644 * n)
                                  #  - i.e. scale follows 1/n
                                  #If no match has :POS, use a single match with :1d
                                  #UINT flags are slightly different:
                                  #  - 1: n/log(m+1)*log(2) instead
                                  #  - 4: not possible

ts_headline([REGCONFIG, ]STR,     #Highlight matches.
 TSQUERY[, 'OPT=VAL,...'])->STR   #For performance, should apply only on ROWs with matches
                                  #  - e.g. select ts_headline(...) from (select ...)
ts_headline([REGCONFIG, ]
 OBJ_JSON[B], TSQUERY
 [, 'OPT=VAL,...'])->OBJ_JSON[B]  #Same but over OBJ values (deeply, STR values only)
OPTS.StartSel                     #STR (def: '<b>'). Prepended to each match
OPTS.StopSel                      #STR (def: '</b>'). Appended to each match
OPTS.FragmentDelimiter            #STR (def: '...'). Ellipsis symbol
OPTS.MinWords                     #UINT (def: 15). Min TOKENs to output
OPTS.MaxWords                     #UINT (def: 35). Max TOKENs to output
OPTS.ShortWord                    #UINT (def: 3). Remove TOKENs with <= UINT characters at start|end of return value,
                                  #unless they are matches
OPTS.HighlighAll                  #BOOL (def: false). Negates OPTS.MinWords|MaxWords|ShortWord
OPTS.MaxFragments                 #UINT (def: 0). Max fragments in output

                                  ┌───────────────────────┐
                                  │   TEXT SEARCH FUZZY   │
                                  └───────────────────────┘

FUZZYSTRMATCH ==>                 #Trusted postgres extension

levenshtein(STR, STR2
 [, INS_COST, DEL_COST, SUB_COST])#Levenshtein distance
 ->INT                            #All COST def: 1
levenshtein_less_equal(..., INT)  #Same but:
 ->INT2                           #  - max return value is INT+1
                                  #  - faster

dmetaphone(STR)->STR2             #Returns main consonant sounds of STR
                                  #Similar sounding consonants use the same characters, i.e. phonetic-style code
                                  #STR must be a single word
                                  #Works with mostly Western languages
                                  #Goal: fuzzy search on homophones, i.e. similar words that only differ in spelling
                                  #Uses Double Metaphone (v2) algorithm
dmetaphone_alt(STR)->STR2         #Uses Double Metaphone alternative algorithm
metaphone(STR, INT)               #Same but using Metaphone v1 (older algorithm)
                                  #Truncates at INT characters (max 255)
                                  #Only for English language
soundex(STR)->STR2                #Same but using Soundex, another algorithm, not as good
                                  #Return value is always 4 characters long
difference(STR, STR2)->INT        #Number of different characters after applying soundex() on each STR

                                  ┌──────────────┐
                                  │   ENCODING   │
                                  └──────────────┘

'ENCODING'                        #Used by STR
                                  #Among:
                                  #  - SQL_ASCII
                                  #  - UTF8|Unicode
                                  #  - LATIN1-10 or ISO_8859_1-16
                                  #  - WIN1250-58, WIN874, WIN866
                                  #  - ISO_8859_5, WIN1251, KOI8[R], KOI8U: Cyrillic
                                  #  - ISO_8859_2, WIN1250: Czech, Polish
                                  #  - BIG5, GBK, GB18030, SJIS, SHIFT_JIS_2004, UHC, JOHAB,
                                  #    EUC_JP, EUC_CN, EUC_KR, EUC_TW, EUC_JIS_2004: East-asian
                                  #  - MULE_INTERNAL: Emacs
ENCODING                          #ENCODING id INT, from 0 to 41
pg_encoding_to_char
 (ENCODING)->'ENCODING'           #
pg_char_to_encoding
 ('ENCODING')->ENCODING           #

initdb|createdb
 --encoding|-E "ENCODING"
create database "DATABASE"
 encoding [=] "ENCODING"          #Server ENCODING
ICONF.server_encoding             #Def: locale (UTF8 in Linux) or SQL_ASCII

ENVVAR PGCLIENTENCODING
SCONF|LIBPQ.client_encoding
set names "ENCODING"              #Client ENCODING
\encoding "ENCODING"              #Def: default OS encoding
pg_client_encoding()->"ENCODING"  #If different from server, applies CONVERSION

set names "ENCODING"              #Same as: set client_encoding to "ENCODING"

pg_database.encoding              #ENCODING. create database ... encoding

                                  ┌────────────────┐
                                  │   CONVERSION   │
                                  └────────────────┘

create conversion "CONVERSION"    #Creates a CONVERSION, i.e. conversion between 2 ENCODINGs
 for 'ENCODING' to 'ENCODING2'    #Using FUNC(ENCODING, ENCODING2, 'INPUT', 'OUTPUT', INPUT_INT, BOOL)->OUTPUT_INT
 from "FUNC"                      #  - BOOL is false if error should throw
                                  #ENCODING[2] cannot be SQL_ASCII
create default conversion ...     #Preferred CONVERSION for this pair of ENCODINGs

pg_conversion                     #TABLE of all CONVERSIONs
pg_conversion.oid                 #OID
pg_conversion.conname             #"CONVERSION" name, e.g. "windows_866_to_windows_1251"
pg_conversion.conforencoding      #Source ENCODING
pg_conversion.contoencoding       #Destination ENCODING
pg_conversion.conproc             #REGPROC performing conversion
pg_conversion.condefault          #BOOL. True if default

BUILT-IN CONVERSIONS ==>          #  - UTF8 <-> all except SQL_ASCII and MULE
                                  #  - ISO_8859_5 <-> KOI8R <-> WIN1251 <-> WIN866: Cyrillic legacy encodings
                                  #  - ISO_8859_2 <-> WIN1250: Czech, Polish
                                  #  - EUC_JP <-> SJIS, EUC_TW <-> BIG5, EUC_JIS_2004 <-> SHIFT_JIS_2004: east-asian
                                  #  - MULE <-> many

convert
 (BYTEA, 'ENCODING', 'ENCODING2')
 ->BYTEA                          #Apply a CONVERSION
convert_to
 (STR, 'ENCODING')->BYTEA         #Like convert(STR, pg_client_encoding(), 'ENCODING')
convert_from
 (BYTEA, 'ENCODING')->STR         #Like convert(STR, 'ENCODING', pg_client_encoding())

convert_to|from(STR, STR2)        #Same, but assumes the dest|original encoding to be the current system's encoding

to_ascii
 (STR[, ENCODING|'ENCODING'])->STR#Remove accents to convert STR (from ENCODING) to ASCII

                                  ┌───────────────────────────┐
                                  │   UNICODE NORMALIZATION   │
                                  └───────────────────────────┘

UNICODE_FORM                      #nfc (def), nfd, nfkc, nfkd (like JavaScript STR.normalize())
                                  #Server ENCODING must be UTF8
normalize
 (STR[, UNICODE_FORM])->STR       #Unicode normalization
STR is [not]
 UNICODE_FORM normalized          #BOOL

                                  ┌────────────┐
                                  │   LOCALE   │
                                  └────────────┘

ENVVAR LANG
initdb|createdb --locale=LANG
initdb --no-locale
create database "DATABASE"
 locale [=] LANG                  #Sets all LC_*, or --icu-locale

ENVVAR LC_ALL                     #Sets all LC_*

initdb|createdb --lc-*=LANG       #Sets single LC_*
ENVVAR LC_*                       #Def is '', i.e.:
*CONF.lc_*                        #  - local one (e.g. 'en_US.UTF-8')
                                  #  - or 'C' if none
                                  #Server-specific, not client

ENVVAR LC_COLLATE                 #Used by:
ICONF.lc_collate                  #  - < > >= <=
create database "DATABASE"        #  - order by
 lc_collate [=] LANG              #  - how INDEXs are persisted
                                  #     - i.e. cannot be changed without a `reindex`
                                  #  - INDEX on like|~ operators
                                  #Only for collatable TYPEs (such as STR)
                                  #Cannot use an OP|FUNC with argument TYPEs that have a different LC_COLLATE
                                  #Must be compatible with current ENCODING

ENVVAR LC_CTYPE                   #Used by:
ICONF.lc_ctype                    #  - letter|digit character classes in PARSER, REGCONF
create database "DATABASE"        #  - [[:...:]] in REGEXPs
 lc_ctype [=] LANG                #  - case: upper|lower|initcap(), REGEXP|GLOB
                                  #Must be compatible with current ENCODING

ENVVAR LC_MESSAGES
ZSCONF.lc_messages                #Used in output|error messages translation

ENVVAR LC_MONETARY
SCONF.lc_monetary                 #Used by to_char()
ENVVAR LC_NUMERIC
SCONF.lc_numeric                  #Used by to_char()
ENVVAR LC_TIME
SCONF.lc_time                     #Used by to_char(), SCONF.DateStyle

C LOCALE ==>                      #Not language-specific, but faster
                                  #Same as POSIX locale

ENVVAR PGLOCALEDIR                #LOCALDIR, i.e. DIR with locale-specific information
                                  #On my system: /usr/share/locale
pg_config --localedir             #Prints LOCALEDIR

pg_database.datctype              #STR. create database ... lc_ctype
pg_database.datcollate            #STR. create database ... lc_collate

                                  ┌───────────────┐
                                  │   COLLATION   │
                                  └───────────────┘

create collation "COLLATION"(OPTS)#Create COLLATION, i.e. combination of ENCODING, lc_collate and lc_ctype

create collation "COLLATION"
 from "COLLATION2"                #Creates an alias

OPTS.locale                       #Value of both lc_collate|ctype, or --icu-locale
OPTS.lc_collate                   #'LANG' value of lc_collate
OPTS.lc_ctype                     #'LANG' value of lc_ctype

initdb|createdb --icu-locale=LANG
create database "DATABASE"
 icu_locale [=] LANG              #Value of --icu-locale

OPTS.deterministic                #BOOL (def: true)
                                  #If false:
                                  #  - allow comparisons to treat equivalent STRs as equal such as:
                                  #     - Unicode normalization
                                  #     - accents
                                  #     - case insensitivity
                                  #  - only with icu provider
                                  #  - slower
                                  #  - cannot use REGEXP|GLOBs

initdb|createdb                   #How to get locale data. Either:
 --locale-provider=PROVIDER       #  - libc (def):
create database ...               #     - ones used by current OS
 locale_provider [=] PROVIDER     #     - uses ENVVAR LC_*
OPTS.provider                     #  - icu:
                                  #     - external ICU, usually better
                                  #     - must have been specified at Postgres build time
                                  #     - does not use ENVVAR LC_*
                                  #     - only a single LANG, specified by --icu-locale

create database "DATABASE"        #Version of OPTS.provider
 collation_version [=] 'X.Y[.Z]'  #Can be empty STR
OPTS.version                      #Meant to detect changes of the actual provider version
                                  #  - compared to the one specified in COLLATION
                                  #  - this can happen if:
                                  #     - libc: OS upgrade of libc
                                  #     - icu: Postgres was re-built with a new ICU version
                                  #  - prints a warning
                                  #  - should rebuild ENTITYs using the COLLATION, e.g. using `reindex`
                                  #     - can be seen by listing pg_depend.refclassid = 'pg_collation'::regclass
                                  #     - then using pg_depend.refobjid to find pg_collation with a wrong collversion
alter collation ...
 refresh version
alter database ...
 refresh collation version        #Should be done after rebuilding ENTITYs due to OPTS.version change
pg_collation_actual_version       #Actual version of COLLATION
 (REGCOLLATION)->'X.Y[.Z]'        #Differ from pg_collation.collversion if there was a change
pg_database_collation_
 actual_version(pg_database.oid)  #Same with pg_database.datcollversion, for a DATABASE

pg_collation                      #TABLE with All COLLATIONs
pg_collation.oid                  #OID
pg_collation.collname             #"COLLATION"
pg_collation.collencoding         #ENCODING. -1 for current server encoding
pg_collation.collcollate          #OPTS.lc_collate
pg_collation.collctype            #OPTS.lc_ctype
pg_collation.collisdeterministic  #OPTS.deterministic
pg_collation.collprovider         #OPTS.provider as 'd' (--locale-provider), 'c' (libc), 'i' (icu)
pg_collation.collversion          #OPTS.version
pg_collation.colliculocale        #--icu-locale

regcollation                      #TYPE to cast pg_collation.oid as "COLLATION" name

pg_database.daticulocale          #STR. create database ... icu_locale
pg_database.datlocprovider        #'c|i'. create database ... locale_provider
pg_database.datcollversion        #STR. create database ... collation_version

BUILT-IN COLLATIONS ==>           #  - default: any locale-provider, any ENCODING, any locale
                                  #  - C|POSIX: libc, any ENCODING, 'C|POSIX' locale
                                  #  - ucs_basic: libc, UTF8, 'C' locale
                                  #  - C.utf8: libc, UTF8, 'C.utf8' locale
                                  #  - LANG[.utf8] (e.g. en_US.utf8): libc, UTF8, 'LANG[.utf8]' locale
                                  #  - LANG-x-icu (e.g. en-US-x-icu): icu, any ENCODING, current OS locale, --icu-locale=LANG
                                  #  - und-x-icu: icu, any ENCODING, current OS locale, --icu-locale=und (no LANG)
                                  #All: OPTS.deterministic true
DEFAULT COLLATION ==>             #'default'

pg_import_system_collations       #Populates pg_collation based on current OS
 (REGNAMESPACE)->INT              #Automatically done by initdb
                                  #REGNAMESPACE is usually pg_catalog
                                  #Returns number of new COLLATIONs

STR collate "COLLATION"           #Sets COLLATION for a single STR
collation for (STR)               #'COLLATION' of STR

VAL ~<~ ~<=~ ~>=~ ~>~ VAL2        #Like VAL < <= >= > VAL, but with COLLATION always "C"

create type "RANGE_TYPE"
 as range(collation = COLLATION)  #For a RANGE
create domain ...
 collate "COLLATION"              #For a DOMAIN

YOPTS.collatable                  #BOOL (def: false). Whether TYPE is COLLATION-sensitive.
                                  #Built-in types: true for STR ("default"), name ("C"), pg_node_tree ("default")
pg_type.typcollation              #REGCOLLATION of the TYPE. 0 if YOPTS.collatable false. Otherwise set.

create [foreign] table "TABLE"
 ("COL" TYPE collate COLLATION)
create index "INDEX" on "TABLE"
 ("COL"|(REXPR) collate COLLATION)
create type "ROW"
 as ("COL" TYPE collate COLLATION)
alter [foreign] table "TABLE"
 add [column] "COL" TYPE
 collate COLLATION
alter type "ROW"
 add attribute "COL" TYPE
 collate COLLATION
alter [foreign] table "TABLE"
 alter [column] "COL"
 [set data] type TYPE
 collate COLLATION
alter type "ROW"
 alter attribute "COL"
 [set data] type TYPE
 collate COLLATION                #For a COL
create table ... partition by ...
 ("COL"|(COL_REXPR)
 collate COLLATION ...)           #For an underlying INDEX COL

pg_attribute.attcollation         #REGCOLLATION of the COL. 0 if none
pg_index.indcollation             #REGCOLLATION_ARR of indexed COLs.

citext                            #TYPE like text, but case-insensitive
                                  #REGEXP can use `c` flag to force case-sensitive
                                  #Trusted EXTENSION 'citext'

                                  ┌───────────┐
                                  │   INDEX   │
                                  └───────────┘

create index "INDEX"              #Create an INDEX
 on "TABLE"("COL"|(REXPR))        #Data structure storing the value "COL"|(REXPR) for each ROW in an optimized data structure
                                  #Used by the planner to automatically speedup read queries
                                  #  - at the expense of write speed, since each write must update INDEX
                                  #Only used by queries:
                                  #  - that use exactly "COL"|(REXPR)
                                  #  - with the clauses supported by the ACCESS_METHOD (e.g. `where`, etc.)
                                  #  - with the OPs supported by the ACCESS_METHOD (e.g. =, etc.)
                                  #     - including equivalent ones, e.g. < > -> between, = -> in, ~~ -> like
                                  #Its contents cannot be directly read|write
                                  #REXPR must be purely functional
                                  #Auto-dependency child of its COL

create index ... with (IOPTS)
create table ...
 exclude|unique|primary key ...
 with (IOPTS)                     #"INDEX storage options". Different from TOPTS.

pg_index                          #TABLE with all INDEXs
pg_index.indexrelid               #REGCLASS of INDEX
pg_index.indrelid                 #REGCLASS of TABLE
pg_index.indnatts                 #INT2. Number of COLs
pg_index.indnkeyatts              #INT2. Number of COLs, except non-key COLs
pg_index.indkey                   #ARR of COLs (pg_attribute.attnum) being indexed. 0 if REXPR
pg_index.indexprs                 #PG_NODE_TREE representing REXPR. null if none
pg_index.indcheckxmin             #BOOL. Whether the INDEX cannot be queried due to awaiting concurrent transactions
pg_index.indisready               #BOOL. Whether the INDEX can be written to
pg_index.indislive                #BOOL. Whether the INDEX is being deleted

pg_indexes                        #Higher-level VIEW over pg_index
pg_indexes.tablename              #"TABLE" name
pg_indexes.indexname              #"INDEX" name
pg_indexes.indexdef               #STR from pg_get_indexdef()

pg_class.relhasindex              #BOOL. Whether RELATION has INDEXs
pg_tables.hasindexes              #BOOL. Whether TABLE has INDEXs
pg_matviews.hasindexes            #BOOL. Whether MVIEW has INDEXs

pg_get_indexdef
 (REGCLASS[, COL_INT4[, BOOL]])   #Returns 'CREATE INDEX ...' statement
 ->STR                            #BOOL (def: false) is prettify

                                  ┌─────────────────┐
                                  │   INDEX SCANS   │
                                  └─────────────────┘

SCONF.enable_seqscan              #"Sequential scan". Query that reads ROWs sequentially, without an INDEX
                                  #Fast if:
                                  #  - small TABLE
                                  #  - query selects most ROWs
SCONF.min_parallel_table_scan_size#STR (def: '8MB'). Minimum amount of TABLE ROWs read to consider using a "parallel sequential scan".
                                  #I.e. sequential scan run in parallel: each worker handles different heap pages
TOPTS.parallel_workers            #NUM of workers when doing parallel sequential scan
                                  #Def: guessed based on TABLE size

SCONF.enable_indexscan            #"[Plain] index scan". Query using an INDEX
                                  #INDEX returns TIDs, which are then used to fetch TABLE ROWs
                                  #Efficient on query that select only few ROWs out of many
SCONF.min_parallel_index_scan_size#STR (def: '512kB'). Minimum amount of INDEX ROWs read to consider using:
                                  #  - a "parallel index scan"
                                  #  - a parallel `vacuum`
                                  #ACCESS_METHOD-specific (only some support it)

SCONF.enable_bitmapscan           #"Bitmap scan". Alternative to index scan.
                                  #Instead of returning TIDs, the INDEX creates a bitmap ("bitmap index scan")
                                  #  - with 0|1 for each heap page (i.e. sets of ROWs)
                                  #  - initially only 0s, each ROW match sets 1 to its heap page ("bitmap populating")
                                  #The bitmap is then used to read TABLE ROWs ("bitmap heap scan")
                                  #  - using a full sequential scan
                                  #  - unlike index scan which uses random access with TIDs
                                  #  - since a heap page contains 1-n ROWs, must re-apply filters to find the right ROWs ("Recheck Cond")
                                  #Faster than index scan if many ROWs are fetched
                                  #  - but not too many, where a sequential scan is then often faster
PARALLEL BITMAP SCAN ==>          #Bitmap scan where the heap scan (not the index scan) is run as a parallel sequential scan

                                  ┌───────────────────────┐
                                  │   INDEX COMBINATION   │
                                  └───────────────────────┘

BITMAP SCAN COMBINATION ==>       #When using '... and|or ...'
                                  #Perform separate bitmap scans, then combine them with bitwise logic
                                  #Sometimes slower than a sequential scan, if too many ...
                                  #Also, individual ordered scans from each ... is lost, i.e. might need to re-sort

create index ...                  #"Multicolumn INDEX"
 on "TABLE"("COL"|(REXPR),...)    #Stores multiple "COL"|(REXPR)
                                  #Can be faster than bitmap scan combination, providing all "COL"|(REXPR) are queried together
                                  #Behavior is ACCESS_METHOD-specific

ICONF.max_index_keys              #32. Max amount of COLs

                                  ┌─────────────────────┐
                                  │   INDEX-ONLY SCAN   │
                                  └─────────────────────┘

SCONF.enable_indexonlyscan        #"Index-only scan".
                                  #Query that uses only the INDEX without visiting the TABLE, i.e. faster
                                  #Only if query uses only the "COL"|(REXPR) can are indexed
                                  #Not efficient with REXPRs
                                  #Only some ACCESS_METHODs can do it
create index ...
 include ("COL",...)              #"Covering INDEX"
create table ...                  #Stores "COL" in INDEX, but do not use it in query planning, nor uniqueness ("non-key COLs")
 exclude|unique|primary key ...   #I.e. only used to increase probability of index-only scans
 include ("COL",...)              #Some ACCESS_METHODs do not support it

VISIBILITY MAP ==>                #Checked before doing index-only scans:
                                  #  - must fetch ROW from TABLE instead of index-only ("heap fetch"):
                                  #     - if heap page lacks all-visible bit
                                  #        - i.e. if was written since last vacuum
                                  #     - reason: there "might" be uncommitted writes
                                  #  - i.e. index-only scans less frequent on write-heavy TABLEs

HOT ==>                           #"Heap-Only Tuples"
                                  #Optimization for MVCC where during an `update`:
                                  #  - INDEX does not need to be updated
                                  #  - dead ROWs created by `update` can be removed by any statement (including `select`) instead of only vacuum
                                  #Only happens if:
                                  #  - `update` does not modify COLs that are indexed
                                  #  - there is enough space on the current page

                                  ┌───────────────────┐
                                  │   PARTIAL INDEX   │
                                  └───────────────────┘

create index ... where BOOL_REXPR #"Partial INDEX". Only indexes ROWs with BOOL_REXPR true
                                  #INDEX only used if BOOL_REXPR matches the one used by the query
                                  #BOOL_REXPR can refer to any "COL" from TABLE, not just the indexed ones
                                  #Goal: faster writes when:
                                  #  - only few ROWs are usually read
                                  #  - other ROWs are write-heavy
                                  #Other possible goal: only apply unique constraint on specific ROWs

pg_index.indpred                  #PG_NODE_TREE representing `where BOOL_REXPR`. null if none

                                  ┌──────────────────────────┐
                                  │   PARALLEL INDEX BUILD   │
                                  └──────────────────────────┘

PARALLEL INDEX BUILD ==>          #Some ACCESS_METHODs can use multiple worker processes with `create index`

SCONF.                            #Max NUM (def: 2) of parallel worker processes used for parallel
 max_parallel_maintenance_workers #`create index` or `vacuum`
                                  #Must be < SCONF.max_parallel_workers
                                  #Higher is faster, but consumes more CPU
                                  #NUM of worker processes is also set by TOPTS.parallel_workers

SCONF.maintenance_work_mem        #STR (def: '64MB'). Max memory used by `create INDEX` and `create foreign key`
                                  #Good idea to increase it.
                                  #If multiple parallel workers, it is limit for all, not for each

                                  ┌─────────────┐
                                  │   REINDEX   │
                                  └─────────────┘

reindex index "INDEX"             #Re-create INDEX, to make it take less space with current data
                                  #Needed to optimize space after changing IOPTS, or after a very big INDEX size decrease
                                  #Also needed if INDEX is corrupted due to software|hardware issue
reindex table "TABLE"             #Same for the TABLE's INDEXs
reindex schema "SCHEMA"           #Same for the SCHEMA's INDEXs
reindex system "DATABASE"         #Same for the pg_catalog.* INDEXs
reindex database "DATABASE"       #Same for the DATABASE's INDEXs

reindex verbose ...               #Prints a progress bar

                                  ┌────────────────────┐
                                  │   INDEX PROGRESS   │
                                  └────────────────────┘

pg_stat_progress_create_index     #TABLE with ongoing `create index` and `reindex` statements
pg_stat_progress_create_index
 .command                         #'CREATE INDEX|REINDEX [CONCURRENTLY] ...'
pg_stat_progress_create_index
 .relid                           #REGCLASS of TABLE
pg_stat_progress_create_index.
 index_relid                      #REGCLASS of INDEX. 0 if none
pg_stat_progress_create_index
 .datid                           #pg_database.oid of DATABASE
pg_stat_progress_create_index
 .datname                         #NAME of "DATABASE"
pg_stat_progress_create_index.pid #BPID
pg_stat_progress_create_index     #STR among:
 .phase                           #  - 'initializing'
                                  #  - 'waiting for writers before build': await concurrent write transactions
                                  #  - 'building index: SUBPHASE': ACCESS_METHOD build INDEX
                                  #  - 'waiting for writers before validation': await concurrent write transactions
                                  #  - 'index validation: ...': only if `create index`
                                  #     - 'index validation: scanning index': find ROWs to validate
                                  #     - 'index validation: sorting tuples': sort ROWs to validate
                                  #     - 'index validation: scanning table': validate ROWs
                                  #  - 'waiting for old snapshots': await concurrent read transactions
                                  #  - 'waiting for readers ...': only if `reindex`
                                  #     - 'waiting for readers before marking dead': await read locks
                                  #     - 'waiting for readers before dropping': await read locks before `drop`
                                  #Unless concurrently, only 'initializing' and 'building index'
pg_stat_progress_create_index
 .current_locker_pid              #INT8. PID of process with a lock being awaited, during 'waiting for ...'
pg_stat_progress_create_index
 .lockers_done|total              #INT8. NUM of processes locking, during 'waiting for ...'
pg_stat_progress_create_index
 .blocks_done|total               #NUM of page heaps processed, during 'building index' and 'index validation: scanning index|table'
pg_stat_progress_create_index
 .tuples_done|total               #NUM of ROWs processed, during 'building index'
pg_stat_progress_create_index
 .partitions_done|total           #NUM of partitions, if partitioned TABLE. 0 during `reindex`

                                  ┌───────────────────┐
                                  │   INDEX CLUSTER   │
                                  └───────────────────┘

cluster "TABLE"                   #Optimizes the physical layout of "TABLE" to match its INDEXs ACCESS_METHODs
                                  #Makes ROWs:
                                  #  - that are conceptually close to each other (e.g. similar value)
                                  #  - be on the same physical page
                                  #Only on current ROWs: future ROWs are not clustered.
                                  #Should run `analyze` afterwards.
cluster ...                       #Without a "TABLE": all TABLEs previously cluster'd by current ROLE

cluster ... using "INDEX"         #Set the INDEX for next calls of `cluster`
                                  #Must be specified the first time for a given "TABLE"
alter table "TABLE"
 cluster on "INDEX"
alter table "TABLE"
 set without cluster              #Changes the INDEX

cluster verbose ...               #Prints progress
pg_stat_progress_cluster          #TABLE with ongoing `cluster` and `vacuum full` statements
pg_stat_progress_cluster.command  #'CLUSTER ...'
pg_stat_progress_cluster.relid    #REGCLASS of TABLE
pg_stat_progress_cluster.
 cluster_index_relid              #REGCLASS of INDEX. 0 if none
pg_stat_progress_cluster.datid    #pg_database.oid of DATABASE
pg_stat_progress_cluster.datname  #NAME of "DATABASE"
pg_stat_progress_cluster.pid      #BPID
pg_stat_progress_cluster.phase    #STR among:
                                  #  - 'initializing'
                                  #  - 'seq scanning heap': sequential scan on TABLE
                                  #  - 'index scanning heap': index scan on TABLE
                                  #  - 'sorting tuples': sort ROWs
                                  #  - 'writing new heap': write sorted ROWs
                                  #  - 'swapping relation files': swap newly written files
                                  #  - 'rebuilding index'
                                  #  - 'performing final cleanup'
pg_stat_progress_cluster
 .heap_tuples_scanned             #NUM of ROWs read during 'seq scanning heap'
pg_stat_progress_cluster
 .heap_tuples_written             #NUM of ROWs written during 'seq scanning heap'
pg_stat_progress_cluster
 .heap_blks_scanned               #NUM of blocks processed during '* heap'
pg_stat_progress_cluster
 .heap_blks_total                 #NUM of blocks in total during '* heap'
pg_stat_progress_cluster
 .index_rebuild_count             #NUM of INDEXs rebuilt during 'rebuilding index'

pg_index.indisclustered           #BOOL. Whether `cluster` was last called on INDEX

pg_repack EXTENSION ???

hypopg EXTENSION ???

                                  ┌──────────────────────┐
                                  │   CONCURRENT INDEX   │
                                  └──────────────────────┘

create index concurrently ...     #Use a weaker lock of TABLE that allows concurrent read|writes
reindex index concurrently ...    #Can fail: must then either:
                                  #  - drop INDEX and recreate it
                                  #  - reindex it
                                  #Slower.
                                  #Cannot be:
                                  #  - in a transaction
                                  #  - on partitioned TABLEs
drop index concurrently ...       #Same for `drop`
                                  #Cannot:
                                  #  - use `cascade`
                                  #  - drop multiple INDEXs

                                  ┌───────────────────┐
                                  │   ACCESS METHOD   │
                                  └───────────────────┘

create                            #Create an "index access method"
 access method "ACCESS_METHOD"    #How a TABLE|INDEX is physically read|written, i.e. its data structure and operators
                                  #Must be superuser
                                  #Parent dependency of any INDEX using it

OPERATIONS ==>                    #Many operations use ACCESS_METHODs
                                  #  - if an INDEX on the COLs|COL_REXPR exist, use its OPCLASS
                                  #     - faster because can re-use INDEX optimized physical structure
                                  #  - otherwise, the default ACCESS_METHOD for that operation + TYPE is used
                                  #Most of those operations are only available with specific ACCESS_METHODs
                                  #Operations:
                                  #  - where|having|on|check VAL OP VAL2
                                  #  - order by "COL"|COL_REXPR (ordered scan, including backward)
                                  #  - order by VAL OP VAL2 (ordering OP)
                                  #  - is [not] null (in BOOL_REXPR)
                                  #  - VAL OP any|all (ARR)
                                  #  - distinct|grouping: distinct, union|intersect|except distinct, AFUNC(distinct), group by, over (partition by)
                                  #  - exclude CONSTRAINT
                                  #  - unique: unique CONSTRAINT, create unique ...
                                  #  - over (range NUM preceding|following)
                                  #  - partition by range|list
                                  #  - partition by hash

SCAN FEATURES ==>                 #Can also support:
                                  #  - multi-COL
                                  #  - plain index scan
                                  #  - bitmap index scan
                                  #  - index-only scan
                                  #  - parallel index scan
                                  #  - parallel index build
                                  #  - predicate lock

INDEX STORAGE ==>                 #ACCESS_METHODs can support:
                                  #  - non-key COLs
                                  #  - storage TYPE
                                  #  - cluster
                                  #  - SCONF.maintenance_work_mem
                                  #with (TOPTS|IOPTS) of TABLE|INDEX are ACCESS_METHOD-specific

create access method ...          #Whether this is meant for:
 type table|index                 #  - INDEXs ("index method"):
                                  #     - most ACCESS_METHODs
                                  #  - TABLEs ("table method"):
                                  #     - by default, only "heap"
                                  #     - also implements WAL

create access method ...          #Main FUNC of ACCESS_METHOD
 handler "FUNC"                   #Returns:
                                  #  - capabilities
                                  #  - expectations about OPs and helper FUNCs
                                  #  - methods: create|delete TABLE|INDEX, CRUD on ROWs, validation of OP(TYPE, TYPE2), vacuum, etc.

SCONF.default_table_access_method #Def ACCESS_METHOD for TABLEs
                                  #Def: 'heap'
create table ...
 using "ACCESS_METHOD"
alter table "TABLE"
 set access method "ACCESS_METHOD"#Set TABLE's ACCESS_METHOD

create index ... on "TABLE"
 using ACCESS_METHOD (...)
create table ...
 exclude using ACCESS_METHOD ...  #Set INDEX's ACCESS_METHOD
create table ...
 unique|primary key               #Always use btree ACCESS_METHOD

pg_am                             #TABLE with ACCESS_METHODs
pg_am.oid                         #OID
pg_am.amname                      #"ACCESS_METHOD" name
pg_am.amtype                      #'t' (TABLE) or 'i' (INDEX)
pg_am.amhandler                   #REGPROC of handler

pg_class.relam                    #pg_am.oid of the RELATION's ACCESS_METHOD
                                  #0 if SEQUENCE|VIEW|ROW_TYPE

pg_indexam_has_property
 (ACCESS_METHOD_OID, 'can_order')
 ->BOOL                           #Supports order by
pg_index_column_has_property
 (REGCLASS, COL_INT, 'orderable')
 ->BOOL                           #Supports ordered scan, i.e. order by "COL"|COL_REXPR
pg_index_has_property
 (REGCLASS, 'backward_scan')->BOOL#Supports backward scan
pg_index_column_has_property
 (REGCLASS, COL_INT,
 'distance_orderable')->BOOL      #Supports ordering OP, i.e. order by VAL OP VAL2 (e.g. <->)
pg_index_column_has_property
 (REGCLASS, COL_INT,
 'search_nulls')->BOOL            #Supports is [not] null (in BOOL_REXPR)
pg_index_column_has_property
 (REGCLASS, COL_INT,
 'search_array')->BOOL            #Supports VAL OP any|all (ARR)
pg_indexam_has_property
 (ACCESS_METHOD_OID,
 'can_exclude')->BOOL             #Supports exclude CONSTRAINT
pg_indexam_has_property
 (ACCESS_METHOD_OID, 'can_unique')
 ->BOOL                           #Supports unique
pg_indexam_has_property
 (ACCESS_METHOD_OID,
 'can_multi_col')->BOOL           #Supports multi-COL
pg_index_has_property
 (REGCLASS, 'index_scan')->BOOL   #Supports plain index scan
pg_index_has_property
 (REGCLASS, 'bitmap_scan')->BOOL  #Supports bitmap index scan
pg_index_column_has_property
 (REGCLASS, COL_INT, 'returnable')
 ->BOOL                           #Supports index-only scan
pg_indexam_has_property
 (ACCESS_METHOD_OID,
 'can_include')->BOOL             #Supports non-key COLs
pg_index_has_property
 (REGCLASS, 'clusterable')->BOOL  #Supports cluster

pg_index_column_has_property
 (REGCLASS, COL_INT, STR)->BOOL
pg_index_has_property
 (REGCLASS, STR)->BOOL            #ACCESS_METHODs can add custom property STR, but none currently does

                                  ┌─────────────────────┐
                                  │   OPERATOR FAMILY   │
                                  └─────────────────────┘

create operator family "OPFAMILY" #"Operator family", i.e. group of OPCLASSs (or "loose" ones) that can be
 using "ACCESS_METHOD"            #simplified when used together in a single expression
                                  #E.g. >(NUM, NUM2) and <(NUM, NUM2) in `where NUM > NUM2 and NUM < NUM3`
                                  #Usually:
                                  #  - named "TYPE_ops"
                                  #  - an OPCLASS defines all OP(TYPE, TYPE) for a given TYPE + ACCESS_METHOD
                                  #  - if there are easily castable TYPEs:
                                  #     - such as: INT2|4|8, FLOAT4|8, BPCHAR|VARCHAR|TEXT, DATE|TIMESTAMP[TZ], CIDR|INET
                                  #     - then OPFAMILY has one OPCLASS for each
                                  #     - also it defines loose OPs for each OP(TYPE, TYPE2) combination ("cross-type OP")
                                  #  - otherwise, OPFAMILY contains a single OPCLASS, often with same name
                                  #Must be a superuser

alter operator family "OPFAMILY"  #Like `create operator class using "ACCESS_METHOD" add operator|function ...` but "loose"
 using "ACCESS_METHOD"            #OPs and support FUNCs can either be in OPCLASSs, or not (loose)
 add operator|function ...        #  - can be deleted without deleting the OPCLASS
                                  #     - i.e. not critical for OPFAMILY to work properly
                                  #  - can use different TYPEs for OP left|right argument
                                  #Otherwise, no differences
alter operator family ...
 drop operator UINT
 "OP"(TYPE, TYPE2)
alter operator family ...
 drop function UINT(TYPE,...)     #

pg_opfamily                       #TABLE with all OPFAMILYs
pg_opfamily.oid                   #OID
pg_opfamily.opfmethod             #pg_am.oid of ACCESS_METHOD
pg_opfamily.opfname               #"OPFAMILY" name

                                  ┌────────────────────┐
                                  │   OPERATOR CLASS   │
                                  └────────────────────┘

create operator class "OPCLASS"   #"Operator class", i.e. OP and helper FUNCs that an INDEX ACCESS_METHOD can use
 for type TYPE                    #ACCESS_METHOD-specific, including its "OPCLASS" name
 using "ACCESS_METHOD"            #Child auto-dependency of its OPFAMILY
 as ...                           #Parent dependency of INDEX using it
                                  #Usually named "TYPE_ops"
                                  #Must be superuser

create operator class "OPCLASS"   #Make it default for the given TYPE
 default for type ...             #If false, must be explicitly specified when creating INDEX|TABLE

create operator class ...
 family "OPFAMILY" as ...         #Def: creates one with same name as "OPCLASS"

create operator class ...         #Add an OP(TYPE, TYPE2) for the INDEX ACCESS_METHOD to use
 as operator UINT OP[(TYPE,TYPE2)]#INDEX ACCESS_METHODs define each OP they expect:
                                  #  - in an abstract, TYPE-agnostic way
                                  #  - assigning a strategy number UINT for each
                                  #  - OP symbol is unspecified, although usually the same symbol is used by all OPCLASSs
                                  #OPCLASSs implement those OPs for specific TYPEs
                                  #Some ACCESS_METHOD's OPs are optional:
                                  #  - including having no required OPs
                                  #TYPE2 can be none for single-argument OPs
                                  #Def TYPE[2]: same as `for type TYPE`

create operator class ...         #Mark as "search operator" (def)
 as operator ...                  #  - OP returns BOOL
 for search                       #  - used in where|having|on|check (VAL OP VAL2)

create operator class ...         #Mark as "ordering operator":
 as operator ...                  #  - OP returns NUM: distance between arguments
 for order by OPFAMILY2           #  - allow using `order by VAL OP VAL2`
                                  #     - if either VAL|VAL2 indexed, as opposed to whole `VAL OP VAL2`
                                  #     - even for TYPEs that do not have < OP
                                  #OPFAMILY2 is used to sort the return values
                                  #  - must use a b-tree ACCESS_METHOD

create operator class ...         #Add a "support function"
 as function UINT [(TYPE, ...)]   #Similar to OPs, except:
 "FUNC"(TYPE3,...)                #  - not directly used in clauses (like `where`, etc.)
                                  #  - but still used by ACCESS_METHOD internally
                                  #E.g. hash computation with `hash` ACCESS_METHOD
                                  #Def (TYPE,...): same as (TYPE3,...)

create operator class ...         #TYPE used to store the values in the INDEX.
 storage TYPE                     #By default, same as the ones used in query.
                                  #Can differ, e.g. when value can be reduced for the purpose of the INDEX logic
                                  #  - e.g. a polygon reduced to an approximative rectangle

LOSSY OPERATOR ==>                #OP that can return some false positive, with a fast approximate logic
                                  #OP is then called again on the returned values, but with the slower exact logic ("index recheck")
LOSSY ACCESS METHODS ==>          #Some ACCESS_METHODs always need two steps, i.e. lossy as well

pg_opclass                        #TABLE with all OPCLASSs
pg_opclass.oid                    #OID
pg_opclass.opcname                #"OPCLASS" name
pg_opclass.opcmethod              #pg_am.oid of ACCESS_METHOD
pg_opclass.opcfamily              #pg_opfamily.oid of OPFAMILY
pg_opclass.opcintype              #REGTYPE of FUNC arguments
pg_opclass.opcdefault             #BOOL. True if default OPCLASS for the given TYPE
pg_opclass.opckeytype             #REGTYPE of values when stored in INDEX. 0 if same as FUNC arguments TYPE

pg_amop                           #TABLE with all OPFAMILYs OPs
pg_amop.oid                       #OID
pg_amop.amopfamily                #pg_opfamily.oid of OPFAMILY
pg_amop.amopstrategy              #UINT. Strategy number
pg_amop.amopopr                   #REGOPERATOR of OP
pg_amop.amopmethod                #pg_am.oid of ACCESS_METHOD
pg_amop.amoppurpose               #Either 's' (search) or 'o' (ordering)
pg_amop.amopsortfamily            #pg_opfamily.oid of OPFAMILY used for sorting, if ordering
                                  #0 if search

pg_amproc                         #TABLE with all OPFAMILYs support FUNCs
pg_amproc.oid                     #OID
pg_amproc.amprocfamily            #pg_opfamily.oid of OPFAMILY
pg_amproc.amprocnum               #UINT. Function number
pg_amproc.amproc                  #REGPROC of OP
pg_amproc.amprocleft|righttype    #REGTYPE of OP left|right argument

create index "INDEX" on "TABLE"   #OPCLASS used by an INDEX "COL"|REGEXP
 (... OPCLASS[(OOPTS)],...) ...   #OOPTS are OPCLASS-specific

pg_index.indclass                 #ARR of OPCLASSs (pg_opclass.oid) of INDEX
pg_index.indoption                #INT2_ARR of INDEX COLs' OOPTs

create table ... exclude
 ("COL"|(REXPR) OPCLASS,...) ...  #OPCLASS used by `exclude` (def: use underlying INDEX's ACCESS_METHOD)
create table ... partition by ...
 ("COL"|(COL_REXPR) OPCLASS)      #Same for `partition by`
create type "RANGE_TYPE" as
 range(subtype_opclass = OPCLASS) #Same for RANGE OPs

... order by ARG using OP         #Changes OP used by `order by` (def: < or >)

                                  ┌───────────┐
                                  │   BTREE   │
                                  └───────────┘

btree                             #Default ACCESS_METHOD for INDEXs
                                  #Use case: most generic INDEX
                                  #Sometimes called "nbtree"

DATA STRUCTURE ==>                #Uses b-tree
                                  #Self-balancing k-way search tree
                                  #Each node contains a sequence of sub-nodes
                                  #  - if children, each sub-node is in-between 2 children (position-wise and value-wise)
                                  #  - i.e. optimized for sequential read|write of chunks
                                  #Each node is a memory page
                                  #Max index ROW: 2.5KB

TYPES/OPS ==>                     #For any TYPE with < <= = >= > <>
                                  #Except TYPEs without those OPs: HSTORE (except =), POINT|BOX|CIRCLE|POLYGON, CID|XID, ACLITEM
                                  #Also ROW with *< *<= *= *>= *<> (requires record_image_ops OPCLASS)

STR like '...%'                   #Can also be used
STR ~ '^...'                      #No glob|REGEXP characters in ...
                                  #Not if case-insensitive
                                  #If COLLATION's lc_collate is not C|POSIX:
                                  #  - must use non-default OPCLASS bpchar|varchar|text_pattern_ops for BPCHAR|VARCHAR|TEXT
                                  #  - this OPCLASS cannot handle < <= >= >

FEATURES ==>                      #  - ordered scan, including backward
                                  #  - is [not] null
                                  #  - VAL OP any|all (ARR)
                                  #  - distinct|grouping
                                  #  - exclude
                                  #  - unique
                                  #  - over (range NUM preceding|following): for NUM, DATE|TIME[STAMP][TZ]|INTERVAL
                                  #  - partition by range|list
                                  #  - plain index scan
                                  #  - bitmap index scan
                                  #  - index-only scan
                                  #  - parallel index scan
                                  #  - parallel index build
                                  #  - predicate lock
                                  #  - non-key COLs
                                  #  - cluster
                                  #  - SCONF.maintenance_work_mem
                                  #  - IOPTS.fillfactor

MULTI-COL ==>                     #Only efficient when all the non-last COLs use =
                                  #  - the second-to-last COL can also use <>
                                  #  - according to COL order specified by `create index`, not by query

IOPTS.deduplicate_items           #BOOL (def: true). Store duplicate INDEX ROWs as single ROW
                                  #For BOOL, STR, INT|MONEY, BSTR, BYTEA, DATE|TIME[STAMP][TZ]|INTERVAL, ENUM, MACADDR[8]|INET, OID|TID|UUID|XID8|PG_LSN
                                  #Done on create index or reindex
                                  #Skipped if unique COLs
                                  #Usually good, except if:
                                  #  - very write-heavy INDEX
                                  #  - with not many duplicates, but no unique CONSTRAINT
                                  #Cannot be used with:
                                  #  - non-deterministic COLLATION
                                  #  - non-key COLs

                                  ┌──────────┐
                                  │   GIST   │
                                  └──────────┘

gist                              #ACCESS_METHOD
                                  #Use cases: specific TYPE|OPs

DATA STRUCTURE ==>                #Generalized balanced search tree
                                  #Generalized: any search tree can be implemented by OPCLASSs (B-Tree, etc.)
                                  #Allows using perfect search tree for a given TYPE and OPs

TYPES/OPS ==>                     #For:
                                  #  - TSQUERY|TSVECTOR with @> <@ @@
                                  #  - [MULTI]RANGE with << >> <@ @> &< &> && = -|-
                                  #  - INET with < <= = >= > <> && << <<= >> >>=
                                  #     - requires inet_ops OPCLASS
                                  #  - LTREE with < <= = >= > @> <@
                                  #  - LTREE[_ARR] with <@ @> ~ @ ?
                                  #  - INT4_ARR with = && @> <@ @@
                                  #     - requires gist__int[big]_ops OPCLASS
                                  #        - big_ops: prefer if many ROWs
                                  #  - HSTORE with @> <@ ? ?| ?&
                                  #  - BOX|CIRCLE|POLYGON|POINT with <-> << >> <@ @> &< &> && ~= <<| |>> &<| |&> <^ >^

btree_gist                        #Also for BOOL|NUM|MONEY|STR|CHAR|NAME|BYTEA|BSTR|DATE|TIME[STAMP][TZ]|INTERVAL|OID|UUID|MACADDR[8]|INET|CIDR|ENUM
                                  #With <= < = >= >
                                  #Usually slower than btree
                                  #  - except when creating multi-COL GiST indexes
                                  #Also has OPs
                                  #  - <>
                                  #  - NUM|MONEY|DATE|TIME[STAMP][TZ]|INTERVAL|OID <-> (ordering OP)
                                  #Trusted extension "btree_gist"

FEATURES ==>                      #  - order by BOX|CIRCLE|POLYGON|POINT <-> POINT (ordering operator) ("nearest-neighbor search")
                                  #  - is [not] null
                                  #  - exclude
                                  #  - plain index scan
                                  #  - bitmap index scan
                                  #  - index-only scans for INET|POINT
                                  #  - predicate lock
                                  #  - non-key COLs
                                  #  - cluster
                                  #  - IOPTS.fillfactor

MULTI-COL                         #Only efficient when the first COLs filter out many ROWs
                                  #For LTREE[_ARR], HSTORE, TSVECTOR

IOPTS.buffering                   #BOOL|'auto' (def)
                                  #Cache ROW inserts, for speed
                                  #If auto: when INDEX size > SCONF.effective_cache_size

OOPTS.siglen                      #NUM (max: 2024)
                                  #Def: 124 (HSTORE), 16 (TSQUERY|INT4_ARR), 8 (LTREE), 28 (LTREE_ARR)
                                  #Some TYPE|OPs use a hash of data for comparison, i.e. lossy
                                  #This its the size (in bytes)
                                  #Higher gives better results but higher INDEX size

OOPTS.numranges                   #NUM (def: 100, max: 253)
                                  #With gist__intbig_ops OPCLASS
                                  #Number of INT_RANGEs to use to summarize each INT4_ARR
                                  #Higher value is faster, but higher INDEX size

                                  ┌────────────┐
                                  │   SPGIST   │
                                  └────────────┘

spgist                            #ACCESS_METHOD
                                  #Use cases: like GiST but more performant for values that intersect a lot

DATA STRUCTURE ==>                #Like GiST but for unbalanced search trees

TYPES/OPS ==>                     #For:
                                  #  - STR with < <= = >= > ~<~ ~<=~ ~>=~ ~>~ ^@
                                  #  - RANGE with << >> <@ @> = -|-
                                  #  - BOX|POLYGON|POINT with <-> << >> <@ @> &< &> && ~= <<| |>> &<| |&> <^ >^
                                  #     - kd_point_ops: non default OPCLASS for POINT, sometimes faster
                                  #  - INET with < <= = >= > <> && << <<= >> >>=

FEATURES ==>                      #  - order by BOX|POLYGON|POINT <-> POINT (ordering operator)
                                  #  - is [not] null
                                  #  - exclude
                                  #  - plain index scan
                                  #  - bitmap index scan
                                  #  - index-only scans, except for POLYGON
                                  #  - predicate lock
                                  #  - non-key COLs
                                  #  - IOPTS.fillfactor

                                  ┌─────────┐
                                  │   GIN   │
                                  └─────────┘

gin                               #ACCESS_METHOD
                                  #Use case: set OPs (subset|superset|intersect), especially with duplicate set elements
                                  #Generally more performant than gist for TSVECTOR|INT4_ARR|HSTORE

DATA STRUCTURE ==>                #Generalized Inverted Index
                                  #B-Tree specialized for storing sets
                                  #Each node is an element of a set, instead of set itself
                                  #I.e. slower inserts due to doing one insert per set element
                                  #Duplicate elements are merged as a single list of TIDs

TYPES/OPS ==>                     #For:
                                  #  - ARR with = && @> <@
                                  #  - INT4_ARR with = && @> <@ @@
                                  #     - gin__int[big]_ops OPCLASS
                                  #        - big_ops (def): prefer if many ROWs but lacks @> <@
                                  #  - TSQUERY @@ TSVECTOR
                                  #  - HSTORE with @> <@ ? ?| ?&
                                  #  - JSONB with @> <@ ? ?| ?& @? @@
                                  #     - jsonb_path_ops OPCLASS
                                  #        - only for OPs @> <@ @? @@
                                  #        - does not support .* nor .** with JSONPATH
                                  #        - non-default OPCLASS that is more performant

btree_gin                         #Also for BOOL|NUM|MONEY|STR|CHAR|NAME|BYTEA|BSTR|DATE|TIME[STAMP][TZ]|INTERVAL|OID|UUID|MACADDR[8]|INET|CIDR|ENUM
                                  #With <= < = >= >
                                  #Usually slower than btree
                                  #Only useful when creating multi-COL GIN indexes
                                  #Trusted extension "btree_gin"

FEATURES ==>                      #  - bitmap index scan
                                  #  - predicate lock
                                  #  - SCONF.maintenance_work_mem

MULTI-COL ==>                     #Efficient regardless of which OP is used, and in any order

IOPTS.fastupdate                  #BOOL (def: true)
                                  #Use a "pending list", i.e. buffer elements to insert, so they are inserted in bulk
                                  #Emptied on either:
                                  #  - SCONF|IOPTS.gin_pending_list_limit INT (in KB) (def: 4MB)
                                  #     - higher values happens less often, but take longer
                                  #  - vacuum|analyze
                                  #  - gin_clean_pending_list(REGCLASS)->INT8
                                  #Pro: faster inserts
                                  #Con: slower reads|updates, since pending list must be queried too

SCONF.gin_fuzzy_search_limit      #NUM (def: 0, i.e. none)
                                  #Max tokens returned by TSQUERY @@ TSVECTOR
                                  #Pro: performance on big TSVECTOR
                                  #Con: less accurate results
                                  #Values of 5e3-20e3 usually good

rum EXTENSION ???

                                  ┌──────────┐
                                  │   BRIN   │
                                  └──────────┘

brin                              #ACCESS_METHOD
                                  #"Block Range INdex"
                                  #Use case:
                                  #  - Very large TABLEs
                                  #  - Data read close to each other, e.g. in chunks
                                  #  - Indexed values increase mostly monotonically

DATA STRUCTURE ==>                #Splits data into block ranges
                                  #Block ranges have a min|max value
                                  #  - better if they do not overlap each other too much
                                  #Block ranges maps to filesystem pages
                                  #Finding right block is fast, but does a sequential read inside the block
                                  #Low memory and CPU overhead of INDEX structure

FEATURES ==>                      #  - is [not] null
                                  #  - bitmap index scan

MULTI-COL ==>                     #Efficient regardless of which OP is used, and in any order

SUMMARIZATION ==>                 #Adding min|max to a block range
                                  #New block ranges are not automatically summarization
                                  #Done on vacuum on the TABLE
IOPTS.autosummarize               #BOOL (def: false). If true, also summarize:
                                  #  - when vacuum on any other TABLE
                                  #  - on any non-last block range
brin_summarize_new_values
 (INDEX_REGCLASS)->UINT           #Summarize all unsummarized block ranges
brin_summarize_range
 (INDEX_REGCLASS, UINT)->UINT2    #Summarize specific block range
brin_desummarize_range            #Remove summary on specific block range
 (INDEX_REGCLASS, UINT)->UINT2    #Goal: when a block range's summary is not accurate anymore due to updates

IOPTS.pages_per_range             #NUM (def: 128) of page heaps per block range
                                  #Should be close to NUM of page heaps usually read by queries
                                  #  - if too high: longer sequential scan
                                  #  - if too low: higher memory|CPU taken by INDEX

CATEGORIES ==>                    #Has multiple categories: minmax, minmax_multi, bloom, inclusion
                                  #Depending on indexed values TYPEs and OPCLASSs

minmax                            #Category for < <= = >= >
                                  #For any TYPE except BOOL, ENUM, MONEY, ARR, RECORD, MULTIRANGE, HSTORE, JSONB, LTREE, CIRCLE|POINT|POLYGON, TSQUERY|TSVECTOR, CID|XID|XID8
                                  #No cross-TYPE OPs for BPCHAR|VARCHAR|TEXT
                                  #Uses normal min|max, i.e. most generic category

minmax_multi                      #Category for same types as `minmax` with < <= = >= >
                                  #  - except B[STR] and STR
                                  #Uses multiple min|max per block range
                                  #  - i.e. good when values have gaps
                                  #Non-default OPCLASSs
OOPTS.values_per_range            #NUM (def: 32, min 8, max 256)
                                  #Max NUM of values used for the min|max ranges
                                  #I.e. max NUM/2 min|max ranges

bloom                             #Category for same types as `minmax` with =
                                  #Uses a Bloom filter
                                  #I.e. good for small INDEX size with OP =, providing false positives are ok
                                  #Non-default OPCLASSs
OOPTS.false_positive_rate         #NUM (def: 0.01, min 0.0001, max 0.25)
                                  #Lower values requires larger INDEX size
OOPTS.n_distinct_per_range        #NUM. Similar to TOPS.n_distinct, but meant as a hint for Bloom filter to reduce its size

inclusion                         #Category for:
                                  #  - RANGE with << >> && &< &> @> <@ -|- < <= = >= >
                                  #  - BOX with << >> && &< &> @> <@ ~= &<| |&> <<| |>>
                                  #  - INET with << >> >>= <<= && =
                                  #Uses multidimensional min|max specific to those TYPEs, e.g. bounding boxes

                                  ┌──────────┐
                                  │   HASH   │
                                  └──────────┘

hash                              #ACCESS_METHOD
                                  #Use case: OP = on large TABLE with unique values

DATA STRUCTURE ==>                #Hash table
                                  #Key is hash of data
                                  #  - 4 bytes
                                  #Value are ROW ids with that hash
                                  #  - i.e. slow if many values are duplicates
                                  #Fast with = on many ROWs
                                  #When TABLE size increase, need to split buckets, which is slow and locks the table
                                  #  - i.e. not good if TABLE size increases rapidly
                                  #Always lossy, because requires searching among values with same checksum

TYPES/OPS ==>                     #For any TYPE with =
                                  #  - except BSTR, MONEY, LTREE, TSQUERY|TSVECTOR, POINT|BOX|CIRCLE|POLYGON
                                  #  - no cross-TYPE OPs for DATE|TIMESTAMP[TZ]

FEATURES ==>                      #  - distinct|grouping
                                  #  - exclude
                                  #  - partition by hash
                                  #  - plain index scan
                                  #  - bitmap index scan
                                  #  - predicate lock
                                  #  - IOPTS.fillfactor

                                  ┌───────────┐
                                  │   BLOOM   │
                                  └───────────┘

bloom                             #ACCESS_METHOD
                                  #Use case: OP = with many duplicates
                                  #  - sometimes faster than btree when queries use many indexed COLs at once with OP =
                                  #Non-trusted extension "bloom"

DATA STRUCTURE ==>                #Bloom filter
                                  #Lossy due false positives being rechecked
                                  #I.e. true is slower than false

TYPES/OPS ==>                     #For: STR|INT4 with =

FEATURES ==>                      #  - plain index scan
                                  #  - bitmap index scan

MULTI-COL ==>                     #Only efficient when all the non-last COLs use =

OOPTS.length                      #NUM (def: 80, max: 4096)
                                  #Bloom filter size in bytes, for all COLs together
                                  #Larger size are faster

OOPTS.col1-32                     #NUM (def: 2, max: 4095)
                                  #Bits taken by individual COLs inside Bloom filter

                                  ┌──────────┐
                                  │   HEAP   │
                                  └──────────┘

heap                              #ACCESS_METHOD
                                  #Unlike other ACCESS_METHODs, meant for TABLEs, not INDEXs

                                  ┌──────────────────────┐
                                  │   PARALLEL QUERIES   │
                                  └──────────────────────┘

PARALLEL COMMAND ==>              #COMMAND using multiple worker processes in parallel
                                  #Must not:
                                  #  - lock any ROW
                                  #  - be inside another parallel command
PARALLEL QUERY ==>                #Must be SUBQUERY
                                  #  - or equivalent: create|refresh materialized view, create table as, select into
                                  #Can be:
                                  #  - sequential|index|bitmap scans
                                  #  - joins
                                  #  - partial AFUNCs
                                  #  - union all, partitioning
PARTIAL PLAN ==>                  #Part of the plan executed by a parallel worker

SCONF.max_parallel_workers        #Max NUM (def: 8) of parallel worker processes
                                  #Must be < PCONF.max_worker_processes
                                  #Increase memory, CPU and I/O linearly, i.e. resource-intensive
                                  #SCONF.work_mem is applied for each worker, not for all
SCONF.                            #Max NUM (def: 2) of parallel worker processes for parallel queries
 max_parallel_workers_per_gather  #Must be < SCONF.max_parallel_workers

SCONF.enable_gathermerge          #"Gather merge": parallel query that is sorted, i.e. parent process performs a merge sort

SCONF                             #If true (def), parent process can perform some of the workers task instead of waiting for them
 .parallel_leader_participation   #However, it increases chances for workers to wait for parent to process their output,
                                  #since parent might be busy.
                                  #  - this is especially likely if many ROWs are returned from workers

create|alter function|aggregate   #Whether [A]FUNC can be:
 ...                              #  - safe: run in parallel workers or their parent
 parallel safe|restricted|unsafe  #     - must be purely functional
                                  #  - restricted: not run in parallel workers, but in their parent
                                  #     - required if gets some global state like: CURSOR, TEMP TABLE, PREP, etc.
                                  #  - unsafe (def): not run in parallel workers nor their parent
                                  #     - required if sets global state
                                  #I.e. restricted|unsafe removes the possibility for parallel queries
                                  #Most built-in FUNCs are parallel safe

SCONF.force_parallel_mode         #Force using parallel queries, for debugging purpose. Can be:
                                  #  - 'off' (def)
                                  #  - 'regress': like 'on' but show less info
                                  #  - 'on'

                                  ┌─────────────┐
                                  │   EXPLAIN   │
                                  └─────────────┘

QUERY PLANNER ==>                 #Internal logic deciding best way to execute COMMANDs

explain [(ZOPTS)] COMMAND         #Show the query plan of COMMAND
                                  #COMMAND can be select|table|values|execute, create table|materialized view as, insert|update|delete|merge, declare
                                  #Should prefer real data close to production, if possible

explain verbose ...               #BOOL (def: false)
ZOPTS.verbose                     #Whether to print more fields

explain analyze ...               #BOOL (def: false)
ZOPTS.analyze                     #Executes the COMMAND, allowing to print fields related to actual execution
                                  #Can use transaction + rollback to avoid side effects

ZOPTS.format                      #text (def) or json|yaml|xml
                                  #text does not show values that are 0

ZOPTS.costs                       #BOOL (def: true)
                                  #Whether to print (costs|rows|width ...)

ZOPTS.timing                      #BOOL (def: true)
                                  #Whether to print (actual time ...)
                                  #Requires ZOPTS.analyze true

ZOPTS.summary                     #BOOL (def: true)
                                  #Whether to print Planning|Execution Time

ZOPTS.buffers                     #BOOL (def: false)
                                  #Whether to print Buffers ...

ZOPTS.wal                         #BOOL (def: false)
                                  #Whether to print WAL ...
                                  #Requires ZOPTS.analyze true

ZOPTS.settings                    #BOOL (def: false)
                                  #Whether to print EXPLAIN-related CONF (like enable_hashjoin, etc.)
                                  #Only if their default value was changed

SCONF.enable_*                    #Whether specific query optimizations are enabled
                                  #All BOOL are true by default, except enable_partitionwise_*
                                  #Can set to false to set alternative plans considered by `explain`
                                  #Some cannot be completely disabled
                                  #  - i.e. false only discourages it
                                  #  - for: enable_seqscan|sort|nestloop|material

discard plans                     #Discard cached `explain` plans of current session

                                  ┌──────────────────┐
                                  │   EXPLAIN TREE   │
                                  └──────────────────┘

TREE ==>                          #Output is a tree with following nodes.
                                  #Each node results include its children.
                                  #Children are executed before parents.

Insert on TABLE                   #`insert`
Update on TABLE                   #`update`
Delete on TABLE                   #`delete`

... on CHILD_TABLE PARENT_TABLE   #Inheritance

Gather [Merge]                    #Parallel query
Workers Planned: NUM              #NUM of parallel worker processes, expected
Workers Launched: NUM             #NUM of parallel worker processes

[Parallel] Seq Scan on TABLE      #

Index [Only] Scan [Backward]
 using INDEX on TABLE             #
Index Cond: EXPR                  #Query "COL"|(REXPR) matching the INDEX's
Rows Removed by Index Recheck: NUM#ROWs excluded by lossy operator recheck
Heap Fetches: UINT                #Index-only heap fetches

Bitmap Heap Scan on TABLE         #
Bitmap Index Scan on TABLE        #
BitmapAnd                         #... and ... (bitmap scan combination)
BitmapOr                          #... or ... (bitmap scan combination)
Recheck Cond: EXPR                #Recheck condition

Values Scan on "..."              #values(...)

Foreign Scan on FTABLE            #FTABLE read

TID Scan on TABLE                 #
TID Cond: EXPR                    #`where`

Result                            #COMMAND return value
Output                            #COMMAND return value contents

Filter: EXPR                      #where|having
Rows Removed by Filter: NUM       #ROWs excluded by Filter

Sort                              #Explicit sort
Sort Key: EXPR                    #Explicit sort argument
Sort Method:
 quicksort Memory: NUM
Sort Method:
 top-N heapsort Memory: NUM
Sort Method:
 external merge Disk: NUM         #Explicit sort methods

Incremental Sort                  #
Presorted Key: EXPR               #Incremental sort argument that is sorted

Materialize                       #Materialization of a ROW_SET

InitPlan NUM                      #(SUBQUERY) that does not use upper queries
                                  #NUM is execution order
SubPlan NUM                       #(SUBQUERY) that uses upper queries, i.e. does a join
Subquery Scan on "QUERY"          #(SUBQUERY) that uses upper queries

... [Left|Right|Full] [Anti] Join #

Nested Loop                       #Nested loop join
Join Filter                       #Nested loop join condition (where|on)
Memoize                           #Nested loop join memoization

Hash Join                         #
Hash Cond: EXPR                   #Hash join condition (where|on)
Hash                              #Creation of hash table for a ROW_SET during a hash join
Buckets: NUM                      #Hash table size
Memory Usage: STR                 #Hash table creation peak memory
Batches: NUM                      #Number of rounds to create hash table
Disk Usage: STR                   #To persist data in-between hash table batches

Merge Join                        #
Merge Cond: EXPR                  #Merge join condition (where|on)

Limit                             #offset|fetch

Unique                            #distinct

[Parallel] Append                 #union all, or partitioning
[Parallel] MergeAppend            #union all + order by
Setop Intersect                   #intersect
Setop Except                      #except
HashSetOp ...                     #Same but using hash aggregation

Aggregate                         #AFUNC
Partial Aggregate                 #Parallel AFUNC worker process
Finalize Aggregate                #Parallel AFUNC parent process, merging workers results

Group                             #group by without AFUNCs
GroupAggregate                    #Group aggregation (group by)
HashAggregate                     #Hash aggregation (group by, or distinct)
MixedAggregate                    #grouping sets
Group Key                         #group by's argument

WindowAgg                         #WFUNC

ProjectSet                        #select FUNC()->SET
Function Scan on FUNC             #from FUNC()->SET

CTE ROW_ALIAS                     #with "ROW_ALIAS"
CTE Scan on ROW_ALIAS             #Using CTE "ROW_ALIAS"
RecursiveUnion                    #with recursive ... select ... union ...
WorkTable Scan                    #Recursive loop in `with recursive`

LockRows                          #select ... for ... update|share

                                  ┌──────────────────┐
                                  │   EXPLAIN COST   │
                                  └──────────────────┘

(costs=NUM..NUM2)                 #Cost. Decides between different strategies
                                  #NUM is "startup cost" (initialization logic), NUM2 is "total cost"
                                  #Can be multiplied by factors set in CONF
SCONF.parallel_setup_cost         #NUM (def: 1000). Cost of starting a worker process
SCONF|AOPTS.random_page_cost      #NUM (def: 4). Cost of random I/O read of a heap page
SCONF|AOPTS.seq_page_cost         #NUM (def: 1). Cost of sequential I/O read of a heap page
SCONF.parallel_tuple_cost         #NUM (def: 0.1). Cost of sending a ROW from a worker to the parent process
SCONF.cpu_tuple_cost              #NUM (def: 0.01). Cost of CPU processing of a TABLE ROW
SCONF.cpu_index_tuple_cost        #NUM (def: 0.005). Cost of CPU processing of an INDEX ROW
SCONF.cpu_operator_cost           #NUM (def: 0.0025). Cost of CPU execution of a FUNC

SCONF.effective_cache_size        #STR (def: '4GB'). Hints how much RAM is available.
                                  #RAM is mostly used by the OS to cache I/O by keeping files in-memory.
                                  #I.e. more RAM makes the cost of I/O cheaper.
                                  #Does not change actual cache size.
                                  #Should be 50-75% of the available RAM.

(actual loops=UINT2)              #Number of times this inner node was performed

(actual time=NUM..NUM2)           #NUM[2] (in ms) initialization|total time spent, per inner node loop
Planning Time                     #Time to plan the query
Execution Time                    #Time to execute the query, excluding Planning Time

(rows=UINT)                       #Number of ROWs returned|written expected, per inner node loop
(actual rows=UINT)                #Same but actual number, after query performed
(width=UINT)                      #Mean size (in bytes) of a ROW

Buffers: ...                      #Used to debug both I/O caching, and amount of I/O
Buffers: shared hit|read=NUM      #Heap pages hit|misses
Buffers: shared dirtied=NUM       #Heap pages dirtied
Buffers: shared written=NUM       #Heap pages written
Buffers: local ...                #Same for local heap pages
Buffers: temp ...                 #Same for temporary heap pages

WAL: fpi=UINT                     #Number of full heap pages added to WAL
WAL: records=UINT                 #Number of ROWs added to WAL
WAL: bytes=UINT                   #Number of bytes added to WAL

                                  ┌──────────────────────┐
                                  │   EXPLAIN FUNCTION   │
                                  └──────────────────────┘

create|alter function ...         #Multiplied to cpu_operator_cost for the planner (i.e. per ROW)
 cost FLOAT                       #Often used:
                                  #  - 1: def for C FUNC
                                  #  - 10: slow C FUNC
                                  #  - 100: def for non-C FUNC
                                  #  - 1000: slow non-C FUNC

create|alter function ...         #Average NUM of ROWs returned, for the planner, if return TYPE is SET
 rows NUM                         #Often used:
                                  #  - 10|20: unknown, but probably very low
                                  #  - 100: unknown, but probably lower
                                  #  - 1000 (def): unknown
                                  #  - 10000: unknown, but probably higher
                                  #  - specific NUM: when returns always the same amount of ROWs

create|alter function ...         #Can be:
 immutable|stable|volatile        #  - volatile (def)
                                  #     - can modify state outside FUNC
                                  #     - even if same args, can return different values per statement
                                  #  - stable:
                                  #     - cannot modify state outside FUNC
                                  #     - if same args, returns same values, but within a given SQL statement
                                  #     - can:
                                  #        - read global state that does not change within statement: TABLEs, CONFVARs, current_timestamp
                                  #        - but not: randomness, SERIALs, clock_timestamp, external processes
                                  #  - immutable:
                                  #     - cannot modify state outside FUNC
                                  #     - if same args, returns same values, always
                                  #     - cannot read global mutable state
                                  #Used by the query planner

create|alter function ...         #Set a FUNC to help query planner
 support FUNC(INTERNAL)->INTERNAL2#Must use LANGUAGE C
                                  #Must be superuser
                                  #INTERNAL[2] not documented yet, but main parts are:
                                  #  - SupportRequestCost: like `create function ... cost`
                                  #  - SupportRequestRows: like `create function ... rows`
                                  #  - SupportRequestSimplify: replace FUNC by its return value
                                  #  (only for FUNC()->BOOL used in `where`)
                                  #  - SupportRequestSelectivity: average percentage of ROWs returning true
                                  #  - SupportRequestIndexCondition: transform into indexable OP
                                  #  (only for WFUNC)
                                  #  - SupportRequestOptimizeWindowClause
                                  #  - SupportRequestWFuncMonotonic: whether monotonic

                                  ┌─────────────┐
                                  │   ANALYZE   │
                                  └─────────────┘

analyze [(OPTS)]                  #Fill in pg_statistic and pg_class.relpages|reltuples|relallvisible
 ["TABLE"[("COL",...)]]           #Def TABLEs|COLs: all that user has access to, except FTABLEs
                                  #FTABLEs are not always supported
OPTS.verbose
analyze verbose ...               #Show progress

OPTS.skip_locked                  #Like vacuum OPTS.skip_locked, except requiring an `access share` lock

pg_stat_progress_analyze          #TABLE with ongoing `analyze` statements.
pg_stat_progress_analyze.relid    #REGCLASS of TABLE
pg_stat_progress_analyze.datid    #pg_database.oid of DATABASE
pg_stat_progress_analyze.datname  #NAME of "DATABASE"
pg_stat_progress_analyze.pid      #BPID
pg_stat_progress_analyze.phase    #STR among:
                                  #  - 'initializing'
                                  #  - 'acquiring sample rows': reading ROWs
                                  #  - 'acquiring inherited sample rows': reading ROWs of child TABLEs
                                  #     - columns child_tables_total, child_tables_done, and current_child_table_relid contain the progress information for this phase.
                                  #  - 'computing statistics'
                                  #  - 'computing extended statistics': for `create statistics`
                                  #  - 'finalizing analyze': updating pg_class.*
pg_stat_progress_analyze
 .sample_blks_total               #INT8. Number of heap pages in total
pg_stat_progress_analyze
 .sample_blks_scanned             #INT8. Number of heap pages done.
pg_stat_progress_analyze
 .ext_stats_total                 #INT8. Number of extended statistics in total
pg_stat_progress_analyze
 .ext_stats_computed              #INT8. Number of extended statistics done, during 'computing statistics'
pg_stat_progress_analyze
 .child_tables_total              #INT8. Number of child tables in total, during 'acquiring inherited sample rows'
pg_stat_progress_analyze
 .child_tables_done               #INT8. Number of child tables done, during 'acquiring inherited sample rows'
pg_stat_progress_analyze
 .current_child_table_relid       #OID of the "CHILD_TABLE" being read, during 'acquiring inherited sample rows'

                                  ┌──────────────────┐
                                  │   PG_STATISTIC   │
                                  └──────────────────┘

SCONF.default_statistics_target   #NUM (def: 100, from 0 to 10000)
                                  #Number of items in pg_statistic.* COLs that are ARRs: most_common_*, histogram_bounds
                                  #Higher values makes `explain` slower but with better plans
alter [foreign] table|index ...
 alter [column] "COL"
 set statistics NUM               #Sets default_statistics_target for a COL. -1 means default. 0 means none.
pg_attribute.attstattarget        #INT4. `set statistics NUM` of that COL

COPTS.n_distinct                  #NUM. Explicitly set pg_statistic.stadistinct for a given COL
COPTS.n_distinct_inherited        #NUM. Same but includes child TABLEs

pg_statistic                      #Statistic of a COL or an index REXPR, used by the planner to optimize queries.
                                  #Only takes a random sample of the ROWs, i.e. approximate.
                                  #Visible only to superuser
pg_statistic.starelid             #REGCLASS of the TABLE
pg_statistic.staatnum             #pg_attribute.attnum of the COL
pg_statistic.stainherit           #BOOL. Like pg_stats.inherited
pg_statistic.stanullfrac          #FLOAT4. Like pg_stats.null_frac
pg_statistic.stawidth             #INT4. Like pg_stats.avg_width
pg_statistic.stadistinct          #FLOAT4. Like pg_stats.n_distinct
pg_statistic.sta*NUM              #Individual statistics. See pg_stats.* for the kinds of statistics
pg_statistic.stakindNUM           #INT. Statistic type
pg_statistic.staopNUM             #REGOPER used to order data. 0 if none
pg_statistic.stacollNUM           #REGCOLLATION used by data. 0 if none
pg_statistic.stanumbersNUM        #FLOAT_ARR. Statistics as FLOATs. null if none
pg_statistic.stavaluesNUM         #ARR. Statistics with the same type as the COL. null if none

pg_stats                          #VIEW on top of pg_statistic
pg_stats.tablename                #"TABLE" name
pg_stats.attname                  #"COL" name
pg_stats.inherited                #BOOL. True if "PARENT_TABLE", i.e. include "CHILD_TABLE" stats

pg_stats.null_frac                #FLOAT4. Percentage of null values
                                  #Used by query planner to estimate number of ROWs with `where`, `group by`
                                  #with value either null or not
                                  #  - e.g. if half of values are null, `where VAL = 1` cannot only return at most half of ROWs

pg_stats.avg_width                #INT4. Average size (in bytes) of non-null values
                                  #Used in `(width)` output of `explain`

pg_stats.n_distinct               #FLOAT4. Number of distinct non-null values. Can be:
                                  #  - NUM:
                                  #     - means NUM values are unique and non-null
                                  #     - used when unlikely to increase as table grows
                                  #  - -NUM:
                                  #     - means NUM% of values are unique and non-null
                                  #     - used when likely to increase as table grows
                                  #  - 0: unknown
                                  #Used by query planner to estimate number of ROWs with `group by`

pg_stats.most_common_vals         #ARR of most common values. null if none
                                  #Used together with `most_common_freqs` by query planner to estimate number of ROWs with `where VAL = VAL2`
                                  #with VAL2 being one of the most common values
                                  #Also used when VAL2 is not one of them, using the average frequency of the remaining (not most common) values
pg_stats.most_common_freqs        #FLOAT4_ARR. Frequencies of most_common_vals. null if none.

pg_stats.histogram_bounds         #ARR. Percentiles. null if none
                                  #Used by query planner to estimate number of ROWs with `where` and OPs like < <= > >=

pg_stats.most_common_elems        #ARR. Like most_common_vals but for ARR items. null if COL TYPE is not ARR.
pg_stats.most_common_elem_freqs   #FLOAT4_ARR. Like most_common_freqs but for ARR items. null if COL TYPE is not ARR.
                                  #Each value is followed by min|max frequency. Optionally also the frequency of null values.
pg_stats.elem_count_histogram     #FLOAT4_ARR. Like histogram_bounds but for ARR items. null if COL_TYPE is not ARR

pg_stats.correlation              #-1 to 1. Statistical correlation between physical locations (ctid) and logical locations (ROW index)
                                  #When close to 0, means index scans will require lots of random access, i.e. expensive
                                  #null if none

pg_class.relpages                 #INT4. Size of the file on-disk, in 8KB pages.
                                  #Used by the query planner to estimate cost of sequential scans
pg_class.reltuples                #FLOAT4. Number of non-dead ROWs
                                  #-1 if VIEW|ROW_TYPE, or if not analyze|vacuum'd yet
                                  #Used by the query planner to estimate cost of sequential scans

YOPTS.analyze                     #FUNC(INTERNAL)->BOOL. Customize `analyze` behavior on that TYPE
                                  #Returns false if should skip analyze
                                  #INTERNAL is pointer to a STRUCT with fields to set
                                  #  - mostly computing the values for pg_statistic
                                  #  - not fully documented yet
                                  #Def: uses a FUNC that relies on = and < OPs

                                  ┌─────────────────────────┐
                                  │   EXTENDED STATISTICS   │
                                  └─────────────────────────┘

create statistics "STATISTICS"    #Make `analyze` collect "multivariate" statistics, i.e. multiple "COL"|(REXPR) together
 on "COL"|(REXPR),...             #If only one, must be a REXPR, not "COL"
 from "TABLE"                     #Useful when those "COL"|(REXPR) are both:
                                  #  - queried together
                                  #  - correlated

create statistics "STATISTICS"
 (KIND,...) ...                   #Specifies which statistics to compute (def: all)

create statistics "STATISTICS"    #Like pg_stats.ndistinct, but multivariate
 (ndistinct,...) ...              #Otherwise, correlated COLs are considered independent by the query planner
                                  #I.e. query planner would overestimate number of ROWs returned by `group by COL, COL2`
                                  #  - e.g. if there are 3 COL values and 3 COL2 values, it would estimate 9 total values,
                                  #    even if those are perfectly correlated, i.e. should be 3 total values

create statistics "STATISTICS"
 (mcv,...) ...                    #Similar but for pg_stats.most_common_values

create statistics "STATISTICS"    #Functional dependency between COLs, i.e. correlation between their values
 (dependencies,...) ...           #Used by query planner to estimate number of ROWs with `where VAL = VAL2 and VAL = VAL3`
                                  #I.e. query planner would overestimate number of ROWs otherwise, if correlated
                                  #Only with "COL", not REXPR

pg_statistic_ext                  #TABLE with all STATISTICs
pg_statistic_ext.oid              #OID
pg_statistic_ext.stxname          #"STATISTICS" name
pg_statistic_ext.stxrelid         #REGCLASS of "TABLE"
pg_statistic_ext.stxstattarget    #INT4. Like pg_attribute.attstattarget
pg_statistic_ext.stxkeys          #ARR of "COL" (pg_attribute.attnum)
pg_statistic_ext.stxexprs         #PG_NODE_TREE of REXPRs
pg_statistic_ext.stxkind          #'d|f|m'_ARR

pg_statistic_ext_data             #TABLE with data collected by `analyze` for STATISTICs
pg_statistic_ext_data.stxoid      #pg_statistic_ext.oid
pg_statistic_ext_data.stxdinherit #BOOL: like pg_statistic.stainherit
pg_statistic_ext_data
 .stxdndistinct                   #PG_NDISTINCT
pg_statistic_ext_data.stxdmcv     #PG_MCV_LIST
pg_statistic_ext_data
 .stxddependencies                #PG_DEPENDENCIES
pg_statistic_ext_data.stxdexpr    #PG_STATISTIC_ARR

pg_stats_ext                      #High-level VIEW on top of pg_statistic_ext and pg_statistic_ext_data
pg_stats_ext.tablename            #"TABLE" name
pg_stats_ext.statistics_name      #"STATISTICS" name
pg_stats_ext.attnames             #"COL"_ARR
pg_stats_ext.exprs                #STR_ARR. pg_statistic_ext.stxexprs
pg_stats_ext.kinds                #CHAR_ARR. pg_statistic_ext.stxkind
pg_stats_ext[_exprs].inherited    #BOOL. pg_statistic_ext_data.stxdinherit
pg_stats_ext.n_distinct           #PG_NDISTINCT. pg_statistic_ext_data.stxdndistinct
pg_stats_ext.dependencies         #PG_DEPENDENCIES. pg_statistic_ext_data.stxddependencies
pg_stats_ext.most_common_vals     #STR_ARR. Like pg_stats.most_common_vals
pg_stats_ext.most_common_val_nulls#BOOL_ARR. Whether most_common_vals[*] is null
pg_stats_ext.most_common_freqs    #FLOAT8_ARR. Like pg_stats.most_common_freqs
pg_stats_ext                      #FLOAT8_ARR. When multiplying frequency of each COL independently when each other,
 .most_common_base_freqs          #not their frequency when used together

pg_stats_ext_exprs                #High-level VIEW on top of pg_statistic_ext and pg_statistic_ext_data
pg_stats_ext_exprs.*              #Like pg_stats.* except no attname ->
pg_stats_ext_exprs.statistics_name#"STATISTICS" name
pg_stats_ext_exprs.expr           #'REXPR'

pg_ndistinct                      #TYPE to store ndistinct statistics
'{"VAL,...": COUNT_NUM}'          #PG_NDISTINCT_UNKNOWN
PG_NDISTINCT ~> STR               #

pg_mcv_list                       #TYPE to store most common values statistics
pg_mcv_list_items
 (PG_MCV_LIST)->ROW_SET           #Parse PG_MCV_LIST
ROW.index                         #INT4. 0-based index of ROW in SET
ROW.values                        #STR_ARR. Like pg_stats_ext.most_common_vals
ROW.nulls                         #BOOL_ARR. Like pg_stats_ext.most_common_val_nulls
ROW.frequency                     #FLOAT8. Like pg_stats_ext.most_common_freqs
ROW.base_frequency                #FLOAT8. Like pg_stats_ext.most_common_base_freqs

pg_dependencies                   #TYPE to store functional dependencies
'{"VAL => VAL2": CORR_FLOAT}'     #PG_DEPENDENCIES_UNKNOWN
PG_DEPENDENCIES ~> STR            #

pg_statistic                      #TYPE representing statistics when using REXPR (instead of "COL")

pg_get_statisticsobjdef           #Returns 'CREATE ...' statement that created STATISTICS
 (STATISTICS_OID[, BOOL])->STR    #BOOL (def: false) is prettify

                                  ┌───────────────┐
                                  │   HEAP PAGE   │
                                  └───────────────┘

HEAP ==>                          #Memory storing TABLEs (as opposed to INDEXs)

HEAP PAGE ==>                     #8KB memory page containing 1-n TABLE ROWs
                                  #Also called "blocks"
ICONF.block_size                  #8192

ROW SIZE ==>                      #Min size: 32 bytes (due to SYSTEM COLs)
                                  #  - i.e. max 256 ROWs per heap
                                  #Max size: 8KB (due to heap page max size)
                                  #With TOAST: max 400GB of actual data

HEAP PAGE NUMBER ==>              #Heap page index within a TABLE
                                  #Stored as INT4, i.e. from 0 to 4e9
                                  #Also called "block number" or "blkno"

TABLE SIZE ==>                    #Max size: 32TB (due to heap number max number)

"ROW_ALIAS".ctid                  #TID of the ROW version
                                  #Since ROWs versions are immutable, each insert|update creates a new ROW version with a new ctid
tid                               #TYPE. Location of a ROW within its TABLE.
                                  #Is (INT4, INT2)
                                  #  - INT4 is heap page number
                                  #  - INT2 is index within heap page
'(UINT, UINT2)'                   #TID_UNKNOWN
SCONF.enable_tidscan              #"TID scan". When using ctid with `where|on`, can directly fetch the ROWs
                                  #without scanning other ROWs, since the ctid contains the ROW physical location.

HEAP PAGE TYPES ==>               #Heap pages can be:
                                  #  - "shared": non-temp TABLE
                                  #  - "local": temp TABLE
                                  #  - "temporary": short-term ROW_SET, e.g. during sorts, joins, etc.

HEAP PAGE CACHING ==>             #Heap pages can be cached in-memory
                                  #  - "hit": when uses cache
                                  #  - "read": when not used
                                  #Heap pages with writes are "dirtied" (using visibility map)
                                  #  - "write": when a dirtied heap page is evicted from cache
                                  #Temporary heap pages are never cached

TOPTS|IOPTS.fillfactor            #10-100. Keep 1-INT% additional free space on the page storing TABLE|INDEX
                                  #Def: 100 (TOPTS) or 90 (IOPTS), i.e. none
                                  #Memory allocation happens on `insert`
                                  #Goal:
                                  #  - faster memory allocation if lots of `update`
                                  #  - `update`s can keep their `cluster` optimization, since they do not need new memory allocations
                                  #  - increase changes of Heap-Only Tuples

pageinspect EXTENSION ???
pgstattuple EXTENSION ???

                                  ┌────────────────────┐
                                  │   FREE SPACE MAP   │
                                  └────────────────────┘

HEAP PAGE FREE SPACE ==>          #Amount of unused bytes
                                  #Only 32 bytes-precise

FREE SPACE MAP ==>                #Data structure storing amount of unused bytes of each heap page
                                  #Binary search tree, with one leaf node per heap page
                                  #Used to know which heap page to use in inserts|updates
                                  #New nodes are automatically created on page heap creation|deletion
                                  #However, free space value is only updated by vacuum
                                  #  - i.e. might not perfectly match current state
                                  #  - new nodes have incorrect value 0 (i.e. no bytes available) until next vacuum
                                  #Also called FSM

pg_freespace(REGCLASS, INT8)->INT2#Returns amount of free space (in bytes) of heap page number INT8 of REGCLASS, according to FSM
                                  #Non-trusted Postgres extension 'pg_freespacemap'
pg_freespace(REGCLASS)->ROW_SET   #Same for all heap pages of REGCLASS, as ROW: blkno INT8, avail INT2

DBDIR|CLUSTERDIR/REGCLASS_OID_fsm #FSM location

                                  ┌─────────┐
                                  │   XID   │
                                  └─────────┘

MVCC ==>                          #"Multiversion concurrency control"
                                  #Strategy to allow concurrency by making each ROW immutable
                                  #Deleted ROWs are kept until vacuum ("dead rows")
                                  #ROW updates behave like a delete + insert (as opposed to being done in-place)
                                  #Transactions see different versions of those ROWs, depending on when they were started and
                                  #their isolation level

xid                               #TYPE. Index of a write transaction within a given DATABASE
                                  #Incrementing, starting at 2
                                  #Used to represent a DATABASE's version
                                  #A session:
                                  #  - increments and acquires the latest XID if starting a write transaction
                                  #  - uses the latest XID if no ongoing write transaction
                                  #     - including after ending a write transaction
                                  #1 is a special value ("bootstrap XID") reserved for write transactions performed during initdb
                                  #Cannot use < <= > >=
                                  #4 bytes. Might be re-used in the lifetime of cluster
                                  #  - min|max values are circular
                                  #  - i.e. previous|next 2e9 values are considered <|>, when taking wraparound into account
XID <~=> TEXT                     #Type cast

xid8                              #Like xid but 8 bytes. I.e. never re-used in the lifetime of cluster
XID8 ~> XID                       #Type cast
XID8 <~=> TEXT                    #Type cast

"ROW_ALIAS".xmin                  #"Insert ID". XID of the transaction that created the ROW
"ROW_ALIAS".xmax                  #"Delete ID". XID of the transaction that deleted the ROW
                                  #0 if not deleted yet

pg_current_xact_id()->XID8        #Current transaction's XID8
                                  #If in a readonly statement|transaction, acquires a new XID8 for it
pg_current_xact_id_if_assigned()  #Current transaction's XID8
 ->XID8                           #If in a readonly statement|transaction, returns null
age(XID)->UINT                    #Difference between current session's XID2 and XID

pg_xact_commit_timestamp(XID)
 ->TIMESTAMPTZ                    #Transaction's timestamp

ROW VISIBILITY ==>                #Cannot see ROWs creations|deletions of other transactions if either:
                                  #  - other is uncommitted
                                  #  - current is uncommitted, and other is later, i.e. ROWs with xmin > current session XID
                                  #However, can check whether a ROW has pending deletion in either case by checking its xmax
                                  #Rolled back transactions undo any ROW creation|deletion and xmax changes

                                  ┌─────────┐
                                  │   CID   │
                                  └─────────┘

cid                               #TYPE. Index of a write statement within a given DATABASE transaction (XID)
                                  #Incrementing, starting at 0
                                  #Cannot use < <= > >=

CID <~=> TEXT                     #Type cast

"ROW_ALIAS".cmin                  #CID of the statement that created|deleted the ROW
"ROW_ALIAS".cmax                  #Identical to cmin

                                  ┌─────────────────┐
                                  │   FROZEN ROWS   │
                                  └─────────────────┘

FREEZING ROWS ==>                 #ROWs with an old xmin are marked as frozen by vacuum (using visibility map)
                                  #This ensures that, even when XIDs wrap around:
                                  #  - their XID is not re-used
                                  #  - their xmin is still considered older than the current session, i.e. remains visible
                                  #Frozen ROWs are unfrozen by any write
                                  #  - since it deletes the old version of the ROW, i.e. creates a new xmin

pg_class.relfrozenxid             #XID. Oldest xmin of the TABLE's not-frozen ROWs.
                                  #Set by vacuum. Initially 0.
                                  #Goal: avoid having to scan all ROWs to know whether some might need to be frozen or not
pg_database.datfrozenxid          #Minimum value for relfrozenxid

SCONF.vacuum_freeze_min_age       #NUM (def: 5e7). Freeze ROWs older than NUM transactions
                                  #Must be at least half of autovacuum_freezen_max_age
PCONF.autovacuum_freeze_max_age   #NUM (def: 2e8, min 1e5). Forces autovacuum (even if disabled)
                                  #if any not-frozen ROW is older than (NUM - vacuum_freeze_min_age) transactions
SCONF.vacuum_freeze_table_age     #NUM (def: 1.5e8). Only check for frozen ROWs in heap pages with dead ROWs,
                                  #unless any not-frozen ROW is older than NUM transactions
                                  #Max value: 95% of autovacuum_freeze_max_age
SCONF.vacuum_failsafe_age         #NUM (def: 1.6e9). If any not-frozen ROW is older than NUM transactions,
                                  #make `vacuum` ignore SCONF.vacuum_cost_* and only perform ROW freezing.
                                  #Min value: 105% of autovacuum_freeze_max_age

vacuum freeze ...                 #Freeze all ROWs, ignoring SCONF.*vacuum_freeze*
vacuum (freeze = true)            #Implied by `vacuum full`
                                  #Might break MVCC

                                  ┌───────────────┐
                                  │   MULTIXACT   │
                                  └───────────────┘

ROW LOCKING ==>                   #When acquiring ROW locks, "ROW_ALIAS".xmax is set with the XID of the locking transaction.
                                  #I.e. xmax has two meaning (locking and deletion), which cannot be distinguished without
                                  #using more complex utilities like pageinspect

MULTIXACT IDS ==>                 #"Multiple transaction ID".
                                  #When more than one transaction locks a ROW, "ROW_ALIAS".xmax is a multixact ID.
                                  #This is a XID, but pointing to an array of transactions, instead of just one.
                                  #Those are stored in pg_multixact/ subdirectory.

pg_get_multixact_members(XID)     #Returns transactions of a multixact ID.
 ->ROW_SET                        #ROW: xid XID2, mode STR (lock mode)
mxid_age(XID)->UINT               #Like age(XID) but for multixact IDs

MULTIXACT WRAPAROUND ==>          #Multixact IDs in xmax have the same wraparound as xmin.
                                  #This is solved the same way, except instead of freezing the ROW, a new more recent xmax is set instead
pg_class.relminmxid               #XID. Like pg_class.relfrozenxid but for multixact IDs
pg_database.datminmxid            #XID. Like pg_database.datfrozenxid but for multixact IDs
SCONF
 .vacuum_multixact_freeze_min_age #NUM (def: 5e6). Same as vacuum_freeze_min_age but for multixact IDs
PCONF.autovacuum_multixact_
 freeze_max_age                   #NUM (def: 4e8). Same as autovacuum_freeze_max_age but for multixact IDs
SCONF.
 vacuum_multixact_freeze_table_age#NUM (def: 1.5e8). Same as vacuum_freeze_table_age but for multixact IDs
SCONF
 .vacuum_multixact_failsafe_age   #NUM (def: 1.6e9). Same as vacuum_failsafe_age but for multixact IDs

                                  ┌────────────────────┐
                                  │   VISIBILITY MAP   │
                                  └────────────────────┘

VISIBILITY MAP ==>                #Bitmap of all heap pages of a TABLE
                                  #Contains 2 bits per heap page.
                                  #"all-visible bit":
                                  #  - set to 0 by any write
                                  #  - set to 1 by vacuum
                                  #  - i.e. 0 means "might" contain uncommitted writes, or dead ROWs
                                  #  - i.e. 1 means latest data can "certainly" be read by any current|future transaction
                                  #  - also set as a PD_ALL_VISIBLE bit in the data itself, as opposed to in the visibility map
                                  #"all-frozen bit":
                                  #  - 1 if has only frozen ROWs
                                  #  - set to 1 by vacuum
                                  #  - set to 0 by any write
                                  #Fast to access
                                  #  - bitmap, i.e. small
                                  #  - usually kept in-memory

pg_visibility[_map]               #Returns visibility map of heap page number INT8 of REGCLASS
 (REGCLASS, INT8)->ROW            #Non-trusted extension 'pg_visibility'
ROW.all_visible                   #BOOL
ROW.pd_all_visible                #BOOL
                                  #Not returned if `_map` (faster)
ROW.all_frozen                    #BOOL

pg_visibility[_map]
 (REGCLASS)->ROW_SET              #Returns visibility map of all heap pages of REGCLASS
pg_visibility_map_summary
 (REGCLASS)->ROW                  #Counts as ROW: all_visible|all_frozen INT8

pg_check_visible|frozen           #Returns TIDs of ROWs with 0 bits in all_visible|frozen,
 (REGCLASS)->TID_SET              #which mismatches actual state of the ROW, i.e. visibility map is corrupted
pg_truncate_visibility_map        #Remove visibility map. It will be rebuilt by next vacuum.
 (REGCLASS)                       #Meant if visibility map corrupted

pg_class.relallvisible            #INT4. Number of RELATION's heap pages with all-visible bit in the visibility map.
                                  #Used by the query planner to estimate cost of sequential scans

DBDIR|CLUSTERDIR/REGCLASS_OID_vm  #Visibility map location

                                  ┌─────────────────┐
                                  │   TRANSACTION   │
                                  └─────────────────┘

begin [work|transaction]          #Start a transaction
start transaction                 #Statements in uncommitted transactions are not:
                                  #  - visible to other sessions
                                  #     - which would otherwise be called a "dirty read"
                                  #  - durable
                                  #However, they wait on locks created by all other transactions, committed or not
                                  #They are committed atomically ("all or nothing")
                                  #If a statement errors, the transaction "aborts", i.e. commit will behave like rollback
                                  #Cannot do it inside another transaction

commit [work|transaction]         #End a transaction
rollback [work|transaction]       #End a transaction, but cancel any statements within it
                                  #Except for: SEQUENCEs, and some aspects of CURSORs
commit|rollback ... and [no] chain#If `and chain`, end a transaction, then start a new one with same characteristics

pg_xact_status(XID8)->STR         #Whether the transaction is 'in progress', 'committed' or 'aborted'
                                  #null if transaction is too old

SINGLE STATEMENTS ==>             #Statements not in a transaction are handled like a single-statement committed transaction
                                  #SQL commands acquire the locks they need
                                  #FUNC() are run in a single `read committed` transaction
                                  #Multiple statements transactions are faster since they only require creating a single transaction

                                  ┌────────────────┐
                                  │   SAVEPOINTS   │
                                  └────────────────┘

savepoint SAVEPOINT               #Mark a specific statement with a SAVEPOINT
                                  #Must be inside a transaction

rollback [work|transaction]       #Rollback to state when SAVEPOINT was created
 to [savepoint] SAVEPOINT         #Delete any other SAVEPOINT created since then

release [savepoint] SAVEPOINT     #Delete a SAVEPOINT
                                  #Automatically done at end of transaction

                                  ┌───────────────┐
                                  │   ISOLATION   │
                                  └───────────────┘

begin isolation level             #Make state consistent at the statement level
 read [un]committed               #Other committed transactions writes are visible
                                  #Default mode

begin isolation level             #Make state consistent at the transaction level
 repeatable read                  #Other committed transactions writes are not visible
                                  #This prevents "nonrepeatable reads":
                                  #  - reads of same ENTITY|ROW in the same transaction give inconsistent results
                                  #  - due to other committed transactions writes
                                  #This also prevents "phantom reads":
                                  #  - same but for reads with a `where BOOL_REXPR`
                                  #  - fixed by predicate locks
                                  #They abort the current transaction if it writes on the same ENTITY|ROW

begin isolation level             #Make state consistent at the database level, with each transaction being atomic
 serializable                     #Same as `repeatable read` except transaction is rolled back on commit if:
                                  #  - other `serializable` transactions wrote on ENTITY|ROWs read by current transaction
                                  #  - providing current transaction might have used the result, i.e. by performing a write
                                  #This prevents "serialization anomaly"
                                  #  - e.g. two transactions inserting count(*) on same TABLE

begin ... read write|only         #If `read only` (def: `read write`), cannot write (except to TEMP)
                                  #This allows some concurrency optimization

begin ... [not] deferrable        #If `deferrable` (def: `not deferrable`), `serializable` and `read only`,
                                  #the transaction's first query initially waits for any concurrent transactions which might cancel it, or vice-versa
                                  #Good for long transactions.

PREDICATE LOCK ==>                #Locks created by `serializable` transactions to check whether it should abort.
                                  #They do not block other transactions
                                  #They can use a `where BOOL_REXPR` instead of a set of ROWs
PCONF.
 max_pred_locks_per_transaction   #NUM (def: 64). Max predicate locks per transaction
HCONF.max_pred_locks_per_relation #NUM (def: -2). If > NUM predicate locks on a given relation, it becomes a table lock
                                  #If NUM is negative, its actual value is max_pred_locks_per_transaction / abs(NUM)
HCONF.max_pred_locks_per_page     #NUM (def: 2). Same for page locks

SCONF.transaction_isolation
SCONF.transaction_read_only       #Current arguments ... of current transaction
SCONF.transaction_deferrable      #Can be set
set transaction ...               #Changes arguments ... passed to `begin` of current transaction
                                  #Must be before any query
set session characteristics
 as transaction ...               #Changes default arguments ... passed to any future transaction in current session
SCONF
 .default_transaction_isolation
SCONF
 .default_transaction_read_only
SCONF
 .default_transaction_deferrable  #Default arguments ... passed for any transaction in any session

                                  ┌──────────────┐
                                  │   SNAPSHOT   │
                                  └──────────────┘

pg_snapshot                       #TYPE of the "database version" visible by a transaction.
                                  #Taken by the first query of a `repeatable read` or `serializable` transaction ("snapshot isolation")
                                  #Contains:
                                  #  - xmin XID8: transaction with lowest XID8 that is visible
                                  #  - xmax XID8: transaction with highest XID8 that is visible
                                  #  - xips XID8_ARR (def: []): individual uncommitted transactions that are not visible
                                  #Cannot use = <> < <= > >=
'XMIN:XMAX:[XIP,...]'             #PG_SNAPSHOT_UNKNOWN
PG_SNAPSHOT <~=> TEXT             #Type cast

pg_current_snapshot()->PG_SNAPSHOT#Gets PG_SNAPSHOT of current transaction
pg_snapshot_xmin|xmax(PG_SNAPSHOT)
 ->XID8                           #Gets PG_SNAPSHOT's xmin|xmax
pg_snapshot_xip(PG_SNAPSHOT)
 ->XID8_SET                       #Gets PG_SNAPSHOT's xips
pg_visible_in_snapshot
 (XID8, PG_SNAPSHOT)->BOOL        #Whether transaction XID8 is visible in PG_SNAPSHOT

PCONF.old_snapshot_threshold      #NUM (def: -1). Allow PG_SNAPSHOTs older than NUM minutes to be vacuum'd
old_snapshot                      #Untrusted extension to inspect PCONF.old_snapshot_threshold behavior
                                  #Not documented yet

                                  ┌─────────────────────┐
                                  │   SYNCHRONIZATION   │
                                  └─────────────────────┘

pg_export_snapshot()              #Make two transactions have the same PG_SNAPSHOT ("snapshot synchronization")
 ->'SNAPSHOT_ID'                  #Both transactions can still not see each other uncommmited writes
set transaction snapshot          #XID1 must use pg_export_snapshot(), XID2 must use set transaction snapshot
 'SNAPSHOT_ID'                    #`set transaction snapshot` must be before any query
                                  #  - but not pg_export_snapshot()
                                  #XID2 must be either
                                  #  - `repeatable read`
                                  #  - `serializable`, in which case XID1 must be too
                                  #If XID1 is readonly, XID2 must be too

                                  ┌──────────────────────────┐
                                  │   PREPARED TRANSACTION   │
                                  └──────────────────────────┘

prepare transaction 'PXID'        #"Two-phase commit". Rollback current transaction, except CONF changes.
                                  #Saves the statements as PXID (max 200 bytes).
                                  #Transaction must not use notify|[un]listen, TEMP, CURSOR with hold
                                  #PXIDs keeps its locks until committed
                                  #  - it also prevents vacuuming
                                  #  - i.e. should not be kept uncommitted for too long
commit|rollback prepared 'PXID'   #Commit|discard statements stored as PXID.
                                  #Must not be inside a transaction.
                                  #Can be done by other sessions, providing same ROLE or superuser.
                                  #Goal: single session managing transactions of others ("transaction management system")

PCONF.max_prepared_transactions   #Max NUM (def: 0, i.e. disabled) of PXIDs, for all connections

pg_prepared_xacts                 #TABLE with all PXIDs
pg_prepared_xacts.gid             #'PXID'
pg_prepared_xacts.transaction     #XID of PXID
pg_prepared_xacts.prepared        #TIMESTAMPTZ when PXID was created
pg_prepared_xacts.database        #"DATABASE" name

                                  ┌────────────────┐
                                  │   TABLE LOCK   │
                                  └────────────────┘

lock "TABLE",...                  #Acquire a lock on "TABLE",...
                                  #Must be inside a transaction:
                                  #  - released at the end of it
                                  #  - must be at beginning of transaction if `repeatable read` or `serializable`
                                  #Automatically done by SQL commands
                                  #Requires one of `update|delete|truncate` PRIVILEGEs, except:
                                  #  - `row exclusive`: can also be `insert` PRIVILEGE
                                  #  - `access|row share`: requires `select` PRIVILEGE instead

lock ... nowait                   #When lock cannot be acquired, prints an error and rollback the transaction,
                                  #instead of waiting

lock ... in access exclusive mode #Do not allow any other locks
                                  #For commands that prevent others to read data
                                  #In general because they delete|re-create ENTITYs: drop table, truncate, reindex, cluster, vacuum full
                                  #Default mode
lock ... in exclusive mode        #Allow other locks if access share
                                  #For commands that prevent others to `select ... for ...`
lock ...                          #Allow other locks if access|row share
 in share row exclusive mode      #For commands that prevent others to write|delete data
lock ... in share mode            #Same as `share row exclusive` except allow other locks to be `share`
lock ...                          #Allow other locks if access|row share or row exclusive
 in share update exclusive mode   #For commands that change DDLs, such as vacuum|analyze, comment
lock ... in row exclusive mode    #For commands that write|delete data
lock ... in row share mode        #For `select ... for ...`
lock ... in access share mode     #For commands that read data

SCONF.lock_timeout                #NUM (in ms, def: 0). Max amount of time to wait for a lock
ZSCONF.deadlock_timeout           #INT (in ms, def: 1000). After that amount of times, check for deadlocks.
                                  #If a deadlock is detected, abort those transactions.
                                  #Should be higher than the average time for a transaction, because deadlock
                                  #check is slow, and to allow ending transactions to resolve locks.
PCONF.max_locks_per_transaction   #NUM (def: 64). Max locks per transaction

                                  ┌──────────────┐
                                  │   ROW LOCK   │
                                  └──────────────┘

select ... for ...                #Acquire a lock on TABLE ROWs
                                  #Acquired|released inside a transaction, like TABLE locks
                                  #  - i.e. not only for the specific `select` statement
                                  #Cannot use union|intersect|except, distinct nor group by, having, AFUNC|WFUNC
select ... for ... of "TABLE",... #Which TABLE to lock. Def: all in the select statement
                                  #Can do multiple `for ...` (space-separated)

select ... for ... nowait         #Like lock ... nowait
select ... for ... skip locked    #If the lock cannot be acquired, ignore the ROW

select ... for update             #Prevent ROWs from being deleted|updated
                                  #Do not allow any other ROW locks
                                  #For commands that write those ROWs, such as `delete`, or `update` on unique COLs
select ... for no key update      #Prevent ROWs from being deleted|updated
                                  #Allow `for key share` locks
                                  #For commands that write those ROWs, but `update` are on non-unique COLs
select ... for share              #Prevent ROWs from being deleted|updated
                                  #For commands that read those ROWs, including non-unique COLs
select ... for key share          #Prevent ROWs from being deleted, or `update` on unique COLs
                                  #For commands that read those ROWs, but only unique COLs

pgrowlocks('TABLE')->ROW_SET      #ROW locks on TABLE
                                  #Non-trusted EXTENSION 'pgrowlocks'
ROW.locked_row                    #TID of ROW
ROW.modes                         #STR_ARR with 'Key Share', 'Share', 'For No Key Update', 'No Key Update', 'For Update', 'Update'
                                  #Multiple if multixact
ROW.locker                        #XID of locking transaction|multixact
ROW.multi                         #BOOL. Whether multixact
ROW.xids                          #XID_ARR if multixact
ROW.pids                          #BPID_ARR. Multiple if multixact

                                  ┌───────────────────┐
                                  │   ADVISORY LOCK   │
                                  └───────────────────┘

pg_advisory_lock(INT8)            #Acquire an advistory lock, i.e. lock linked to an ID (INT8)
                                  #If locked by:
                                  #  - same session: succeeds, and requires additional unlock then
                                  #  - other session: waits until unlocked
pg_try_advisory_lock(INT8)->BOOL  #Same except return false instead of waiting

pg_advisory_unlock(INT8)->BOOL    #false if:
                                  #  - no lock
                                  #  - locked by another session
                                  #Automatically done at end of session
pg_advisory_unlock_all()          #

pg_advisory_xact_*(INT8)          #Automatically release at end of transaction, instead of session

pg_advisory_*_shared(INT8)        #Allow other lock_shared() (but not other lock())
pg_advisory_unlock_shared(INT8)   #

pg_advisory_*(INT4, INT4)         #Same with two INT4s instead of a INT8

                                  ┌────────────────┐
                                  │   LIST LOCKS   │
                                  └────────────────┘

pg_blocking_pids(BPID)->BPID2_ARR #BPID2s preventing BPID from acquiring a lock
pg_safe_snapshot_blocking_pids
 (BPID)->BPID2_ARR                #BPID2s blocking BPID's `begin ... deferrable`

pg_locks                          #TABLE with all locks
                                  #Most of them are null if not relevant for the given locktype

pg_locks.locktype                 #Lock type among:
                                  #  - relation: TABLE lock
                                  #  - tuple: ROW lock
                                  #  - advisory: pg_advisory*
                                  #Those others are mostly internal:
                                  #  - object: ENTITY
                                  #  - extend: add a COL to a TABLE
                                  #  - spectoken: inserting a ROW
                                  #  - frozenid: setting pg_database.datfrozenxid|datminmxid
                                  #  - page: heap page
                                  #  - transactionid: wait for a transaction to end
                                  #  - virtualxid
                                  #  - userlock

pg_locks.granted                  #BOOL. Whether lock is held, as opposed to awaited.
pg_locks.waitstart                #TIMESTAMPTZ. When starting waiting for lock
pg_locks.fastpath                 #BOOL. Whether lock was cached

pg_locks.pid                      #BPID
pg_locks.database                 #pg_database.oid of the DATABASE
                                  #0 if shared object

pg_locks.relation                 #pg_class.oid of the TABLE being locked
pg_locks.mode                     #STR. Lock mode if locktype 'relation|tuple'
                                  #Is 'SIReadLock' if predicate lock
pg_locks.page                     #INT4. Heap page number
pg_locks.tuple                    #INT2. Index ROW being locked within its heap page
pg_locks.classid
pg_locks.objid
pg_locks.objsubid                 #ENTITY with locktype 'object'
pg_locks.virtualxid               #STR. Virtual ID if locktype 'virtualxid'
pg_locks.virtualtransaction       #STR. Virtual ID of the other transaction
pg_locks.transactionid            #XID of transaction, if locktype 'transactionid'

                                  ┌────────────┐
                                  │   VACUUM   │
                                  └────────────┘

vacuum (OPTS)                     #Does:
 ["TABLE"[("COL",...)]]           #  - delete dead ROWs on:
                                  #     - TABLEs
                                  #     - INDEXs ("index cleanup")
                                  #        - only after a specific amount of dead ROWs on TABLE have accumulated
                                  #  - freeze ROWs
                                  #     - and update multixact IDs to avoid wraparound
                                  #  - update visibility map
                                  #  - update FSM values
                                  #  - update pg_class.relhas*|relpages|reltuples|relallvisible
                                  #  - update pg_stat.*
                                  #Def "TABLE": all that current ROLE has permissions
                                  #Def "COL": all
                                  #Cannot be done inside a transaction
                                  #Makes database slower during vacuuming

vacuum analyze ...
OPTS.analyze                      #BOOL (def: false). Run `analyze`

vacuum verbose ...
OPTS.verbose                      #BOOL (def: false). Print details

vacuum full ...                   #BOOL (def: false)
OPTS.full                         #Unless specified:
                                  #  - deleted dead ROWs can be used for new writes
                                  #  - but the memory taken by their heap page, if empty, is not freed to the OS
                                  #  - i.e. the TABLE size does not shrink (from an OS standpoint)
                                  #Do a full TABLE rewrite, i.e. requires `exclusive` lock
                                  #Slow and should be used only when necessary

OPTS.truncate                     #BOOL. When true (def), free the OS space of empty heap pages
TOPTS.vacuum_truncate             #(due to deleted dead ROWs), if at the end of TABLE.
                                  #Requires `access exclusive` lock when this happens
                                  #  - skipped if cannot obtain the lock

OPTS.index_cleanup                #on|off or auto (def). Whether to delete dead ROWs on INDEXs
TOPTS.vacuum_index_cleanup        #If auto, done if there are enough dead ROWs on the TABLE of the INDEXs
                                  #Always `on` if `vacuum full`

OPTS.disable_page_skipping        #BOOL. If false (def), ignore heap pages with a visibility map having either:
                                  #  - all_visible 1
                                  #     - except with `vacuum full`
                                  #  - all_frozen 1
                                  #Also ignores some heap pages if locked by other transactions
                                  #Can be set to true if visibility map is corrupted

OPTS.skip_locked                  #BOOL (def: false). `vacuum` requires `shared update exclusive` lock.
                                  #If true and the lock cannot be obtained immediately, skip vacuuming the specific TABLE.
                                  #Only for normal TABLEs, not for its INDEXs, child TABLEs, or FTABLEs.

OPTS.parallel                     #Max NUM of parallel workers when vacuuming INDEXs
                                  #Max 1 per INDEX on a given TABLE
                                  #Def: max, i.e. NUM of INDEXs on the TABLE
                                  #Only on INDEXs matching SCONF.min_parallel_table_scan_size
                                  #Cannot be used with `vacuum full`

pg_class.relhasindex|relhasrules  #Set to true immediately, but only set to false by `vacuum`.
 |relhastriggers|relhassubclass   #I.e. might be true if ENTITY was dropped recently

pg_stat_scan_tables               #Members of that built-in ROLE can access TABLEs through commands like `vacuum`

                                  ┌─────────────────────┐
                                  │   VACUUM PROGRESS   │
                                  └─────────────────────┘

pg_stat_progress_vacuum           #TABLE with ongoing `vacuum` statements

pg_stat_progress_vacuum.relid     #REGCLASS of TABLE
pg_stat_progress_vacuum.datid     #pg_database.oid of DATABASE
pg_stat_progress_vacuum.datname   #NAME of "DATABASE"
pg_stat_progress_vacuum.pid       #BPID
pg_stat_progress_vacuum.phase     #STR among:
                                  #  - 'initializing'
                                  #  - 'scanning heap': read heap, freeze ROWs
                                  #  - 'vacuuming indexes': remove dead ROWs of INDEX
                                  #  - 'vacuuming heap': remove dead ROWs of TABLE, update visibility map
                                  #  - 'cleaning up indexes'
                                  #  - 'truncating heap'
                                  #  - 'performing final cleanup': update FSM, pg_class.rel*, pg_stat*
pg_stat_progress_vacuum
 .heap_blks_total                 #INT8. Amount of heap pages in total
pg_stat_progress_vacuum
 .heap_blks_scanned               #INT8. Amount of heap pages read, progressing during 'scanning heap'
pg_stat_progress_vacuum
 .heap_blks_vacuumed              #INT8. Number of heap pages vacuumed, progressing during 'vacuuming heap'
pg_stat_progress_vacuum
 .num_dead_tuples                 #INT8. Number of dead ROWs collected on TABLE during 'vacuuming heap'
pg_stat_progress_vacuum
 .max_dead_tuples                 #INT8. After that many number of dead ROWs, INDEX will need to be vacuumed
pg_stat_progress_vacuum
 .index_vacuum_count              #INT8. Number of completed rounds during 'vacuuming indexes'

                                  ┌─────────────────┐
                                  │   VACUUM COST   │
                                  └─────────────────┘

SCONF.vacuum_cost_delay           #NUM (def: disabled, in ms) or 'DURATION'.
                                  #Make vacuum sleep NUMms if it takes too much resources.
SCONF.vacuum_cost_limit           #NUM (def: 200). Cost threshold that triggers vacuum to sleep
SCONF.vacuum_cost_page_hit        #NUM (def: 1). Cost to read from cache
SCONF.vacuum_cost_page_miss       #NUM (def: 2). Cost to read from disk
SCONF.vacuum_cost_page_dirty      #NUM (def: 20). Cost to write

                                  ┌────────────────┐
                                  │   AUTOVACUUM   │
                                  └────────────────┘

HCONF.autovacuum                  #BOOL (def: false). Automatically run `vacuum [analyze]` on TABLEs
                                  #Not run on TEMP TABLEs nor CHILD_TABLEs (including through partition)
                                  #`analyze` not run on FTABLEs
HCONF.
 autovacuum_vacuum_scale_factor   #NUM (def: 0.2)
HCONF.autovacuum_vaccum_threshold #NUM (def: 50). Run autovacuum after NUM inserted|updated|deleted ROWs * autovacuum_vacuum_scale_factor
HCONF.autovacuum_vacuum_
 insert_scale_factor              #NUM (def: 0.2)
HCONF.autovacuum_vaccum_
 insert_threshold                 #NUM (def: 1000). Run autovacuum after NUM inserted ROWs * autovacuum_vacuum_insert_scale_factor
HCONF.autovacuum_analyze_
 scale_factor                     #NUM (def: 0.1)
HCONF.autovacuum_analyze_threshold#NUM (def: 50). Same for `vacuum analyze`
HCONF.autovacuum_naptime          #STR (def: '1min'). Mininum duration between 2 autovacuums, per DATABASE
PCONF.autovacuum_max_workers      #NUM (def: 3) of DATABASEs that can be vacuumed at the same time

HCONF.autovacuum_cost_delay       #NUM (def: 2ms). Like SCONF.vacuum_cost_delay, but only during autovacuum
HCONF.autovacuum_cost_limit       #NUM (def: not set). Like SCONF.vacuum_cost_limit, but only during autovacuum

TOPTS.*autovacuum*                #Set SCONF.*autovacuum* for this TABLE
                                  #Not for: autovacuum_naptime|max_workers
                                  #Different names:
                                  #  - autovacuum -> autovacuum_enabled
                                  #  - vacuum_freeze_* -> autovacuum_freeze_*
TOPTS.toast.*autovacuum*          #Same but only for pg_toast_OID TABLE
                                  #Def: same value
                                  #Not for: autovacuum_analyze*

HCONF.autovacuum_work_mem         #NUM (in KB). Max memory used by each `vacuum` worker process
                                  #Def: -1, i.e. same as SCONF.maintenance_work_mem

                                  ┌──────────┐
                                  │   ROLE   │
                                  └──────────┘

create role "ROLE"                #Create a ROLE, i.e. identity with sets of PRIVILEGEs and ownerships, for a given CLUSTER.
create|alter user ...             #Same as create role ... except `login` is true by default

create|alter role "ROLE"          #Whether the ROLE is superuser:
 [no]superuser                    #  - has all PRIVILEGEs
                                  #  - is implicitly a member of all ROLEs
                                  #Current ROLE must be superuser too
ICONF.is_superuser                #BOOL. Readonly

pg_authid                         #TABLE with all ROLEs
                                  #Visible only to superuser
pg_authid.oid                     #OID
pg_authid.rolname                 #"ROLE" name
pg_authid.rolsuper                #BOOL. create role ... superuser
pg_authid.rolinherit              #BOOL. create role ... inherit
pg_authid.rolcreaterole           #BOOL. create role ... createrole
pg_authid.rolcreatedb             #BOOL. create role ... createdb
pg_authid.rolcanlogin             #BOOL. create role ... login
pg_authid.rolreplication          #BOOL. create role ... replication
pg_authid.rolbypassrls            #BOOL. create role ... bypasssrl
pg_authid.rolconnlimit            #INT4. create role ... connection limit
pg_authid.rolpassword             #STR|null. create role ... password
pg_authid.rolvaliduntil           #TIMESTAMPTZ|null. create role ... valid until

regrole                           #TYPE to cast pg_authid.oid as "ROLE" name
pg_get_userbyid(ROLE_OID)->'ROLE' #

pg_roles                          #Higher-level VIEW on pg_authid
                                  #pg_roles blanks out the password
pg_roles.oid
pg_roles.rolname
pg_roles.rolsuper
pg_roles.rolinherit
pg_roles.rolcreaterole
pg_roles.rolcreatedb
pg_roles.rolcanlogin
pg_roles.rolreplication
pg_roles.rolbypassrls
pg_roles.rolconnlimit
pg_roles.rolvaliduntil            #Like pg_authid.*
pg_roles.rolpassword              #'********'|null
pg_roles.rolconfig                #ROLE-specific 'CONFVAR=VAL'_ARR, taken from pg_db_role_setting

pg_shadow
pg_user                           #Deprecated TABLE alternatives to pg_roles

                                  ┌───────────────────┐
                                  │   ROLE BUILT-IN   │
                                  └───────────────────┘

CLUSTER FIRST ROLE ==>            #Has same name as CLUSTER owner's OS_USER, who can authenticate to it
                                  #Is a superuser ROLE
                                  #Cannot be deleted
initdb --username|-U ROLE         #Override cluster's first ROLE name

public                            #Implicit ROLE that any other ROLE belongs to
"[R]PROLE"                        #Either "[R]ROLE" or public

BUILT-IN ROLES ==>                #Their permissions are hardcoded in Postgres code, not in ACLITEMs

pg_read_all_data                  #Built-in ROLE with PRIVILEGEs:
                                  #  - `select` on all RELATION|SEQUENCE|LARGEOBJs
                                  #  - `usage` on all SCHEMAs
pg_write_all_data                 #Built-in ROLE with PRIVILEGEs:
                                  #  - `update` on all RELATION|SEQUENCE|LARGEOBJs
                                  #  - `insert|delete` on all RELATIONs
                                  #  - `usage` on all SCHEMAs
pg_monitor                        #Built-in ROLE with PRIVILEGEs:
                                  #  - member of ROLEs: pg_read_all_settings, pg_read_all_stats, pg_stat_scan_tables
                                  #  - pg_ls_*() (except pg_ls_dir())

pg_read_server_files              #Built-in ROLE that can read filesystem with same OS privileges as server process including:
                                  #  - COPY ... from 'PATH'
                                  #  - pg_ls*()
pg_write_server_files             #Same but to write filesystem:
                                  #  - COPY ... to 'PATH'
                                  #  - pg_basebackup --target=PATH
pg_execute_server_program         #Same but to execute OS commands:
                                  #  - COPY ... from|to program

                                  ┌─────────────────────┐
                                  │   ROLE MEMBERSHIP   │
                                  └─────────────────────┘

create role "ROLE"                #Makes ROLE2 members of ROLE:
 in role "ROLE2",...              #  - ROLE2 inherits ROLE's PRIVILEGEs
create role "ROLE2" role "ROLE"   #     - except superuser|login|createdb|createrole PRIVILEGEs
grant "ROLE",... to "ROLE2",...   #  - ROLE2 can switch to ROLE
                                  #Membership is inherited deeply
                                  #I.e. ROLEs can be used as "groups", not only "users"

revoke "ROLE",... to "ROLE2",...  #Remove membership
 [restrict|cascade]               #Whether to also removes the related PRIVILEGEs

create|alter group ...            #Deprecated alternative syntax

create|alter role "ROLE"          #If inherit (def), members inherit parent ROLE's PRIVILEGEs
 [no]inherit                      #Regardless of [no]inherit, members can switch to parent ROLE

pg_auth_members                   #TABLE with ROLE memberships
pg_auth_members.roleid            #REGROLE of parent ROLE
pg_auth_members.member            #REGROLE of member ROLE
pg_auth_members.grantor           #REGROLE which granted the membership
pg_auth_members.admin_option      #BOOL

pg_has_role(["ROLE"|ROLE_OID,]
 'ROLE2'|ROLE2_OID, 'member')
 ->BOOL                           #Whether ROLE can `set role ROLE2`
pg_has_role(["ROLE"|ROLE_OID,]
 'ROLE2'|ROLE2_OID, 'usage')
 ->BOOL                           #Whether ROLE's PRIVILEGEs are a subset of ROLE2's

                                  ┌───────────────┐
                                  │   SUPAUTILS   │
                                  └───────────────┘

supautils                         #EXTENSION version 1.7.2
                                  #Protects ROLEs

SCONF.supautils.reserved_roles    #'ROLE,...' that cannot be altered by other non-superuser ROLEs, even if they have `createrole` PRIVILEGE
SCONF.supautils
 .reserved_memberships            #'ROLE,...' that other non-superuser ROLEs cannot become a member of

SCONF.supautils
 .privileged_extensions           #'EXTENSION,...'. Use a different 'ROLE' than superuser with those EXTENSIONs
SCONF.supautils
 .privileged_extensions_superuser #'ROLE'
SCONF.supautils.privileged
 _extensions_custom_scripts_path  #'PATH'

                                  ┌──────────────────┐
                                  │   ROLE SESSION   │
                                  └──────────────────┘

"RROLE"                           #Either "ROLE", current_role|user or session_user

ENVVAR PGUSER
LIBPQ.user                        #"Initial session ROLE", i.e. ROLE that starts the session
psql DATABASE ROLE                #Def: same name as CLIENT_USER
psql --username|-u ROLE           #Used to check for permission to `set session authorization`

session_user                      #ROLE that can be changed by `set session authorization`
                                  #Initially same as initial_session_user
                                  #Used to check for permission to `set role`

[current_]user                    #ROLE that can be changed by `set role`
current_role                      #Initially same as session_user
                                  #Used for PRIVILEGEs

set role 'ROLE'                   #Sets current_role
                                  #session_user must a member of new ROLE
reset role
set role none                     #Sets current_role to session_user

set session authorization 'ROLE'  #Sets current_role + session_user
                                  #initial_session_user must be superuser
reset session authorization
set session authorization default #Sets current_role + session_user to initial_session_user

set local|session role|session ...#Same as set local|session CONFVAR ...

insert_usernames("COL")           #TFUNC which sets TABLE."COL" = current_role
                                  #Must be `before insert or update` + `for each row`
                                  #Part of spi EXTENSION

                                  ┌───────────┐
                                  │   OWNER   │
                                  └───────────┘

ENTITY OWNER ==>                  #Def: ROLE that created the ENTITY
                                  #ROLE has all PRIVILEGEs over their ENTITYs
                                  #  - as "default PRIVILEGEs", i.e. on creation
                                  #  - can be revoked
                                  #ROLE is parent dependency of owned ENTITYs
                                  #  - cannot `drop cascade`, i.e. can only be deleted if it does not own any ENTITY
                                  #For all ENTITYs but:
                                  #  - not for: role, user mapping, text search parser|template
                                  #  - always same as TABLE's owner: index, rule, trigger, policy
                                  #  - readonly for: extension

alter ENTITY "ENTITY"             #Change owner
 owner to RROLE                   #Current ROLE must:
                                  #  - be RROLE, or a member of it
                                  #  - have `create` PRIVILEGE on ENTITY's SCHEMA
reassign owned                    #Same for all ENTITYs owned by RROLE
 by RROLE,... to RROLE2           #Includes cluster-wide ENTITYs, but excludes ENTITYs in other DATABASEs

drop owned by RROLE,...           #Drop all ENTITYs owned by RROLE, except cluster-wide ones
                                  #Also revoke PRIVILEGEs for RROLE on those ENTITYs, including cluster-wide ones

create database "DATABASE"
 owner "ROLE"                     #Must be current ROLE (def) or a member of it

pg_database_owner                 #Built-in ROLE that DATABASE owner's ROLE is a member of.
                                  #Owns `public` SCHEMA, i.e. with `create` and `usage` PRIVILEGEs
                                  #In a DATABASE's TEMPLATE:
                                  #  - can grant PRIVILEGEs to pg_database_owner
                                  #  - to forward those to actual owner after TEMPLATE has been instantiated

create tablespace ... owner RROLE #Def: current ROLE

create schema ["SCHEMA"]          #Set SCHEMA's owner
 authorization RROLE              #Def "SCHEMA": ROLE

pg_database.datdba                #REGROLE of DATABASE's owner
pg_namespace.pg_nspowner          #REGROLE of SCHEMA's owner
pg_type.typowner                  #REGROLE of TYPE's owner
pg_largeobject_metadata.lomowner  #REGROLE of LARGEOBJ's owner
pg_class.relowner                 #REGROLE of RELATION's owner
pg_tables.tableowner              #REGROLE of TABLE's owner
pg_views.viewowner                #REGROLE of VIEW's owner
pg_matviews.matviewowner          #REGROLE of MVIEW's owner
pg_sequences.sequenceowner        #REGROLE of SEQUENCE's owner
pg_ts_dict.dictowner              #REGROLE of DICTIONARY's owner
pg_ts_config.cfgowner             #REGROLE of REGCONF's owner
pg_conversion.conowner            #REGROLE of CONVERSION's owner
pg_collation.collowner            #REGROLE of COLLATION's owner
pg_opfamily.opfowner              #REGROLE of OPFAMILY's owner
pg_opclass.opcowner               #REGROLE of OPCLASS's owner
pg_extension.extowner             #REGROLE of EXTENSION's owner
pg_language.lanowner              #REGROLE of LANGUAGE's owner
pg_foreign_data_wrapper.fdwowner  #REGROLE of FDW's owner
pg_foreign_server.srvowner        #REGROLE of FSERVER's owner
pg_tablespace.spcowner            #REGROLE of TABLESPACE's owner
pg_proc.proowner                  #REGROLE of FUNC's owner
pg_event_trigger.evtowner         #REGROLE of EFUNC's owner
pg_operator.oprowner              #REGROLE of OP's owner
pg_publication.pubowner           #REGROLE of PUB's owner
pg_subscription.subowner          #REGROLE of SUB's owner
pg_statistic_ext.stxowner         #REGROLE of STATISTICS's owner
pg_stats_ext[_exprs]
 .statistics_owner                #"ROLE" name of STATISTICS's owner
pg_prepared_xacts.owner           #"ROLE" name of PXID's owner

                                  ┌─────────────────┐
                                  │   ROLE CALLER   │
                                  └─────────────────┘

VOPTS.security_invoker            #BOOL. In SUBQUERY on VIEW, whether to use ROLE of:
                                  #  - false (def): VIEW owner
                                  #  - true: query caller
                                  #Whether false|true, query caller's ROLE is used:
                                  #  - in FUNC() calls in SUBQUERY
                                  #  - to know whether VIEW itself can be used

create|alter function|procedure   #Uses ROLE of:
 ... [external]                   #  - security invoker (def): caller
 security invoker|definer         #  - security definer: FUNC owner
                                  #If `security definer`:
                                  #  - forbids `set role`
                                  #  - should protect against SCONF.search_path attacks

                                  ┌──────────────────────┐
                                  │   PRIVILEGES GRANT   │
                                  └──────────────────────┘

grant PRIVILEGE,...               #Add PRIVILEGEs to a ROLE for a given ENTITY
 on [ENTITY] "ENTITY",...         #For ENTITYs:
 to "RPROLE",...                  #  - table (def): RELATION (except SEQUENCE)
                                  #  - sequence
                                  #  - database
                                  #  - type
                                  #  - domain
                                  #  - function|procedure|routine
                                  #  - language
                                  #  - schema
                                  #  - tablespace
                                  #  - large object
                                  #  - foreign data wrapper
                                  #  - foreign server
                                  #  - parameter: "CONFVAR"
grant ... on all ENTITYs
 in schema "SCHEMA" ...           #For ENTITYs: tables|sequences, function|procedures|routines
grant all [privileges] ...        #Grant all PRIVILEGEs (with known ACLs) for a given ENTITY

revoke PRIVILEGE,...              #Remove PRIVILEGEs from a ROLE for a given ENTITY
 on [ENTITY] "ENTITY",...         #Always also remove grant|admin PRIVILEGEs
 from "PROLE",...                 #Revoking a PRIVILEGE does not deny it, it just removes it
                                  #  - might still be granted when inherited through:
                                  #     - ROLE membership
                                  #     - parent ENTITY:
                                  #        - RELATION -> COL
                                  #        - DATABASE -> RELATION: for `analyze`

revoke ... restrict|cascade       #If ROLE granted PRIVILEGEs to other ROLE2s:
                                  #  - restrict (def): fail
                                  #  - cascade: revoke them too

grant|revoke ... granted by RROLE #Requires current_user to be RROLE

has_ENTITY_privilege
 (["ROLE"|ROLE_OID, ]
 'ENTITY'|ENTITY_OID,
 'PRIVILEGE,...')->BOOL           #Whether ROLE (def: current_role) has PRIVILEGE (or any of them) in ENTITY
has_any_column_privilege
 (...)->BOOL                      #Same as has_table_privilege(...) but for any of its COLs
has_column_privilege
 (["ROLE"|ROLE_OID, ]
 'ENTITY'|ENTITY_OID,
 "COL"|COL_NUM, 'PRIVILEGE,...')
 ->BOOL                           #Same for a single COL

                                  ┌────────────────────────┐
                                  │   PRIVILEGES DEFAULT   │
                                  └────────────────────────┘

alter default privileges          #Like `grant`, but on "default PRIVILEGEs":
 grant PRIVILEGE,... on ENTITYs   #  - PRIVILEGEs assigned to newly created ENTITYs
 to "PROLE",...                   #  - does not apply to ENTITYs already created
                                  #Includes:
                                  #  - owner PRIVILEGEs
                                  #  - PRIVILEGEs inherited through membership (e.g. from `public` ROLE)
                                  #Only for ENTITYs: tables (RELATIONs), sequences, functions|routines, types, schemas
alter default privileges
 revoke PRIVILEGE,... on ENTITYs
 from "PROLE",...                 #Same for `revoke`

alter default privileges          #Only for ENTITYs created by ROLE
 for role|user "ROLE" ...         #Must be current_role (def) or one of its child ROLEs

alter default privileges
 in schema "SCHEMA" ...           #Only for ENTITYs created in SCHEMA

PUBLIC PRIVILEGES ==>             #`public` ROLE has default PRIVILEGEs:
                                  #  - DATABASE: connect, temp
                                  #  - TYPE|DOMAIN: usage
                                  #  - FUNC: execute
                                  #  - LANGUAGEs: usage
                                  #Cannot have `grant` PRIVILEGE

acldefault('CHAR', REGROLE)       #Default PRIVILEGEs of ENTITYs 'CHAR' owned by REGROLE
 ->ACLITEM_ARR                    #'CHAR' can be:
                                  #  - 'd': DATABASE
                                  #  - 'p': CONFVAR
                                  #  - 'n': SCHEMA
                                  #  - 'T': TYPE|DOMAIN
                                  #  - 'r': RELATION
                                  #  - 'c': COL
                                  #  - 's': SEQUENCE
                                  #  - 'L': LARGEOBJ
                                  #  - 'l': LANGUAGE
                                  #  - 'f': FUNC
                                  #  - 't': TABLESPACE
                                  #  - 'F': FDW
                                  #  - 'S': FSERVER

pg_default_acl                    #TABLE with default PRIVILEGEs
pg_default_acl.oid                #OID
pg_default_acl.defaclrole         #REGROLE who created it
pg_default_acl.defaclobjtype      #ENTITY among: 'r' (RELATIONs), 'S' (sequences), 'f' (functions|routines), 'T' (types), 'n' (schemas)
pg_default_acl.defaclnamespace    #REGNAMESPACE of ENTITY
pg_default_acl.defaclacl          #ACLITEM_ARR

                                  ┌────────────────────────┐
                                  │   PRIVILEGES INITIAL   │
                                  └────────────────────────┘

INITIAL PRIVILEGES ==>            #PRIVILEGEs granted either by:
                                  #  - initdb:
                                  #     - on pg_catalog.*
                                  #     - on some superuser-restricted pg_*() (like pg_ls*()) and lo_import|export()
                                  #  - `grant` inside an EXTENSION's SQLMAIN

pg_init_privs                     #TABLE with initial privileges
pg_init_privs.classoid
pg_init_privs.objoid
pg_init_privs.objsubid            #ENTITY
pg_init_privs.privtype            #'i' if granted by initdb, 'e' if by EXTENSION
pg_init_privs.initprivs           #ACLITEM_ARR

                                  ┌─────────────────────┐
                                  │   PRIVILEGES LIST   │
                                  └─────────────────────┘

ALTER|DROP ==>                    #PRIVILEGE on any ENTITY, no ACL
                                  #`alter|drop` on that ENTITY
                                  #Also settings like: comment, POLICY, etc.
                                  #Always granted to owner ROLE (and members), cannot be granted to others

grant ... with grant option       #PRIVILEGE on any ENTITY, no ACL
revoke grant options for ...      #Calling `grant PRIVILEGE` on that ENTITY

create role "ROLE2" admin "ROLE"
grant "ROLE",... to "ROLE2",...
 with admin options
revoke admin options for          #PRIVILEGE on a ROLE, no ACL
 "ROLE",... to "ROLE2",...        #Calling `grant "ROLE"`

create|alter role "ROLE"          #PRIVILEGE, no ACL
 [no]bypassrls                    #Not being impacted by row-level security
                                  #Can only be granted by superusers

create|alter role ... createrole  #PRIVILEGE, no ACL
                                  #Create any ROLE (including with higher PRIVILEGEs)
                                  #Implies `admin` PRIVILEGE
                                  #Only allow doing so on superuser ROLE, if current ROLE is superuser

create|alter role ... createdb    #PRIVILEGE on a CLUSTER, no ACL
                                  #Create a DATABASE

connect                           #PRIVILEGE on DATABASE, with ACL: c
                                  #Start a client session
                                  #Without it, can still start a client session with a different ROLE, then switch to ROLE2
create|alter role ... login       #Same but for a given ROLE. No ACL.

create|alter role ... replication #PRIVILEGE, no ACL
                                  #Be used as ROLE consuming physical|logical replication
                                  #Can only be granted by superusers
                                  #Required by pg_basebackup

set                               #PRIVILEGE on a CONFVAR, with ACL: s
                                  #Setting CONFVAR value that otherwise require superuser ROLE
alter system                      #PRIVILEGE on an CONFVAR, with ACL: A
                                  #Setting CONF with `alter system`

create                            #PRIVILEGE on DATABASE, with ACL: C
                                  #Create SCHEMA|PUBLICATION, enable EXTENSION
create                            #PRIVILEGE on SCHEMA, with ACL: C
                                  #Create ENTITYs in SCHEMA
                                  #Rename ENTITYs in SCHEMA, if owner
usage                             #PRIVILEGE on SCHEMA with ACL: U
                                  #Read ENTITYs in SCHEMA
                                  #Without PRIVILEGE, can still list ENTITYs names|attributes by using its ENTITY_CATALOG

usage                             #PRIVILEGE on TYPE|DOMAIN with ACL: U
                                  #Create ENTITYs with that TYPE|DOMAIN

select                            #PRIVILEGE on LARGEOBJ, with ACL: r
                                  #Reading content
update                            #PRIVILEGE on LARGEOBJ, with ACL: w
                                  #Updating content

select                            #PRIVILEGE on RELATION|SEQUENCE, with ACL: r
                                  #Reading ROWs
                                  #Including in clauses like `where` or `returning`
                                  #Including through FUNCs, e.g. currval|lastval()
update                            #PRIVILEGE on RELATION|SEQUENCE, with ACL: w
                                  #Updating ROWs
                                  #Including `select ... for ...`
                                  #Including through FUNCs, e.g. setval|nextval()
insert                            #PRIVILEGE on RELATION, with ACL: a
                                  #Adding ROWs
delete                            #PRIVILEGE on RELATION, with ACL: d
                                  #Deleting ROWs
truncate                          #PRIVILEGE on RELATION, with ACL: D
                                  #`truncate`
references                        #PRIVILEGE on RELATION, with ACL: x
                                  #Reading ROWs with a foreign key pointing to that RELATION
trigger                           #PRIVILEGE on RELATION, with ACL: t
                                  #Create TFUNC on that RELATION
select|update|insert|references
 ("COL",...)                      #Same as the PRIVILEGE on the RELATION, but on a COL

temp[orary]                       #PRIVILEGE on DATABASE, with ACL: T
                                  #Create a TEMP RELATION

usage                             #PRIVILEGE on SEQUENCE, with ACL: U
                                  #Using nextval|currval|lastval() (not setval())
                                  #Or'd with select|update PRIVILEGEs
                                  #  - e.g. only needs either select or usage PRIVILEGE to use currval()

usage                             #PRIVILEGE on LANGUAGE, with ACL: U
                                  #Create FUNC with this LANGUAGE
execute                           #PRIVILEGE on FUNC, with ACL: X
                                  #Execute FUNC() (including TFUNC())

create                            #PRIVILEGE on TABLESPACE, with ACL: C
                                  #Assign ENTITYs to TABLESPACE

usage                             #PRIVILEGE on FDW with ACL: U
                                  #Create FSERVER using FDW
usage                             #PRIVILEGE on FSERVER, with ACL: U
                                  #Create FTABLE|FUSERMAP using FSERVER

                                  ┌─────────┐
                                  │   ACL   │
                                  └─────────┘

aclitem                           #TYPE for PRIVILEGEs
                                  #Some PRIVILEGEs do not have ACLs (see above)
                                  #The others are associated with a CHAR (see above)
                                  #Cannot use < <= > >=

'[ROLE]=CHAR.../ROLE2'            #ACLITEM_UNKNOWN
                                  #CHAR: PRIVILEGE
                                  #CHAR*: `grant` PRIVILEGE
                                  #ROLE: having the PRIVILEGE (def: `public`)
                                  #ROLE2: granting the PRIVILEGE
                                  #Does not include default PRIVILEGEs nor owner's PRIVILEGEs

aclexplode(ACLITEM_ARR)->ROW_SET  #Return ACLITEM as ROW_SET
ROW.grantee                       #ROLE. 0 if `public`
ROW.grantor                       #ROLE2
ROW.privilege_type                #'PRIVILEGE'
ROW.is_grantable                  #BOOL. `grant` PRIVILEGE

makeaclitem('ROLE', 'ROLE2',
 'PRIVILEGE,...', BOOL)->ACLITEM  #BOOL is `grant` PRIVILEGE

ACLITEM_ARR @> ACLITEM            #At least one ACLITEM has:
                                  #  - same ROLE[2]
                                  #  - at least the same PRIVILEGEs

pg_database.datacl                #ACLITEM_ARR of DATABASE
pg_namespace.aclitem              #ACLITEM_ARR of SCHEMA
pg_type.typacl                    #ACLITEM_ARR of TYPE|DOMAIN
pg_class.relacl                   #ACLITEM_ARR of RELATION|SEQUENCE
pg_attribute.attacl               #ACLITEM_ARR of COL
pg_largeobject_metadata.lomacl    #ACLITEM_ARR of LARGEOBJ
pg_language.lanacl                #ACLITEM_ARR of LANGUAGE
pg_proc.proacl                    #ACLITEM_ARR of FUNC
pg_tablespace.spcacl              #ACLITEM_ARR of TABLESPACE
pg_foreign_data_wrapper.fdwacl    #ACLITEM_ARR of FDW
pg_foreign_server.srvacl          #ACLITEM_ARR of FSERVER

pg_parameter_acl                  #TABLE with PRIVILEGEs on CONFVARs
pg_parameter_acl.oid              #OID
pg_parameter_acl.parname          #'CONFVAR'
pg_parameter_acl.paracl           #ACLITEM_ARR

                                  ┌────────────────────────┐
                                  │   ROW-LEVEL SECURITY   │
                                  └────────────────────────┘

create policy "POLICY" on "TABLE" #Creates a "row-level security" POLICY, i.e. ROW-wise authorization check
                                  #POLICY is TABLE-specific, including its "POLICY" name

create|alter policy ...           #If false, make current ROW invisible (not with `insert`)
 using (BOOL_REXPR)               #BOOL_EXPR is called with query caller's ROLE, not TABLE's owner
                                  #User might still infer values ("covert channel")
                                  #  - e.g. by checking if a CONSTRAINT fail with them
                                  #  - `with check` can prevent this, before it is called before CONSTRAINTs

create|alter policy ...           #Check new ROWs (with `insert|update`). Errors if false.
 with check (BOOL_REXPR)          #Def: same as `using`
                                  #BOOL_EXPR is called with query caller's ROLE, not TABLE's owner

create policy ...                 #Whether POLICY is
 as permissive|restrictive        #  - permissive (def): allowlist, i.e. at least one permissive POLICY must match
                                  #  - restrictive: denylist, i.e. all restrictive POLICYs must match
                                  #They are combined as:
                                  #  (PERMISSIVE_POLICY or PERMISSIVE_POLICY2 or ...)
                                  #  and RESTRICTIVE_POLICY and RESTRICTIVE_POLICY2 and ...
                                  #If 0 permissive POLICYs: deny any query ("default deny")
                                  #  - including if 0 POLICYs

create policy ... for             #Whether POLICY is applies on `select|insert|update|delete` (same meaning as PRIVILEGEs)
 all|select|insert|update|delete  #Def: 'all'

create|alter policy ...
 to RPROLE,...                    #Def: `public`

alter table ...
 enable|disable row level security#If disabled (def), POLICYs are noop
pg_class.relrowsecurity
pg_tables.rowsecurity             #BOOL. Whether RLS is enabled

alter table ...
 [no] force row level security    #If `no force` (def), POLICYs are noop for TABLE's owner
pg_class.relforcerowsecurity      #BOOL. Whether `[no] force`
row_security_active
 ('TABLE'|TABLE_OID)->BOOL        #Whether RLS is enabled for TABLE + current ROLE

SCONF.row_security                #BOOL (def: true). If false, make POLICYs always emit an error
                                  #Meant for commands which should use full TABLEs, not ROW-wise, like backups

pg_policy                         #TABLE with all POLICYs
pg_policy.oid                     #OID
pg_policy.polname                 #"POLICY" name
pg_policy.polrelid                #REGCLASS of TABLE
pg_policy.polcmd                  #CHAR among '*' (all), 'r' (select), 'a' (insert), 'w' (update), 'd' (delete)
pg_policy.polpermissive           #BOOL. permissive|restrictive
pg_policy.polroles                #REGROLE_ARR. 0 means `public`
pg_policy.polqual                 #PG_NODE_TREE of `using`
pg_policy.polwithcheck            #PG_NODE_TREE of `with check`

pg_policies                       #High-level VIEW on top of pg_policy
pg_policies.policyname            #"POLICY" name
pg_policies.tablename             #"TABLE" name
pg_policies.cmd                   #'ALL|SELECT|INSERT|UPDATE|DELETE'
pg_policies.permissive            #'PERMISSIVE|RESTRICTIVE'
pg_policies.roles                 #"ROLE"_ARR
pg_policies.qual                  #STR of `using`
pg_policies.with_check            #STR of `with check`

create|alter function ...         #Does not give any information about arguments:
 [not] leakproof                  #  - including:
                                  #     - exceptions on some arguments but not others
                                  #     - printing argument value
                                  #  - except: from return value
                                  #Goal:
                                  #  - allow passing ROWs as argument, even if those will be restricted by POLICYs or VOPTS.security_barrier
                                  #  - otherwise, enforces FUNC always called after those, even inside TFUNCs
                                  #Requires `immutable`
                                  #Def:
                                  #  - leakproof if not called with any ROWs restricted by POLICYs or VOPTS.security_barrier
                                  #  - otherwise, not leakproof
                                  #Must be superuser

                                  ┌──────────────┐
                                  │   OS USERS   │
                                  └──────────────┘

CLIENT_USER                       #User name, as specified by client
                                  #Mapped to ROLEs by authentication

OS_USER                           #OS user name
                                  #Used as CLIENT_USER when calling binaries

SERVER OS_USER ==>                #Used when performing OS|filesystem operations
                                  #Cannot be root
                                  #Prefer OS_USER with only permissions over DATADIR
                                  #Default installation creates 'postgres' OS_USER (group 'postgres') for this

ENVVAR PGREQUIREPEER              #'OS_USER' of the server. Fail if does not match.
LIBPQ.requirepeer                 #This prevents hijacking it when server is restarting.

CLUSTER OWNER ==>                 #OS_USER that created the CLUSTER should own DATADIR

                                  ┌──────────────┐
                                  │   HBA FILE   │
                                  └──────────────┘

zPCONF.hba_file                   #'PATH' to HBA file
                                  #On my system: CLUSTERCONFDIR/pg_hba.conf

HBA                               #Main configuration file for authentication
                                  #Whitespace-separated
                                  #Must "-quote whitespaces " and keywords
                                  #Can use #COMMENT
                                  #Can use \-terminated lines
                                  #First matching line is used
                                  #  - should put most likely first for efficiency
DEFAULT HBA ==>                   #On my machine:
                                  #  - any with Unix socket
                                  #  - local IP with TCP + scram-sha-256

HBA[0]                            #Protocol of client authenticating
HBA[3]                            #IPv4|6 of client authenticating
HBA[4]                            #Network mask

HBA[5]                            #Authentication method
HBA[5] trust                      #Always accept
HBA[5] reject                     #Always deny
HBA[5] ident                      #Accept if IDENT[1] for current CLIENT_USER exists
                                  #Current OS_USER uses OS's "ident" utilities
HBA[5] peer                       #Same but current OS_USER does not use OS's "ident" utilities
HBA[5] ldap                       #LDAP authentication method. Not documented yet
HBA[5] radius                     #Radius authentication method. Not documented yet
HBA[5] pam                        #Linux PAM authentication method. Not documented yet
HBA[5] bsd                        #BSD authentication method. Not documented yet

initdb --auth|-A=STR              #Forces an authentication method
initdb --auth-local|host=STR      #Same but only for local|remote connections

HBA[6] VAR=VAL ...                #Authentication method options
                                  #Can be empty

HBA[2]                            #ROLE,... being assumed
HBA[2] all                        #Any ROLE
HBA[2] +ROLE                      #Include any member
HBA[2] @PATH                      #Like HBA[1] @PATH

HBA[1]                            #DATABASE,... being connected to
HBA[1] all                        #Any DATABASE
HBA[1] sameuser                   #DATABASE with same name as ROLE
HBA[1] samerole                   #DATABASE with same name as ROLE or a member
HBA[1] replication                #DATABASE used by physical replication
HBA[1] @PATH                      #To newline-separated file with list of DATABASEs
                                  #Relative to HBA file
                                  #Can include #COMMENT
                                  #Can nest other @PATH

pg_hba_file_rules                 #TABLE with HBA.
                                  #Visible only to superuser
pg_hba_file_rules.line_number     #INT4
pg_hba_file_rules.error           #'MESSAGE'|null. Set if syntax error in HBA
pg_hba_file_rules.type            #STR. HBA[0]
pg_hba_file_rules.database        #STR_ARR. HBA[1]
pg_hba_file_rules.user_name       #STR_ARR. HBA[2]
pg_hba_file_rules.address         #STR. HBA[3]
pg_hba_file_rules.netmask         #STR. HBA[4]
pg_hba_file_rules.auth_method     #STR. HBA[5]
pg_hba_file_rules.options         #STR_ARR. HBA[6]

                                  ┌─────────────────┐
                                  │   UNIX SOCKET   │
                                  └─────────────────┘

HBA[0] local                      #Connect using Unix sockets
                                  #Not with authentication methods: ident

UNIX_SOCKET_DIR/.s.PGSQL.PORT     #Unix socket

postgres -k STR                   #'[@]DIR,...' of Unix sockets
zPCONF.unix_socket_directories    #Can be empty
                                  #If @, is a virtual path instead
                                  #Def on my system: VARDIR

PIDF[4]
ENVVAR PGHOST                     #Absolute '[@]PATH' to Unix socket, as specified by client
LIBPQ.host                        #Def: UNIX_SOCKET_DIR/.s.PGSQL.PORT

PCONF.unix_socket_group           #OS group owning socket
PCONF.unix_socket_permissions     #Unix socket permissions (def: 0777)
                                  #Def: current one

                                  ┌────────────┐
                                  │   TCP/IP   │
                                  └────────────┘

HBA[0] host                       #TCP/IP

PIDF[5]                           #'IPv4|v6,...' of server sockets.
PCONF.listen_addresses            #Can be '*' (IPv4|6), '0.0.0.0' (IPv4) or '::' (IPv6)
postgres -h STR                   #Can be empty
inet_server_addr()->INET          #Def: 'localhost'

ENVVAR PGHOST
LIBPQ.host
psql --host|-h
inet_client_addr()->INET          #'HOSTNAME,...' (def: localhost), as specified by client
ENVVAR PGHOSTADDR                 #Same as 'IPv4|v6,...'
LIBPQ.hostaddr                    #Can't be used with Kerberos, GSSAPI or verify-full SSL

PCONF.port
PIDF[3]
portgres -p NUM                   #Port number (def: 5432)
inet_server_port()->INT4          #One per CLUSTER

ENVVAR PGPORT
LIBPQ.port
psql --port|-p NUM
inet_client_port()->INT4          #'PORT,...' (def: 5432), as specified by client

HBA[3]                            #IPv4|6 of client authenticating
                                  #Can include a network mask (in CIDR notation)
                                  #Can also be a hostname
                                  #  - .DOMAIN includes sub-domains
                                  #Empty if HBA[0] local
HBA[3] all                        #Any
HBA[3] samehost                   #Current machine's IPs
HBA[3] samenet                    #Current machine's subnet

HBA[4]                            #Network mask (in subnet notation) applied to HBA[3]
                                  #Can be empty

                                  ┌───────────┐
                                  │   IDENT   │
                                  └───────────┘

zPCONF.ident_file                 #'PATH' to IDENT file, which maps CLIENT_USER to ROLEs
                                  #On my system: CLUSTERCONFDIR/pg_ident.conf
                                  #Same format as HBA
IDENT[0]                          #IDENT_GROUP
                                  #Can be specified multiple times
IDENT[1]                          #CLIENT_USER
                                  #Can be /REGEXP (partial match)
IDENT[2]                          #ROLE
                                  #Can use \1 referring to first (...) in IDENT[1] /REGEXP

HBA[6] map=IDENT_GROUP            #Use IDENT with IDENT[0] = IDENT_GROUP
                                  #Def: use ROLE with same name as CLIENT_USER
                                  #With identification methods: ident

pg_ident_file_mappings            #TABLE with IDENT
                                  #Visible only to superuser
pg_ident_file_mappings.line_number#INT4
pg_ident_file_mappings.error      #'MESSAGE'|null. Set if syntax error in HBA
pg_ident_file_mappings.map_name   #STR. IDENT[0]
pg_ident_file_mappings.sys_name   #STR. IDENT[1]
pg_ident_file_mappings.pg_username#STR. IDENT[2]

                                  ┌──────────────┐
                                  │   PASSWORD   │
                                  └──────────────┘

HBA[5] password                   #Password authentication method, passed as plain text
HBA[5] md5                        #Same but passed as md5 checksum
HBA[5] scram-sha-256              #Same but passed as SCRAM SHA-256 checksum

ENVVAR PGPASSWORD
LIBPQ.password                    #'PASSWORD|MD5_CHECKSUM' passed for authentication
psql --password|-W
psql --no-password|-w             #Prompt [or not] for password

~/.pgpass                         #Same as 'PATH'
ENVVAR PGPASSFILE                 #Colon-separated fields: host, port, database, user, password
LIBPQ.passfile                    #Fields can be * (except password)
                                  #Permission must be 0600

create|alter role "ROLE"
 password null                    #No password (default)
create|alter role "ROLE"
 password 'PASSWORD|CHECKSUM'     #Set password
create|alter role "ROLE"
 encrypted password ...           #Same
SCONF.password_encryption         #'scram-sha-256' (def) or 'md5'
                                  #Algorithm used for create role ... password 'CHECKSUM'

initdb --pwfile=PATH              #Set CLUSTER's first ROLE's password
initdb --pwprompt|-W              #Same using stdin

create|alter role "ROLE"
 valid until TIMESTAMPTZ          #Expire password after this

ENVVAR PGCHANNELBINDING           #Whether to use channel binding with scram-sha-256, which prevents some man-in-the-middle attacks
LIBPQ.channel_binding             #Can be: 'require', 'prefer' (def), 'disable'

passwordcheck                     #C addon that cancels `create|alter role` if `password "PASSWORD"` too weak
                                  #Only with authentication method 'password'
                                  #Should rebuild the module by modifying the Makefile to enable CrackLib (better weak password recognition)

                                  ┌─────────┐
                                  │   SSL   │
                                  └─────────┘

postgres -l
HCONF.ssl                         #BOOL (def: false). Must be true to allow SSL authentication

HBA[0] host[[no]ssl]              #Def: both with|without SSL

HBA[5] cert                       #Authentication method using SSL certificate

ENVVAR PGSSLMODE                  #Priority of SSL over non-SSL:
LIBPQ.sslmode                     #  - disable: non-SSL
                                  #  - allow: first non-SSL, then SSL
                                  #  - prefer (def): first SSL, then non-SSL
                                  #  - require: SSL. If root CA, verify client certificate
                                  #  - verify-ca: SSL. Always verify client certificate
                                  #  - verify-full: Same but also verify that CLIENT_NAME match in certificate's CN

ENVVAR PGSSLCERT
USERCONFDIR/postgresql.crt
LIBPQ.sslcert                     #'PATH' to client certificate file
HBA[6] clientcert=PATH            #Same but can be used with any authentication method

DATADIR/server.crt                #'PATH' to server certificate file
HCONF.ssl_cert_file               #Relative to DATADIR

ENVVAR PGSSLKEY
USERCONFDIR/postgresql.key        #Client secret key 'PATH'
LIBPQ.sslkey                      #Can also be 'ENGINE:KEY' for OpenSSL engines

DATADIR/server.key                #Server secret key 'PATH'
HCONF.ssl_key_file                #Must have permissions 0600

LIBPQ.sslpassword                 #Password to client secret key
                                  #Def: prompts

zHCONF.ssl_passphrase_command     #Shell 'COMMAND' to get the password to server secret key on stdout
                                  #Can use %p for prompted value
HCONF.ssl_passphrase_command      #BOOL (def: false). Whether to reload ssl_passphrase_command when CONF is reloaded.
 _supports_reload                 #Should be true unless use prompted value

ENVVAR PGSSLROOTCERT
USERCONFDIR/root.crt
LIBPQ.sslrootcert                 #Client CA certificate 'PATH'

HCONF.ssl_ca_file                 #Server CA certificate 'PATH'
                                  #Relative to DATADIR

ENVVAR PGSSLCRL
USERCONFDIR/root.crl
LIBPQ.sslcrl                      #Client CA revocation list 'PATH'

HCONF.ssl_crl_file                #Server CA revocation list 'PATH'
                                  #Relative to DATADIR

ENVVAR PGSSLCRLDIR
LIBPQ.sslcrldir                   #Client CA revocation list 'DIR'

HCONF.ssl_crl_dir                 #Server CA revocation list 'DIR'
                                  #Relative to DATADIR
                                  #Loaded on each new client connection

HBA[6] clientname=STR             #Whether to use the 'CN' (def, Common Name) or 'DN' (Distinguished Name) of the certificate

ENVVAR PGSSLSNI
LIBPQ.sslsni                      #1|0 (def: 1, i.e. true). Whether client enables SNI

ENVVAR PGSSLMIN|MAXPROTOCOLVERSION
zHCONF|LIBPQ                      #Among 'TLSv1[.1|2|3]'
 .ssl_min|max_protocol_version    #Def: min TLSv1.2

zHCONF.ssl_ciphers                #STR (def: 'HIGH:MEDIUM:+3DES:!aNULL'). List of OpenSSL ciphers
HCONF.ssl_prefer_server_ciphers   #BOOL (def: true). Prefer server ciphers over client's

zHCONF.ssl_dh_params_file         #'PATH' to Diffie-Hellman parameters
zHCONF.ssl_ecdh_curve             #ECDH key exchange algorithm among 'prime256v1' (def), 'secp384r1', 'secp521r1'

ICONF.ssl_library                 #E.g. 'OpenSSL'

ENVVAR OPENSSL_CONF               #Can be used

pg_stat_ssl                       #TABLE with SSL info of each client connection
pg_stat_ssl.pid                   #BPID
pg_stat_ssl.ssl                   #BOOL. Whether SSL is used
                                  #If false, all next fields null
pg_stat_ssl.version               #STR. SSL version
pg_stat_ssl.cipher                #STR. SSL cipher
pg_stat_ssl.bits                  #INT4. Number of bits in encryption algorithm
pg_stat_ssl.client_dn             #STR. DN of client certificate. Truncated above 63 chars
pg_stat_ssl.client_serial         #NUMERIC. Serial number of client certificate
pg_stat_ssl.issuer_dn             #STR. DN of client certificate's issuer. Truncated above 63 chars

sslinfo                           #FUNCs to find similar information as provided by pg_stat_ssl
                                  #Non-trusted EXTENSION 'sslinfo'
                                  #Not documented yet

                                  ┌────────────┐
                                  │   GSSAPI   │
                                  └────────────┘

HBA[0] host[[no]gssenc]           #TCP/IP, GSSAPI encrypted
                                  #Def: both with|without it

HBA[5] gss|sspi                   #Authentication method using GSSAPI

ENVVAR PGGSSENCMODE               #Whether to use GSSAPI encryption:
LIBPQ.gssencmode                  #  - 'disable'
                                  #  - 'prefer' (def)
                                  #  - 'require'

ENVVAR PGGSSLIB                   #Whether to use 'gssapi' or 'sspi'
LIBPQ.gsslib                      #On Unix, always use gssapi. On Windows, def: sspi

pg_stat_gssapi                    #TABLE with GSSAPI info of each client connection
pg_stat_gssapi.pid                #BPID
pg_stat_gssapi.encrypted          #BOOL. Whether GSSAPI encrypted
pg_stat_gssapi.gss_authenticated  #BOOL. Whether GSSAPI authenticated
pg_stat_gssapi.principal          #STR. Client's principal. Truncated above 63 chars

                                  ┌──────────────┐
                                  │   KERBEROS   │
                                  └──────────────┘

HBA[5] krb5                       #Authentication method with Kerberos5

ENVVAR PGREALM|PGKRBSRVNAME       #Kerberos server name
LIBPQ.krbsrvname                  #Def: 'postgres'

SYSCONFDIR/krb5.keytab
zHCONF.krb_server_keyfile         #'PATH' to Kerberos server key

HCONF.krb_caseins_users           #BOOL (def: false). Whether Kerberos user names are case-insensitive

                                  ┌─────────────┐
                                  │   TIMEOUT   │
                                  └─────────────┘

ENVVAR PGCONNECT_TIMEOUT
LIBPQ.connect_timeout             #NUM (in secs, def: 0). Client connection timeout

HCONF.authentication_timeout      #NUM (in secs, def: 60). Client authentication timeout

SCONF|LIBPQ.tcp_user_timeout      #After NUMms of a client request without a server response, close connection
                                  #Def: 0, i.e. OS default

SCONF.idle_session_timeout        #After NUMms of a client without requests (and no ongoing transaction), close connection
                                  #Def: 0, i.e. disabled
SCONF.idle_in_transaction         #Same for client without request but an ongoing transaction
 _session_timeout                 #Def: 0, i.e. disabled

SCONF.                            #Poll every NUMs that a client is still connected
 client_connection_check_interval #Def: 0, i.e. disabled, i.e. detects it at next request from any client

LIBPQ.keepalives                  #1 (true, def) or 0. TCP keepalives. If connection seems lost, sends packet to check it actually is.

SCONF.tcp_keepalives_interval     #Keepalives interval
LIBPQ.keepalives_interval         #Def: 0, i.e. OS default

SCONF.tcp_keepalives_count        #Max keepalives packets
LIBPQ.keepalives_count            #Def: 0, i.e. OS default

SCONF.tcp_keepalives_idle         #NUM (in sec) when to start sending keepalives packets
LIBPQ.keepalives_idle             #Def: 0, i.e. OS default

SCONF.statement_timeout           #NUM (in ms, def: 0) timeout for each statement

                                  ┌───────────────────┐
                                  │   RATE LIMITING   │
                                  └───────────────────┘

auth_delay                        #C addon that rate limits authentication failures
HCONF.auth_delay.milliseconds     #NUM (def: 0) of ms between attempts

HCONF.pre_auth_delay              #NUM (def: 0). Delay before authentication, meant for debugging
postgres -W NUM
LCONF.post_auth_delay             #NUM (def: 0). Delay after authentication, meant for debugging

postgres -N NUM                   #Max amount of connections per CLUSTER. Def: 100
PCONF.max_connections             #Includes superuser ROLEs and background processes

PCONF.
 superuser_reserved_connections   #NUM (def: 3) in max_connections reserved for superuser ROLEs

create|alter database "DATABASE"  #Max amount of connections per DATABASE. Def: -1 (unlimited)
 connection limit NUM             #Excludes superuser ROLEs and background processes

create|alter role "ROLE"          #Max amount of connections per ROLE. Def: -1 (unlimited)
 connection limit NUM             #Not on superuser ROLE

pg_database.datconnlimit          #INT4 (-1 if none). create database ... connection limit

                                  ┌─────────────────────┐
                                  │   SECURITY LABELS   │
                                  └─────────────────────┘

security label on ENTITY "ENTITY"
 is 'SECURITY_LABEL'              #Add metadata intended for a security provider like SELinux

security label for "PROVIDER"     #Name of PROVIDER

pg_seclabel                       #TABLE with all SECURITY_LABELs
pg_seclabel.classoid
pg_seclabel.objoid
pg_seclabel.objsubid              #ENTITY
pg_seclabel.provider              #'PROVIDER'
pg_seclabel.label                 #'SECURITY_LABEL'

pg_shseclabel                     #Like pg_seclabel, but for cluster-wide ENTITYs. No objsubid

pg_seclabels                      #High-level VIEW on top of pg_[sh]seclabel
pg_seclabels.objoid
pg_seclabels.classoid
pg_seclabels.objsubid
pg_seclabels.provider
pg_seclabels.label                #Like pg_[sh]seclabel
pg_seclabels.objtype              #'ENTITY'
pg_seclabels.objname              #'NAME'

                                  ┌──────────────────────┐
                                  │   EXTENSION CREATE   │
                                  └──────────────────────┘

SHAREDIR/extension/               #EXTENSION_DIR containing all enabled|disabled EXTENSIONs
                                  #Can add more to it manually
                                  #Many are already present in most builds
                                  #  - called "contrib"
                                  #  - disabled except for "plpgsql"

EXTENSION_DIR/                    #INIMAIN ("control file"), EXTENSIONS's main declarative file
 EXTENSION[--EVERSION].control    #INI format. ASCII only.
                                  #If --EVERSION, only for that version
                                  #  - cannot specify INIMAIN.default_version|directory then
INIMAIN.default_version           #Current 'EVERSION'
                                  #Def: one specified with `create extension ... version`
INIMAIN.comment                   #STR. Description
                                  #Can also use `comment on extension` instead
INIMAIN.superuser                 #BOOL (def: true). Whether should be run with superuser privileges.
                                  #I.e. by default, created ENTITYs will be owned by superuser.
INIMAIN.trusted                   #BOOL (def: !INIMAIN.superuser). Whether non-superuser can enable the EXTENSION.
INIMAIN.requires "EXTENSION",...  #Fail if other EXTENSIONs not already installed
INIMAIN.directory                 #'DIR' of SQLMAIN (def: './extension')
                                  #Relative to SHAREDIR
INIMAIN.schema                    #Default 'SCHEMA' in SQLMAIN, i.e. set as SCONF.search_path
                                  #Def: keep current SCONF.search_path
                                  #SCHEMA must already exist
                                  #Setting it prevents:
                                  #  - INIMAIN.relocatable true
                                  #  - `create extension ... schema`
INIMAIN.relocatable               #BOOL (def: false). Whether 'SCHEMA' can be overridden by `alter extension ... set schema`
INIMAIN.module_pathname           #STR which can be used as `MODULE_PATHNAME` in SQLMAIN
                                  #Can include `$libdir`, e.g. '$libdir/EXTENSION'
                                  #Meant to be used inside `create function|procedure ... as 'MODULE_PATHNAME', 'FUNC_NAME' language C`
INIMAIN.encoding                  #'ENCODING' (def: server's ENCODING) of SQLMAIN

EXTENSION_DIR/                    #SQLMAIN ("script file"), EXTENSION's main imperative file
 EXTENSION--EVERSION.sql          #It is a SQL file which can execute any statements, usually DDLs
                                  #Only applies to current DATABASE
                                  #  - cluster-wide ENTITYs can be created, but are not associated with the EXTENSION
                                  #Cannot use POLICYs nor SECURITY_LABELs
                                  #Wrapped in a transaction, i.e. cannot use transactions itself
                                  #Any ENTITY created is an auto-dependency child of EXTENSION

@extowner@                        #Replaced by current "ROLE", inside SQLMAIN
@extschema@                       #Replaced by current "SCHEMA", inside SQLMAIN

EXTENSION_DIR/                    #"Upgrade script".
 EXTENSIN--EVERSION--EVERSION2.sql#Executed when upgrading from EVERSION to EVERSION2 with `alter extension ... update`
                                  #Can also be downgrade scripts
pg_extension_update_paths         #Returns all upgrade scripts
 ('EXTENSION')->ROW_SET           #ROW: source|target 'EVERSION', path 'EVERSION--...'|null

pg_extension_config_dump          #Mark TABLE as both used by EXTENSION, but writable by user.
 ("TABLE", 'where BOOL_REXPR')    #Meant for EXTENSION's config.
                                  #This ensures TABLE is included in backups, as opposed to rest of EXTENSION.
                                  #'where BOOL_REXPR' filters which ROWs to backup. Can be ''.
                                  #Can be called several times, to override previous calls (e.g. in upgrade script)

\echo Use "CREATE EXTENSION ..."
 to load this file.
\quit                             #Should be put to protect against using psql on SQLMAIN

PGXS                              #Build system for EXTENSIONs, as a Makefile
                                  #On my system, main file is at /usr/lib/postgresql/VERSION/lib/pgxs/src/makefiles/pgxs.mk
                                  #Not documented yet
pg_config --pgxs                  #Prints PGXS's main file

                                  ┌───────────────────┐
                                  │   EXTENSION USE   │
                                  └───────────────────┘

create extension "EXTENSION"      #Enable an EXTENSION
create extension ...
 version 'EVERSION'               #Override INIMAIN.default_version
create extension ...
 schema "SCHEMA"                  #Override INIMAIN.schema
create extension ... cascade      #Enable any EXTENSIONs from INIMAIN.requires

alter extension "EXTENSION"
 update [to 'EVERSION']           #Changes EVERSION (def: INIMAIN.default_version)

alter extension "EXTENSION"       #Add an ENTITY to the EXTENSION
 add|drop ENTITY "ENTITY"         #Meant for upgrade scripts

alter ENTITY "ENTITY" [no]        #Mark ENTITY as a dependency
 depends on extension "EXTENSION" #Only for ENTITY: function|routine|procedure|trigger, materialized view, index

PCONF.EXTENSION.CONFVAR           #EXTENSIONs can have their own CONFVARs

                                  ┌────────────────────┐
                                  │   EXTENSION LIST   │
                                  └────────────────────┘

pg_available_extension_versions   #TABLE with all EXTENSION for all EVERSIONs
pg_available_extension_versions
 .name                            #"EXTENSION" name
pg_available_extension_versions
 .version                         #'EVERSION'
pg_available_extension_versions
 .installed                       #BOOL. Whether enabled
pg_available_extension_versions
 .comment                         #STR. INIMAIN.comment
pg_available_extension_versions
 .superuser                       #BOOL. INIMAIN.superuser
pg_available_extension_versions
 .trusted                         #BOOL. INIMAIN.trusted
pg_available_extension_versions
 .requires                        #"EXTENSION"_ARR. INIMAIN.requires
pg_available_extension_versions
 .schema                          #"SCHEMA". INIMAIN.schema. null if relocatable
pg_available_extension_versions
 .relocatable                     #BOOL. INIMAIN.relocatable

pg_available_extensions           #TABLE with all EXTENSIONs for their default EVERSION
pg_available_extensions.name      #"EXTENSION" name
pg_available_extensions
 .default_version                 #'EVERSION'. null if no INIMAIN.default_version
pg_available_extensions
 .installed_version               #'EVERSION'. null if disabled
pg_available_extensions.comment   #INIMAIN.comment

pg_extension                      #TABLE with all enabled EXTENSIONs
pg_extension.oid                  #OID
pg_extension.extname              #"EXTENSION" name
pg_extension.extnamespace         #REGNAMESPACE of main SCHEMA
pg_extension.extrelocatable       #BOOL. INIMAIN.relocatable
pg_extension.extversion           #'EVERSION'
pg_extension.extconfig            #REGCLASS_ARR of TABLEs marked by pg_extension_config_dump()
                                  #null if none
pg_extension.extcondition         #'BOOL_REXPR'_ARR of pg_extension_config_dump() second argument
                                  #null if none

                                  ┌──────────┐
                                  │   PGXN   │
                                  └──────────┘

PGXN ==>                          #Package manager for Postgres EXTENSIONs
                                  #Can view repository info, and download files
pgxn                              #CLI
                                  #Document ???

PGRX ==>                          #Rust framework to build EXTENSIONs

                                  ┌────────────┐
                                  │   PG_TLE   │
                                  └────────────┘

pg_tle                            #Framework and package manager for EXTENSIONs that are specified as STR instead of files. Document ???

                                  ┌───────────┐
                                  │   DBDEV   │
                                  └───────────┘

dbdev                             #Package manager for pg_tle EXTENSIONs
                                  #Installed itself through pgsql_http then using pg_tle
                                  #Called either as SQL FUNC, or as CLI (Rust)

dbdev.install(...)                #Downloads an EXTENSION
dbdev install                     #Must be then enabled with `create extension`

dbdev.uninstall(...)
dbdev uninstall                   #

dbdev.[un]install
 ('EXTENSION'[, 'EVERSION'])
--package 'EXTENSION'             #
--version 'EVERSION'              #

dbdev ... --connection            #'LIBPQ'

                                  ┌───────────────┐
                                  │   TRANSFORM   │
                                  └───────────────┘

create transform "TYPE"
 language "LANGUAGE" (
  from sql with function
   FUNC(INTERNAL)->INTERNAL       #Add a TYPE to a LANGUAGE
  to sql with function            #Meant for EXTENSIONs
   FUNC2(INTERNAL)->TYPE_VAL      #FUNC is called on arguments, FUNC2 on return value
 )                                #FUNC[2] not documented yet

create function|procedure ...
 transform for type TYPE ,...     #Declare a FUNC with a TYPE that has a TRANSFORM

pg_transform                      #TABLE with all TRANSFORMs
pg_transform.oid                  #OID
pg_transform.trftype              #REGTYPE
pg_transform.trflang              #pg_language.oid
pg_transform.trffromsql           #REGPROC of FUNC, or 0
pg_transform.trftosql             #REGPROC of FUNC2, or 0

                                  ┌──────────────────────────┐
                                  │   FOREIGN DATA WRAPPER   │
                                  └──────────────────────────┘

create foreign data wrapper "FDW" #Creates a FDW, i.e. virtualization of DATABASE|TABLEs
                                  #E.g. to use a foreign source FSOURCE (another DBMS, files, etc.) as regular TABLEs
                                  #Can be slow and not optimized.
                                  #Must be superuser.
                                  #Parent dependency of FSERVER|FTABLE
                                  #Based on standard SQL/MED

create|alter ... "FDW"
 handler FUNC                     #Main FUNC
create|alter ... "FDW" no handler #Must be in LANGUAGE C

fdw_handler                       #TYPE to return from handler FUNC. Is a STRUCT with pointers towards many FUNCs including:
                                  #  - `explain` helpers: estimate query number of ROWs, access paths, plan, joins
                                  #  - analyze
                                  #  - query: start|end, iterate, join, batch, ROW locks, parallel
                                  #  - insert|update|delete|truncate
                                  #  - import foreign schema
                                  #Can get FDW_OPTS|FSERVER_OPTS|FTABLE_OPTS|FCOL_OPTS|FUSERMAP_OPTS|FIMPORT_OPTS
                                  #Not documented yet

create|alter ... "FDW"            #FUNC('VAR=VAL'_ARR, ENTITY_CATALOG_OID) validating
 validator FUNC                   #FDW_OPTS|FSERVER_OPTS|FTABLE_OPTS|FCOL_OPTS|FUSERMAP_OPTS|FIMPORT_OPTS
create|alter ... "FDW"            #Must be in LANGUAGE C
 no validator                     #Errors should call ereport('MESSAGE')
                                  #Not documented yet

create|alter ... "FDW"
 options (FDW_OPTS)
alter ... "FDW" options
 ([add|set|drop] OPTVAR [VAL],...)#Options passed to FDW

pg_foreign_data_wrapper           #TABLE with all FDWs
pg_foreign_data_wrapper.oid       #OID
pg_foreign_data_wrapper.fdwname   #"FDW" name
pg_foreign_data_wrapper.fdwhandler#REGPROC|0 of handler FUNC
pg_foreign_data_wrapper
 .fdwvalidator                    #REGPROC|0 of validator FUNC
pg_foreign_data_wrapper.fdwoptions#'FDW_OPTVAR=VAL'_ARR

pg_attribute.attfdwoptions        #'FDW_OPTVAR=VAL'_ARR of FTABLE "COL"

                                  ┌────────────────────┐
                                  │   FOREIGN SERVER   │
                                  └────────────────────┘

create server "FSERVER"
 foreign data wrapper "FDW"       #Creates a FSERVER, i.e. like a DATABASE but using a FDW

create server "FSERVER"
 type 'FSERVER_TYPE' ...          #FDW-specific type

create|alter server "FSERVER"
 version 'FSERVER_VERSION' ...    #FDW-specific version

create server "FSERVER" ...
 options (FSERVER_OPTS)
alter server "FSERVER" options
 ([add|set|drop] OPTVAR VAL,...)  #FDW-specific FSERVER options

pg_foreign_server                 #TABLE with all FSERVERs
pg_foreign_server.oid             #OID
pg_foreign_server.srvname         #"FSERVER" name
pg_foreign_server.srvfdw          #FDW.oid
pg_foreign_server.srvtype         #'FSERVER_TYPE'
pg_foreign_server.srvversion      #'FSERVER_VERSION'
pg_foreign_server.srvoptions      #'FSERVER_OPT=VAL'_ARR

                                  ┌──────────────────┐
                                  │   USER MAPPING   │
                                  └──────────────────┘

create user mapping               #Specifies ROLE-specific options on a FSERVER, usually authentication-related
 for RPROLE server "FSERVER"      #Child dependency of FSERVER

create user mapping ...
 options (FUSERMAP_OPTS)
alter user mapping ... options
 ([add|set|drop] OPVAR VAL,...)   #FDW-specific ROLE options

pg_user_mapping                   #TABLE with all FUSERMAPs
                                  #Visible only to superuser
pg_user_mapping.oid               #OID
pg_user_mapping.umuser            #REGROLE of RPROLE. 0 if public
pg_user_mapping.umserver          #FSERVER_OID
pg_user_mapping.umoptions         #'FUSERMAP_OPT=VAL'_ARR

pg_user_mappings                  #High-level VIEW on pg_user_mapping visible to non-superuser
pg_user_mappings.umid             #pg_user_mapping.oid
pg_user_mappings.srvid            #FSERVER_OID
pg_user_mappings.srvname          #"FSERVER" name
pg_user_mappings.umuser           #REGROLE of RPRROLE. 0 if public
pg_user_mappings.usename          #Same but as "ROLE" name
pg_user_mappings.umoptions        #'FUSERMAP_OPT=VAL'_ARR. null if current_role is not RPROLE

                                  ┌───────────────────┐
                                  │   FOREIGN TABLE   │
                                  └───────────────────┘

create foreign table "FTABLE"
 (FCOL_ARG,...) server "FSERVER"  #Create a FTABLE, i.e. like a TABLE but using a FSERVER

create ... server "FSERVER"
 options (FTABLE_OPTS)
alter foreign table "FTABLE"
 options
 ([add|set|drop] OPTVAR VAL,...)  #FDW-specific FTABLE options

"COL" TYPE                        #FCOL_ARG
alter foreign table "FTABLE"
 add [column] FCOL_ARG            #
alter foreign table "FTABLE"
 rename [column] "COL" to "COL2"  #
alter foreign table "FTABLE"
 alter [column] "COL"
 [set data] type TYPE            #
alter foreign table "FTABLE"
 drop [column] [if exists] "COL"
 [restrict|cascade]               #

"COL" TYPE options (FCOL_OPTS)    #FCOL_ARG
alter foreign table "FTABLE"
 alter "COL" options
 ([add|set|drop] OPTVAR VAL,...)  #FDW-specific FCOL options

"COL" TYPE FCONSTRAINT,...        #FCOL_ARG
alter foreign table "FTABLE"
 alter "COL" set|drop FCONSTRAINT #

[not] null
default VAL                       #FCONSTRAINTs
generated always as (VAL) stored  #Enforced by FSOURCE (if supported), not by FDW nor FTABLE itself

check(BOOL_EXPR) [no inherit]     #FCONSTRAINT|FCOL_ARG

constraint "CONSTRAINT" FCOL_ARG
"COL" TYPE constraint "CONSTRAINT"
 FCONSTRAINT,...                  #

pg_foreign_table                  #TABLE with all FTABLEs
pg_foreign_table.ftrelid          #OID
pg_foreign_table.ftserver         #FSERVER_OID
pg_foreign_table.ftoptions        #'FSERVER_OPT=VAL'_ARR

SCONF.enable_async_append         #BOOL (def: true). Allow queries on multiple FTABLEs to query them in parallel
                                  #Only when multiple FTABLEs due to `union` or partitioning

                                  ┌────────────────────┐
                                  │   FOREIGN SCHEMA   │
                                  └────────────────────┘

import foreign schema "SCHEMA"
 from server "FSERVER"
 into "SCHEMA2"                   #Copy SCHEMA from FSERVER to local SCHEMA2

import foreign schema ...
 limit to("FTABLE",...)           #Only those FTABLEs
import foreign schema ...
 except("FTABLE",...)             #Not those FTABLEs

import foreign schema ...
 options (FIMPORT_OPTS)           #FDW-specific import options

                                  ┌──────────────────┐
                                  │   POSTGRES_FDW   │
                                  └──────────────────┘

postgres_fdw                      #EXTENSION adding a FDW for other DBMSs
                                  #Any FUNC (e.g. through TFUNC, RULE, etc.) uses SCONF.search_path with only `pg_catalog`

FCOL                              #Must match the COLs of the FSOURCE

FSERVER_OPT.*                     #Like LIBPQ.* (which can be used too), except:
                                  #  - user|password|sslpassword|sslkey|sslcert -> FUSERMAP.* instead
                                  #     - also FUSERMAP.password_required BOOL (def: true)
                                  #  - client_encoding -> FUSERMAP.* instead (def: SCONF.client_encoding)
                                  #  - application_name -> SCONF.postgres_fdw.* instead
                                  #  - fallback_application_name -> always 'postgres_fdw'

FTABLE_OPT.schema_name|table_name
 |column_name                     #STR (def: same as FSOURCE)

FSERVER_OPT|FTABLE_OPT.updatable  #BOOL (def: true). Allow insert|update|delete
FSERVER_OPT|FTABLE_OPT.truncatable#BOOL (def: true). Allow truncate

FSERVER_OPT|FTABLE_OPT
 .use_remote_estimate             #BOOL (def: false). Call `explain` to get cost estimate
FSERVER_OPT.fdw_startup_cost      #NUM (def: 100). Network cost of starting a Foreign Scan
FSERVER_OPT.fdw_tuple_cost        #NUM (def: .01). Network cost of reading|writing a ROW in a Foreign Scan

FSERVER_OPT|FTABLE_OPT.fetch_size #INT4 (def: 100). Number of ROWs to read in one batch
FSERVER_OPT|FTABLE_OPT.batch_size #INT4 (def: 1). Number of ROWs to write in one batch

FSERVER_OPT.extensions            #'EXTENSION,...' installed on the FSOURCE
                                  #I.e. can let FSOURCE do `where VAL OP VAL2` with an OP defined by those EXTENSIONs,
                                  #instead of doing it locally
                                  #Reason: performance, reducing number of ROWs sent over the network

FSERVER_OPT|FTABLE_OPT
 .async_capable                   #BOOL (def: false). Like SCONF.enable_async_append
FSERVER_OPT.parallel_commit       #BOOL (def: false). Allow multiple FSERVER to run in parallel inside the same transaction

FIMPORT_OPT.import_not_null       #BOOL (def: true). Import not null CONSTRAINTs
FIMPORT_OPT.import_default        #BOOL (def: false). Import COLs' `default` VALs
FIMPORT_OPT.import_generated      #BOOL (def: true). Import COLs' `generated` VALs
FIMPORT_OPT.import_collate        #BOOL (def: true). Import COLs' COLLATIONs

FSERVER_OPT.keep_connections      #BOOL (def: true). Pool connection sockets
                                  #Closed at end of session

postgres_fdw_get_connections()
 ->ROW_SET                        #ROW: server_name 'FSERVER', valid BOOL
postgres_fdw_disconnect('FSERVER')
 ->BOOL                           #
postgres_fdw_disconnect_all()
 ->BOOL                           #

                                  ┌──────────────┐
                                  │   FILE_FDW   │
                                  └──────────────┘

file_fdw                          #EXTENSION adding a FDW for files, using `copy from ...`
                                  #Readonly

FTABLE_OPT.filename               #Absolute '/PATH'
FTABLE_OPT.program                #Alternative: 'SHELL_COMMAND', to use its stdout
FTABLE_OPT.format|header|delimiter
 |quote|escape|null|encoding      #Like `copy`

FCOL_OPT.force[_not]_null         #Like `copy`

                                  ┌──────────────┐
                                  │   WRAPPERS   │
                                  └──────────────┘

supabase/wrappers                 #Rust framework to write FDWs
                                  #Uses PGRX
                                  #Only need to define some CRUD event handlers
                                  #Not documented yet

AVAILABLE WRAPPERS ==>            #  - S3: read-only from CSV or JSON lines
                                  #  - Stripe: read-only except customers, products, subscriptions
                                  #  - Firebase: read-only
                                  #  - BigQuery: read-write
                                  #  - Airtable
                                  #  - Clickhouse: read-write

                                  ┌─────────────────────┐
                                  │   BUILD-TIME DATA   │
                                  └─────────────────────┘

pg_config                         #Prints all build-time configuration
                                  #Is both a CLI, a TABLE where each ROW is a variable, a FUNC returning that TABLE
                                  #Must be superuser

pg_config
 --configure
 --cc
 --cflags[_sl]
 --cppflags
 --ldflags[_sl|_ex]
 --libs                           #Prints CLI flags used at build time

BINDIR                            #Main DIR for binaries (psql, postgres, pg_ctl, etc.)
                                  #On my system: /usr/lib/postgresql/VERSION/bin/
                                  #Often /usr/bin symlink to it
pg_config --bindir                #Prints BINDIR location

VARDIR                            #DIR with runtime data
                                  #On my system: /var/lib/postgresql

SHAREDIR                          #DIR with shared files: EXTENSIONs, TEMPLATE files, man pages, etc.
                                  #On my system: /usr/share/postgresql/VERSION
pg_config --sharedir              #Prints SHAREDIR

MANDIR                            #DIR with man files
                                  #On my system: /usr/share/postgresql/VERSION/man
pg_config --maindir               #Prints MANDIR

DOCDIR                            #DIR with changelogs, license files and generic documentation
                                  #On my system: /usr/share/doc/postgresql*
pg_config --docdir                #Prints DOCDIR location

HTMLDIR                           #Same as DOCDIR but for HTML files
                                  #On my system: same as DOCDIR
pg_config --htmldir               #Prints HTMLDIR location

                                  ┌─────────────┐
                                  │   CLUSTER   │
                                  └─────────────┘

initdb                            #Creates a CLUSTER, i.e. set of DATABASEs, managed by a single server

initdb --no-sync|-N               #Do not wait for completion

initdb --no-instructions          #Unless specified, prints instructions on how to connect

initdb --debug|-d                 #

PCONF.cluster_name                #"CLUSTER" (def: 'POSTGRES_VERSION/main')

DATADIR/postmaster.pid
zPCONF.external_pid_file          #PIDF. File with CLUSTER's info

                                  ┌──────────────────────┐
                                  │   CLUSTER ENTITIES   │
                                  └──────────────────────┘

CLUSTER-WIDE ENTITYS ==>          #The following ENTITYs are cluster-wide, not DATABASE-wide:
                                  #  - DATABASE (including their CONF, templates)
                                  #  - TABLESPACE
                                  #  - ROLE (including ACL, security label)
                                  #  - LANGUAGE
                                  #  - logical replication (including PUB, SUB, SLOT)
                                  #Also cluster-wide:
                                  #  - dependencies
                                  #  - COMMENTs
                                  #  - WAL
                                  #  - logs

pg_class.relisshared              #BOOL. Whether RELATION is cluster-wide
                                  #Only true for pg_catalog.* TABLEs (and their INDEX and TOAST_TABLEs) about cluster-wide ENTITYs

                                  ┌──────────────────┐
                                  │   CLUSTER DATA   │
                                  └──────────────────┘

ENVVAR PGDATA
zPCONF.data_directory
PIDF[1]
VARDIR/CLUSTER                    #DATADIR, i.e. DIR with CLUSTER-specific data
initdb --pgdata|-D DATADIR        #Created by initdb

initdb --allow-group-access|-g    #Set DATADIR with permissions 0750
                                  #Otherwise 0700
ICONF.data_directory_mode         #DATADIR permission

DATADIR/global                    #CLUSTERDIR. Cluster-wide data.

                                  ┌──────────────┐
                                  │   DATABASE   │
                                  └──────────────┘

create database "DATABASE"        #Create a DATABASE, i.e. set of SCHEMAs
                                  #Cannot be inside a transaction
                                  #Also called "catalog"
                                  #Max 4e9 DATABASEs per CLUSTER

postgres                          #DATABASE created by initdb, meant as default one

create database "DATABASE"        #Clones DATABASE2, except its CONF and PRIVILEGEs
 template "DATABASE2"             #DATABASE2 cannot be accessed while `create database` is ongoing
template1                         #DATABASE created by initdb. Default value for `create database ... template`
                                  #Can be modified
template0                         #DATABASE created by initdb. Copy of template0 before any modification

create|alter database "DATABASE"  #Whether can be used as `create database ... template "DATABASE"` by other ROLEs than DATABASE's owner
 is_template BOOL                 #Def: false

create|alter database "DATABASE"
 allow_connections BOOL           #BOOL (def: true). Whether clients can connect to it

create database "DATABASE" oid OID#Specifies DATABASE.oid. Mostly meant for internal usage by pg_upgrade

drop database ... force           #Unless done, fail if ongoing connections
                                  #Terminates them using pg_terminate_backend()

pg_database                       #TABLE with all DATABASEs
pg_database.oid                   #OID
pg_database.datname               #"DATABASE" name
pg_database.datistemplate         #BOOL. create database ... is_template
pg_database.datallowconn          #BOOL. create database ... allow_connections

                                  ┌─────────────────────────┐
                                  │   DATABASE CONNECTION   │
                                  └─────────────────────────┘

ENVVAR PGDATABASE
LIBPQ.dbname                      #DATABASE to connect to
psql DATABASE
psql --database|-d DATABASE       #Def: same name as CLIENT_USER

HCONF.db_user_namespace           #BOOL (def: false). Require ROLE to end with either:
                                  #  - @DATABASE: can only connect to DATABASE
                                  #  - @: can connect to any DATABASE

current_catalog
current_database()->"DATABASE"    #

                                  ┌───────────────────┐
                                  │   DATABASE DATA   │
                                  └───────────────────┘

DBDIR                             #DIR with DATABASE-specific data
                                  #On my system: DATADIR/base/DATABASE_OID
                                  #6MB for empty database

DBDIR|CLUSTERDIR/REGCLASS_OID     #Data and metadata of a relation
                                  #Contains all its heap pages

pg_class.relfilenode              #OID. REGCLASS_OID used in DBDIR
                                  #Same as regclass.oid, except 0 if:
                                  #  - VIEW|ROW_TYPE
                                  #  - some pg_catalog.* TABLEs: cluster-wide ones, and pg_class|attribute|type|proc

pg_relation_filepath(REGCLASS)
 ->'PATH'                         #Relative to DATADIR
pg_relation_filenode(REGCLASS)
 ->REGCLASS_OID                   #
pg_filenode_relation
 (TABLESPACE_OID, REGCLASS_OID)
 ->REGCLASS                       #TABLESPACE_OID can be 0 to use DATABASE's default TABLESPACE

                                  ┌──────────┐
                                  │   SIZE   │
                                  └──────────┘

pg_relation_size                  #Size (in bytes) of a TABLE (including TOAST), INDEX, SEQUENCE
 (REGCLASS[, STR])->INT8          #On-disk, using DBDIR|CLUSTERDIR/REGCLASS_OID*
                                  #STR is "fork", i.e. one of:
                                  #  - 'main' (def): REGCLASS_OID
                                  #  - 'vm': REGCLASS_OID_vm
                                  #  - 'fsm': REGCLASS_OID_fsm
                                  #  - 'init': REGCLASS_OID_init
pg_table_size(REGCLASS)->INT8     #On-disk size but including all of REGCLASS_OID* + TOAST tables
pg_indexes_size(REGCLASS)->INT8   #On-disk size of TABLE's INDEXs
pg_total_relation_size
 (REGCLASS)->INT8                 #pg_table_size() + pg_indexes_size()

pg_database_size
 (DATABASE_OID|"DATABASE")->INT8  #On-disk size of DATABASE, i.e. of DBDIR
pg_tablespace_size
 (TABLESPACE_OID|"TABLESPACE")
 ->INT8                           #On-disk size of TABLESPACE's DIR

pg_size_pretty(INT8|NUMERIC)->STR #Convert a bytes size into human-friendly STR, adding unit 'bytes|kB|MB|GB|TB|GB'
pg_size_bytes(STR)->INT8          #Inverse

                                  ┌────────────────┐
                                  │   TABLESPACE   │
                                  └────────────────┘

create tablespace "TABLESPACE"    #Create a TABLESPACE, a physical location in a CLUSTER's DATADIR
 location 'DIR'                   #Can contain DATABASEs and TABLE|INDEX|MVIEWs
                                  #'DIR' must be absolute. It must be empty.
                                  #Changing an ENTITY's TABLESPACE locks it and moves its data files
                                  #Must be superuser
                                  #Goals:
                                  #  - performance
                                  #     - e.g. putting heavily used INDEX on fast storage
                                  #  - space usage
                                  #     - e.g. put heavy space DATABASE on high-volume storage, or move to higher storage

create tablespace ... with (AOPTS)#

drop tablespace "TABLESPACE"      #Can only be done if empty

DATADIR/pg_tblspc/TABLESPACE      #Symlink to TABLESPACE's DIR
ZSCONF.allow_in_place_tablespaces #BOOL (def: false). Allow manually adding DATADIR/pg_tblspc/TABELSPACE DIRs
                                  #Meant for debugging

SCONF.default_tablespace          #Default TABLESPACE
pg_default                        #Not used by new DATABASEs: they use the TABLESPACE from their template DATABASE2 instead

pg_global                         #TABLESPACE for cluster-wide ENTITYs

create database
 tablespace "TABLESPACE"
create table ...
 tablespace "TABLESPACE" ...
create materialized view ...
 tablespace "TABLESPACE" ...
create index ...
 tablespace "TABLESPACE"
reindex
 tablespace "TABLESPACE" ...      #Set TABLESPACE
create table ...
 exclude|unique|primary key ...
 using index tablespace "TABLSPAC"#Set TABLESPACE of CONSTRAINT's INDEX

alter ENTITY "ENTITY" ...         #Set TABLESPACE of one ENTITY
 set tablespace "TABLESPACE"      #For same ENTITYs as above

alter ENTITY
 all in tablespace "TABLESPACE"   #Move all ENTITYs from one TABLESPACE to another
 set tablespace "TABLESPACE2"     #For same ENTITYs as above, except database
alter ENTITY all in tablespace ...
 owner by ROLE,...                #Only ENTITYs owned by ROLE,...
alter ENTITY all in tablespace ...#All ENTITYs are locked.
 nowait                           #If nowait, uses lock ... nowait, i.e. fail if cannot lock right away

pg_tablespace                     #TABLE with all TABLESPACEs
pg_tablespace.oid                 #OID
pg_tablespace.spcname             #"TABLESPACE" name
pg_tablespace.spcoptions          #'AOPT_VAR=VAL'_ARR

pg_database.dattablespace         #pg_tablespace.oid of DATABASE
pg_class.reltablespace            #pg_tablespace.oid of RELATION
                                  #0 for DATABASE's one
pg_tables.tablespace              #pg_tablespace.spcname of TABLE
pg_indexes.tablespace             #pg_tablespace.spcname of INDEX
pg_matviews.tablespace            #pg_tablespace.spcname of MVIEW

pg_tablespace_databases
 (TABLESPACE_OID)
 ->DATABASE_OID_SET               #null with pg_global
pg_tablespace_location
 (TABLESPACE_OID)->'DIR'          #null with pg_global|pg_default

                                  ┌────────────────────┐
                                  │   SERVER PROCESS   │
                                  └────────────────────┘

postgres                          #Starts the server for a given CLUSTER

DATADIR/postmaster.opts           #CLI flags passed to `postgres` server

PIDF[0]                           #SPID. Server main process PID

SIGTERM -> SPID                   #"Smart shutdown". No new connections, but let current ones end.
SIGINT -> SPID                    #"Fast shutdown". Abort connections, then close server properly
SIGQUIT -> SPID                   #"Immediate shutdown". Abort connections and server

HCONF.restart_after_crash         #BOOL. If true (def), restart server on crash.

postgres --single [DATABASE]      #"Single-user mode". Start both the server and a client session as superuser ROLE
                                  #Def DATABASE: same name as OS_USER
                                  #No readline, except Ctrl-D
-r PATH                           #Log stdout|stderr to PATH
-E                                #Prints commands to stdout before execution
-j                                #Make line terminator ;\n\n instead of \n
                                  #Only one command can be send

PCONF.bonjour[_name]              #Used to advertise server's existence with macOS's Bonjour

                                  ┌───────────────────┐
                                  │   SERVER STATUS   │
                                  └───────────────────┘

pg_postmaster_start_time()
 ->TIMESTAMPTZ
PIDF[2]                           #DATE_NUM when server started

PIDF[7]                           #Server status, e.g. 'ready'

pg_isready                        #Returns server status, according to exit code:
                                  #  - 0: success
                                  #  - 1: deny connections
                                  #  - 2: no server response
                                  #  - 3: could not send request
--host|-h
--port|-p
--username|-U
--dbname|-d                       #LIBPQ connection
--timeout|-t NUM                  #NUM (in secs, def 3). 0 to disable
--quiet|-q                        #

                                  ┌─────────────┐
                                  │   SESSION   │
                                  └─────────────┘

SESSION ==>                       #Series of commands in a specific client connection to the server
                                  #E.g. interactive prompt
                                  #Only one DATABASE per SESSION

BACKEND                           #Server process started for each connection
                                  #For performance, often cached in a connection pool
                                  #  - however, very long-lived connections (>1h) tend to become bloated
pg_backend_pid()->BPID            #Backend PID

SIGTERM -> BPID                   #Terminate another session
pg_terminate_backend(BPID[, INT8])#Current ROLE can be a member of either session's, or of built-in ROLE pg_signal_backend
 ->BOOL                           #Wait until process exists, up to INT8 secs
                                  #BOOL is success

SIGINT -> BPID                    #Terminate another session's current statement
pg_cancel_backend(BPID)->BOOL     #Same permissions as pg_terminate_backend()

current_query()->STR              #Currently executing statement

discard all                       #Remove all session state. Same as:
                                  #  - close all
                                  #  - set session authorization default
                                  #  - reset all
                                  #  - deallocate all
                                  #  - unlisten *
                                  #  - select pg_advisory_unlock_all()
                                  #  - discard plans
                                  #  - discard temp
                                  #  - discard sequences

                                  ┌───────────┐
                                  │   LIBPQ   │
                                  └───────────┘

libpq                             #Main C client library

BACKEND PROTOCOL ==>              #Network protocol implemented byb all clients, including libpq

ECPG ==>                          #"Embedded SQL". Allows executing SQL inline in C code
                                  #File extension: .pgc
                                  #libpq pre-processes it to a C file with libpq statements.

LIBPQ                             #"Libpq variables", used by many clients
'LIBPQ'                           #Libpq connection string, either:
                                  #  - LIBPQ_VAR=VAL ...
                                  #     - can '-quote whitespaces
                                  #     - can \-quote ' \
                                  #  - postgres[ql]://[USER[:PASSWORD]@][HOST][:PORT],.../[DATABASE][?LIBPQ_VAR=VAL]
                                  #     - percent-encoded
psql 'LIBPQ'                      #

SYSCONFDIR/pg_service.conf        #INI file storing LIBPQ.* that clients can use
                                  #Key is 'SERVICE' and values are LIBPQ.*
ENVVAR PGSERVICEFILE
~/.pg_service.conf                #Same but per OS user
ENVVAR PGSERVICE
LIBPQ.service                     #'SERVICE' used by client

ENVVAR PGAPPNAME                  #Name of the client, used in logs and pg_stat_activity
SCONF|LIBPQ.application_name      #Max 63 chars
LIBPQ.fallback_application_name   #Default value of LIBPQ.application_name

                                  ┌─────────────────┐
                                  │   CONFIG FILE   │
                                  └─────────────────┘

GUC ==>                           #"Grand Unified Configuration". Other name for *CONF

ENVVAR PGSYSCONFDIR               #SYSCONFDIR, i.e. DIR with system-wide configuration
                                  #On my system: /etc/postgresql-common
pg_config --sysconfdir            #Prints SYSCONFDIR

CLUSTERCONFDIR                    #DIR with cluster-wide configuration
                                  #On my system: /etc/postgresql/CLUSTER

USERCONFDIR                       #DIR with OS user-specific configuration
                                  #On my system: ~/.postgresql

CLUSTERCONFDIR/postgresql.conf
zPCONF.config_file                #Set CONF for CLUSTER, as an INI file

PCONF.include[_if_exists]         #'PATH'. Inside CONF file, include another one
                                  #Relative to CONF file
PCONF.include_dir                 #'DIR'. Same for DIR/*.conf, in alphabetical order

CLUSTERCONFDIR/
 postgresql.auto.conf             #Like postgresql.conf but set by `alter system`
alter system set|reset ...        #Like `set|reset ...` but for postgresql.auto.conf
                                  #Only effective after CONF reload
                                  #Cannot be inside a transaction

postgres -C CONFVAR               #Prints CONFVAR from CLUSTER CONF file

pg_file_settings                  #TABLE with all CONFVARs set in CONF files
                                  #Visible only to superuser
pg_file_settings.sourcefile       #'PATH' to CONF file
pg_file_settings.error            #'MESSAGE' if syntax error
pg_file_settings.sourceline       #INT4. Line number
pg_file_settings.seqno            #INT4. 1-based serial number
pg_file_settings.name             #'CONFVAR'
pg_file_settings.setting          #'VAL'
pg_file_settings.applied          #BOOL. True if applied successfully

                                  ┌─────────────────┐
                                  │   CONFIG LOAD   │
                                  └─────────────────┘

CONF VALUES ==>                   #Are always STR
                                  #BOOL can use same values as BOOL_UNKNOWN: 'on|off', etc.
                                  #NUM that use units can also be '...B|kB|MB|GB|TB' or '...us|ms|s|min|h|d'

ZCONF                             #CONF that can only be set by a superuser ROLE
zCONF                             #CONF that can only be set|get by a superuser ROLE
                                  #Can also get if member of built-in ROLE pg_read_all_settings

ICONF                             #"Internal" CONF that never changes
PCONF                             #"Postmaster" CONF that is set on server start (CONF file, `postgres` CLI flags)
HCONF                             #CONF that is also set on reload (SIGHUP, etc.)
LCONF                             #CONF that is also set at session start (LIBPQ)
SCONF                             #CONF that is also set during session (`set ...`)

SIGHUP -> SPID|BPID
pg_ctl reload                     #Reload CONF, HBA and IDENT
pg_reload_conf()                  #Must be superuser

pg_conf_load_time()->TIMESTAMPTZ  #

postgres -c CONFVAR=VAL
postgres --CONFVAR=VAL            #Set CONF for CLUSTER

pg_settings_get_flags             #Returns whether CONFVAR is:
 ('CONFVAR')->STR_ARR             #  - EXPLAIN: EXPLAIN-related, i.e. shown with ZOPTS.settings
                                  #  - RUNTIME_COMPUTED: computed on-the-fly, only for some ICONF.*
                                  #  - NO_SHOW_ALL:
                                  #     - not shown by `show all`
                                  #     - only a few like ICONF.is_superuser
                                  #  - NO_RESET_ALL:
                                  #     - not changed by `reset all`
                                  #     - only a few like ICONF.is_superuser and
                                  #       SCONF.transaction_deferrable|isolation|read_only
                                  #  - NOT_IN_SAMPLE: not present in example CONF file

                                  ┌────────────────────┐
                                  │   CONFIG SESSION   │
                                  └────────────────────┘

ENVVAR PGOPTIONS
LIBPQ.options                     #'-c CONFVAR=VAL ...' for current session

set CONFVAR to VAL                #Set CONFVAR value for current session

set CONFVAR from current          #Set CONFVAR value using current session value, for all other sessions

set CONFVAR to default
reset CONFVAR                     #Unset CONFVAR for current session, i.e. use default value
reset all                         #Unset all CONFVARs for current current session

set session ...                   #Same as set ...
set local ...                     #Like set ... but only for current transaction

set_config('CONFVAR', 'VAL', BOOL)#Like `set [local] CONFVAR to VAL`
 ->'VAL'                          #BOOL (def: false) is `local`

                                  ┌───────────────────┐
                                  │   CONFIG SCOPED   │
                                  └───────────────────┘

alter role all ...                #Like `alter role "ROLE" ...` but for all ROLEs

alter role "ROLE" set|reset ...   #Like `set|reset ...` but for all sessions using initial session ROLE

alter role "ROLE"
 in database "DATABASE"
 set|reset ...                    #Like `set|reset ...` but for ROLE + DATABASE

alter database "DATABASE"
 set|reset ...                    #Like `set|reset ...` but for all sessions using DATABASE

create function|procedure ...
 set ...                          #Like `set ...` but inside a whole FUNC
set local ...                     #Inside a FUNC, changes the value from `create function|procedure ... set ...`

pg_db_role_setting                #TABLE with all CONFVARs set to specific ROLE or DATABASE
pg_db_role_setting.setdatabase    #pg_database.oid or 0
pg_db_role_setting.setrole        #REGROLE or 0
pg_db_role_setting.setconfig      #'CONFVAR=VAL'_ARR

pg_proc.proconfig                 #'CONFVAR=VAL'_ARR of FUNC

                                  ┌────────────────┐
                                  │   CONFIG GET   │
                                  └────────────────┘

show CONFVAR                      #Print CONFVAR's value for current session

current_setting                   #Like `show CONFVAR`
 ('CONFVAR'[, BOOL])->'VAL'       #Fails if missing unless BOOL true

show all                          #Print all CONFVARs of current session: name, value, description

postgres --describe-config        #Prints a whitespace-separated list of all CONFVARs:
                                  #name, description, defaults

pg_settings                       #TABLE with all CONFVARs, except from EXTENSIONs
pg_settings.name                  #'CONFVAR'
pg_settings.setting               #'VAL'
pg_settings.category              #'CATEGORY[ / SUBCATEGORY]', e.g. 'Resource Usage / Disk'
pg_settings.short_desc            #STR. Short description
pg_settings.extra_desc            #STR. Long description
pg_settings.vartype               #STR among 'string', 'bool', 'integer', 'real', 'enum'
pg_settings.min|max_val           #'VAL'. null if not NUM value
pg_settings.enumvals              #'VAL'_ARR. null if not ENUM value
pg_settings.unit                  #Unit among:
                                  #  - null
                                  #  - 'ms|s|min'
                                  #  - 'B|kB|8kB|MB'
pg_settings.context               #Can be:
                                  #  - 'internal': ICONF
                                  #  - 'postmaster': PCONF
                                  #  - 'sighup': HCONF
                                  #  - 'superuser-backend': ZLCONF
                                  #  - 'backend': LCONF
                                  #  - 'superuser': ZSCONF
                                  #  - 'user': SCONF
pg_settings.source                #STR among:
                                  #  - 'default'
                                  #  - 'configuration file': set in CONF file
                                  #  - 'override': set in `postgres` CLI flags
                                  #  - 'client': set in session
pg_settings.sourcefile            #'PATH' to CONF file, if set there
pg_settings.sourceline            #INT4 in CONF file, if set there
pg_settings.boot_val              #'VAL' at server startup
pg_settings.reset_val             #'VAL' if `reset` was called
pg_settings.pending_restart       #BOOL. Whether was changed but need a server restart

                                  ┌─────────┐
                                  │   IPC   │
                                  └─────────┘

notify "CHANNEL"[, 'MESSAGE']     #Sends MESSAGE to client listening to CHANNEL
pg_notify('CHANNEL', 'MESSAGE')   #Def 'MESSAGE': ''
                                  #Max MESSAGE length: 8KB
                                  #Also send the BPID
                                  #Only sent|received when current transaction is committed
                                  #  - if MESSAGE sent twice in same transaction on same CHANNEL, noop
                                  #Received in same order as sent

listen "CHANNEL"                  #How this is done is client-specific
                                  #The server does not send push events, i.e. always pull-based (e.g. polling)
unlisten "CHANNEL"                #
unlisten *                        #Automatically done at end of session

pg_listening_channels()
 ->'CHANNEL'_SET                  #

pg_notification_queue_usage()->NUM#Percentage of the queue used
                                  #The queue holds MESSAGEs sent but not received yet
                                  #Fails if full. Often 8GB large.

psql                              #Prints MESSAGEs on stderr
                                  #Only done after a statement has been executed

                                  ┌────────────────┐
                                  │   FILESYSTEM   │
                                  └────────────────┘

FILESYSTEM ACCESS ==>             #All require superuser

pg_ls_dir('DIR'[, BOOL, BOOL2])   #Must be relative path (.. not allowed), relative to DATADIR
 ->'FILENAME'_SET                 #BOOL (def: false): do not fail if DIR not existing
                                  #BOOL2 (def: false): also return '.' and '..'

pg_read_file
 ('PATH'[, INT8, INT8[, BOOL]])   #Read file
 ->STR                            #INT8 are offset and length
pg_read_binary_file(...)->BYTEA   #BOOL (def: false): do not fail if does not exist

pg_stat_file('PATH'[, BOOL])->ROW #Get file metadata
                                  #BOOL (def: false): do not fail if does not exist
ROW.size                          #INT8
ROW.isdir                         #BOOL
ROW.access|modification|change
 |creation                        #atime|mtime|ctime|birthtime TIMESTAMPTZ

pg_file_*                         #Trusted postgres extension 'adminpack'

pg_file_write
 ('PATH', 'PATH2', BOOL)->INT8    #BOOL is append
pg_file_rename
 ('PATH', 'PATH2'[, 'PATH3'])
 ->BOOL                           #'PATH2' is copied to 'PATH3' first (if specified)
pg_file_unlink('PATH')->BOOL      #
pg_file_sync('PATH')              #

                                  ┌────────────────────────┐
                                  │   PREPARED STATEMENT   │
                                  └────────────────────────┘

prepare PREP as COMMAND           #Save COMMAND as PREP
                                  #COMMAND must be select|values or insert|update|delete|merge
                                  #Pre-parse it
                                  #  - i.e. faster to execute
                                  #  - re-parsed on changes, such as:
                                  #     - DDL impacting COMMAND
                                  #     - planner statistics changed
                                  #     - SCONF.search_path changed
                                  #Does some inlining too
                                  #  - e.g. 'now'::timestamptz, but not now()->TIMESTAMPTZ
prepare PREP(TYPE, ...)           #TYPEs are parameters
 as COMMAND                       #They can be used in COMMAND as $1, etc.
                                  #  - must be own token, e.g. not inside a 'STR'
                                  #  - must not be a "VAR"
                                  #  - automatically escaped
                                  #Optional:
                                  #  - arguments can be passed even without a corresponding parameter TYPE
                                  #  - they are cast as unknown

execute PREP[(VAL,...)]           #Execute COMMAND from PREP

deallocate PREP|all               #Delete a PREP
                                  #Automatically done at end of each session

SCONF.plan_cache_mode             #Whether to use:
                                  #  - a generic plan: ignore TYPEs
                                  #     - faster planning time
                                  #  - a custom plan: take TYPEs into account
                                  #     - potentially faster execution time
                                  #Def: 'auto'
                                  #  - first 5 `execute` use a custom plan
                                  #  - a generic plan is used based on them
                                  #  - next `execute` use the generic plan unless it seems like a custom plan is better
                                  #Can also be 'force_generic|custom_plan'

pg_prepared_statements            #TABLE with all PREPs
pg_prepared_statements.name       #'PREP'
pg_prepared_statements
 .parameter_types                 #REGTYPE_ARR of parameters
pg_prepared_statements.statement  #'COMMAND'
pg_prepared_statements.from_sql   #BOOL. Whether COMMAND is SQL
                                  #PREPs can also be created through some low-level protocol
pg_prepared_statements
 .prepare_time                    #TIMESTAMPTZ of creation
pg_prepared_statements
 .generic|custom_plans            #UINT. Number of `execute` which used a generic|custom plan

                                  ┌───────────────────┐
                                  │   FUNCTION CALL   │
                                  └───────────────────┘

FUNC(VAL)                         #Positional argument
FUNC("ARG" => VAL)
FUNC("ARG" := VAL)                #Named argument
FUNC(VAL, "ARG" => VAL)           #Mixed positional|named argument

FUNC(..., ...)
FUNC(..., variadic ARR)           #Calling a variadic argument

do [language "LANGUAGE"] 'BODY'   #Call anonymous FUNC
                                  #Def LANGUAGE: plpgsql
                                  #Cannot use sql LANGUAGE

                                  ┌─────────────────────────┐
                                  │   FUNCTION DEFINITION   │
                                  └─────────────────────────┘

create function                   #Create a FUNC
 "FUNC"([FUNC_ARG,...])           #'BODY' often uses $$...$$ notation
 returns TYPE as 'BODY'           #FUNC is parent dependency of anything that uses it (e.g. VIEW, etc.)

OVERLOADING ==>                   #Possible

"ARG" TYPE                        #FUNC_ARG

TYPE ...                          #"ARG" can be omitted in FUNC_ARG, in which case, it cannot be used in FUNC body

"ARG" TYPE default VAL
"ARG" TYPE = VAL                  #Argument's default value

variadic "ARG" ARR_TYPE           #Declaring a variadic FUNC_ARG
                                  #Not optional by default, i.e. often add `default array[]::TYPE[]`

out "ARG" TYPE                    #Declare return TYPE in parameters list
                                  #Return value "ARG" can be directly assigned
out "ARG" TYPE, ...               #Same but returns a ROW_TYPE where each "ARG" is a COL
inout "ARG" TYPE                  #Same as `"ARG" TYPE` + `out "ARG" TYPE`, i.e. both argument and return TYPE

"ROW_ALIAS"."COL"%type            #TYPE of "COL"
                                  #Cannot be used between FUNC_ARGs

SCONF.check_function_bodies       #BOOL. If true (def), check syntax error in 'BODY' when FUNC is created
                                  #Sometimes, this can be an issue when some VARs are not setup yet
                                  #  - e.g. this is disabled by pg_dump

ICONF.max_function_args           #100. Max NUM of arguments in a FUNC

                                  ┌───────────────┐
                                  │   PROCEDURE   │
                                  └───────────────┘

create|alter procedure "PROCEDURE"#Like `function` except can only be called top-level, using `call`
 ...                              #Also:
                                  #  - return TYPE must be either void or ROW_SET
                                  #  - can start|end transactions
                                  #`[in]out "ARG" TYPE`
                                  #  - must be used instead of `returns TYPE`
                                  #  - `out` ARGs must be specified by caller as if they were `inout`
                                  #     - however, they are ignored, i.e. usually `null` is passed
                                  #Same syntax as `create|alter function ...` except:
                                  #  - no `strict`
                                  #  - no `leakproof`
                                  #  - cannot be WFUNC
                                  #  - no query planner optimization: parallel, cost, rows, support

call PROCEDURE_FUNC(...)          #

                                  ┌──────────────────────┐
                                  │   CUSTOM AGGREGATE   │
                                  └──────────────────────┘

create aggregate
 "AFUNC"(FUNC_ARG,...) (OPTS)     #Creates an AFUNC(...)

OPTS.sfunc                        #FUNC(VAL, VAL2,...)->VAL
                                  #Reduces the SET elements VAL2s (from FUNC_ARGs) to a single VAL
                                  #By convention, FUNC is `strict`:
                                  #  - does not call OPTS.sfunc with nulls elements
                                  #  - calls OPTS.finalfunc even if only nulls elements

OPTS.initcond                     #UNKNOWN. Initial value passed to OPTS.sfunc
                                  #Def: null
OPTS.stype                        #TYPE to cast OPTS.initcond

OPTS.finalfunc                    #FUNC(VAL)->VAL applied at end

OPTS.finalfunc_extra              #Means the last FUNC_ARGs are not passed to any OPTS.* FUNCs
                                  #Useful for following edge case:
                                  #  - when those are polymorphic any*
                                  #  - which cannot be the first FUNC_ARG, because that has `internal` TYPE

OPTS.finalfunc_modify             #Whether OPTS.finalfunc is:
                                  #  - read_only
                                  #  - shareable: not readonly but idempotent
                                  #  - read_write (def)
                                  #Used by query planner for optimization
                                  #Can only use as WFUNC if read_only
OPTS.sortop                       #OP (def: <) used to compare VALs
                                  #Used by some optimizations, e.g. skipping some ROWs when using min|max() AFUNCs
OPTS.sspace                       #NUM (def: guessed). Average size of each VAL, used by query planner to compute cost

OPTS.msfunc
OPTS.minitcond
OPTS.mstype
OPTS.mfinalfunc
OPTS.mfinalfunc_extra
OPTS.mfinalfunc_modify            #OPTS.m* is like OPTS.* but when called as WFUNC
OPTS.msspace                      #OPTS.msfunc cannot return null
OPTS.minvfunc                     #FUNC that reverts OPTS.msfunc, for WFUNC:
                                  #  - new appended element to WINDOW calls OPTS.msfunc
                                  #  - element removed at beginning from WINDOW calls OPTS.minvfunc
                                  #Can return null to opt-out of being used, when reversal is not possible

create function ... window        #Declare a WFUNC.
                                  #Passes additional arguments about current WINDOW
                                  #Only in C LANGUAGE
                                  #Not documented yet

create aggregate "AFUNC"          #Creates an ordered-set AFUNC (i.e. uses ZSET)
 (... order by TYPE ,...)         #TYPE is ZSET's
 (OPTS)                           #"Direct arguments" are passed to OPTS.finalfunc instead of OPTS.sfunc
                                  #OPTS.finalfunc must sort ZSET
                                  #OPTS: cannot use m* (WFUNC), combinefunc, [de]serialfunc, sortop
                                  #Must use LANGUAGE C
OPTS.hypothetical                 #BOOL (def: false). Whether can use both as AFUNC and WFUNC
                                  #"direct arguments" and "aggregate arguments" must have same TYPE

OPTS.combinefunc                  #FUNC(VAL, VAL2)->VAL3 meant to support "partial aggregation"
                                  #Like OPTS.sfunc, but combining two VALs returned by other OPTS.sfuncs|initcond
                                  #Must use OPTS.parallel 'safe'
OPTS.serialfunc                   #FUNC(INTERNAL)->BYTEA used to serialize VALs while performing a partial aggregation
OPTS.deserialfunc                 #FUNC(BYTEA)->INTERNAL to do inverse

pg_aggregate                      #TABLE with all AFUNCs
pg_aggregate.aggfnoid             #REGPROC of AFUNC
pg_aggregate.aggtransfn           #REGPROC. OPTS.sfunc
pg_aggregate.agginitval           #STR. OPTS.initcond
pg_aggregate.aggtranstype         #REGTYPE. OPTS.stype
pg_aggregate.aggfinalfn           #REGPROC. OPTS.finalfunc. 0 if none
pg_aggregate.aggfinalextra        #BOOL. OPTS.finalfunc_extra
pg_aggregate.aggfinalmodify       #'r|s|w'. OPTS.finalfunc_modify
pg_aggregate.aggsortop            #REGOPERATOR. OPTS.sortop
pg_aggregate.aggtransspace        #INT4. OPTS.sspace. 0 if none
pg_aggregate.aggminitval
pg_aggregate.aggmtranstype
pg_aggregate.aggmtransfn
pg_aggregate.aggmfinalfn
pg_aggregate.aggmfinalextra
pg_aggregate.aggmfinalmodify
pg_aggregate.aggmtransspace       #OPTS.m*
pg_aggregate.aggminvtransfn       #REGPROC. OPTS.minvfunc. 0 if none
pg_aggregate.aggcombinefn         #REGPROC. OPTS.combinefunc. 0 if none
pg_aggregate.aggserialfn          #REGPROC. OPTS.serialfunc. 0 if none
pg_aggregate.aggdeserialfn        #REGPROC. OPTS.deserialfunc. 0 if none
pg_aggregate.aggkind              #CHAR among: 'n' (normal), 'o' (ordered-set), 'h' (OPTS.hypothetical)
pg_aggregate.aggnumdirectargs     #INT2. Number of "direct arguments". null if not "ordered-set"

                                  ┌─────────────┐
                                  │   ROUTINE   │
                                  └─────────────┘

FUNC                              #"Routine", i.e. either `function`, `procedure` or `aggregate`

alter routine ...                 #Like alter function ... but works also on PROCEDURE|AFUNC
                                  #Cannot alter `strict`, `support`
drop routine ...                  #Like drop function ... except works also on PROCEDURE|AFUNC

pg_proc                           #TABLE with all FUNCs
pg_proc.oid                       #OID
pg_proc.proname                   #"FUNC" name
pg_proc.prokind                   #'CHAR' among: 'f' (function), 'p' (procedure), 'a' (aggregate), 'w' (window)
pg_proc.prolang                   #pg_language.oid of LANGUAGE
pg_proc.prosqlbody                #PG_NODE_TREE of 'BODY'
                                  #null if not SQL or if `as '...'`
pg_proc.prosrc                    #Either 'BODY' or 'FUNC_NAME' from `create function ... as "PATH", "FUNC_NAME"`
pg_proc.probin                    #'PATH'. `create function ... as "PATH", "FUNC_NAME"`
pg_proc.proisstrict               #BOOL. `create function ... strict`
pg_proc.procost                   #FLOAT4. `create function ... cost`
pg_proc.prorows                   #FLOAT4. `create function ... rows`. 0 if none
pg_proc.provolatile               #'i|s|v'. `create function ... immutable|stable|volatile`
pg_proc.prosupport                #REGPROC. `create function ... support`. 0 if none
pg_proc.prosecdef                 #BOOL. `create function ... security definer`
pg_proc.proleakproof              #BOOL. `create function ... leakproof`
pg_proc.proparallel               #'s|r|u'. `create function ... parallel safe|restrict|unsafe`
pg_proc.protrftypes               #REGTYPE_ARR. `create function ... transform for type TYPE`
                                  #Null if none.
pg_proc.proargtypes               #REGTYPE_ARR of arguments
pg_proc.pronargs                  #INT2. Number of arguments
pg_proc.pronargdefaults           #INT2. Number of arguments with default values
pg_proc.proargdefaults            #PG_NODE_TREE of arguments default values
                                  #null if none
pg_proc.proargnames               #'ARG'_ARR of arguments
                                  #If no ARG name, empty STR. If all no name, null.
pg_proc.provariadic               #REGTYPE of underlying TYPE if `variadic`. 0 if not.
pg_proc.prorettype                #REGTYPE of return value
pg_proc.proretset                 #BOOL. Whether returns a SET
pg_proc.proallargtypes            #REGTYPE_ARR of arguments + `[in]out` ones
                                  #null if no `[in]out`
pg_proc.proargmodes               #'CHAR'_ARR of arguments + `[in]out` ones among: 'i' (in), 'o' (out), 'b' (inout), 'v' (variadic), 't' (table(...))
                                  #null if no `[in]out`

regproc                           #TYPE to cast pg_proc.oid as "FUNC" name
regprocedure                      #TYPE to cast pg_proc.oid as "FUNC(TYPE,...)" name

pg_get_functiondef
 (REGPROCEDURE)->STR              #Returns 'CREATE ...' statement that created FUNC
pg_get_function_identity_arguments
 (REGPROCEDURE)->STR              #Returns 'FUNC_ARG,...' used in REGPROCEDURE::text, i.e. to distinguish from other REGPROCEDUREs
pg_get_function_arguments
 (REGPROCEDURE)->STR              #Returns 'FUNC_ARG,...' specified in 'CREATE ...' statement that created FUNC
pg_get_function_result
 (REGPROCEDURE)->STR              #Same for return 'TYPE'

                                  ┌──────────────┐
                                  │   OPERATOR   │
                                  └──────────────┘

create operator "OP"(OPTS)        #Creates an OP, i.e. a FUNC using punctuation signs as name.
                                  #OP can use +-*/<>=~!@#%^&|`?
                                  #Can use overloading
OPTS.function                     #FUNC. Can have one (rightarg) or two arguments (leftarg|rightarg)
OPTS.leftarg|rightarg             #TYPE

alter operator
 "OPERATOR"(TYPE, TYPE2)
 set (OPTS)                       #

OPTS.commutator                   #OP2, with VAL OP VAL2 === VAL2 OP2 VAL
                                  #Used for query planner optimization, to reorder a query's expressions
                                  #  - e.g. to match a multi-COL INDEX

OPTS.negator                      #OP2, with VAL OP VAL2 === not (VAL OP2 VAL2)
                                  #Or OP VAL === not (OP2 VAL)
                                  #Used for query planner optimization, to simplify query
                                  #  - e.g. not (VAL OP VAL2) -> VAL OP2 VAL2

OPTS.restrict                     #FUNC hinting how much percentage of ROWs are returned by `where COL OP VAL2`
                                  #Only if OP returns BOOL
                                  #Used for query planner optimization, to compute query cost
                                  #Can choose among default following ones
eqsel                             #Very small percentage, like =
neqsel                            #Large percentage, like <>
scalar[lt|le|gt|ge]sel            #Semi-large percentage before or after, like < <= > >=
matchingsel                       #Like matching|subset OPs for TSVECTOR, JSON, LTREE, HSTORE
tsmatchsel                        #Like TSQUERY @@
arraycontsel                      #Like subset OPs for ARR, like @> &&
[ic][n]likesel                    #Like GLOB match [negated] [case insensitive]
[ic][n]regexeqsel                 #Same for REGEXP
prefixsel                         #Like ^@
[multi]rangesel                   #Like OPs for [MULTI]RANGE
contsel                           #Like subset OPs for geometry
areasel                           #Like overlapping OPs for geometry
positionsel                       #Like positioning OPs for geometry
networksel                        #Like OPs for CIDR|INET

OPTS.join                         #FUNC. Like OPTS.restrict but for `where COL OP COL2`
                                  #Can choose among default following ones
*joinsel                          #Like *sel above

OPTS.hashes                       #BOOL (def: false). Whether VAL OP VAL2 === hash(VAL) OP hash(VAL2)
                                  #Only if OP returns BOOL
                                  #Used for query planner optimization, to know if can do a hash join

OPTS.merges                       #BOOL (def: false). Whether has a total order
                                  #Only if OP returns BOOL
                                  #Used for query planner optimization, to know if can do a merge join

pg_operator                       #TABLE with all OPERATORs
pg_operator.oid                   #OID
pg_operator.oprname               #"OP" name
pg_operator.oprcode               #REGPROC. OPTS.function
pg_operator.oprleft|oprright      #REGTYPE. OPTS.leftarg|rightarg
pg_operator.oprkind               #CHAR. 'b' (2 arguments) or 'l' (1 argument)
pg_operator.oprresult             #REGTYPE of return
pg_operator.oprcom                #REGOPERATOR. OPTS.commutator. 0 if none.
pg_operator.oprnegate             #REGOPERATOR. OPTS.negator. 0 if none.
pg_operator.oprrest               #REGPROC. OPTS.restrict. 0 if none.
pg_operator.oprjoin               #REGPROC. OPTS.join. 0 if none.
pg_operator.oprcanmerge           #BOOL. OPTS.merges
pg_operator.oprcanhash            #BOOL. OPTS.hashes

regoper                           #TYPE to cast pg_operator.oid as "OP" name
regoperator                       #TYPE to cast pg_operator.oid as "OP(TYPE,...)" name

                                  ┌─────────┐
                                  │   JIT   │
                                  └─────────┘

SCONF.jit                         #BOOL. If true (def), compile SQL clauses in bytecode to speed them up
                                  #In: `select VALs`, `where BOOL_REXPR`, AFUNCs
pg_jit_available()->BOOL          #SCONF.jit true and JIT is supported

SCONF.jit_above_cost              #NUM (def: 1e5). When a query's `explain` cost >= NUM, perform JIT
SCONF.jit_inline_above_cost       #NUM (def: 5e5). When a query's `explain` cost >= NUM, inline FUNC bodies
                                  #Only for FUNCs with LANGUAGE C
SCONF.jit_optimize_above_cost     #NUM (def: 5e5). When a query's `explain` cost >= NUM, perform JIT expensive optimizations
                                  #Max: jit_inline_above_cost
SCONF.jit_expressions             #BOOL (def: true). Allow EXPRs (not only FUNCs) to use JIT
SCONF.jit_tuple_deforming         #BOOL (def: true). Use JIT when "deforming" ROWs, i.e. when loading them from file to in-memory

zPCONF.jit_provider               #STR (def: 'llvmjit')
ZSCONF.jit_dump_bitcode           #BOOL (def: false). Outputs JIT bytecode in DATADIR, for debugging purpose
ZLCONF.jit_debugging_support      #BOOL (def: false). Use GDB with JIT, for debugging purpose
ZLCONF.jit_profiling_support      #BOOL (def: false). Outputs profiling info to ~/.debug/jit/, for debugging purpose

EXPLAIN NODES ==>                 #
JIT                               #JIT compilation
  Functions: NUM                  #NUM of FUNCs compiled
  Options: Inlining BOOL          #SCONF.jit_inline_above_cost
  Options: Optimization BOOL      #SCONF.jit_optimize_above_cost
  Options: Expressions BOOL       #SCONF.jit_expressions
  Options: Deforming BOOL         #SCONF.jit_tuple_deforming
  Timing: ...                     #How long JIT took

$libdir/bitcode/EXTENSION.index.bc#EXTENSIONs must generate bytecode at build time to be able to use it
$libdir/bitcode/EXTENSION/*.bc    #Those must be output there
                                  #Automatically done by PGXS

                                  ┌──────────────┐
                                  │   LANGUAGE   │
                                  └──────────────┘

create language "LANGUAGE"        #Create and enable a LANGUAGE
 handler FUNC                     #`handler` is called when a FUNC is run
                                  #Must use pg_proc to find information about that FUNC
                                  #Must be superuser
                                  #Usually packaged into an EXTENSION
                                  #Not documented yet
language_handler                  #TYPE returned by LANGUAGE `handler` FUNC

create language "LANGUAGE"
 handler FUNC inline FUNC2        #FUNC2 is called when a FUNC is run with `do ...`

create language "LANGUAGE"
 handler FUNC validator FUNC2     #FUNC2 is called when a FUNC is created, to validate its syntax|TYPEs

create trusted language "LANGUAGE"#Allow non-superuser ROLEs to enable
 ...                              #Also, runs LANGUAGE with current ROLE's PRIVILEGEs, e.g. cannot access filesystem
                                  #False for C|R|SH, true for SQL|PGSQL

create function|procedure ...     #Use a LANGUAGE in a FUNC
 language 'LANGUAGE'              #Def LANGUAGE: sql, if using `return ...`. Otherwise, no default

pl*                               #Procedural LANGUAGEs. Faster than sql, slower than C
plpython3u                        #Python LANGUAGE. Not documented yet
plperl                            #Perl LANGUAGE. Not documented yet
pltcl                             #Tcl LANGUAGE. Not documented yet

pg_language                       #TABLE with all LANGUAGEs
pg_language.oid                   #OID
pg_language.lanname               #"LANGUAGE" name
pg_language.lanispl               #BOOL. False for internal LANGUAGEs (internal|c|sql). True for others.
pg_language.lanpltrusted          #BOOL. `create trustred language ...`
pg_language.lanplcallfoid         #REGPROC. `handler` FUNC
pg_language.laninline             #REGPROC. `inline` FUNC2
pg_language.lanvalidator          #REGPROC. `validator` FUNC2

plv8 EXTENSION ???

                                  ┌───────┐
                                  │   C   │
                                  └───────┘

internal                          #LANGUAGE for the C builtin FUNCs
                                  #Can be referred to to alias them using `create function|procedure ... strict`

c                                 #LANGUAGE for the C non-buitin FUNCs
                                  #Not documented yet

create function|procedure ...     #Define C FUNC
 as 'PATH'[, 'FUNC_NAME']         #Calls load 'PATH', using its exported 'FUNC_NAME' (def: same as "FUNC")

load 'PATH'                       #Loads a C library
zPCONF.shared_preload_libraries   #'DIR,...' that perform `load 'FILE'`. Must omit file .EXT
                                  #Def: none
                                  #Some "C addons" are pre-installed in '$libdir'
                                  #  - similar to EXTENSIONs, but only a C library
                                  #  - enabled by putting '$libdir/NAME' in PCONF.shared_preload_libraries
zSCONF.session_preload_libraries  #'DIR,...'. Same but loaded by each session
                                  #Must be superuser
SCONF.local_preload_libraries     #'DIR,...'. Same but loaded by each session
                                  #Does not need to be superuser
zSCONF.dynamic_library_path       #'DIR:...' (def: '$libdir'). Relative paths of `load 'FILE'` if not absolute.
                                  #Can include '$libdir'

$libdir                           #DIR with EXTENSION-defined C libraries
                                  #On my system: /usr/lib/postgresql/VERSION/lib/
                                  #Only $libdir/plugins/ can be used by non-superusers
pg_config --pkglibdir             #Prints $libdir location

SHAREDLIBDIR                      #DIR with system C libraries
                                  #On my system: /usr/lib/x86_64-linux-gnu
pg_config --libdir                #Prints SHAREDLIBDIR

INCLUDEDIR                        #DIR with C header files for clients
                                  #Not always present
                                  #On my system: /usr/include/postgresql
pg_config --includedir            #Prints INCLUDEDIR

INCLUDEDIR-SERVER                 #DIR with C header files for server
                                  #Not always present
                                  #On my system: /usr/include/postgresql/VERSION/server
pg_config --includedir-server     #Prints INCLUDEDIR-SERVER

PKGINCLUDEDIR                     #DIR with other C header files
                                  #Not always present
                                  #On my system: /usr/include/postgresql
pg_config --pkgincludedir         #Prints PKGINCLUDEDIR

                                  ┌────────────┐
                                  │   PL/SQL   │
                                  └────────────┘

sql                               #LANGUAGE always available, with BODY being SQL
                                  #Cannot use transactions, vacuum
                                  #Cannot create ENTITYs then refer to them

create function|procedure ...     #Like `as '...'` but parsed as FUNC creation time instead of execution time
 begin atomic ... end             #Cannot use any* TYPEs
                                  #Also, sets FUNC as parent dependency of ENTITYs used in ...
create function|procedure ...
 return ...                       #Same as `begin atomic select ... end`

RETURN VALUE ==>                  #Last SQL statement must return either:
                                  #  - a MSUBQUERY
                                  #  - void

["FUNC".]"ARG"                    #Can be used, including for `out` ARGs
                                  #Readonly
$NUM                              #Refers to "ARG", 1-based

                                  ┌────────────────┐
                                  │   PGSQL MAIN   │
                                  └────────────────┘

plpgsql                           #PL/PGSQL LANGUAGE
                                  #Like SQL but with: VARs, structures|loops, exception handling, logs
plpgsql                           #EXTENSION with that LANGUAGE. Enabled by default

CASE SENSITIVITY ==>              #Like in SQL, e.g. keywords case insensitive, "VAR" quoting, etc.

-- COMMENT ...
/* COMMENT */                     #Like in SQL

STATEMENT;                        #Like in SQL
BLOCK;                            #Semicolon at the end of BLOCKs
                                  #Optional for `begin ... end`

VAL                               #Like `select VAL`
                                  #I.e. can use `from`, AFUNC, `where`, etc.
                                  #Cannot use union|intersect|except

#CONFVAR VAL                      #Sets PCONF.plpgsql.CONFVAR VAL for a single FUNC, as a top-level COMMAND

CACHING ==>                       #FUNC calls parsing is cached (using PREPs internally)
                                  #I.e. "ROW_ALIAS"."COL" TYPEs must not change between calls
                                  #  - can use `record` to prevent issues
                                  #`execute 'SQL_COMMAND'` parsing is not cached (i.e. slower)

begin                             #Lexical scope BLOCK
  STATEMENTS...                   #VARs are local to BLOCK
end                               #Can be top-level (required) or nested

TRANSACTIONS ==>                  #FUNC is run in a transaction, with exceptions rollbacking the transaction
commit|rollback [and chain]       #Can be used to end current transaction and start a new one
                                  #Only if FUNC was called with `do ...` or `call ...` (PROCEDURE)

return VAL                        #Return value of the FUNC
return                            #When using either:
                                  #  - `void` return TYPE
                                  #  - `out` ARGs
return next [VAL]                 #When returning a SET, one `return` per item
                                  #Def VAL: current `out` ARGs
                                  #Final `return` must be empty

plpgsql_check EXTENSION ???

                                  ┌─────────────────────┐
                                  │   PGSQL VARIABLES   │
                                  └─────────────────────┘

declare
  VAR [constant] TYPE
   [collate "COLLATION"]
   [not null]                     #Declare VARs
   [default|:= VAL];              #Def VAL: null
  ...                             #VAL is evaluated call-time, not declaration-time
begin ...                         #VAL can use VARs declare in same `declare` block

VAR                               #Use VARs

["FUNC".]ARG                      #Like other LANGUAGEs
$NUM                              #`out` ARGs are initially null (including $0)

$0                                #`out` ARG automatically created for the return value when it is any*

declare
  VAR alias for ARG|$NUM
begin ...                         #Give a VAR alias to an ARG

VAR%type                          #TYPE of VAR
"TABLE"%rowtype                   #ROW_TYPE of TABLE

VAR := VAL                        #Assignment
ROW.COL := VAL
ARR[NUM] := VAL
ARR[NUM:NUM2] := ARR2             #Assignment

PCONF.plpgsql.variable_conflict   #Whether ambiguous VAR shadowing should:
                                  #  - 'error' (def)
                                  #  - 'use_variable': use "FUNC".ARG
                                  #  - 'use_column': use "ROW_ALIAS"."COL"

                                  ┌─────────────────────┐
                                  │   PGSQL EXCEPTION   │
                                  └─────────────────────┘

raise                             #Throw an exception
                                  #If currently catching an exception, rethrow it
raise EXCEPTION ...               #Sets condition name
raise sqlstate 'STR' ...          #Sets error code
raise 'MESSAGE'[, VAL...] ...     #Sets error message
                                  #Can substitute % with each VAL...
raise ... using EVAR = STR ,...   #Sets exception attributes
                                  #Same EVAR as `get stack diagnostics` but named: errcode, message, detail, hint,
                                  #column, constraint, datatype, table, schema
raise LEVEL ...                   #Exception level among: exception (def), warning, notice, info, log, debug
                                  #LEVELs others than `exception` print on stderr, instead of throwing
                                  #LEVEL is matched by ZSCONF.log_min_messages and SCONF.client_min_messages

assert BOOL[, 'MESSAGE']          #If true, call: raise ASSERT_FAILURE using message = 'MESSAGE'
                                  #Def MESSAGE: 'assertion failed'
PCONF.plpgsql.check_asserts       #BOOL (def: true). Enable `assert ...`

begin ...                         #Catches exceptions
exception ...                     #Only runs the first matching `when`. If none, rethrow exception.
end                               #Can use the VARs at the moment exceptions was thrown
                                  #Using exception handling blocks has a performance cost
begin ...
exception when EXCEPTION then ...
end                               #Catches exception by name ("condition name")
begin ...
exception when sqlstate 'STR'     #Catches exception by "error code"
 then ...                         #5 chars|digits. First 2 are the category.
end                               #If last 3 are 000, catches whole category
begin ...
exception when others then ...
end                               #Catch-all
begin ...
exception when ... or ...
 then ...
end                               #Can use `or`

sqlstate                          #VAR with current error code STR
sqlerrm                           #VAR with current error 'MESSAGE'

get stacked diagnostics EVAR = ...#Set EVAR with EXCEPTION.* attributes
                                  #Empty '' if none
get stacked diagnostics
 EVAR = returned_sqlstate         #sqlstate
get stacked diagnostics
 EVAR = message_text              #sqlerrm
get stacked diagnostics
 EVAR = pg_exception_detail       #Additional details to the error message
get stacked diagnostics
 EVAR = pg_exception_hint         #Hint to fix
get stacked diagnostics
 EVAR = pg_exception_context      #Stack trace
get stacked diagnostics
 EVAR = column_name               #'COL' that threw
get stacked diagnostics
 EVAR = constaint_name            #'CONSTRAINT' that threw
get stacked diagnostics
 EVAR = pg_datatype_name          #'TYPE' that threw
get stacked diagnostics
 EVAR = table_name                #'TABLE' that threw
get stacked diagnostics
 EVAR = schema_name               #'SCHEMA' that threw

get diagnostics VAR = pg_context  #Current stack trace

                                  ┌───────────────────┐
                                  │   PGSQL COMMAND   │
                                  └───────────────────┘

null;                             #Noop
                                  #Useful inside a structure, e.g. in an exception catch clause

SQL_COMMAND                       #Execute SQL command
                                  #Can only contains VARs if select|insert|update|delete|merge
perform ...                       #Must be used instead of `select ...` or `insert|update|delete ... returning ...`
                                  #No return value
perform (...) ...                 #Must be used instead of `with (...) select ...`
                                  #Can only return one ROW

execute 'SQL_COMMAND'             #Execute SQL command, but specified as a STR
                                  #$$...$$ often used
execute ... using VAL,...         #Substitute $NUM in 'SQL_COMMAND' with VALs
                                  #Only with select|insert|update|delete|merge
                                  #  - other commands must concatenate 'SQL_COMMAND' directly instead (e.g. with format())
                                  #VAL cannot be a "NAME"
                                  #Should use quote_* for dynamic values

MSUBQUERY into VAR,...            #Set VAR with MSUBQUERY's return value
execute ... into VAR,...          #If returns ROW, can either use:
                                  #  - one VAR per COL
                                  #  - one ROW_TYPE VAR
MSUBQUERY into strict VAR,...     #Throws exception if MSUBQUERY returns SET with:
execute ... into strict VAR,...   #  - no items: NO_DATA_FOUND
                                  #  - several items: TOO_MANY_ROWS
                                  #Otherwise:
                                  #  - no items -> null
                                  #  - several items -> use first one only
                                  #`... returning ....` are always `strict`
PCONF.plpgsql.print_strict_params #BOOL (def: false). Sets EXCEPTION.detail on NO_DATA_FOUND|TOO_MANY_ROWS

return query MSUBQUERY
return query execute ...          #Like `return next`, but using the command's return value

found                             #BOOL_VAR. Whether last SQL command read|wrote at least one ROW
                                  #Only set by select|perform, insert|update|delete|merge, fetch|move, for|foreach
                                  #Not set by `execute ...`

get diagnostics VAR = row_count   #INT8 of ROWs read|wrote by last SQL command

                                  ┌─────────────────────┐
                                  │   PGSQL STRUCTURE   │
                                  └─────────────────────┘

if BOOL then ...
[elsif BOOL then ...]
[else ...]
end if;                           #

case ... end case;                #Like in SQL: case ... end
                                  #Except: can use `when TVAL,...` (matches any TVAL)

[while BOOL] loop ...
end loop                          #Def BOOL: true

for "INT4_VAR"
 in [reverse] NUM..NUM2 [by NUM3]
loop ...
end loop                          #Loop through NUM (included) to NUM2 (included) with step NUM3 (def: 1)

for VAR,... in MSUBQUERY
loop ...
end loop                          #Iterates over: MSUBQUERY into VAR,...
for VAR,... in execute ...
loop ...
end loop                          #Same with execute ...

foreach VAR in array ARR
loop ...
end loop                          #

foreach ARR_VAR slice NUM ...     #Iterates through NUM elements at a time,

foreach VAR,... in array ROW      #

                                  ┌─────────────────┐
                                  │   PGSQL BLOCK   │
                                  └─────────────────┘

<<LABEL>> begin ... end [LABEL]
<<LABEL>> while|for|foreach ...
 end loop [LABEL]                 #Label a BLOCK

exit                              #Exit current BLOCK
                                  #If the BLOCK is `for[each]`, its VAR is still accessible
exit LABEL                        #Specifies block (def: innermost)
exit when BOOL                    #Only exit if BOOL true
continue ...                      #Same as exit ... but start a new loop iteration instead

"LABEL".VAR                       #Specifies BLOCK of a VAR, in case of shadowing

                                  ┌───────────────────┐
                                  │   PGSQL TRIGGER   │
                                  └───────────────────┘

TFUNC ==>                         #Those are VARs defined in TFUNCs

tg_argv                           #STR_ARR from: create trigger ... execute function FUNC(STR,...)
tg_nargs                          #INT4. tg_argv length

tg_name                           #'TFUNC'

ts_table_name                     #'TABLE'
tg_relid                          #REGCLASS of TABLE
ts_table_schema                   #'SCHEMA' of TABLE

tg_when                           #'BEFORE|AFTER|INSTEAD OF'
tg_level                          #'STATEMENT|ROW'
tg_op                             #'INSERT|UPDATE|DELETE|TRUNCATE'

old                               #Current RECORD, before changes
                                  #Only if `for each row`
                                  #Not if `insert`
new                               #Same but after changes
                                  #Not if `delete`

EFUNC ==>                         #Those are VARs defined in EFUNCs
tg_event                          #'EVENT'
tg_tag                            #'COMMAND'

                                  ┌──────────────────┐
                                  │   PGSQL CURSOR   │
                                  └──────────────────┘

CURSOR cursor for SUBQUERY        #Declare CURSOR and its SUBQUERY
open CURSOR                       #Calls the SUBQUERY
                                  #Can use "CURSOR" even after FUNC ended
                                  #But closes with end of transaction
CURSOR cursor(ARG TYPE,...)
 for ...
open CURSOR(...)                  #Define and pass arguments when opening CURSOR

CURSOR refcursor                  #Declare CURSOR
open CURSOR
 for SUBQUERY|execute ...         #Declare and calls SUBQUERY

CURSOR [no] scroll cursor ...
open CURSOR [no] scroll ...       #Backwards iteration

fetch ...                         #Cannot fetch multiple ROWs
fetch ... into VAR                #Set VAR using: `fetch ...`

for RECORD_VAR in CURSOR[(...)]
loop ...                          #Calls open CURSOR(...) then loop using `fetch next from CURSOR`
end loop                          #Closes CURSOR at end of loop

                                  ┌────────────────┐
                                  │   PGSQL LINT   │
                                  └────────────────┘

PCONF.plpgsql.extra_warnings      #'RULE,...', 'none' (def) or 'all'. Print linting warnings
                                  #Should not use in production, for performance
PCONF.plpgsql.extra_errors        #Same but throws exceptions

shadowed_variables                #VAR shadows another
strict_multi_assignment           #When assigning multiple VARs, the number of VARs must match
too_many_rows                     #Like TOO_MANY_ROWS exception

                                  ┌───────────┐
                                  │   PL/SH   │
                                  └───────────┘

plsh                              #LANGUAGE for current OS shell (including Bash)
                                  #Cannot use: ROW, SET, any*, `out` ARGs
                                  #Version 2022-09-17

#!...                             #Must be at start of BODY

ARG                               #Same as shell, e.g. for Bash: $1, "$@", $#, etc.

RETURN VALUE ==>                  #Print on stdout, with final newline stripped
                                  #null if exit (exit code 0) with nothing on stdout

EXCEPTION ==>                     #Non-0 exit code
                                  #Can print on stderr

psql ...                          #Must be called to run SQL commands

SHELL COMMANDS ==>                #Use superuser ROLE

TFUNC|EFUNC                       #Defines PLSH_TG_* like tg_* in PL/PGSQL (old|new unavailable)
                                  #TFUNC() is run, but does not modify current ROW

                                  ┌──────────┐
                                  │   PL/R   │
                                  └──────────┘

PL/R ==>                          #plr: for R:
                                  #  - Arguments: named arguments.
                                  #  - Return value: return(VAL)
                                  #  - Types (other than obvious):
                                  #    - dimensions (max 3):
                                  #      - 0 dimension  (TYPE)                    <-> VAL
                                  #      - 1 dimension  (setof TYPE, ARR)         <-> VALv
                                  #      - 2 dimensions (setof ROW, ARR(2 dim)) <-> DATA.FRAME|ARR(2dim)
                                  #        - "TABLE"|"ROW" as argument -> DATA.FRAME, but must use as.data.frame(DATA.FRAME) if want to be returned
                                  #      - 3 dimensions (ARR (3 dim))             <-> ARR(3dim)
                                  #    - null <-> NA|NULL(pref)
                                  #    - BYTEA <-> OBJECT ([un]serialize on RAW)
                                  #    - everything else <-> STR
                                  #  - TFUNC: defines pg.tg.* like tg_* in PL/PGSQL
                                  #  - WFUNC: will pass:
                                  #     - fargNUM...: other values in window (NUM starts at 1)
                                  #     - fnumrows: window size
                                  #     - prownum: offset of window
                                  #  - Global data are possible across calls, including global functions.

PL/R FUNC() ==>                   #
install_rcmd(STR)                 #Execute R code STR (e.g. a function definition).
plr_environ()                     #Returns all environment variables as TABLE with STR columns name and value.
plr_set_display(STR)              #Change the DISPLAY env variable (useful for plots)

PL/R R FUNCTIONS ==>              #
pg.spi.exec(STR)                  #Execute SQL command STR.
                                  #For select ..., returns query as DATA.FRAME (null -> NA).
                                  #For others, returns number of manipulated rows.
pg.spi.prepare                    #Like prepare in SQL
(STR, INT_ARR)                    #INT_ARR are the types oid:
                                  #  - same as in pg_type.oid
                                  #  - can use SQL FUNC() load_r_typenames() to create R variables holding types oid.
                                  #    To see those variables, use SQL FUNC() r_typenames()
                                  #  - must be NA if no arguments
                                  #Returns a PLAN.
pg.spi.execp(PLAN, LIST)          #Like pg.spi.exect(), but executing a PLAN.
                                  #LIST is unnammed:
                                  #  - must contain only NA if no argument.
                                  #  - must be NA for a NULL in SQL
pg.spi.factor(DATA.FRAM)          #Convert non-NUM columns of DATA.FRAME into FACTOR.

pg.spi.cursor(STR, PLAN[, LIST])  #Creates and returns a readonly CURSOR names STR for the command defined by PLAN and LIST.
pg.spi.fetch(CURSOR, BOOL, INT)   #Same as fetch forward|backward (true|false) INT in SQL
pg.spi.close(CURSOR)              #

pg.spi.lastoid()                  #If last action was an insert of a single row, returns OID of that row.
pg.thrownotice|error(STR)         #Like raise notice|exception in PL/PGSQL
pg.quoteliteral|ident(STR)        #Like quote_literal|ident in SQL

PL/R OTHERS ==>                   #
plr_modules                       #TABLE executing plr_modules.modsrc (R code as STR) at start of each session or if reload_plr_modules()
                                  #is called.
                                  #plr_modules.modseq INT is the priority/order of execution.
                                  #Needs to be created as plr_modules(modseq int4, modsrc text). Should be readable by all, writable
                                  #only by trusted users.

                                  ┌─────────────┐
                                  │   TRIGGER   │
                                  └─────────────┘

create trigger "TFUNC"            #Execute FUNC when a specific write EVENT happens on "TABLE|VIEW|FTABLE"
 before|after|instead of EVENT    #If multiple FUNCs, called in alphabetical order of "TFUNC"
 on "TABLE|VIEW|FTABLE"           #LANGUAGE cannot be `sql`
 execute function FUNC(STR,...)   #Auto-dependency child of its TABLE|COL

EVENT insert                      #
EVENT update                      #
EVENT update of "COL",...         #Not if:
                                  #  - `instead of`
                                  #  - `referencing ...`
EVENT delete                      #
EVENT truncate                    #Not if:
                                  #  - `instead of`
                                  #  - `for each row`
                                  #  - VIEW|FTABLE

create trigger "TFUNC"
 before EVENT ...                 #Call before the EVENT, CONSTRAINTs and generated COL

create trigger "TFUNC"            #Replaces the EVENT
 instead of EVENT ...             #Only on VIEWs
                                  #Not with child TABLEs

create trigger "TFUNC"
 after EVENT ...                  #Call after the EVENT, CONSTRAINTs and generated COL

create trigger "TFUNC"
 ... EVENT or EVENT2 ...          #

create trigger ...                #Whether to call FUNC:
 for each row|statement ...       #  - for each statement (def): once for all changed ROWs (even if none)
                                  #  - for each row: once per changed ROW
                                  #If VIEW:
                                  #  - if `instead of`: must `for each row`
                                  #  - otherwise: must `for each statement`

create trigger ...                #Only call TFUNC when BOOL_REXPR true
 when (BOOL_REXPR) ...            #If `for each row`, can refer to `old|new` ROW_ALIAS
                                  #Not with `instead of`

create trigger ...                #"Transition relation". Set ROW_ALIAS (to use inside FUNC) with:
 referencing old|new table        #  - old: all deleted|updated ROWs
 [as] "ROW_ALIAS" ...             #  - new: all inserted|updated ROWs
                                  #Must be `after EVENT`
                                  #Not with `constraint trigger`
                                  #If `after each row`, not on child TABLEs

create constraint trigger ...     #Allows making TFUNC `deferred`
                                  #Must be `after EVENT` and `for each row`
                                  #Can be used to simulate a CONSTRAINT by raising exceptions
                                  #Not on FTABLEs

INTERNAL TFUNC ==>                #`constraint` TFUNC automatically created by:
                                  #  - foreign key CONSTRAINT
                                  #     - also by its `on update|delete` clauses
                                  #  - deferred CONSTRAINT

create trigger ...                #Changes TABLE2 of internal TFUNC used for foreign key CONSTRAINTs
 on "TABLE" from "TABLE2" ...     #Not recommended

alter [foreign] table "TABLE"
 enable|disable trigger TRIGGER   #
alter [foreign] table ...
 trigger user                     #All TRIGGERs of current ROLE, excluding internal TFUNCs
alter [foreign] table ...         #All TRIGGERs of current ROLE, including internal TFUNCs
 trigger all                      #If any iternal TFUNC, must be superuser ROLE

TFUNC ARGUMENTS ==>               #No arguments. Input is passed using special LANGUAGE-specific VARs

trigger                           #Return TYPE of TFUNCs
                                  #FUNC must actually return either:
                                  #  - null:
                                  #     - `for each row` + `before|instead of EVENT`:
                                  #        - cancel insert|update|delete for that ROW
                                  #        - do not call other TFUNCs
                                  #     - otherwise: do nothing
                                  #  - ROW:
                                  #     - if `insert|update`: `new` ROW, possibly modified
                                  #     - if `delete`: `old` ROW, not modified
                                  #     - only with `for each row`
                                  #     - not with `after EVENT`

pg_trigger_depth()->NUM           #Depth, if a TFUNC calls a SQL command which fires another TFUNC ("cascading trigger"), including itself
                                  #Starts at 0

triggered_change_notification     #Create a TFUNC that calls `notify "CHANNEL"` (def CHANNEL: 'tcn')
 (['CHANNEL'])                    #MESSAGE is 'VAL,...' with:
                                  #  - "TABLE" name
                                  #  - I|U|D (insert|update|delete)
                                  #  - "COL"='VAL',... for each primary key
                                  #Must be `for each row` + `after EVENT`
                                  #Cannot be `truncate`
                                  #Trusted postgres extension 'tcn'

pg_trigger                        #TABLE with all TFUNCs
pg_trigger.oid                    #OID
pg_trigger.tgname                 #"TFUNC" name
pg_trigger.tgrelid                #REGCLASS of TABLE
pg_trigger.tgparentid             #pg_trigger.oid of parent TFUNC. 0 if not inherited
pg_trigger.tgfoid                 #REGPROC of the FUNC
pg_trigger.tgtype                 #INT2. Or'd flag:
                                  #  - 0|1: for each statement|row
                                  #  - 0|2|64: after|before|instead of
                                  #  - 4|8|16|32: insert|delete|update|truncate
pg_trigger.tgattr                 #ARR of "COL" (pg_attribute.attnum). `update of "COL" or ...`
pg_trigger.tgqual                 #PG_NODE_TREE. `create trigger ... when (BOOL_REXPR)`. null if none
pg_trigger.tgconstraint           #pg_constraint.oid. `create constraint trigger ...`. 0 if not
pg_trigger.tgdeferrable           #BOOL. Whether deferrable constraint
pg_trigger.tginitdeferred         #BOOL. Whether initially deferred constraint
pg_trigger.tgisinternal           #BOOL. Whether internal TFUNC, related to a CONSTRAINT
pg_trigger.tgconstrindid          #REGCLASS of the INDEX, if internal TFUNC. 0 if none
pg_trigger.tgconstrrelid          #REGCLASS of the other TABLE, if internal TFUNC related to a foreign key CONSTRAINT. 0 if none
pg_trigger.tgold|newtable         #"TABLE". `referencing old|new table "TABLE"`. null if none
pg_trigger.tgnargs                #INT2 of arguments passed to FUNC
pg_trigger.tgargs                 #BYTEA of arguments passed to FUNC

pg_class.relhastriggers           #BOOL. Whether RELATION has TFUNCs
pg_tables.hastriggers             #BOOL. Whether TABLE has TFUNCs

pg_get_triggerdef                 #Returns 'CREATE ...' statement that created TFUNC
 (TFUNC_OID[, BOOL])->STR         #BOOL (def: false) is prettify

suppress_redundant_updates        #TFUNC which prevents updates that set COL with its current value, i.e. do not change anything
 _trigger()                       #Must be `before update` + `for each row`
                                  #Meant as a performance optimization on TABLEs where this happens often

                                  ┌───────────────────┐
                                  │   EVENT TRIGGER   │
                                  └───────────────────┘

create event trigger "EFUNC"      #Like TFUNC (same behavior) but EVENT is DDL
 on EVENT execute function FUNC() #Not for cluster-wide ENTITYs nor EFUNCs
                                  #Rollbacks the COMMAND if EFUNC fails
                                  #Must be superuser

create event trigger "EFUNC"
 on EVENT
 when tag in ('COMMAND',...) ...  #Only specific COMMANDs, e.g. 'drop table'

EVENT ddl_command_start           #Before create|alter|drop|grant|revoke|comment|security label
                                  #ENTITY might not exist
EVENT ddl_command_end             #After successful create|alter|drop|grant|revoke|comment|security label
EVENT sql_drop                    #After successful drop or `alter ... drop`
EVENT table_rewrite               #Before alter table, alter materialized view or alter type "ROW_TYPE"

alter event trigger disable|enable#

EFUNC ARGUMENTS ==>               #Like TFUNC
event_trigger                     #TYPE to return from EFUNCs
                                  #Uses special VARs like TFUNCs, but different ones

pg_event_trigger                  #TABLE with all EFUNCs
pg_event_trigger.oid              #OID
pg_event_trigger.evtname          #"EFUNC" name
pg_event_trigger.evtevent         #"EVENT" name
pg_event_trigger.evtfoid          #REGPROC of FUNC
pg_event_trigger.evttags          #'COMMAND'_ARR or null. `when tag in ...`

pg_event_trigger_ddl_commands()
 ->ROW_SET                        #In EFUNC with EVENT 'ddl_command_end', returns current ENTITYs
ROW.classid
ROW.objid
ROW.objsubid                      #ENTITY
ROW.object_type                   #'ENTITY'
ROW.schema_name                   #'SCHEMA'|null
ROW.object_identity               #'SCHEMA.NAME'
ROW.in_extension                  #BOOL. Whether in an EXTENSION's SQLMAIN
ROW.command_tag                   #'COMMAND'
ROW.command                       #Full COMMAND as PG_DDL_COMMAND

pg_ddl_command                    #TYPE representing a COMMAND during an EFUNC with EVENT 'ddl_command*'
                                  #Can only be used in C FUNCs

pg_event_trigger_dropped_objects()
 ->ROW_SET                        #In EFUNC with EVENT 'sql_drop', returns currently dropped ENTITYs
ROW.classid
ROW.objid
ROW.objsubid
ROW.object_type
ROW.schema_name
ROW.object_identity               #Like above
ROW.object_name                   #'NAME'|null
ROW.address_names()->STR_ARR
ROW.address_args()->STR_ARR       #To pass to pg_get_object_address()
ROW.is_temporary                  #BOOL if temporary ENTITY
ROW.original                      #BOOL. False if dropped due to being a child dependency
ROW.normal                        #BOOL. Whether dependency was "normal" (pg_depend.deptype 'n')

pg_event_trigger_table_
 rewrite_oid()->OID               #In EFUNC with EVENT 'table_rewrite', returns current TABLE
pg_event_trigger_table_
 rewrite_reason()->INT4           #Same with reason number

                                  ┌──────────┐
                                  │   RULE   │
                                  └──────────┘

create rule "RULE"                #Before COMMAND on "TABLE|VIEW", call NEW_COMMAND
 as on COMMAND to "TABLE|VIEW"    #COMMAND can be select|insert|update|delete
 do NEW_COMMAND                   #NEW_COMMAND can be select|insert|update|delete|notify or `nothing`
                                  #If COMMAND `select`, NEW_COMMAND must be `select` too
                                  #If COMMAND `insert`, NEW_COMMAND performed after instead
                                  #COMMAND cannot use `with ...`
                                  #NEW_COMMAND uses ROLE of TABLE|VIEW owner, not COMMAND caller
                                  #Used internally by [M]VIEWs
                                  #  - named "_RETURN"
                                  #  - should prefer VIEWs to RULE with COMMAND `select`
                                  #Child auto-dependency of its TABLE|VIEW

create rule ...
 do (NEW_COMMAND;...)             #Not with COMMAND `select`

RULE VS TFUNC ==>                 #RULEs are similar to TFUNCs but:
                                  #  - implemented by rewriting the original COMMAND
                                  #     - as opposed to calling a FUNC separately
                                  #  - use SQL command instead of a FUNC: simpler but less flexible
                                  #  - fewer features: no `for each row`, `update on "COL"`, `after EVENT`, `truncate`, `deferred`
                                  #  - `instead` RULEs tend to be faster since query planner knows of the full final commands,
                                  #    i.e. can optimize them

create rule ...                   #If COMMAND `select`:
 do instead NEW_COMMAND           #  - required
                                  #  - replaces the original COMMAND's `from ...`
                                  #  - other clauses are kept as is
                                  #     - e.g. `where`, `select VALs`, `order by`, etc.
                                  #     - i.e. like in VIEWs
                                  #If not COMMAND `select`:
                                  #  - replaces the whole original COMMAND
                                  #  - should use `returning ...`
                                  #     - only on a single RULE, and cannot use `where BOOL_REXPR`

create rule ...                   #Only perform when BOOL_REXPR true
 where BOOL_REXPR do NEW_COMMAND  #Not with COMMAND `select`
                                  #Can use `old|new` "ROW_ALIAS" (like TFUNCs)

alter table enable|disable ...
 rule RULE|user|all               #Like `alter table enable|disable ... trigger TRIGGER|user|all` but for RULEs

pg_rules                          #TABLE with all RULEs, excluding "_RETURN"s
pg_rules.rulename                 #"RULE" name
pg_rules.tablename                #"TABLE|VIEW" name
pg_rules.definition               #'CREATE RULE ...'

pg_rewrite                        #TABLE with all RULEs, including "_RETURN"s
pg_rewrite.oid                    #OID
pg_rewrite.rulename               #"RULE" name
pg_rewrite.ev_class               #REGCLASS of TABLE|VIEW
pg_rewrite.ev_type                #Among '1' (select), '2' (update), '3' (insert), '4' (delete)
pg_rewrite.is_instead             #BOOL. `do instead`
pg_rewrite.ev_action              #PG_NODE_TREE of `NEW_COMMAND`
pg_rewrite.ev_qual                #PG_NODE_TREE of `where BOOL_REXPR`

pg_class.relhasrules              #BOOL. Whether TABLE|VIEW has RULEs
pg_tables.hasrules                #BOOL. Whether TABLE has RULEs

pg_get_ruledef                    #Returns 'CREATE RULE ...' statement
 (RULE_OID[, BOOL])->STR          #BOOL (def: false) is prettify

                                  ┌─────────────────┐
                                  │   PUBLICATION   │
                                  └─────────────────┘

create publication "PUB"          #"Logical replication" PUB, i.e. replicate a TABLE
                                  #Each SUB does replication, i.e. does not start until there is one
                                  #There can be multiple SUBs per PUB, and multiple PUBs per SUB
                                  #Unlike physical replication:
                                  #  - copies transaction-wise, not heap page-wise
                                  #  - only copies data, not DDL
                                  #Also called "change set" or "replication set"

create publication "PUB"          #TABLEs to replicate
 for table "TABLE",...            #Cannot be temporary|unlogged nor [M]VIEW|FTABLE
                                  #Does not replicate SEQUENCE's state
                                  #Current ROLE must own the TABLEs

create publication "PUB"          #COLs to replicate (def: all current|future COLs)
 for table "TABLE"("COL",...)     #Non-replicated COLs can differ between PUB|SUB
                                  #Replicated COLs can differ between PUB|SUB
                                  #  - in terms of configuration: TYPE, CONSTRAINT, etc.
                                  #  - providing they are compatible for copy purpose

create publication "PUB"          #"Row filter". Do not replicate ROWs where BOOL_REXPR false
 for table "TABLE"                #Noop with `truncate` COMMANDs
 where (BOOL_REXPR)               #Cannot use:
                                  #  - user-defined FUNC|OP|TYPE|COLLATION
                                  #  - non-immutable FUNC
                                  #  - pg_catalog.*

create publication "PUB"          #Replicate all current|future TABLEs in SCHEMA
 for tables in schema "SCHEMA",...#"SCHEMA" can be current_schema
                                  #Must be superuser

create publication "PUB"          #Replicate all current|future TABLEs in DATABASE
 for all tables                   #Must be superuser

alter publication "PUB"
 add|set|drop table "TABLE" ...
alter publication "PUB"
 add|set|drop tables in schema ...#

create publication ... with (OPTS)#

OPTS.publish                      #'COMMAND,...' (def: all) among 'insert', 'update', 'delete', 'truncate'
                                  #Only replicate transactions with those commands
                                  #Does not impact initial snapshot done when SUB starts

OPTS.publish_via_partition_root   #BOOL (def: false). When replicating a partitioned parent|child TABLE,
                                  #whether to use the parent TABLE instead
                                  #This allows SUB to replicate to a non-partitioned TABLE
                                  #If true, `truncate` is ignored

PCONF.wal_level                   #Must be 'logical' in PUB

pg_publication                    #TABLE with all PUBs
pg_publication.oid                #OID
pg_publication.pubname            #"PUB" name
pg_publication.puballtables       #BOOL. `for all tables`
pg_publication.pubinsert
 |pubupdate|pubdelete|pubtruncate #BOOL. OPTS.publish
pg_publication.pubviaroot         #BOOL. OPTS.publish_via_partition_root

pg_publication_rel                #TABLE with all `create publication ... for table ...`
pg_publication_rel.oid            #OID
pg_publication_rel.prpubid        #pg_publication.oid of PUB
pg_publication_rel.prrelid        #REGCLASS of TABLE
pg_publication_rel.prattrs        #ARR of COLs (pg_attribute.attnum), or null for all COLs.
pg_publication_rel.prqual         #PG_NODE_TREE|null. `where BOOL_REXPR`

pg_publication_namespace          #TABLE with all `create publication ... for tables in schema`
pg_publication.oid                #OID
pg_publication.pnpubid            #pg_publication.oid of PUB
pg_publication.pnnspid            #REGNAMESPACE of SCHEMA

pg_publication_tables             #High-level VIEW combining pg_publication, pg_publication_rel and pg_publication_namespace
pg_publication_tables.pubname     #"PUB" name
pg_publication_tables.tablename   #"TABLE" name
pg_publication_tables.attnames    #"COL"_ARR
pg_publication_tables.rowfilter   #'BOOL_REXPR' of `where`

                                  ┌──────────────────────┐
                                  │   REPLICA IDENTITY   │
                                  └──────────────────────┘

alter table "TABLE"               #Sets which COLs identify ROWs
 replica identity ...             #Used by PUB|SUB when updating|deleting ROWs
                                  #Unless there are no update|delete transactions:
                                  #  - PUB COLs must include replica identity COLs
                                  #  - PUB `where` can only include replica identity COLs
                                  #Also used by WAL

alter table "TABLE"
 replica identity default         #Default if primary key (and not pg_catalog.*): use those COLs

alter table "TABLE"               #Default otherwise: use no COLs
 replica identity nothing         #Cannot be used with PUB, unless there are no update|delete transactions

alter table "TABLE"
 replica identity full            #Use all COLs. Slower.

alter table "TABLE"               #Use INDEX COLs
 replica identity                 #Must be unique + not null
 using index "INDEX"              #Must not be partial, nor deferrable

pg_class.relreplident             #'CHAR' with `replica identity` among 'd|n|f|i'
pg_index.indisreplident           #BOOL. Whether INDEX is used in a `replica identity`

                                  ┌─────────────────────────┐
                                  │   SUBSCRIPTION CREATE   │
                                  └─────────────────────────┘

create subscription "SUB"         #Subscribe to a PUB
 connection 'LIBPQ'               #Connect with 'LIBPQ'
 publication "PUB",...            #  - can be in a different DATABASE|CLUSTER|machine
                                  #  - uses the connection ROLE, including to run:
                                  #     - PUB's `where`
                                  #     - POLICYs
                                  #Must be superuser
                                  #If multiple PUBs on same TABLE:
                                  #  - must have same COLs
                                  #  - `where BOOL_EXPRs` are or'd
                                  #PUB might not exist yet
                                  #SUB can modify replicated TABLE:
                                  #  - if this leads to conflict, stops SUB
                                  #  - must then solve the conflict
                                  #  - then skip offending transactions with `skip (lsn = PG_LSN)` or pg_replication_origin_advance()

create subscription "SUB" ...
 with (OPTS)                      #

alter subscription "SUB"
 connection 'LIBPQ'               #
alter subscription "SUB"
 add|set|drop publication "PUB"
 [with OPTS]                      #

alter subscription "SUB"
 add|set|drop publication "PUB"
 with (refresh = BOOL)            #BOOL (def: false). Update PUBs after adding|removing them
alter subscription "SUB"          #OPTS: only copy_data
 refresh publication [with (OPTS)]#If true, cannot be in a transaction

alter subscription "SUB"          #Skip replicating specific transactions, as specified by PG_LSN
 skip (lsn = PG_LSN)              #Must be superuser
                                  #PG_LSN can be `none` to undo

alter subscription "SUB"
 enable|disable                   #
OPTS.enabled                      #BOOL (def: true)

OPTS.disable_on_error             #BOOL (def: false). Disable if any internal error in SUB

OPTS.connect                      #BOOL. If false (def: true), do not start until `refresh publication`

OPTS.create_slot                  #BOOL. If true (def):
                                  #  - automatically create SLOT
                                  #  - cannot be in a transaction
                                  #If false:
                                  #  - publisher must create it with pg_create_logical_replication_slot()
                                  #  - OPTS.enabled must be false
                                  #  - required when PUB is in the same CLUSTER
                                  #  - also useful if:
                                  #     - SLOT already exists, e.g. when moving a SUB from one machine to another
                                  #     - PUB's machine temporarily unavailable

OPTS.slot_name                    #"SLOT" name (def: "SUB")
                                  #Can be 'NONE' when OPTS.create_slot false

OPTS.copy_data                    #BOOL. If true (def), copy pre-existing data when SUB starts, in an "initial snapshot"
                                  #Creates a temporary SLOT named "pg_SUB_OID_sync_TABLE_OID_*"
                                  #Internally similar to a `copy` command
                                  #Once done, "initial data synchronization", i.e. catches up changes that happened during initial snapshot

OPTS.streaming                    #BOOL. Whether to send transactions in bulk (false, def) or incrementally (true)

OPTS.binary                       #BOOL. Whether to serialize TYPEs using:
                                  #  - 'UNKNOWN' (false, def), i.e. YOPTS.input|output: more portable across Postgres versions
                                  #  - binary (true), i.e. YOPTS.send|receive: smaller size

OPTS.two_phase                    #BOOL. Whether to send PREPs on creation (true) or on commit (false, def)
                                  #If true and OPTS.copy_data true, cannot use `refresh`

OPTS.synchronous_commit           #Like SCONF.synchronous_commit but only for this SUB
                                  #Def is 'off' because lost transactions are automatically recovered
                                  #When using synchronous logical replication, 'off' can be slower

pg_subscription                   #TABLE with all SUBs
                                  #Visible only to superuser
pg_subscription.oid               #OID
pg_subscription.subname           #"SUB" name
pg_subscription.subpublications   #'PUB'_ARR
pg_subscription.subconninfo       #'LIBPQ'
pg_subscription.subdbid           #pg_database.oid of SUB
pg_subscription.subskiplsn        #PG_LSN or '0/0'. `skip (lsn = PG_LSN)`
pg_subscription.subenabled        #BOOL. OPTS.enabled
pg_subscription.subslotname       #"SLOT". OPTS.slot_name
pg_subscription.substream         #BOOL. OPTS.streaming
pg_subscription.subbinary         #BOOL. OPTS.binary
pg_subscription.subtwophasestate  #CHAR. OPTS.two_phase: 'd' (disabled), 'e' (enabled), 'p' (pending enablement)
pg_subscription.subdisableonerr   #BOOL. OPTS.disable_on_error
pg_subscription.subsynccommit     #STR. OPTS.synchronous_commit

pg_subscription_rel               #TABLE with all SUBs state
pg_subscription_rel.srsubid       #pg_subscription.oid of SUB
pg_subscription_rel.srrelid       #REGCLASS of TABLE
pg_subscription_rel.srsubstate    #Among:
                                  #  - 'i': before initial copy
                                  #  - 'd': initial copy
                                  #  - 'f': finished ininial copy
                                  #  - 's': initial data synchronization
                                  #  - 'r': ready
pg_subscription_rel.srsublsn      #PG_LSN of the last replicated transaction
                                  #null if srsubstate not 's|r'

pg_stat_subscription              #TABLE with all SUBs workers
pg_stat_subscription.subid        #pg_subscription.oid of SUB
pg_stat_subscription.subname      #"SUB" name
pg_stat_subscription.relid        #REGCLASS of TABLE. null for the main worker
pg_stat_subscription.pid          #INT4. PID of worker process
pg_stat_subscription
 .last_msg_receipt_time           #TIMESTAMPTZ of last message sent by PUB
pg_stat_subscription.received_lsn #PG_LSN of last transaction received
pg_stat_subscription
 .last_msg_send_time              #TIMESTAMPTZ of last message received by SUB
pg_stat_subscription
 .latest_end_lsn                  #PG_LSN of last transaction reported back to PUB
pg_stat_subscription
 .latest_end_time                 #TIMESTAMPTZ of last transaction reported back to PUB

pg_stat_subscription_stats        #TABLE with count of SUBs errors
pg_stat_subscription_stats.subid  #pg_subscription.oid of SUB
pg_stat_subscription_stats.subname#"SUB" name
pg_stat_subscription_stats
 .apply_error_count               #INT8. Number of errors related to data copy
pg_stat_subscription_stats
 .sync_error_count                #INT8. Number of errors related to initial data copy
pg_stat_subscription_stats
 .stats_reset                     #TIMESTAMPTZ of last update of pg_stat_subscription_stats

                                  ┌─────────────────────────┐
                                  │   SUBSCRIPTION LIMITS   │
                                  └─────────────────────────┘

PCONF.max_replication_slots       #NUM (def: 10). In publisher, max amount of SLOTs
                                  #In consumer, max amount of SUBs
                                  #Must be <= PCONF.max_wal_senders

PCONF                             #NUM (def: 4). In consumer, max amount of worker processes used for SUBs
 .max_logical_replication_workers #Disabled SUBs have 0 workers
                                  #Initial snapshot requires an additional worker
                                  #Must be <= PCONF.max_worker_processes

HCONF.                            #NUM (def: 2). Max amount of parallel workers during initial snapshot
 max_sync_workers_per_subscription#Max 1 per TABLE
                                  #Must be <= PCONF.max_logical_replication_workers

SCONF.logical_decoding_work_mem   #NUM|STR (def: 64MB). Size of in-memory buffer used by SLOTs
                                  #Once full, swaps on-disk instead ("spill")

pg_stat_replication_slots         #TABLE with all SLOTs statistics
pg_stat_replication_slots
 .slot_name                       #"SLOT" name
pg_stat_replication_slots
 .spill_txns                      #INT8. NUM of transactions spilled
pg_stat_replication_slots
 .spill_count                     #INT8. NUM of times transactions were spilled
pg_stat_replication_slots
 .spill_bytes                     #INT8. Amount of bytes spilled
pg_stat_replication_slots
 .stream_*                        #Like spill_* but for transactions sent to consumer without spilling
pg_stat_replication_slots
 .total_*                         #Like spill_* + stream_*
pg_stat_replication_slots
 .stats_reset                     #TIMESTAMPTZ of last update of pg_stat_replication_slots

                                  ┌───────────────────────────┐
                                  │   SUBSCRIPTION TRIGGERS   │
                                  └───────────────────────────┘

ZSCONF.session_replication_role   #Whether to disable TFUNC|EFUNC|RULEs:
                                  #  - 'origin' (def): no, intended for neither PUB|SUB
                                  #  - 'local': no, intended for PUB
                                  #  - 'replica': yes, intended for SUB
                                  #     - this avoids calling TFUNC|EFUNC|RULEs twice, in both PUB and SUB
alter [foreign] table ...
 disable|enable
 always trigger|rule ...          #Enable TFUNC|RULE even if ZSCONF.session_replication_role 'replica'
alter [foreign] table ...
 disable|enable
 replica trigger|rule ...         #Enable TFUNC|RULE only if ZSCONF.session_replication_role 'replica'
alter event trigger disable|enable
 replica|always                   #Same for EFUNC

pg_trigger.tgenabled              #CHAR among: D (disabled), O (enable without always|replica), A (enable always), R (enable replica)
pg_event_trigger.evtenabled       #Same for EFUNC
pg_rewrite.ev_enabled             #Same for RULE

                                  ┌──────────────────────┐
                                  │   LOGICAL DECODING   │
                                  └──────────────────────┘

STREAMING REPLICATION PROTOCOL ==>#Binary protocol used for physical|logical replication
                                  #Client sends replication commands, instead of SQL commands
                                  #Replication commands are not documented yet, but similar to:
                                  #  - get machine ID and WAL location
                                  #  - `show` CONFVAR
                                  #  - get timeline history file
                                  #  - create|delete, read, enable|disable SLOT
                                  #  - base backup

LIBPQ.replication                 #Start a connection using the streaming replication protocol among:
                                  #  - false (def)
                                  #  - true: physical replication
                                  #  - 'database': logical replication

LOGICAL DECODING ==>              #Using the streaming replication protocol for logical replication,
                                  #but with pg_*logical*(...) FUNC calls instead of PUB|SUB
                                  #I.e. more flexible but harder to use

SLOT                              #Current position (PG_LSN) in the WAL
                                  #Represents a SUB's current logical replication state
                                  #Stored in the publisher's CLUSTER
                                  #Position is only persisted in WAL checkpoints
                                  #  - i.e. might go back in case of a crash
                                  #  - PUB handles the potential for getting same transaction twice
                                  #     - usually by keeping track of last PG_LSN received
                                  #WAL entries not consumed prevent dead ROWs vacuuming or xmin wraparound
                                  #  - i.e. should read SLOTs and delete them when not needed anymore

pg_create_logical_replication_slot#Create a SLOT
 ("SLOT", "REPPLUG"[,BOOL, BOOL2])#BOOL (def: false) is whether temporary, i.e. dropped at end of session, or on error
 ->ROW                            #BOOL2 (def: false) is like OPTS.two_phase
ROW.slot_name                     #"SLOT"
ROW.lsn                           #PG_LSN

pg_drop_replication_slot("SLOT")  #Delete a SLOT

pg_copy_logical_replication_slot
 ("SLOT", "SLOT2"[, BOOL])->ROW   #Like pg_create_logical_replication_slot() but cloned from another SLOT

pg_replication_slot_advance
 ("SLOT", PG_LSN)->ROW            #Move forward current position PG_LSN of SLOT
ROW.slot_name                     #"SLOT"
ROW.end_lsn                       #PG_LSN

pg_logical_slot_get_changes       #Like pg_replication_slot_advance(), but also returns those transactions
 ("SLOT", PG_LSN, INT4)->ROW_SET  #Only ones before PG_LSN, unless null
                                  #Only up to INT4 ROWs, unless null
ROW.lsn                           #PG_LSN
ROW.xid                           #XID
ROW.data                          #STR. Transaction's command
                                  #Format not documented yet

pg_logical_slot_get_binary_changes
 (...)->ROW_SET                   #Same but ROW.data is BYTEA

pg_logical_slot_peek_*
 (...)->ROW_SET                   #Like pg_logical_slot_get_*(...) but does not move current position

pg_replication_slots              #TABLE with all SLOTs
pg_replication_slots.slot_name    #"SLOT" name
pg_replication_slots.slot_type    #Type of replication among: 'physical', 'logical'
pg_replication_slots.datoid       #pg_database.oid of SLOT
                                  #null if physical replication
pg_replication_slots.database     #"DATABASE" name of SLOT
                                  #null if physical replication
pg_replication_slots.temporary    #BOOL. Whether temporary SLOT
pg_replication_slots.two_phase    #BOOL. OPTS.two_phase
pg_replication_slots.active       #BOOL. Whether enabled
pg_replication_slots.active_pid   #BPID of PUB. null if disabled
pg_replication_slots.xmin         #XID. Allow vacuum to delete transactions < XID
pg_replication_slots.catalog_xmin #XID. Same for transactions related to pg_catalog.*
pg_replication_slots.restart_lsn  #PG_LSN|null. Allow WAL checkpoints to delete transactions < PG_LSN
                                  #Except if above HCONF.max_slot_wal_keep_size
pg_replication_slots              #PG_LSN of last transaction received by SUB
 .confirmed_flush_lsn             #null if physical replication
pg_replication_slots.wal_status   #How SUB is catching up WAL files, among:
                                  #  - 'reserved': within HCONF.max_wal_size
                                  #  - 'extended': above HCONF.max_wal_size, but still keep WAL files, e.g. due to HCONF.wal_keep_size
                                  #  - 'unreserved': above HCONF.max_slot_wal_keep_size, and WAL files will be removed by next checkpoint
                                  #  - 'lost': above HCONF.max_slot_wal_keep_size, and WAL files have been removed, and "SLOT" is now disabled
pg_replication_slots.safe_wal_size#INT8. Number of bytes to write to WAL without wal_status being 'lost'

DATADIR/pg_logical                #DIRs used by logical decoding
pg_ls_logicalmapdir()->ROW_SET    #Returns files in pg_logical/mappings DIR
                                  #ROW: name STR, size INT8, modification TIMESTAMPTZ
pg_ls_logicalsnapdir()->ROW_SET   #Returns files in pg_logical/snapshots DIR
                                  #ROW: name STR, size INT8, modification TIMESTAMPTZ

                                  ┌────────────────────┐
                                  │   PG_RECVLOGICAL   │
                                  └────────────────────┘

pg_recvlogical                    #CLI around pg_*logical*()
--dbname|-d
--host|-h
--port|-p
--username|-U
--[no-]password|-w|-W             #LIBPQ connection options

--create-slot                     #Like pg_create_logical_replication_slot()
--if-not-exists                   #With --create-slot, do not fail if already exists
--two-phase|-t                    #With --create-slot, OPTS.two_phase

--drop-slot                       #Like pg_drop_logical_replication_slot()

--start                           #Like pg_logical_slot_get_changes(), streamed to output
--startpos|-I                     #PG_LSN. With --start, starts at that transaction
--endpos|-E                       #PG_LSN. With --start, stops at that transaction

--slot|-S                         #"SLOT"

--file|-f                         #'PATH' of output, or '-' for stdout (def)
--fsync-interval|-F               #NUM (in secs). How often to flush output to disk

--no-loop|-n                      #Unless set, reconnect when connection is lost
--status-interval|-s              #NUM (in secs, def 10). How often to ping the connection

                                  ┌───────────────────┐
                                  │   OUTPUT PLUGIN   │
                                  └───────────────────┘

REPPLUG                           #"Output plugin"
                                  #Handles and transforms transactions consumed from a SLOT
                                  #Optional
                                  #C addon. Full interface not documented yet

pg_create_logical_replication_slot
 ("SLOT", "REPPLUG", ...)->ROW_SET#

pg_copy_logical_replication_slot
 (..., "REPPLUG")->ROW_SET        #

pg_recvlogical --plugin|-P        #"REPPLUG"

REPPLUGOPT                        #Option passed to REPPLUGs

pg_logical_slot_*_changes
 (..., 'REPPLUGOPT=VAL'_ARR)
 ->ROW_SET                        #

pg_recvlogical --option-name|-o   #'REPPLUGOPT=VAL'

pg_replication_slots.plugin       #"REPPLUG" name. null if physical replication

pg_logical_emit_message           #Sends REPPLUG-specific message to REPPLUG
 (BOOL, STR, STR2|BYTEA)->PG_LSN  #BOOL is whether should be part of current transaction (true) or be its own transaction (false)
                                  #STR is message prefix

TOPTS.user_catalog_table          #BOOL. Allow REPPLUGs to read this TABLE, even if not being the one replicated.
                                  #Def: true for pg_catalog.*, false otherwise

                                  ┌────────────────────────┐
                                  │   REPLICATION ORIGIN   │
                                  └────────────────────────┘

pg_replication_origin_*()         #Must be superuser
                                  #"Replication origin" is how a SUB can keep track of the last PG_LSN read from a PUB
                                  #This allows re-consuming any transaction not flushed to disk if SUB crashes
                                  #This is automatically by SUBs, i.e. only needed when using logical decoding pg_*(...) directly

pg_replication_origin_create
 ("RORIGIN")->RORIGIN_OID         #
pg_replication_origin_drop
 ("RORIGIN")                      #
pg_replication_origin_oid
 ("RORIGIN")->RORIGIN_OID|null    #

pg_replication_origin_
 session_setup("RORIGIN")         #Use RORIGIN in current session
pg_replication_origin_
 session_reset()                  #Unset RORIGIN from current session
pg_replication_origin_
 session_is_setup()->BOOL         #

pg_replication_origin_progress    #Get position of SLOT in any RORIGIN
 ("RORIGIN", BOOL)->PG_LSN        #BOOL is whether must wait for it to be flushed on-disk
pg_replication_origin_
 session_progress(BOOL)->PG_LSN   #Same but in current session's RORIGIN
pg_replication_origin_advance
 ("RORIGIN", PG_LSN)              #Manually set position of SLOT in RORIGIN

pg_replication_origin_xact_setup
 (PG_LSN, TIMESTAMPTZ)            #Set position of SLOT in consumer
pg_replication_origin_xact_reset()#Undo pg_replication_origin_xact_setup()

pg_replication_origin             #TABLE with all RORIGINs
pg_replication_origin.roident     #RORIGIN_OID
pg_replication_origin.roname      #"RORIGIN" name

pg_replication_origin_status      #TABLE with all RORIGINs status
                                  #Visible only to superuser
pg_replication_origin_status
 .local_id                        #RORIGIN_OID
pg_replication_origin_status
 .external_id                     #"RORIGIN" name
pg_replication_origin_status
 .remote_lsn                      #PG_LSN. SLOT position in any RORIGIN
pg_replication_origin_status
 .local_lsn                       #PG_LSN. SLOT position in current session's RORIGIN

pg_xact_commit_timestamp_origin   #Transaction's timestamp and RORIGIN
 (XID)->ROW                       #ROW: timestamp TIMESTAMPTZ, roident RORIGIN_OID
pg_last_committed_xact()->ROW     #Last transaction's XID, timestamp and RORIGIN
                                  #ROW: xid XID, timestamp TIMESTAMPTZ, roident RORIGIN_OID

                                  ┌──────────┐
                                  │   PSQL   │
                                  └──────────┘

psql                              #CLI client
                                  #Commands are from stdin
READLINE ==>                      #Used, i.e. can use an .inputrc

-c STR                            #
-f FILE                           #Redirect input from STR or FILE (non-interactive shell)
-o FILE                           #Redirect output to FILE
-L FILE                           #Prints queries to FILE (logging)

-X                                #Do not read init files (files read at session start containing any command that PSQL understands)
                                  #Init file can be:
                                  #  - systemwide (/etc/postgresql-common/psqlrc)
                                  #  - user-specific (shell variable PSQLRC, by def HOME/.psqlrc)
                                  #Can append -NUM[.NUM2[.NUM3]] to target only specific PostgreSQL versions.
-n                                #Don't use readline (useful when pasting)
-s                                #Ask for confirmation before each command
-1                                #Wrap commands in a transaction block. Commands should not contain transaction blocks themselves.
                                  #Disable all EFUNCs
-l                                #Does \list then exits

\COMMAND                          #psql can use special commands. Finished by newline not semicolon.
                                  #Can use \n \t \r \000 \x00 in 'STR'. Can do shell substitution with `COMMAND`
                                  #Can appear anywhere a SQL command can.
                                  #Some commands use SREGEXP:
                                  #  - . only means SCHEMA separation (otherwise current schema).
                                  #    For all objects outside current SCHEMA, do *.*
                                  #  - $ not present
                                  #  - ? and * are globbing
                                  #  - case-insensitive unless ""

\q                                #Exits
\h [COMMAND]                      #Help on SQL commands
\?                                #Help on PSQL commands
\! [COMMAND]                      #Execute a shell command according to the shell variable SHELL
\timing [on|off]                  #Show time taken by commands

\pset VAR [VAL]                   #If VAL, sets printing options, if not either toggle or print current value.
                                  #VAR [VAL] can be:
format STR                        #How things are printed. Can be unaligned, aligned (def), wrapped, html, latex[-long table], troff-ms.
                                  #  - Wrapped: like aligned but wrap long lines according to columns INT (if 0, only on terminal
                                  #    output, and uses shell env variable COLUMNS or detected screen size)
                                  #  - unaligned: can control separators with field|recordsep STR or field|recordsep_zero (use \0)
x [on|off|auto]                   #Put in expanded mode (switch cols and rows, good for table with long width). If auto, do it only for
                                  #wide tables.
t                                 #No footer nor headers
footer [on|off]                   #footer is command tag, etc.
title STR                         #Print STR in front of all tables
border INT                        #Column width
linestyle ascii|unicode           #
null STR                          #What to print for null strings (def: "")
numericlocale on|off              #Locale-specific NUM
pager on|off|always               #Using env variable PAGER (def: less)
tableattr STR                     #In HTML output format, HTML attributes of <table>

END OF LINE ==>                   #The seven following commands should be put at the end of a command (instead of ;):
\w FILE| |COMMAND                 #Print current input to FILE or pipe to COMMAND (don't execute it)
\p                                #Same as \w |cat
\g [FILE| |COMMAND]               #Redirect output like \o, but for current input only.
\r                                #Clears current input.
\e [FILE]                         #Edit current command (or if FILE, FILE) with editor (shell variable [PSQL_]EDITOR, i.e. vim), which
                                  #becomes the new command.
                                  #New command is only executed if terminated by ;
\ef [FUNC[(...)]]                 #Same but the command is a "create or replace function FUNC". If no FUNC, creates a empty definition.
\watch INT                        #Execute current input every INT seconds, until interrupted (or error).

\o [FILE| |COMMAND]               #Redirect stdout (not stderr) (def: to stdout)
\i[r] FILE                        #Execute command in FILE.
                                  #If r and non-interactive, relative path to script DIR, otherwise relative to PWD)
\copy ...                         #Like SQL copy but performed locally, not on the server.
                                  #Can use pstdin|out to avoid any stdin|stdout redirection (i.e. use terminal input|output)
\lo_export OID STR
\lo_import STR                    #Like lo_ex|import(...), but performed locally, not on the server.

\[q]echo [-n] VAL                 #Prints VAL (use q if \o has been used), without trailing newline if -n
                                  #Can appear anywhere in a SQL command.
\setenv VAR [VAL]                 #Sets shell environment variables

\d...[S][+] [SREGEXP]             #Show info about VAR specified in ... (S for also system ones, + for more info) among:
                                  #  - nothing (all RELATIONs), t (table), v (view), i (index), m (materialized view), s (sequence)
                                  #  - u (ROLE), dp (default user privilege), p (all RELATIONs with privileges)
                                  #  - d (constraint, operator*, rule, trigger)
                                  #  - n (SCHEMA)
                                  #  - b (tablespace)
                                  #  - L (LANGUAGE), x (EXTENSION)
                                  #  - T (TYPE), D (domain), C (cast)
                                  #  - O (COLLATION), c (conversion)
                                  #  - E|et (ftable), es (foreign server), eu (user mapping), ew (foreign data wrapper)
                                  #  - f[n|a|w|t] (func, afunc, wfunc, tfunc), y (efunc), o (OPERATOR)
                                  #  - F (REGCONF), Fd (DICTIONARY), Fp (PARSER), Ft (TEMPLATE)
                                  #  - l (large objects)
                                  #  - rds: CONF, ROLE-specific (SREGEXP) and optionally database-specific too (use a second SREGEXP)
                                  #  - \l[+] (not \d): DATABASE
                                  #TODO: move those to their respective chapters in this doc???
\sf [FUNC[(...)]]                 #Prints definition of FUNC

\c [DATABASE [USER]
[HOST] [PORT]]                    #Connect to different database. Def is current
\conninfo                         #Print current connection info
\cd [DIR]                         #Change PWD (def: HOME)

\[un]set INTVAR [VAL]             #Internal VAR. INTVAR is case-sensitive. Are not CONF.
                                  #Can also use psql -v INTVAR[=[VAL]]
                                  #Can be created INTVAR. Substitution is done with:
                                  #  - :INTVAR: macro expansion of INTVAR
                                  #  - :'INTVAR': same but surround with '', unless already present (do with STR)
                                  #  - :"INTVAR": same with "" (do with VAR)
\gset [WORD]                      #Put at end of command (like \p, \r, etc.)
                                  #Command output is redirected to new INTVAR (one by column) called [WORD_]"COL".
                                  #Columns must be named. Null give unset variables, failing commands don't change variables
\prompt [-f] [STR]
INTVAR                            #Prompt for INTVAR, with message STR. Use terminal (no -f) or stdin/stdout (-f)

DBNAME                            #
HOST                              #
PORT                              #
USER                              #Connections info

ON_ERROR_STOP                     #When set, errors terminate script (non-interactive) or line (interactive)
                                  #SCONF.exit_on_error is also available, where errors terminate whole session.
ON_ERROR_ROLLBACK                 #If on, errors in transactions are just ignored. If off (def), they abort the whole transaction.
on|interactive|off                #Interactive means on for interactive and off for non-interactive.
IGNOREEOF INT                     #Number of EOF (C-D) to send to terminate a session (def: 1)

PROMPT1|2|3                       #Prompt. Literal STR with possible sequences escaped by %: M (full host), m (short host), > (port),
                                  #n (user), / (database), ~ (database, but ~ if default one), # (# if superuser, > otherwise),
                                  #R (= if normal, ! if disconnected), x (transaction block), NNN (octal), `command`, :VAR:,
                                  #[ and ] (ansi escaping sequences). Def is %/%#
                                  #PROMPT1 is normal, PROMPT2 when continuing on a new line, PROMPT3 when reading from stdin
COMP_KEYWORD_CASE
[preserve-]lower|upper            #Completion case. If preserve, tries to keep current word case.
QUIET                             #Don't print welcome message
ECHO                              #When set to '' (def), do nothing.
                                  #When 'queries', print all input to output.
                                  #When 'all', same but only for non-interactive input.
ECHO_HIDDEN                       #When set, prints commands behind \ commands

HISTFILE                          #Def: ~/.psql_history. Written at exit.
                                  #Can for example use user, database-specific, etc. hist files
                                  #Can also use shell variable PSQL_HISTORY
                                  #Can also use \s [FILE] (always relative to PWD) (def: print to stdout)
HISTSIZE                          #Number max of commands (def: 500)
HISTCONTROL
ignoredups|space|both             #Like in Bash

AUTOCOMMIT on|off                 #By def (on), each individual command is wrapped in a single transaction. When off, a start
                                  #transaction is implicitly fired but needs to manually commit it
LASTOID                           #OID of last written object
FETCH_COUNT                       #Number of max rows in memory at once

ENVVAR PG_COLOR                   #Whether to use colors in CLIs output
                                  #Can be:
                                  #  - 'always'
                                  #  - 'auto': if stderr is TTY
                                  #  - otherwise: no
ENVVAR PG_COLORS                  #'KEY=VAL;...' to customize colors
                                  #KEY is error|warning|note|locus
                                  #Def: 'error=01;31:warning=01;35:note=01;36:locus=01'

text search commands: https://www.postgresql.org/docs/current/textsearch-psql.html???

                                  ┌──────────────┐
                                  │   PGADMIN3   │
                                  └──────────────┘

PGADMIN3 ==>                      #GUI client. Can do almost anything that can be done with psql.
                                  #Installing/launching:
                                  #  - MaintenanceDB:
                                  #     - DATABASE where pgAdmin connects first (should use postgres)
                                  #     - should install adminpack extension
                                  #  - Should use the same CLIENT_USER we would use for a normal psql session
                                  #Usage:
                                  #  - Is not refreshed automatically: needs to refresh it manually.
                                  #  - Some types of objects are hidden by default (e.g. AFUNC or TYPE): can change in options
                                  #  - Servers have names, and can be grouped.
                                  #Useful tools:
                                  #  - Easy access to objects, with properties and statistics, and conf files
                                  #  - Can open a psql session in a console
                                  #  - Edit/View data: simple spreadsheet.
                                  #    Read-only if no primary key.
                                  #    blank is null (needs to write '' for '')
                                  #  - Server status: current clients, locks, log (needs to edit path in options), transactions
                                  #Less useful tools:
                                  #  - Grant wizard (available when on a SCHEMA): generate SQL grant statements with GUI
                                  #  - Reports: generating HTML files for objects properties, statistics, dependencies.
                                  #  - Query tool: useless, use the console (unless needs a SQL debugger, which needs to be installed)

                                  ┌─────────────┐
                                  │   PGAGENT   │
                                  └─────────────┘

PGAGENT ==>                       #  - SQL "cron", inside pgadmin3
                                  #  - to install on a cluster:
                                  #     - connect to postgres
                                  #     - install plpgsql
                                  #     - as superuser ROLE, execute pgagent.sql (i.e. in pgadmin3 sharedir).
                                  #       It will create TABLE and FUNC used for storing/manipulating the jobs and schedules, in SCHEMA
                                  #       pagent
                                  #     - launch pgagent 'LIBPQ'
                                  #        - this daemon will look at those tables and determine if need to launch job
                                  #        - run as root
                                  #        - options:
                                  #           -s LOG_FILE
                                  #           -l1 (best verbosity)
                                  #           -t (poll time, def: 10 sec)
                                  #        - do no put password in 'LIBPQ' (use passfile instead)
                                  #        - automatically in background and detached from current terminal tab
                                  #        - should automatically launch it at startup
                                  #  - configure jobs using pgadmin, under "Jobs":
                                  #     - steps are:
                                  #         - SQL commands (will be executed as superuser ROLE)
                                  #         - or "batch" (shell commands, run as root, must start with #!/bin/bash)
                                  #     - schedules are when it is done
                                  #  - monitor with check_postgres

                                  ┌───────────────┐
                                  │   PGMODELER   │
                                  └───────────────┘

PGMODELER ==>                     #GUI modelling tool:
                                  #  - goal is to create/modify the DDL of a database, using a GUI.
                                  #     - can import DDL from existing database (of objects the user has permissions to query).
                                  #  - outputs SQL commands (or send to a database) or PNG image.
                                  #  - can validate DDL and issue warnings (requires connection to a database)
                                  #  - most DDL is available except foreign wrapper, etc., materialized views, event triggers,
                                  #    dictionaries, unlogged|temp tables, reference to VIEW COL
                                  #  - relationships: generalization is inherits, copy is create table like, others are foreign keys (with proper uniqueness)
                                  #  - there is a tree to go through object on the right panel

                                  ┌───────────────┐
                                  │   PGBOUNCER   │
                                  └───────────────┘

pgbouncer PGBFILE                 #Does connection pooling: maintains a single connection to be reused for each DATABASE+USER pair.
                                  #Goal is to lower connection time.
                                  #Can be much faster when connection time is important (small sessions).
                                  #Disadvantages:
                                  #  - requires more fds, so might needs lower max_client_conn than PostgreSQL's server
                                  #  - hides original host+port information in logs (all traffic goes though pgbouncer)
                                  #  - cannot implement all authentication method
                                  #Act as layer of abstraction: connection to pgbouncer DATABASE can be redirected to DATABASE of
                                  #other names, or of different clusters/machines.
                                  #Should be run as same OS_USER as the server.
                                  #Should be installed:
                                  #  - on database server, if lot of web servers connect to it (because it is the center of all
                                  #    connections that should be pooled)
                                  #  - on web server, if connects to lot of database servers
                                  #Each pool (DATABASE+USER) has:
                                  #  - clients (to pgBouncer) and servers (connection of pgBouncer to PostgreSQL).
                                  #    1 client = 0|1 server: 0 server when client just connected (session pool_mode) or is not issuing
                                  #    a request (transaction pool_mode)
                                  #  - cl_active (from show pool, see below) is number of clients on a pool.
                                  #    If more than pool size, clients will be cl_waiting instead until cl_active is lower.
                                  #    Pool size is determined by:
                                  #      - [default_]pool_size: cluster-wide and database-specific pool size.
                                  #      - min_pool_size: at first client, opens at least NUM idle servers, to make it more responsive
                                  #        in the first requests.
                                  #      - reserver_pool_size: extra pool size used for clients waiting (cl_waiting) for more than
                                  #        reserve_pool_timeout
                                  #  - max_client_conn is max number of cl_active for all pools together.
                                  #    When reached, clients don't wait, they crash.
                                  #  - Optimize limits:
                                  #     - number of file descriptors used = 2 + 1 per client (max_client_conn) + 1 per server
                                  #       (pool_size * number of users * number of databases)
                                  #         - pool_size should be at max without creating more servers than PCONF.max_connections
                                  #         - max_client_conn should be max number of servers + expected number of idle clients
                                  #         - total should not exceed max number of file descriptors
                                  #Pool mode:
                                  #  - when server is not used anymore, returns back to pool (sv_active -> sv_idle|used)
                                  #  - it is done according to pool_mode, either after each session (def), transaction or query (avoid).
                                  #    transaction doesn't support session states, i.e. [re]set CONFVAR, listen|notify, with hold CURSOR,
                                  #    PREP, load, user-defined volatile FUNC
                                  #    Use transaction if lot of idle times in sessions, or if long queries.
                                  #Look at check_postgres for monitoring.
-d                                #Run in background.
                                  #Needs to give pidfile = FILE in [pgbouncer] in PGBFILE (FILE is created with the PID)
-R                                #Online restart: closes current running pgbouncer and inherits its connections without interrupting
                                  #anything (current running pgbouncer will be closed). Useful to upgrade without interrupting anything.
-q                                #Quiet mode
-v                                #Verbosity (can do several times)

PGBFILE ==>                       #Usually called pgbouncer.ini
                                  #Has two parts, each started with [databases], then [pgbouncer] on a single line, and separated by
                                  #blank line.
                                  #Each part has VAR = VAL ... (STR don't have any quoting)

                                  #[databases]:
DATABASE                          #STR, LIBPQ string, but with only:
                                  #  - dbname: def. is same as DATABASE
                                  #  - host: def. is using Unix socket.
                                  #  - port: def. 5432
                                  #  - user: def. is same user
                                  #  - password
                                  #When client asks PgBouncer to connect on DATABASE, will use STR to connect to server.
                                  #Can also specify:
                                  #  - pool_size: Per-database pool size
                                  #  - connect_query: query done at connection start.
                                  #    For connection end (not DATABASE-specific), use server_reset_query (def: "discard all")
                                  #Can use * DATABASE to mean "any other database"

                                  #[pgbouncer]:
listen_port                       #Proxy port (which client should connect to in order to reach server)
listen_addr                       #Same for proxy address. Can be *
unix_socket_dir|mode|             #Like PCONF.unix_socket_directories|permissions|group
group                             #Def. are /tmp, 0777 and ""
auth_type                         #Similar as in pg_hba.conf. Can be md5 (def), plain (like password in pg_hba.conf), trust or any.
                                  #any is like trust, except that users are not even remembered which means:
                                  #  - all DATABASE must specify user=VAL in their LIBPQ STR
                                  #  - control with admin_users is not effective
auth_file                         #"USER" "PASSWORD" ...
                                  #Necessary (only USER with a line in it will be able to connect)
admin_users                       #USER... (pgBouncer USER) allowed to connect to pgBouncer and issue statements on it.
stats_users                       #Same but can only use show CONFVARs (except show fds)

logfile                           #Redirect stderr to FILE, without stopping stderr
log_[dis]connections              #Logs them (def: 1)
log_pooler_errors                 #Logs errors sent to client (def: 1)
stats_period                      #Logs stats every NUM seconds (def: 60)
syslog[_ident|facility]           #

pool_mode                         #See above (def: session)
                                  #If transaction, server_reset_query should be ""
max_client_conn                   #(def: 100)
default_pool_size                 #(def: 20)
min_pool_size                     #(def: 0)
reserve_pool_size|
timeout                           #(def: 0 and 5 seconds)

server_check_delay                #After NUM seconds (def: 30), goes from sv_idle to sv_used, i.e. run sanity check query on server
                                  #connections when going from idle to active.
server_lifetime                   #Closes server connections opened for more than NUM seconds (def: 3600)
server_idle_timeout               #Same but for idle server connections (def: 600)
server_connect_timeout            #Same but for connecting time (def: 15)
client_login_timeout              #If client connects but does not login before NUM seconds (def: 60), drops it.
autodb_idle_timeout               #Closes pools (using * in [databases]) that have been unused for more than NUM seconds (def: 3600)

server_login_retry                #Waits NUM seconds (def: 15) after each failed authentification.
dns_max_ttl                       #DNS (host resolution) cache time in seconds (def: 15)
max_packet_size                   #Max packet size between PostgreSQL and pgBouncer, in bytes (def: 2GB)

server_round_robin                #If 0 (def), reuse connections in LIFO manner. If 1, in a random manner (better if TCP round-robin
                                  #distributing load between servers)

pgbouncer DATABASE ==>            #Virtual DATABASE, where only show CONFVARs is allowed, with some commands:
reload                            #Reload PGBFILE (can also use SIGHUP)
pause [DATABASE]                  #Safest way to stop pgBouncer: wait for clients to complete. Can also use SIGINT (CTRL-C)
shutdown                          #Like pause, but exit pgBouncer completely. Can also use SIGTERM
suspend                           #Drop clients, but flush buffers
kill DATABASE                     #Least saft way to stop DATABASE
resume [DATABASE]                 #Resume from pause|resume

                                  #Can also show the following CONVARs:
lists                             #Snapshot of all other info
databases                         #DATABASE: connection+pool_size
stats                             #DATABASE:
servers                           #
clients                           #
pools                             #
fds                               #File descriptors
users                             #All users in auth_file
config                            #PGBFILE info
dns_hosts
dns_zones                         #Host resolution

TO DOCUMENT: prisma (https://www.prisma.io/docs/guides/performance-and-optimization/connection-management/configure-pg-bouncer)

                                  ┌────────────────┐
                                  │   DURABILITY   │
                                  └────────────────┘

DURABILITY ==>                    #PostgreSQL has durability: write operations will succeed even after a crash.
                                  #A crash will lead to:
                                  #  1) an inconsistent state if transaction was half written because of:
                                  #     - cache:
                                  #        - HCONF.fsync (def: 'on'): don't use cache, i.e. flush WAL records as they are written.
                                  #          Can be disabled at server startup with postgres -F
                                  #           - when setting from false to true, should re-sync using: initdb --sync-only|-S
                                  #        - HCONF.wal_sync_method tells which OS command to use to flush cache (when using fsync):
                                  #          open_datasync, fdatasync, fsync, fsync_writethrough or open_sync (def: fdatasync). Best one
                                  #          can be determined with:
                                  #             pg_test_fsync -f FILE (FILE must be on same filesystem than DATADIR)
                                  #        - HDD cache on Linux:
                                  #           - queried with: hdparm -I /dev/FILE | grep "Write cache" (* at beginning if cache enabled)
                                  #           - disabled with: hdparm -W 0 /dev/FILE
                                  #        - Filesystem caching through journaling: disable it with mount options (e.g. data=writeback
                                  #          on ext3).
                                  #     - partial writes, controlled by HCONF.full_page_writes (def: 'on').
                                  #       Putting to 'off' can improve performance.
                                  #  2) lost transactions (but no inconsistency) because of:
                                  #     - no synchronous commit: doesn't wait for the WAL to be written to report success of operation.
                                  #       SCONF.synchronous_commit can be activated (local|remote_write|on (def)) or not ('off')
                                  #     - WAL is written after ZSCONF.commit_delay (def: 0ms) in hope several operations will happen in
                                  #       the delay, which will then use a single flush. Best value is half the time of a single
                                  #       8kB write, as reported by last line of pg_test_fsync
                                  #       Only happens when min. SCONF.commit_siblings (def: 5) transactions are currently opened.
                                  #     - HCONF.wal_writer_delay (INT in ms, def: 200) too high: delay between each WAL writes
                                  #1) is dangerous: database could not be restared without a restore.
                                  #2) gives similar performance gain without that problem.
                                  #Putting DATADIR in a RAM disk is hardcore non-durable, and limits space to RAM space, but highly
                                  #efficient.

PCONF.data_sync_retry ???
postgres -P
LCONF.ignore_system_indexes ???

                                  ┌─────────────┐
                                  │   PG_DUMP   │
                                  └─────────────┘

BACKUP VS HIGH                    #Backup strategy (saving data) is different from, but should be combined with high availability
AVAILABILITY ==>                  #strategy (quick restore of system if a node falls down)

BACKUPS ==>                       #Either:
                                  #  - pg_dump: more stable from one PostgreSQL version to another, or from one architecture to another.
                                  #  - WAL archiving: provides continuous archiving and PITR
                                  #Best: do both too (do a pg_dumpall after each base backup).
                                  #Good idea to compress backups
                                  #Backups methods are all hot backups.

pg_dump [DATABASE]                #Def DATABASE: PGDATABASE or CLIENT_USER
                                  #Must be connect as superuser ROLE (for both backups and restores).
                                  #Unless "all", doesn't backup cluster-specific information. Remember then to restore them before
                                  #psql <FILE.
                                  #template1-specific information are backuped too: remember to restore from template0.
                                  #"INT" ON_ERROR_STOP should be set.
                                  #Recommendations for restore:
                                  #  - psql --single can be used to make everything rollback if error
                                  #  - Make sure tablespace DIR are good
                                  #  - should analyze restored databases.
-F p|c|d|t                        #Format of the output:
                                  #  - p (def): sql command in text format
                                  #  - c: custom compressed format (must be restored with pg_restore)
                                  #  - d -f DIR: put in a directory DIR (must be restored with pg_restore) with one file by TABLE, and a
                                  #    table of content file
                                  #  - t -f DIR: same but use tar (not compressed). Limit of GB per table.
-a                                #Don't save SCHEMAs (save only data)
-s                                #Save only SCHEMAs (not data)
-n SREGEXP                        #Only VAR... in SCHEMA matching SREGEXP (see psql). Can be specified several times.
                                  #Caution: doesn't dump VAR of other SCHEMA2... that SCHEMA might depend on.
-N                                #Inverse: SCHEMA not matching SREGEXP
-t SREGEXP                        #Same for TABLE matching SREGEXP. Incompatible with -n or -N
-T SREGEXP                        #Inverse: TABLE not matching SREGEXP.
--exclude-table-data=
SREGEXP                           #Same but only exclude TABLE data, not definition
-b                                #Include large objects, which is the default unless -n, -s or -t is used
-o                                #Includes OID
-O                                #Don't save ROLE ownership (with -F p). Will be able to restore backups without being superuser, but
                                  #restorer will get ownership of all objects.
-x                                #Don't save privileges (grant/revoke)
--no-tablespaces                  #Save everything in same, default tablespace.
--no-unlogged-table-data          #Don't save content of unlogged TABLEs
--no-security-labels              #Don't save seLINUX labels (when using it)
-c                                #Put cleaning commands first (drop VAR before trying to create it)
-C                                #Create the database in the beginning (otherwise need to create it).
--[column-]inserts                #Use insert instead of copy (slower). With column, put "COL" names instead of using positions. Is
                                  #much slower.
--serializable-deferrable         #Execute command in a serializable deferrable transaction (useful only when dumping to clone to
                                  #another machine)
--disable-dollar-quoting          #Use standard SQL quoting ' ' instead of $$ $$
--disable-triggers                #Create commands (with -F p) which disable triggers on tables before dump is restored.
-E STR                            #Encoding (def: PGCLIENTENCODING)
-j NUM                            #Use several threads in same time (faster but uses more resources). Make sure PCONF.max_connections
                                  #is high enough. Doesn't work if any exclusive lock is being requested meanwhile.
--lock-wait-timeout=NUM           #Wait for NUM seconds when asking for locks (def: unlim)
-d -h -p -U -w|W                  #Connection options (see psql)
--role=ROLE                       #ROLE when getting the dump data

pg_dumpall                        #Same as pg_dump, but for the whole cluster (except template0)
                                  #Use same options as pg_dump, except ones that are irrelevant, and selection options (like -T).
                                  #All databases must already exist.
-g                                #Only saves cluster-wide objects
-t                                #Only saves tablespaces
-r                                #Only saves ROLE

https://www.postgresql.org/docs/current/populate.html#POPULATE-PITR???

                                  ┌────────────────┐
                                  │   PG_RESTORE   │
                                  └────────────────┘

pg_restore [FILE]                 #Restore a backup produced by pg_dump -F (except for normal format, which should be restored with psql).
                                  #Def FILE is stdin. If no -d DATABASE is specified, print a text version of the restoration instead.
-a
-c
-C
-F c|d|t
-j NUM
-n SCHEMA
-O
-s
-S ROLE
-t SREGEXP
-x
--disable-triggers
--no-tablespaces
--no-security-labels
-d -h -p -U -w|W                  #Like pg_dump
-e                                #Sets SCONF.exit_on_error
-1                                #Put in only one transaction
-L FILE                           #Restore only objects present in FILE (can be produced with pg_restore -l, then manipulated)

                                  ┌─────────┐
                                  │   WAL   │
                                  └─────────┘

WAL ==>                           #Write-ahead logs. Logs that store every operation on the cluster before they are performed.
                                  #Goal:
                                  #  - when starting the server, if the last operations of the WAL have not been applied to the data
                                  #    (i.e. if the DATADIR data don't match the WAL), last operations are performed.
                                  #    Goal is to recover from crash.
                                  #  - can also be used for backups (see below)
                                  #Only WAL log are garanteed to be flushed (faster), not real operations, to ensure durability.
                                  #Structure:
                                  #  - Use 16MB segments. A log "line" is a "record".
                                  #    Every write on the cluster adds a new record on the last segment.
                                  #    New segments are automatically added and rotated.
                                  #    Are in DATADIR/pg_xlog/ but could be moved to a faster storage using symlinks.
                                  #  - initdb --waldir|-X WALDIR
                                  #  - initdb --wal-segsize=NUM
                                  #Checkpoints are when operations recorded by WAL are flushed to the disk (as opposed to flushing
                                  #the WAL itself, which is controlled by fsync, etc.):
                                  #  - last one is where to restart in crash recovery
                                  #  - are performed at min. time between CONF.checkpoint_segments (number of segments, def 3) and
                                  #    HCONF.checkpoint_timeout (time between checkpoints, def '5min').
                                  #    Increasing it will improve performance but increase crash recovery time (values between 32 to 256
                                  #    are often used for checkpoint_segments, and HCONF.checkpoint_timeout can be one day)
                                  #    If HCONF.checkpoint_warning (def: '30s') is less than the time between checkpoints, but more
                                  #    than HCONF.checkpoint_timeout, a warning will be issued to the server log.
                                  #  - can also issue SQL command `checkpoint` to do it
                                  #     - must be superuser or member of built-in ROLE pg_checkpoint
                                  #  - flushes performed by a checkpoints are spread to the next checkpoint. The spread is
                                  #    HCONF.checkpoint_completion_target, i.e. percentage of size spread for the free time allowed
                                  #    between checkpoints (def: 0.5, best is 0.9). Can go up to 0.9 will improve performance, but
                                  #    increase recovery time. Can only be set at server start.
pg_xlogdump [FILE]                #Show a WAL file in human readable format
                                  #When in DATADIR, can also use FILE FILE2 to go from FILE to FILE2
pg_resetxlog                      #To use when WAL is corrupted. Look at online doc
pg_controldata DATADIR            #Show debug info for WAL

pg_ls_waldir()->ROW_SET           #Returns files in WAL DIR
                                  #ROW: name STR, size INT8, modification TIMESTAMPTZ
pg_ls_archive_statusdir()->ROW_SET#Returns files in pg_wal/archive_status
                                  #ROW: name STR, size INT8, modification TIMESTAMPTZ

SCONF.backend_flush_after ???
HCONF.checkpoint_flush_after ???
HCONF.wal_writer_flush_after ???
ZSCONF.wal_compression ???
ZSCONF.wal_consistency_checking ???
ZSCONF.wal_init_zero ???
ZSCONF.wal_recycle ???
SCONF.wal_skip_threshold ???

HCONF.min_wal_size ???
HCONF.max_wal_size ???
ICONF.wal_block_size ???
ICONF.wal_segment_size ???
PCONF.wal_decode_buffer_size ???
PCONF.wal_log_hints ???
HCONF.max_slot_wal_keep_size ???
HCONF.wal_keep_size ???
PCONF.ignore_invalid_pages ???
ZSCONF.zero_damaged_pages ???

pg_current_wal_flush_lsn()???
pg_current_wal_insert_lsn()???
pg_current_wal_lsn()???
pg_switch_wal()???
pg_walfile_name()???
pg_walfile_name_offset()???
pg_wal_lsn_diff()???

create unlogged table|sequence ...#TABLE|SEQUENCE is not written to WAL
alter table "TABLE" set [un]logged#Faster, but truncated on unclean shutdown
select ... into unlogged table ...#Also, cannot use replication to standby servers

DBDIR|CLUSTERDIR/REGCLASS_OID_init#"Initialization fork".
                                  #Copy of unlogged TABLE|INDEX|SEQUENCE, without any data.
                                  #Used when truncating it on unclean shutdown, by copying it over.

create database "DATABASE"        #Whether to:
 strategy wal_log|file_copy       #  - wal_log (def): record each heap page to WAL
                                  #  - file_copy:
                                  #     - record all heap pages to WAL once at start and then at end
                                  #     - requires a checkpoint at start and end

SEQUENCE.log_cnt                  #0-32 (def: 0). Decrements at each setval|nextval() then cycles to 32.
                                  #When at 0, writes SEQUENCE to WAL.
                                  #I.e. only every 32 new value of SEQUENCEs are written to WAL, for performance

pg_walinspect EXTENSION ???

                                  ┌───────────────────┐
                                  │   WAL ARCHIVING   │
                                  └───────────────────┘

WAL ARCHIVING /                   #  - goals:
ONLINE BACKUP ==>                 #     - "continuous archiving". Just need to archive new WAL segments.
                                  #     - point in time recovery (PITR): instead of single snapshots, can recover to specific time in
                                  #       past
                                  #  - enabled by PCONF.wal_level to 'archive|hot_standby' (def: 'minimal') and PCONF.archive_mode to 'on'
                                  #  - backing up WAL segments continuously, and DATADIR at regular times:
                                  #     - backup in different folders, let's call them DIR1 and DIR2
                                  #     - events since the last DATADIR since the crash are then restored thanks to the archived WAL
                                  #       segments
                                  #  - backup of WAL segments:
                                  #     - each time a new WAL segment is about to be erased (because of rotation),
                                  #       HCONF.archive_command STR is fired to back it up:
                                  #        - can include %p for its path and %f for its filename, e.g.:
                                  #            '[ ! -f "DIR1/%f" ] && cp -a "%p" "DIR1/%f"'
                                  #        - should give exit code != 0 if error, so that it retries it
                                  #        - should not allow overwritting files
                                  #        - on Linux, use sh, not Bash
                                  #        - should be faster than the speed at which WAL segments appear
                                  #        - check permissions of server daemon to execute command
                                  #     - new segments are automatically made. But can be created manually by:
                                  #        - running pg_switch_xlog()
                                  #        - can be made every max. every HCONF.archive_timeout (def: 0, in seconds). Should not be
                                  #          under 60s.
                                  #          Goal is for databases with low traffic: new segments are rarely created but still want to
                                  #          archive the little traffic.
                                  #     - archived WAL segments before the last "base backup" can be erased to save space, up until when
                                  #       we want to do a PITR
                                  #     - Can also use command pg_receivexlog -D DIR, which archive WAL segments to DIR, according to
                                  #       connection options (see psql) -d -h -p -U -w|W
                                  #  - backup of DATADIR ("base backups"):
                                  #     - manually, steps are:
                                  #        - connect to any DATABASE of the cluster and fire pg_start_backup(STR) as superuser.
                                  #          STR should be the number of this unique backup
                                  #           - creates a text file DATADIR/pg_xlog/FILE.*.backup, where FILE is the last WAL segment
                                  #             archived, with information used by the recovery process (e.g. last WAL segment of
                                  #             current DATADIR)
                                  #           - creates DATADIR/backup_label, which is a very similar file
                                  #        - backup DATADIR with any command (such as cp -a) to DIR2:
                                  #           - don't include postmaster.* nor pg_xlog/*
                                  #           - don't forget directories that might be elsewhere, e.g. tablespaces or directories using
                                  #             symlinks postgresql.conf, pg_hba.conf, pg_ident.conf could also be put somewhere else
                                  #             with PCONF.config|hba|ident_file
                                  #           - copy might issue warnings because DATADIR files change on the fly (since cluster is
                                  #             running): it's fine
                                  #        - fire pg_stop_backup() as superuser.
                                  #           - removes backup_label file
                                  #        - utilities (not necessarily needed):
                                  #           - pg_is_in_backup(), pg_backup_start_time()
                                  #           - pg_start|stop_backup() returns the WAL segment as STR:
                                  #              - must be superuser
                                  #              - to translate into filenames:
                                  #                 - pg_xlogfile_name[_offset](STR)
                                  #                 - pg_xlog_location_diff(STR, STR2)
                                  #     - pg_basebackup:
                                  #        - automate all this. Options are:
                                  #            -h -p -U -w      Connection options
                                  #            -D DIR           DIR to copy to. Can be - (stdout) for tar mode
                                  #            -F p|t           If p, do a simple copy. Files pointed by symlinks (such as tablespaces),
                                  #                             will be copied to the destination using the same absolute path
                                  #                             If t, will tar it under the filename base.tar (symlinks files are tar'd
                                  #                             too, under their abs. path)
                                  #                             Can also use -z to gzip it and -Z 1-9 for the compression level (def: 6)
                                  #            -R               Put a recovery.conf sample if the backup
                                  #            -X s             Includes first WAL segment in the backup (def: doesn't include any WAL
                                  #                             segment).
                                  #                             Will use two clients in PCONF.max_wal_senders
                                  #            -l STR           Label used in backup_label (def: 'pg_basebackup base backup')
                                  #            -c fast|spread   Change HCONF.checkpoint_completion_target (def: spread)
                                  #            -P               Progress bar
                                  #        - use same privileges as streaming replication (PCONF.max_wal_senders, replication privilege, etc.)
                                  #        - basebackup_to_shell EXTENSION???
                                  #     - in all cases, need to be done regularly, e.g. with a cron script
                                  #        - more regular base backups require more storage, but make faster recoveries
                                  #  - recovery:
                                  #     - steps:
                                  #        - stop server
                                  #        - replace DATADIR by DIR2, but keeping the WAL segments:
                                  #           - move DATADIR/* to temporary DIR3 (including tablespaces, etc., see above)
                                  #           - copy DIR2/* to DATADIR (including tablespaces, etc., see above), with right ownership
                                  #             and permissions
                                  #           - replace DATADIR/pg_xlog/* by DIR3/pg_xlog/*, with right ownership|permissions
                                  #             (in case some WAL segments were not archived but still present in DATADIR)
                                  #        - copy archived WAL segments from DIR1 to DATADIR:
                                  #           - create DATADIR/recovery.conf (its presence instructs server start to be in recovery mode)
                                  #              - can copy template SHAREDIR/recovery.conf.sample
                                  #              - must set:
                                  #                 - HCONF.restore_command STR: just like HCONF.archive_command, but to copy the WAL segments from
                                  #                   DIR1 to DATADIR/pg_xlog/
                                  #                   Should overwrite existing ones.
                                  #                   Will emit warnings because try to copy files that might not exist.
                                  #                   Ex: 'cp -a "DIR1/%f" "%p"'
                                  #              - can recover to a specific time (PITR):
                                  #                 - by setting (in recovery.conf) any of:
                                  #                    - PCONF.recovery_target_time TIMESTAMP
                                  #                    - PCONF.recovery_target_xid STR: the transaction ID
                                  #                    - PCONF.recovery_target_name STR: STR is a restore point, which must have been
                                  #                      previously created by pg_create_restore_point(STR)
                                  #                       - must be superuser
                                  #                    - PCONF.recovery_target ???
                                  #                    - PCONF.recovery_target_action ???
                                  #                    - PCONF.recovery_target_lsn ???
                                  #                 - time must be after the creation time of DIR2/*
                                  #                 - recover just before|after according to variable (in recovery.conf)
                                  #                   PCONF.recovery_target_inclusive (def: true, i.e. after)
                                  #                 - will stop (unless variable pause_at_recovery_target is set to false or if
                                  #                   hot_standby mode), so we can check if the state is fine. Can resume by firing
                                  #                   pg_xlog_replay_resume()
                                  #                 - must remove WAL segments that have been archived after that time, to restart
                                  #                   archiving them normally
                                  #           - start the server in single user mode
                                  #           - recovery will happen: when done, recovery.conf will be recovery.done
                                  #        - make sure everything is ok, then restart the server normally
                                  #     - timelines:
                                  #        - each time a recovery suceeds, it increments the first number of the WAL segment files, e.g
                                  #          00...00100..0034 to 00...00200..0034
                                  #        - the first number is the timeline ID. Goal it that following WAL archives doesn't overwrite
                                  #          previous WAL archives created between the recovery and the crash, in case we want to come
                                  #          back to that point.
                                  #        - by default, recover to the timeline that was used during the base backup, but can specify
                                  #          PCONF.recovery_target_timeline STR with "latest" in recovery.conf, or with the specified
                                  #          timeline ID

HCONF.recovery_init_sync_method ???
HCONF.recovery_min_apply_delay ???
HCONF.recovery_prefetch ???

HCONF.archive_library ???

pg_stat_archiver                  #???
pg_stat_recovery_prefetch         #???
pg_stat_progress_basebackup       #TABLE with ongoing base backups. ???
pg_stat_wal                       #???
pg_stat_wal_receiver              #???

pg_lsn                            #TYPE holding an address in the WAL
                                  #2 * 4 bytes INTs
'XXXXXXXX/XXXXXXXX'               #PG_LSN_UNKNOWN, using hex chars
PG_LSN - PG_LSN2                  #NUMERIC
PG_LSN + NUMERIC
PG_LSN - NUMERIC                  #PG_LSN2

pg_control_checkpoint()->ROW???
pg_control_system()->ROW???
pg_control_init()->ROW???
pg_control_recovery()->ROW???

pg_backup_start()???
pg_backup_stop()???

                                  ┌──────────────────┐
                                  │   LOG SHIPPING   │
                                  └──────────────────┘

HIGH AVAILABILITY ==>             #Can use:
                                  #  - log shipping: master ships WAL to a DIR, then standby gets it from DIR
                                  #  - streaming replication: ships directly WAL from master to slave. Probably better.
                                  #     - async. (better performance) or sync. (better availability)
                                  #Any standby can also be a hot standby (makes more sense for a streaming replication one) to improve
                                  #load balancing (watch out precautions)

LOG SHIPPING /                    #  - Goal: not backup (but can be combined with backup) but to maintain a copy of the master server, so
WARM STANDBY ==>                  #    a switchover to the standby can happen quickly if there is a problem with the master
                                  #  - Idea: the standby machine keeps on reading the WAL archive (master must do WAL archiving) and
                                  #    applies them right away.
                                  #  - How:
                                  #     - start a cluster with a base backup, with a recovery.conf file in it.
                                  #       recovery.conf variable standby_mode should be on.
                                  #     - will continuously call recovery.conf HCONF.restore_command (same format as HCONF.archive_command)
                                  #       to copy WAL archive DIR1 to its own pg_xlog/, e.g. 'cp -a "DIR1/%f" "%p"'
                                  #        - will show error messages for next WAL segment, and .history file -> it's normal
                                  #     - Put PCONF.recovery_target_timeline to "latest" (to stay sync. with the timeline chosen by the master)
                                  #     - If don't want to use DIR1 for backup purpose, clean every WAL archive that has been copied by
                                  #       setting variable HCONF.archive_cleanup_command:
                                  #        - %r is the filename (not path) of the first WAL file to keep
                                  #        - pg_archivecleanup is a command line often used:
                                  #            - pg_archivecleanup "DIR" "%r"
                                  #            - flags are -d (verbose), -x STR (use it if WAL segments have this extension,
                                  #              e.g. -x .gz) and -n (dry-run)
                                  #     - Can stop standby mode and become a master:
                                  #        - by creating file specified by recovery.conf variable trigger_file, or firing
                                  #          pg_ctl promote.
                                  #           - change recovery.conf to recovery.done
                                  #        - never two masters at same time:
                                  #           - should turn off former master shortly before
                                  #           - before restarting, former master should become the new slave
                                  #        - good idea to prepare already the slave to become a master by setting up WAL archiving, etc.
                                  #        - JCONF.recovery_end_command STR will be fired (%r is the same as HCONF.archive_cleanup_command)
                                  #        - automatic failover is only possible using external packages.
                                  #  - Precautions:
                                  #     - DIR1 should not be on the master machine.
                                  #     - WAL segments are sent async (don't wait for shipping to execute), so there's a window for data
                                  #       loss, that can be reduce by lowering HCONF.archive_timeout
                                  #     - standby and master should have similar config:
                                  #        - logically, e.g. symlinks (including table spaces)
                                  #        - software-wise
                                  #        - hardware wise. CPU architecture must be same.
                                  #     - switchover is manual: should have own mechanism to notify when the primary server is down, and
                                  #       to automatically failover

pg_promote()???
  - must be superuser

pg_last_wal_receive_lsn()???
pg_last_wal_replay_lsn()???
pg_last_xact_replay_timestamp()???
pg_get_wal_resource_managers()???
pg_is_wal_replay_paused()???
pg_get_wal_replay_pause_state()???
pg_wal_replay_pause()???
pg_wal_replay_resume()???

                                  ┌─────────────────────────────────┐
                                  │   ASYNC STREAMING REPLICATION   │
                                  └─────────────────────────────────┘

ASYNC. STREAMING                  #  - Goal: like log shipping, but smaller delay between master and slave state (still small one)
REPLICATION ==>                   #  - Idea: like log shipping, but doesn't use WAL archive DIR1 (nor HCONF.restore_command,
                                  #    PCONF.recovery_target_timeline, HCONF.archive_cleanup_command), but directly get WAL from the server (over
                                  #    TCP connection).
                                  #  - How:
                                  #     - Set recovery.conf variable zHCONF.primary_conninfo (as "LIBPQ_VAR=VAL ...") for how to connect to the master.
                                  #     - Same as above for PCONF.recovery_target_timeline
                                  #     - Must have privileges:
                                  #        - to connect to "replication" virtual DATABASE (in pg_hba.conf)
                                  #        - replication and login privileges (better to create a ROLE than to set up as superuser).
                                  #        - max number of connections is PCONF.max_wal_senders (def: 0).
                                  #     - slave must keep up with the pace:
                                  #        - can increase CONF.wal_keep_segments on the master (number of segments that should be
                                  #          recycled but are kept, def: 0)
                                  #        - can use log shipping in parallel.
                                  #        - If fall behind, can redo a base backup.
                                  #        - Can tell by:
                                  #           - comparing pg_current_xlog_[insert_]location() on the master (current WAL),
                                  #             pg_last_xlog_receive|replay_location|timestamp() on the slave
                                  #           - use pg_stat_replication system view
                                  #        - Connection waits only for HCONF.wal_receiver_timeout (def:60s) from slave to master, and
                                  #          SCONF.wal_sender_timeout (def: 0, turned off) from master to slave.
                                  #     - Cascading replication:
                                  #        - Just use replication from downstream to upstream servers.
                                  #        - Goal: to reduce cost for master, but introduces more delay for other standbies.
                                  #        - sync. replication doesn't work for downstream servers.

PCONF.track_commit_timestamp ???
HCONF.primary_slot_name ???

HCONF.wal_receiver_create_temp_slot ???
HCONF.wal_receiver_status_interval ???
HCONF.wal_retrieve_retry_interval ???

pg_create_physical_replication_slot() ???
pg_copy_physical_replication_slot() ???

pg_ls_replslotdir()???

pg_stat_replication               #WAL sender processes.
pg_stat_database_conflicts        #DATABASE, with query cancelled due to recovery on standby servers.

                                  ┌────────────────────────────────┐
                                  │   SYNC STREAMING REPLICATION   │
                                  └────────────────────────────────┘

SYNC. STREAMING                   #  - Goal: like async. streaming replication, but reduces data loss window to nothing (at expense of
REPLICATION ==>                   #    performance): every write transaction returns only after WAL is sent to standby ("2-safe
                                  #    replication").
                                  #  - How:
                                  #     - Master must set HCONF.synchronous_standby_names with standbies:
                                  #        - comma-separated-list, only picks the first connected in the list
                                  #        - names must match SCONF.application_name in zHCONF.primary_conninfo
                                  #           - can be * for any SCONF.application_name
                                  #        - def is walreceiver
                                  #     - Actually waits according to SCONF.synchronous_commit:
                                  #        - on (received and flushed to disk on slave), remote_write (only received) or local|off
                                  #          (nothing).
                                  #        - Makes it possible to set SCONF.synchronous_commit specific values for databases, users or
                                  #          transactions, for different durability/performance tradeoff.
                                  #  - Precautions:
                                  #     - If last standby loses connection, will wait forever
                                  #        - if last standby needs to be down, must first put SCONF.synchronous_commit to off in a
                                  #          pg_start|stop_backup() block

                                  ┌─────────────────┐
                                  │   HOT STANDBY   │
                                  └─────────────────┘

HOT STANDBY ==>                   #  - Goal: use a standby server (streaming replication or log shipping) for readonly queries (load
                                  #    balancing).
                                  #  - How:
                                  #     - Must set PCONF.hot_standby to on on standby and PCONF.wal_level to hot_standby for master
                                  #     - Must start with a new base backup (if switching from non hot standby to hot standby)
                                  #  - Precautions:
                                  #     - Watch out for the delay between master write and ability to read it in standby. If an arriving
                                  #       WAL archive is conflicting with a current query (e.g. if master dropped a table while standby
                                  #       is querying it), it will wait HCONF.max_standby_archive|streaming_delay (for streaming
                                  #       replication mode or not) (def: 30000 ms, -1 for unlim) then cancel
                                  #        - low value provokes more cancels, but standby and master are more in sync: good if goal is
                                  #          more High availability, bad if goal is more load balancing
                                  #        - could be set at approx max time of queries.
                                  #        - Can also increase HCONF.vacuum_defer_cleanup_age if lot of vacuum-related conflicts.
                                  #          Cancels can be seen on system view pg_stat_database_conflicts.
                                  #     - Hot standby stops at startup when standby tries to catch up servers WAL segments. During that
                                  #       period, there might be seemingly weird behavior.
                                  #       pg_is_in_recovery() will return true.
                                  #     - those CONFVARs must be superior or equal on the standby than the master: PCONF.max_connections,
                                  #       PCONF.max_prepared_transactions, PCONF.max_locks_per_transaction
                                  #     - advisory locks can't be shared between master and slave
                                  #     - isolation level serializable not available

ENVVAR PGTARGETSESSIONATTRS
LIBPQ.target_session_attrs ???

ICONF.in_hot_standby ???
HCONF.hot_standby_feedback ???
HCONF.promote_trigger_file ???
HCONF.trace_recovery_messages ???

                                  ┌────────────┐
                                  │   REPMGR   │
                                  └────────────┘

repmgr                            #Must have rsync, pg_ctl and pg_config in $PATH. Must be installed from source (see online doc).
                                  #Actions can be:
                                  #  - standby clone "NODE": make it possible to put as standby (do a base backup).
                                  #  - master|standby register: put as master|standby (master should be done first)
                                  #  - standby promote|follow: in case of a failover, automatical new master to promoted, and followers
                                  #    will replicate from it. Automatical or manual???
-d -h -p -U                       #Connection options
-D DATADIR                        #Cluster to target
-f DIR                            #repmgr.conf DIR (def: same as executable).
                                  #repmgr has three lines: cluster STR, node number INT, libpq_conninfo STR
--force                           #Do with standby clone when a master is up again after having being down, to get back the changes
                                  #since then from the new master.

repmgrd                           #Daemon doing automatic failover.
                                  #Needs to do all the standby register first.
-f DIR                            #

                                  ┌────────────────┐
                                  │   EFFICIENCY   │
                                  └────────────────┘

WRITING ==>                       #Best way to write a big amount of data fast:
                                  #  - put in only one transaction/statement
                                  #  - use copy or (if copy not possible) prepare, if possible on an empty TABLE
                                  #  - create the INDEX and foreign keys constraints after the data has been put into
                                  #  - less checkpoints (increasing HCONF.checkpoint_timeout)
                                  #  - temporarily disabling WAL or replication
                                  #Should run analyze afterwards.

PERFORMANCE ==>                   #Can:
                                  #  - disable durability, by:
                                  #      - putting HCONF.fsync and HCONF.full_page_writes off (risky)
                                  #      - putting SCONF.synchronous_commit off (more durable and almost same performance gain)
                                  #  - less checkpoints (see below)

PERFORMANCE TUNING ==>            #CONF:
                                  #  - SCONF.work_mem (def: 1MB): max memory used by a single command for each of its sort operations and hash
                                  #    tables, before writing temp files to disk.
                                  #    Average total memory taken will be average_number_of_hash/sort_operations_by_command *
                                  #    number_of_connections * SCONF.work_mem. Should not be more than RAM taken by:
                                  #      kernel + other applications + PCONF.shared_buffers + let memory for kernel buffer
                                  #    Can also be set with postgres -S NUM
                                  #  - PCONF.wal_buffers (def: -1, which auto-select a value): memory used for caching WAL, i.e. number of
                                  #    WAL segments (16MB) that can be cached for all sessions before flushing them.
                                  #    If high number of transactions, might consider increasing for better performance.
                                  #    Best is 16MB.
                                  #  - ZSCONF.max_stack_depth (def: 2MB):
                                  #     - higher can provoke stack overflow (crashing the server) if higher than the kernel limit, with
                                  #       a safety margin of 2MB
                                  #       current OS limit can be seen with ulimit -s (8MB)
                                  #     - lower can cancel complex queries requiring more stack.
                                  #  - ZSCONF.temp_file_limit (def: -1, unlim): max memory for temp files, in KB
                                  #  - PCONF.max_files_per_processes (def: 1000): max opened files per session (see limit with ulimit -S|H -n)
                                  #    Def on Linux: 1024, so that's good.
                                  #  - SCONF|AOPTS.effective_io_concurrency: when using several disks at same time (e.g. RAID), number of disks that
                                  #    can write at same time
                                  #  - SCONF|AOPTS.maintenance_io_concurrency
                                  #  - PCONF.shared_buffers (def: 128MB): memory for shared buffers (def: 128MB).
                                  #    Good value is 25% of RAM (if > 1GB total RAM)
                                  #    Can also be set by postgres -B NUM
                                  #Look at amount of memory taken with pgcluu or pgbadger

HARDWARE ==>                      #  - more RAM -> more cache
                                  #  - good hard drives. RAID0 or RAID1 is good idea
                                  #  - CPU less important, but still important for complex functions

PCONF.max_worker_processes ???
SCONF.hash_mem_multiplier ???

HCONF.bgwriter_delay ???
HCONF.bgwriter_flush_after ???
HCONF.bgwriter_lru_maxpages ???
HCONF.bgwriter_lru_multiplier ???

PCONF.min_dynamic_shared_memory ???
PCONF.shared_memory_type ???
PCONF.dynamic_shared_memory_type ???
ICONF.shared_memory_size ???
ICONF.shared_memory_size_in_huge_pages ???
PCONF.huge_pages ???
PCONF.huge_pages_size ???

pg_prewarm EXTENSION ???

                                  ┌─────────────┐
                                  │   LOGGING   │
                                  └─────────────┘

LOGDIR                            #DIR with logs
                                  #Def on my system: /var/log/postgresl

pg_ls_logdir()->ROW_SET           #Returns files in log DIR
                                  #ROW: name STR, size INT8, modification TIMESTAMPTZ
pg_logdir_ls()->ROW               #

LOGGING ==>                       #Controlled by some CONF
HCONF.log_destination             #Where to put log messages (comma-separated list):
                                  #  - stderr (def)
                                  #  - csvlog:
                                  #     - with PCONF.logging_collector, will output as CSV files
                                  #     - goal is to import them in tables with copy from
                                  #  - syslog:
                                  #     - prefer using the PCONF.logging_collector
                                  #     - Needs to put local0.* LOGDIR/ in syslog conf file
                                  #     - Can use HCONF.syslog_facility, HCONF.syslog_ident, HCONF.syslog_sequence_numbers,
                                  #       HCONF.syslog_split_messages, and PCONF.event_source
PCONF.logging_collector           #When on, use the logging facility:
                                  #  - redirect stderr to file in zHCONF.log_directory too (can be relative to DATADIR) (def: pg_log).
                                  #      - files are named according to zHCONF.log_filename, which can use %... (data escape)
                                  #        (def: "postgresql-%Y-%m-%d_%H%M%S.log") for file creation time
                                  #      - a new file is created every HCONF.log_rotation_age (def: 1d)
                                  #        or every time the file is more than HCONF.log_rotation_size (def: 10MB)
                                  #         - or when pg_rotate_file() is called
                                  #            - must be superuser
                                  #    If csvlog, will be in CSV format and use name SCONF.application_name.
                                  #  - Files have permission HCONF.log_file_mode (def: 0600, only server owner can read/write)
pg_current_logfile()???
  - must be superuser

postgres -d NUM
ZSCONF.log_min_messages           #Between debug5-1, log, notice, warning, error, fatal, panic (def: notice for client, warning for log) for
SCONF.client_min_messages         #either client messages or logging.
                                  #postgres -d NUM can set ZSCONF.log_min_messages (from 0 to 5, def: 0), for DEBUG5-1
ZSCONF.log_error_verbosity        #Verbosity of messages: default, verbose (include SQLSTATE error code) or terse (no defail, hint,
                                  #query nor context)
ZSCONF.log_min_error_statement    #Same as ZSCONF.log_min_messages, but for logging the statements themselves (def: error).
ZSCONF.log_statement              #Which statements to log among none (def), all, ddl or mod (include ddl)
ZSCONF.log_min_duration_statement #Logs time of statement execution, when it is higher than this limit (in ms, 0 to log all, -1 not to
                                  #log it (def))
postgres -s
ZSCONF.log_statement_stats        #If on, server prints to stderr the statements executed and the time it took
HCONF.log_line_prefix             #What to put in beginning of each log line. Can include %-escapes:
                                  #  - a: application_name
                                  #  - u: user
                                  #  - d: database
                                  #  - r: host+port
                                  #  - h: host
                                  #  - p: PID
                                  #  - t|m: timestamp (to seconds|ms). Timezone is controlled by HCONF.log_timezone (def: 'localtime')
                                  #  - s: process start time
                                  #  - c: session id (process start time + PID)
                                  #  - i: command
                                  #  - e: error code
                                  #  - l: log number, session-wise
                                  #  - x|v: [virtual] transaction ID
HCONF.log_checkpoints             #Logs checkpoints (def: off)
ZLCONF.log_[dis]connections       #Logs [dis]connections attempts (def: off)
ZSCONF.log_lock_waits             #Logs deadlocks (see ZSCONF.deadlock_timeout)

HCONF.log_autovacuum_min_duration ???
HCONF.log_recovery_conflict_waits ???
HCONF.log_startup_progress_interval ???
ZSCONF.log_duration ???
ZSCONF.log_executor_stats ???
ZSCONF.log_min_duration_sample ???
ZSCONF.log_parameter_max_length ???
SCONF.log_parameter_max_length_on_error ???
ZSCONF.log_parser_stats ???
ZSCONF.log_planner_stats ???
ZSCONF.log_replication_commands ???
ZSCONF.log_statement_sample_rate ???
ZSCONF.log_transaction_sample_rate ???
ZSCONF.log_temp_files ???
ZSCONF.backtrace_functions ???
SCONF.debug_pretty_print ???
SCONF.debug_print_parse ???
SCONF.debug_print_plan ???
SCONF.debug_print_rewritten ???
SCONF.trace_notify ???
SCONF.trace_sort ???

HCONF.log_truncate_on_rotation ???

HCONF.log_hostname ???

pg_log_backend_memory_contexts()???

auto_explain EXTENSION???

pgaudit EXTENSION???

                                  ┌────────────────┐
                                  │   MONITORING   │
                                  └────────────────┘

DETAILED MONITORING ==>           #Usually not needed, because there are higher-level monitoring tools:
                                  #  - ps auxww | grep ^postgres: see individual processes and description:
                                  #     - postgres master process
                                  #     - several master background processes: checkpoints, WAL, autovacuum, statistics collector
                                  #     - each client connection has one process with description showing CLIENT DATABASE HOST ACTIVITY
                                  #       (autoupdate can be turned on|off by ZSCONF.update_process_title)
                                  #  - statistic collector:
                                  #     - daemon that fill in pg_stat* system views
                                  #     - used to collect statistics on activity
                                  #     - controlled by:
                                  #        - ZSCONF.track_activities BOOL (def: true) (COMMAND executed and time of execution)
                                  #           - PCONF.track_activity_query_size (size of tracks in track_activities, def: 1024). Can only be
                                  #             set at server start.
                                  #        - ZSCONF.track_counts BOOL (def: true) (general activity). Also allows explain.
                                  #        - ZSCONF.track_io_timing BOOL (def: false) (I/O timing). Can be slow.
                                  #        - ZSCONF.track_wal_io_timing BOOL (def: false)
                                  #        - ZSCONF.track_functions (def: 'none') (FUNC calls). Can also be 'pl' (PL/*) or 'all' (PL/*, SQL
                                  #          and C functions)
                                  #     - temp stats are stored in CONFVAR DATADIR/stats_temp_directory (def: 'pg_stat_tmp').
                                  #       Putting it in a RAM disk can improve performance.

pg_stat_activity                  #Server processes, with names, usernames, start|last time, addresses and command activity.
pg_stat_bgwriter                  #Background writer process's activity, e.g. for checkpoints.
pg_stat_database                  #DATABASE, with number of servers/clients, transactions, temp files, tuples manipulated
                                  #(fetch|select|insert|update|delete), blocks read|hits, time spent on I/O read|write, deadlocks.
pg_stat[_xact|io]                 #TABLE, with:
 all|sys|user_tables              #  - not io: number of sequential|indexed scans (and tuples they fetched), tuples manipulated
                                  #    (insert|update|delete), number of rows (live|dead), [auto]vacuum|analyze activity
                                  #  - io: disk read|hits for all, index-only, TOAST and TOAST index
                                  #Can be for only system catalogs (sys) or not (user).
                                  #If xact_, take the current transaction into account.
pg_stat[io]_all|sys|user_indexes  #INDEX, with:
                                  #  - not io: number of scan (with tuples fetched: bitmap + simple index scan, or simple index scan
                                  #    only)
                                  #  - io: index blocks read|hits (efficient if low read/hits %)
pg_statio_all|sys|user_sequences  #SEQUENCE, with number of blocks read|hits
pg_stat[_xact]_user_functions     #FUNC, with number of calls and total time (only FUNC, or FUNC called by it too).
                                  #ZSCONF.track_functions must be on.

pg_stat_reset*() ??? Must be superuser

initdb --data-checksums|-k ???
ICONF.data_checksums
ZSCONF.ignore_checksum_failure ???

ZSCONF.compute_query_id ???
SCONF.stats_fetch_consistency ???

postgres -s ???

pg_backend_memory_contexts
                                  #Visible only to superuser
pg_shmem_allocations
                                  #Visible only to superuser
PIDF[6]                           #Shared memory segment ID
pg_stat_slru                      #???

pg_read_all_stats                 #Members of that built-in ROLE can use:
                                  #  - `select` on pg_stat*, pg_backend_memory_contexts, pg_shmem_allocations
                                  #  - pg_database|tablespace_size()
                                  #  - ZSCONF.track_activities

pg_stat_statements                #VIEW for all queries (query, time, number of rows, I/O).
                                  #Can be reset with pg_stat_statements_reset().
                                  #Can use PCONF.pg_stat_statements.max (def: 1000)
                                  #Must put pg_stat_statements in PCONF.shared_preload_libraries and use EXTENSION pg_stat_statements.

pg_stat_monitor ???

pg_buffercache EXTENSION ???

                                  ┌────────────────────┐
                                  │   CHECK_POSTGRES   │
                                  └────────────────────┘

check_postgres                    #Performs several sanity monitoring tests, and outputs warnings.
-db -H -u -p                      #Connection options. Some actions requires several clusters/databases: then use STR...
--dbpass=STR...                   #Can also use STR... for any action to perform the check separately on several clusters/databases
                                  #(will return problem if any of them is wrong), or on master/slave
--output=STR                      #Output format (this doc only talks about nagios):
                                  #  - nagios (def):
                                  #     - compatible with NAGIOS (server network monitoring application)
                                  #     - one line with test name, then OK|WARNING|CRITICAL|UNKNOWN (and exit code 0 to 3 accordingly),
                                  #       followed by colon and description.
                                  #       UNKNOWN is when test cannot be performed, and WARNING|CRITICAL are set up according to
                                  #       -w|c VAL ("thresholds", depends on action). If warning = critical, turn off warnings.
                                  #     - can use option:
                                  #       --showperf=1|0: show performance at end of line (def: 1)
                                  #           --perflimit=NUM: limit --showperf to NUM items (def: 0, i.e. unlim)
                                  #           --showtime=1|0: show queries execution time (def: 1)
                                  #  - mrtg
                                  #     - compatible with MRTG (traffic load monitoring application)
                                  #     - four lines: NUM (usually main info), description (usually 0), blank and DATABASE
                                  #       (only when relevant)
                                  #     - can use option --mrtg=VAL to pass arguments to MRTG
                                  #     - usually don't issue warnings|critical
                                  #  - simple
                                  #     - like mrtg, but only first line (NUM)
                                  #     - can be followed by unit, e.g. --output=simple,MB
--action=STR...                   #Checks to perform, among:
                                  #Connections:
                                  #  - connection:
                                  #    Checks if server is up.
                                  #    CRITICAL + psql error description if no, OK + server version if yes.
                                  #  - backends:
                                  #    Checks if number of connections is more than threshold (NUM or % of PCONF.max_connections) or if more
                                  #    than threshold connections are left (-NUM).
                                  #    Can only select --noidle connections.
                                  #    Look at --include below for how to specify per DATABASE.
                                  #  - pgbouncer_backends:
                                  #    Same but with pgBouncer (max_client_conn)
                                  #  - pgb_pool_maxwait|cl_active|waiting|sv_active|idle|used|tested|login:
                                  #    Checks if any pgBouncer pool has more than thresholds (see show pools in pgBouncer)
                                  #Space usage (look at --include below):
                                  #  - disk_space:
                                  #    Checks if any partition used by any data in the cluster (DATADIR, tablespaces, WAL dir, log dir)
                                  #    is using more than thresholds of memory (can use percentage, "MB", etc. units, and "and|or")
                                  #  - database|relation|index|table_size:
                                  #    Checks if any DATABASE|TABLE|INDEX is more than thresholds (can include "MB", etc.).
                                  #    Prints size in bytes (first line), and name (last line) of biggest one.
                                  #  - bloat:
                                  #    Checks if there are more than threshold (NUM (unit: 'KB', etc.) or % of TABLE size) dead rows
                                  #    in any TABLE|INDEX (only consider ones with > 10|15 pages)
                                  #  - wal_files:
                                  #    Checks if there are more than thresholds WAL files.
                                  #    Number of WAL files is usually comprised in a given range, unless there is a malfunction
                                  #    (long transaction, wrong HCONF.archive_command, etc.), creating disk space usage risk.
                                  #Unusual state:
                                  #  - pgagent_jobs:
                                  #    Checks if all pgagent jobs since threshold (unit 's|m|h|d') have an exit code of 0
                                  #  - logfile:
                                  #    Checks if redirection to log file is happening correctly.
                                  #    Must provide log full path with --logfile=STR (can use "%Y|%m|%d|%H").
                                  #    Does not work if redirection to stderr without logging collector on.
                                  #  - commitratio:
                                  #    Checks if commit ratio (non-rollbacked transactions/transactions) is lower than thresholds.
                                  #  - disabled_triggers:
                                  #    Checks if number of disabled triggers is >= thresholds.
                                  #  - locks:
                                  #    Checks if number of locks held >= threshold.
                                  #  - txn_idle:
                                  #    Checks if there are more than thresholds idle current transactions (waiting for locks), and if
                                  #    any has lasted more than threshold (unit 's|m|h|d')
                                  #  - prepared_txns:
                                  #    Checks max. age of prepared transactions (not prepared statements).
                                  #Corruption:
                                  #  - sequence:
                                  #    Checks if sequence has been used more than threshold (%)
                                  #  - txn_wraparound:
                                  #    Checks if more than thresholds transactions have not been vacuumed, creating risk for
                                  #    xid wraparound. Wraparound happends every 2e9, so value should be e.g. 1.5e9
                                  #  - autovac_freeze:
                                  #    Checks if number of old transactions is more than threshold (%) of autovacuum_freeze_max_age
                                  #Performance (look at --include below):
                                  #  - query_runtime:
                                  #    Checks if queries specified by --queryname=STR (VIEW or FUNC) runs in more than time specified
                                  #  - txn|query_time:
                                  #    Same for running transactions|queries
                                  #  - hitratio:
                                  #    Checks if cache hit ratio is lower than thresholds.
                                  #  - last_[auto]analyze|vacuum:
                                  #    Checks if has been run (auto only checks autovacuum|analyze, other checks all) since threshold
                                  #    (in s|m|h|d, def: 1d for vacuum, 2d for analyze).
                                  #    Should exclude tables with no dead rows.
                                  #  - dbstats:
                                  #    For each DATABASE, print one line with backends (number of processes), commits|rollbacks
                                  #    (number since beginning), read|hit (number of blocks since beginning), ret|fetch|ins|upd|del
                                  #    (number of rows), dbname, idx..., seq...
                                  #    Cannot use alternate outputs.
                                  #Comparison:
                                  #  - same_schema:
                                  #    Compares two or more databases, schema-wise (not data-wise).
                                  #    If only one host: make a time-based comparaison: next time it will be executed, will compare
                                  #    with previous version.
                                  #    To do so, create a file at ./check_postgres.audit.port.PORT.db.DATABASE:
                                  #      - Use --replace to overwrite it.
                                  #      - can add .STR to the filename with suffix=STR
                                  #    Can exclude objects with:
                                  #      --filter=nouser|schema|table|view|index|sequence|constraint|trigger|perm|funcbody|function[='REGEXP']
                                  #      --filter=noposition: don't compare columns positions
                                  #  - settings_checksum:
                                  #    Compares two CONFs for a given user.
                                  #    First use -c 0 to get checksum, then do -w|c=CHECKSUM
                                  #  - pgbouncer_checksum:
                                  #    Same but with pgBouncer
                                  #  - timesync:
                                  #    Checks if local time diff >= threshold (in sec., should not be <5)
                                  #Standbies (can all test standby mode with --assume-standby|prod-mode):
                                  #  - hot_standby_delay:
                                  #    Checks if delay between current database (master) and slave >= threshold (number of WAL lines)
                                  #  - replicate_row:
                                  #    Checks that updates of a single row takes no more than threshold to replicate using replication.
                                  #    Should choose column to change (should pick one not likely to be changed by another process),
                                  #    with --repinfo=TABLE,PKEY,PKEY_VAL(to select row),"COL",OLD_VAL,NEW_VAL
                                  #  - checkpoint:
                                  #    Checks if last checkpoint was run more than threshold ago (unit: 's|m|h|d').
                                  #    Meant to be run on a slave. Must supply --datadir DATADIR
                                  #Upgrades:
                                  #  - new_version_bc|cp|pg:
                                  #    Checks if new version of Bucardo|check_postgres|PostgreSQL is available.
                                  #    Only nagios. UNKNOWN if binary not here, CRITICAL is revision upgrade, WARNING is major upgrade.
                                  #  - version:
                                  #    Checks that server version is at least threshold
                                  #Custom:
                                  #  - custom_query:
                                  #    Checks a custom --query=STR, which returns a single column called "result", if any row value,
                                  #    depending on type of -w|c VAL:
                                  #      - NUM: >= NUM
                                  #      - NUM[KB, etc.]: >= NUM
                                  #      - STR's|m|h|d': older or same as STR
                                  #      - STR: same as STR
--in|exclude=STR...               #Limit the objects checked:
                                  #  - DATABASE: for backends, database_size, locks, query_time, txn_idle, txn_time
                                  #  - TABLE|INDEX: for bloat, index|table|relation_size, last_[auto]vacuum|analyze
                                  #  - FILESYSTEM: disk_space
                                  #include alone means "include only", but not alone means "include also" (to reinstate objects that
                                  #have been excluded with --exclude).
                                  #STR:
                                  #  - ending with . matches a schema
                                  #  - starting with ~ is a REGEXP (otherwise full VAR name)
--in|excludeuser=STR...           #Same for objects owned by 'ROLE'...
                                  #Works for relation|database_size, query|txn_time, last_[auto]vacuum|analyze.
-t NUM                            #Timeout (in secs, def: 10) after which returns UNKNOWN status, per cluster.
-v ...                            #Verbosity. Do several times to increase verbosity.
--debugoutput=LETTER...           #Prints also the psql output for a (all), c (critical), w (warning), o (ok), u (unknown)
--PGBINDIR=STR                    #psql directory (see man page on precautions to use)

                                  ┌──────────────┐
                                  │   PGBADGER   │
                                  └──────────────┘

pgbadger FILE[...]                #FILE... are the log files (stderr, csvlog (need Text::csv_xs module) or syslog format).
                                  #FILE can be - for stdin (not for csvlog).
                                  #Recognize compressed files from extensions .gz, .bz2 or .zip
                                  #Should put:
                                  #  - ZSCONF.log_statement to 'none' (do not enable it)
                                  #  - ZSCONF.log_min_duration_statement to 0
                                  #  - HCONF.log_checkpoints, [dis]connections|lock_waits to 'on'
                                  #  - ZSCONF.log_temp_files to 0
                                  #  - ZSCONF.lc_messages to 'C'
                                  #If stderr:
                                  #  - HCONF.log_line_prefix to '%t [%p]: [%l-1] user=%u,db=%d,host=%h,application=%a'
                                  #    Use pgbadger -p '%t ...' (same as above) -f stderr
                                  #Use latest release (3.3 is not)
                                  #Needs to put as much as possible in logs to get all graphs.
                                  #Can zoom it with shift button.
-f stderr|csvlog|syslog           #Def: stderr
                                  #For syslog:
                                  #  -i STR: Program name used as ident for syslog
-o FILE                           #Output file and format (among .html, .txt and .tsung). Def is output.html
                                  #Can also use -x text|html|tsung. Tsung is <sessions> tag for XML config file with most usual session.
-q                                #Quiet

-c HOST
-d DATABASE
-u USER
-N APPLICATION_NAME               #Filter for only this parameter (can be used several times)
-U USER                           #Filter for excluding USER (can be used several times)
-b|e DATE                         #Start|end time to be processed.
-l FILE                           #Only use logs starting from this log file.

-a NUM                            #Step (in min, def: 5) for the average number of query per second.

-s NUM                            #Number of sample queries (def: 3)
-t NUM                            #Number of top queries (def: 20)
--pie-limit NUM                   #Minimum percentage for pie chart slices

-S                                #Only analyze select queries
--exclude-query STR               #Exclude queries matching regexp STR
--exclude-file FILE               #Same but regexps are in FILE
--include-...                     #Inverse: include only.
-T                                #HTML <title> (def: "pgBadger")
-C                                #Remove /*comment*/ from queries
--disable-error|hourly|
type|session|temporary|
connection|query|lock|
autovacuum|checkpoint             #Remove a specific part in the report

-j|J NUM                          #Multiprocessing. Cannot be used with compressed files, csvlog or on Windows.
                                  #j is number of jobs/log file, J is number of log files in same time.

                                  ┌────────────┐
                                  │   PGCLUU   │
                                  └────────────┘

pgcluu_collectd DIR               #GUI that gives info on resource and space usage (similar to pgbadger, but gives some different stats).
                                  #pgcluu_collectd is the daemon collecting stats, pgcluu the tool creating reports
                                  #Should be run as the OS_USER owning the cluster, on a DIR owned by this OS_USER.
                                  #Good idea is to put inside DATADIR, with same permissions as other folders.
                                  #psql, sar (from package sysstat) should be installed. Their path should be given with -P|s STR if not
                                  #in /usr/bin/
                                  #Can find a sar file and several CSV files in DIR/
-d -h -p -U                       #Connection options
-D                                #Run as daemon. Can be killed with pgcluu_collectd -k
-i NUM                            #Frequency in seconds (def: 60)
-f FILE                           #PID FILE (def: /tmp/pgcluu_collectd.pid)
--stat-type all                   #Includes also system catalogs stats.
-m STR                            #Restrict data collection with a comma-separated list of metrics to perform (list can be found with
                                  #pgcluu_collectd --list-metric)
--pgbouncer-args=STR              #If pgbouncer (connection pooling utility) is used, arguments to pass to it (e.g. connection options)

pgcluu DIR                        #Creates report. DIR is the pgcluu_collectd DIR
                                  #Should be run as same OS_USER as pgcluu_collectd
                                  #sadf (from package sysstat) should be installed. Its path should be given with -s STR if not
                                  #in /usr/bin/
                                  #Can zoom in graphs
-b|e DATETIME                     #Begin|end time when to report.
-d DATABASE                       #Filter for only DATABASE (can be used several times)
-T TABLE                          #Same for TABLE (don't seem to work)
-t                                #Per table stats (don't seem to work)
-p DEVICE                         #Filter I/O info for only DEVICE (can be used several times)
-o DIR                            #DIR to create the HTML files (def: $PWD)

                                  ┌────────────┐
                                  │   PG_TOP   │
                                  └────────────┘

pg_top [NUM]                      #Show info about running PostgreSQL clients and servers in realtime, tables|indexes read|write.
                                  #psql is shown as "postgresql" command.
                                  #Must be run as the OS_USER owning the server.
                                  #If NUM, only show NUM first processes.
                                  #Accepts the following keystrokes:
                                  #  C-L: refresh
                                  #  R|X: switch with table|index stats
                                  #    t: show cumulative, not instant stats
                                  #  i: toggle display of idle processes
                                  #  k: kill
                                  #  o: change sorting
                                  #  Q: show current query
                                  #  u: show only specific user
                                  #Also available for smartphones/tablets.
-I                                #Do not display idle processes.
-o FIELD                          #Sorts according to FIELD
-z USER                           #Filter for only USER
-x [NUM]                          #Prints NUM first processes (def: "all"), then exits.
-c                                #Show command name instead of full command line
-s NUM                            #Delay in seconds (def: 5)
-r                                #Connects to a remote database. Needs to use -h -p -U -W connection options.

                                  ┌───────────┐
                                  │   PGTAP   │
                                  └───────────┘

PGTAP UNITS ==>                   #Needs to be installed.
                                  #Tested database must enable PL/PGSQL.
                                  #Idea is to create assertions (see below for list) in a separate test unit SQL file. Usually put in a
                                  #tests/ folder
                                  #Usually do test manipulation on the database between assertions, so in the end should rollback:
                                  #  - put in a transaction block that rollbacks.
                                  #  - put "INT" ON_ERROR_ROLLBACK and ON_ERROR_STOP
                                  #For best formatting:
                                  #  - put "INT" ECHO to nothing, QUIET to 1
                                  #  - \pset format unaligned, pager on, t true
                                  #  - if using psql, use -X to bypass init files
                                  #Each assertion produce a TAP format line (common text format for test results, that is runned and
                                  #parsed by "test harnesses")
                                  #Trusted postgres extension 'pgtap'
select plan(NUM)                  #Starts a unit with exactly NUM assertions. If not sure use select * from no_plan() instead (avoid).
select * from finish()            #Completes a test unit

PGTAP XUNIT TESTS ==>             #Same as normal pgTap units (same output and assertions) but:
                                  #  - use functions, not files. Functions just execute the assertions functions, and returns them as a
                                  #    STR_ARR:
                                  #      create or replace function SCHEMA.FUNC()
                                  #      returns setof text as
                                  #      $$begin
                                  #          return next ASSERTION_FUNC(ARGS)...
                                  #        end$$
                                  #      language pgsql
                                  #  - don't need anything to start|finish the unit but needs to run the unit with:
                                  #      select * from runtests([STR][, STR2])
                                  #    where STR is SCHEMA, and STR2 is a regular expression to match the FUNC to choose.
                                  #    Since STR and STR2 are both optional (def: 'public' and '^test') cast to name if using only STR
                                  #     - Use transaction on all tests as a whole, then on each individual test (including fixture
                                  #       functions)
                                  #  - can use fixture functions (same definition as above), special FUNC used at specific moments.
                                  #    Each set run in alphabetical order. FUNC name must start with the name of the phase:
                                  #     - startup, once before all tests
                                  #     - setup, once before each test
                                  #     - teardown|shutdown: same as setup|startup, but after tests
                                  #    Watch out to exclude the fixture functions in runtests(). Good practice is to use a SCHEMA, and
                                  #    '^test' for tests.

pg_prove [DIR|FILE...]            #Test harness for pgTap (executes tests).
                                  #Like doing psql, but better output, and don't need to set \pset and "INT"
                                  #(but should still put in a transaction block)
                                  #For DIR, recognize test files according to extension ".pg"
                                  #Same for xUnit-style tests, but:
                                  #  - don't use FILE... but -R, which fires runtests()
                                  #  - use -s SCHEMA and -x REGEXP to specify arguments to runtests(STR, STR2)
-d -U -h -p                       #Connection options
-P|S VAR=VAL                      #Does \[p]set VAR VAL
--ext STR                         #With DIR, use extension STR, not ".pg"
-r                                #With DIR, recursive

--shuffle|reverse                 #Modify test execution order
--state STR,...                   #Which tests to run:
                                  #  - last: same as last time
                                  #  - all: in normal order
                                  #  - failed|passed: only ones that failed|passed
                                  #  - hot: most recent failure first
                                  #  - todo: only test with todos
                                  #  - slow|fast: in speed order
                                  #  - new|old: in mtime order
                                  #  - fresh: only the ones that have been modified
                                  #  - save: save state in a file ./.pg_prove (must be done first to be able to do --state next time)

-f                                #Print failed tests
-q|Q                              #Quiet, or even quieter
--verbose                         #Outputs full TAP format
--no-comments                     #Don't show diag() messages
--directives                      #Only show skip() messages and todo() tests
-D                                #Dry-run
-t                                #Show time of execution of each test

-j NUM                            #Number of jobs in parallel
-b FILE                           #PSQL location

PGTAP ASSERTIONS ==>              #They are FUNC that all come with an optional (but recommended) last arg STR for error message
                                  #(def: '').
                                  #They print the result of the assertion as a STR

GENERAL ASSERTS ==>               #
ok(BOOL)                          #Asserts that BOOL is true.
                                  #Prefer other function when possible, e.g. is(VAL, VAL2) over ok(VAL = VAL2), because more descriptive
                                  #output.
pass|fail()                       #Like ok(true|false) (avoid them)
is[nt](VAL, VAL2)                 # is [not] distinct from
[i]matches(VAL, VAL2)             # ~[*]
doesnt_[i]match(...)              # !~[*]
[un][i]alike(VAL, VAL2)           # [not] [a]like
cmp_ok(VAL, 'OP', VAL2)           # VAL OP VAL2
isa_ok(VAL, STR)                  # pg_type(VAL) = STR

SQL QUERIES RESULTS==>            #Asserts results of sql select ...:
'SQL'                             #Means SQL statement STR (either as is, or name of a PREP (recommended)).
                                  #A PREP with arguments needs to be written as is, i.e. not 'PREP' but 'execute PREP(ARGS)'
throws_ok('SQL'[, STR2 [, STR3]]) #Asserts that 'SQL' throws an exception, with errcode STR2 and errmessage STR3 (each can be null
                                  #(def) for all errcode|errmessage)
lives_ok('SQL')                   #Inverse of throws_ok('SQL')
throws_[i]like|matching
 ('SQL'[, STR2])                  #Same as throws_ok('SQL', null, STR2), but STR2 needs to match with [i]like or ~[*], not = <>
performs_ok('SQL', INT)           #Asserts that 'SQL' performs in less than INT ms.
results_eq|ne('SQL'|CURSOR,       #Asserts that both queries compare with = <>
 'SQL2'|ARR|CURSOR2)              #Is row-wise, so make sure they are ordered the same.
                                  #CURSOR iterates over all rows (must be STR casted as refcursor)
                                  #ARR represents a single-column (values ... could also be used for several columns)
bag|set_eq|ne('SQL',              #Same but compares not row-wise, but the whole set of values together (so order doesn't matter).
'SQL2'|ARR)                       #set removes duplicates, bag doesn't.
bag|set_has[nt]('SQL', 'SQL2')    #Same as bag|set_eq|ne, but only for subset, i.e. asserts that 'SQL' includes 'SQL2'
is[nt]_empty('SQL')               #Asserts number of rows = <> 0
row_eq('SQL', "ROW")              #Same as results_eq, but for a single row

SCHEMA CONFORMANCE ==>            #Asserts that current variables are exactly this.
schemas|tablespaces|roles
 |languages|casts_are(STR_ARR)    #
tables|views|sequences|functions
 |opclasses|types|domains|enums
 |operators_are                   #Can restrict to a SCHEMA, otherwise use SCONF.search_path
 (['SCHEMA', ]STR_ARR)            #Functions are only the name, without arguments.
columns|indexes|triggers
 |rules_are
 (['SCHEMA', ]'TABLE', STR_ARR)   #

SCHEMA EXISTENCE ==>              #Asserts that variable exist.
has[nt]_schema|role|language(STR) #
has[nt]_table|view|sequence
 |foreign_table|type|composite
 |domain|enum|opclass|relation
 (['SCHEMA', ]STR)                #relation is table|view|sequence|ctype
has[nt]_index(['SCHEMA',]
 'TABLE', 'INDEX'[, 'COL'[_ARR]]) #'COL'[_ARR] not with hasnt.
has[nt]_trigger|rule
 (['SCHEMA', ]'TABLE', STR)       #
has[nt]_function(['SCHEMA',]
 'FUNC'[, 'ARGSTYPE'_ARR])        #
has[nt]_cast('TYPE', 'TYPE2'
 [, 'SCHEMA'][, 'FUNC'])          #
has_operator('TYPE'[, 'SCHEMA'],
 'OP', 'TYPE2'[, 'RETURNTYPE'])   #
has_left|rightop(['SCHEMA'],
 'OP', 'TYPE'[, 'RETURNTYPE'])    #
has[nt]_tablespace(STR[, STR2])   #Can use a STR2 as tablespace location (not with hasnt).

COL ATTRIBUTES ==>                #
has[nt]_column
 (['SCHEMA', ]'TABLE', 'COL')     #
col_not|is_null|
has[nt]_default|pk|fk|
unique|check(['SCHEMA',]
 'TABLE', 'COL'_[ARR])            #pk is primary key, fk foreign key constraint.
is_clustered|
index_is_unique|primary
 (['SCHEMA', ]['TABLE', ]'INDEX') #Asserts properties for an index COL
has[nt]_unique|check|pk|fk
 (['SCHEMA', ]'TABLE')            #TABLE has at least those constraints.
col_default_is(['SCHEMA',]
 'TABLE', 'COL', VAL)             #
fk_ok(['SCHEMA', ]'TABLE',
 'COL'[_ARR], 'TABLE2',
 'COL2'[_ARR])                    #Asserts that COL references COL2

TYPES ==>                         #
col_type_is(['SCHEMA', ]'TABLE',
 'COL', ['SCHEMA2', ]'TYPE')      #
index_is_type(['SCHEMA',]
 ['TABLE', ]'INDEX', 'TYPE')      #'TYPE' is 'btree', 'hash', etc.
domain_type_is[nt](['SCHEMA',]
 'DOMAIN', ['SCHEMA2', ]'TYPE')   #'TYPE' is 'btree', 'hash', etc.
enum_has_labels(['SCHEMA', ]
 'ENUM_TYPE', 'VAL'_ARR)          #

FUNCTIONS ==>                     #
can(['SCHEMA', ]'FUNC'_ARR)       #Same as has_function, but without 'ARGSTYPE'_ARR, and with FUNC_ARR
function_lang_is
 (['SCHEMA', ]'FUNC'
 [, 'ARGSTYPE'_ARR], 'LANGUAGE')  #
function_returns
 (['SCHEMA', ]'FUNC'
 [, 'ARGSTYPE'_ARR], 'TYPE')      #
volatility_is
 (['SCHEMA', ]'FUNC'
 [, 'ARGSTYPE'_ARR], STR)         #
function_is_definer|
strict|aggregate(['SCHEMA',]
 'FUNC', ['ARGSTYPE'_ARR])        #
cast_context_is
 ('TYPE', 'TYPE2', STR)           #STR can be 'implicit', 'assignment', 'explicit'
trigger_is
 (['SCHEMA', ]'TABLE', 'TFUNC',
 ['SCHEMA2', ] 'FUNC')            #Asserts that TFUNC executes FUNC
rule_is_instead
 (['SCHEMA', ]'TABLE', 'RULE')    #
rule_is_on(['SCHEMA',]
 'TABLE', 'RULE', 'EVENT')        #

ROLES AND SECURITY ==>
db|schema|tablespace|
 language_owner_is(STR, 'ROLE')   #
table|view|sequence|composite
 |foreing_table|relation|opclass
 |type_owner_is
 (['SCHEMA', ]STR, 'ROLE')        #
index_owner_is(['SCHEMA',]
 'TABLE', 'INDEX', 'ROLE')        #
function_owner_is(['SCHEMA', ]
 'FUNC', 'ARGSTYPE'_ARR, 'ROLE')  #
*_privs_are                       #Same as *_owner_is(...), but asserts PRIVILEGE[_ARR] for ROLE. Differences:
 (..., 'PRIVILEGE'[_ARR])         #  - db -> database
                                  #  - no relation, view, composite, foreign_table, index, opclass, type
                                  #  - there is also:
                                  #     - column*(..., 'TABLE', 'COL', ...) and any_column*(..., 'TABLE')
                                  #     - fdw|server(FDW|'FSERVER', ...)

is[nt]_superuser(ROLE)            #
is_member_of
 ('ROLE', 'ROLE2'[_ARR])          #
language_is_trusted('LANGUAGE')   #

UTILITIES ==>                     #
diag(STR...)                      #Returns STR (separated by newline), in front of a #, to add comments to the output.
skip(STR[, INT])                  #Skip the next INT (def: 1) PGTAP functions, with explanation STR.
                                  #To put in a conditional branch (e.g. case when ...) when a test might provoke the whole unit test
                                  #to throw an exception (language or function not available).
collect_tap(ASSERT_FUNC(...)...)  #Do several PGTAP assertions functions at once.
                                  #Useful when can't be put several COMMAND; but only one, for example in a SQL case when
todo(STR[, INT])                  #Same, but instead of skipping, just declares that tests are expected to fail, because still on the
                                  #todo list.
todo_start|end(STR)               #Do todo() for all tests between start and end.
in_todo()                         #Returns true if in a todo_start|end block.
os_name()                         #e.g. 'linux'

OWN ASSERTION_FUNC ==>            #Just create a plpgsql function that returns text, with a last optional text argument, and which
                                  #returns ok() if test passes, or returns error message if not.

datafiller.py [FILE]              #Script printing commands filling randomly some TABLE...
                                  #FILE (def: stdin) is a list of DDL commands creating the TABLE.
                                  #Hints on how to fill are provided with --comments:
                                  #  - syntax:
                                  #     -- df [MACRO]: VAR[=VAL]
                                  #       - with MACRO, can do elsewhere use=DIRECTIVE to repeat all the VAR[=VAL]...
                                  #          - some predefined MACRO:
                                  #             words: word=/etc/dictionaies-common/words
                                  #       - VAL can use '' for STR and TIMESTAMP
                                  #     - can also use -- df T=TABLE A="COL": ... to target a TABLE or "COL" on a separate line
                                  #       after it. TABLE cannot use skip=FLOAT.
                                  #     - to specify a VAR, I write $VAR, but it should be written VAR
                                  #  - supported VAR:
                                  #     - all TABLE (put comment on a line by itself)
                                  #        - size, offset, mangle, null, seed: see below
                                  #     - TABLE (put comment after the opening parenthesis of creation):
                                  #        - size=INT: number of tuples to fill.
                                  #          Can only be on TABLE, not COL (except for gen=serand)
                                  #        - mult=INT: multiply $size for this TABLE
                                  #          mult (def: 1) should be done on each TABLE (relative size with each other)
                                  #          size (def: 100) only once for all TABLE (to scale it)
                                  #        - skip=FLOAT: divide $size for this TABLE.
                                  #          As opposed to mult, actually produce the rows, but randomly don't output them
                                  #        - nogen, null=FLOAT: same as below
                                  #     - COL (put comment after it):
                                  #        - all:
                                  #           - type=TYPE: generate another TYPE, then casted to the actual type
                                  #           - nogen: no random data (use only default values)
                                  #           - null=FLOAT: percentage of nulls
                                  #           - seed=INT: set random seed (def: use OS (usually depends on current time))
                                  #        - BOOL:
                                  #           - rate=FLOAT: percentage of true (def: 0.5)
                                  #        - INT (integer, not int)|DATE|TIMESTAMP|INTERVAL|INET|CIDR|MAC:
                                  #           - gen=STR: distribution, among:
                                  #              - serial: counter, increments $step (def: 1, must not be divider of $size) from
                                  #                $shift (def:0), then modulo $size, then adds $offset (def: 1)
                                  #                If $mangle, choose random $shift and $step
                                  #              - uniform: uniform distribution, from $offset to $offset + $size - 1
                                  #              - serand: serial up to $size1, then uniform to $size2 - $size1 ($size1 and $size2
                                  #                are the COL-level, and TABLE-level $size)
                                  #              - for other distributions: just use type=float, then use float distributions
                                  #           - offset, shift, step, size, mangle: see above
                                  #        - FLOAT:
                                  #           - gen=WORD: distribution, among:
                                  #              - uniform, gauss|norm, log (lognormal), beta, gamma, weibull, vonmises: use $alpha and
                                  #                $beta
                                  #              - exp, pareto: use $alpha
                                  #           - alpha|beta: see above
                                  #        - STR, followed by:
                                  #           - nothing: prefix followed by repetition of number, separated by _
                                  #              - prefix=STR (def: "COL")
                                  #              - length|lenvar=NUM: average length and diff from average of STR (def: 12 and 3)
                                  #           - chars=STR: choose random characters among a dictionary built with random words using
                                  #             characters in STR
                                  #              - cgen=MACRO: specifies INT parameters (to be used like use=) to specify how selection
                                  #                is done
                                  #              - length and lenvar: see above
                                  #           - text: can use INT parameters, choose from list of words
                                  #              - word=FILE|:STR,...: list of words, of 'size' words
                                  #              - length and lenvar: see above
                                  #           - word=FILE|:STR,...: same as above, but length to 1 and lenvar to 0. Can support unique.
                                  #        - DATE|TIMESTAMP|INTERVAL:
                                  #           - start|end=...
                                  #           - prec=NUM: in days for DATE, in seconds for TIMESTAMP
                                  #        - TIMESTAMP:
                                  #           - tz=STR
                                  #        - INTERVAL:
                                  #           - unit=s|m|h|d|mon|y (def: s)
                                  #        - BYTEA:
                                  #           - length and lenvar: see above
                                  #        - INET|CIDR:
                                  #           - network=STR
                                  #        - MAC
                                  #COL can't be unique for FLOAT, STR chars|text and BYTEA.
                                  #Uniqueness is tried 10 times (can be changed with datafiller.py --tries=NUM)
--[no-]filter                     #Output also FILE (commands creating the TABLE...), before commands filling the TABLE...
--drop                            #Output also commands dropping the TABLE...
--truncate                        #Sale for truncating
--size|offset|seed INT
--null FLOAT
--mangle                          #Sets VAR
-T                                #Put in a single transaction (normal isolation level)

                                  ┌─────────────┐
                                  │   PGBENCH   │
                                  └─────────────┘

pgbench                           #Does a benchmark, to compare machines or server conf speed.
                                  #Must first do a pgbench -i to initialize it (creates four pgbench_* tables), with following options
                                  #while initializing:
-F NUM                            #Percentage of not-null in pgbench_* tables (def: 100)
-s NUM                            #Multiply default number or rows in pgbench_* tables. Should be at least >= -c NUM
--[index-]tablespace=TABLESPACE   #Use a custom TABLESPACE for tables or indexes (to do if used in production)
--unlogged-tables                 #Create pgbench_* as unlogged tables
                                  #While not initializing:
                                  #  - tps is transactions per seconds.
                                  #  - has following options:
-h -p -U                          #Connection options (see psql)
-c NUM                            #Number of concurrent connections. Should be close to average in real production.
-t NUM                            #Number of transactions per client. Higher gives more precision.
                                  #Should be high enough to run few minutes
-j NUM                            #Number of threads
-n -f FILE                        #Execute SQL FILE, instead of default one (simple update, select and insert statements)
                                  #Can include commands:
                                  #  - \setrandom "INT" MIN MAX
                                  #  - \setshell "INT" COMMAND ARGS
-S                                #Perform only select statements
-r                                #Show execution time for clients, per statements.

                                  ┌────────────┐
                                  │   PGTUNE   │
                                  └────────────┘

pgtune -i FILE                    #Checks postgresql.conf FILE, and prints an optimized version (mostly for performance CONF)
                                  #Can do -o FILE2, but should pipe it to diff - FILE, to see differences.
-M NUM                            #Total memory in bytes (def: guess it)
-c NUM                            #Number of connections expected (change PCONF.max_connections and SCONF.work_mem)
-T WORD                           #Type of application, among DW (OLAP), OLTP, Web or Desktop. Def is Mixed (-> unspecified)
                                  #Desktop assumes lower cache, mem and connections, DW moderate, and Web and OLTP very high.

                                  ┌────────┐
                                  │   PG   │
                                  └────────┘

https://github.com/porsager/postgres ???

VERSION ==>                       #3.6.2

PG                                #Installation requires libpq

new PG.Client([STR|OBJ],          #Connect to the database specified by STR|OBJ, then fire FUNC.
 FUNC(ERROR, CLIENT,FUNC2(ERROR)))#FUNC2 must be fired when all operations are done to close connection.
                                  #STR is "[connectionname://][user[:password]@][host[:port]][/database]"
                                  #(all defaults if no first arg) or a IPC socket folder path.
                                  #Connectionname can be anything, it just differentiate sessions. OBJ has members :
                                  #  - user (def: process.env.USER)
                                  #  - database (def: process.env.USER)
                                  #  - password (def: null)
                                  #  - port (def: 5432)
                                  #  - host (def: null): if not URL, use DIR/.s.PGSQL.PORT
                                  #  - ssl (def: false)
                                  #Defaults are in PG.defaults.VAR
                                  #Other defaults:
                                  #  - PG.defaults.parseInt8:
                                  #     - PSQL bigint (such as result of count()) is too big for JavaScript INT.
                                  #     - If false (def), bigint -> STR. If true, bigint -> INT
                                  #Returns CLIENT, but should only be used for events. Use CLIENT in callback for connect|end()
CLIENT.connect
([FUNC(ERROR, CLIENT)])           #
CLIENT.end()                      #

                                  ┌─────────────┐
                                  │   QUERIES   │
                                  └─────────────┘

CLIENT.query(STR[, VAL_ARR]       #Returns a QUERY from PostgreSQL command STR.
 [, FUNC(ERROR, OBJ)])            #If FUNC, also execute it and event handlers of QUERY cannot be used (so QUERY is useless then).
                                  #OBJ is same as in QUERY end event handler.
                                  #If VAL_ARR, each "$1", "$2", etc. in STR will be replaced by those VAL, providing it does not
                                  #point to a TABLE, a COL or a SCHEMA. It is slower but it prevents SQL injections (VAL_ARR are
                                  #properly escaped instead of using risky STR concatenation).
CLIENT.query(OBJ[, FUNC])         #Same but OBJ can have members :
                                  #  - text: same as STR
                                  #  - values: same as VAL_ARR
                                  #  - name STR3:
                                  #     - make it PREP: but using PSQL Extended Protocol, so same effect (skip parsing phase when
                                  #       calling came query with same name (will use same text|values)), but not actual PREP
                                  #     - parsing is only done when values VAL_ARR is used, so only useful then

QUERY.on("row", FUNC(OBJ))        #Execute QUERY and fire event handler for each row OBJ: {VAR: VAL}...
QUERY.on("end", FUNC(OBJ))        #Execute QUERY and fire event handler for all rows. OBJ has members :
                                  #  - command STR : SQL command
                                  #  - rowCount UINT
                                  #  - oid DOUBLE
                                  #  - rows OBJ_ARR: {VAR: VAL}...
                                  #  - fields OBJ_ARR:
                                  #     - name STR
                                  #     - format 'TYPE'
                                  #     - tableID DOUBLE
                                  #     - columnID DOUBLE
                                  #     - dataTypeID DOUBLE
                                  #     - dataTypeSize UINT
                                  #     - dataTypeModifier TYPEMOD_UINT
QUERY.on("error", FUNC(ERROR))    #

CLIENT.query
 (new PG-QUERY-STREAM(STR))       #Like CLIENT.query(STR) but returns as ISTREAM.
CLIENT.query
 (new PG-CURSOR(STR)[, VAL_ARR])  #Like CLIENT.query(STR[, VAL_ARR]) but returns a CURSOR (version 0.2.0).
CURSOR.read
 (UINT, FUNC(ERROR, OBJ_ARR))     #OBJ_ARR is {VAR: VAL}... or [] if no more rows
CLIENT.copyFrom|To(STR)           #COPY...FROM|TO statement must use this instead of CLIENT.query().
                                  #Returns a I|OSTREAM (must execute I|OSTREAM.end()).
                                  #Can use stdin (not stdout) in STR if writing|reading from I|OSTREAM
CLIENT.pause|resumeDrain()        #Stops|resumes emission of drain events (useful when async operations need to complete first)

                                  ┌──────────────────────┐
                                  │   OTHER OPERATIONS   │
                                  └──────────────────────┘


CLIENT.on("drain", FUNC())        #Fired each time all queries have been executed
CLIENT.on("error", FUNC(ERROR))   #
CLIENT.on                         #Fired with listen/notify SQL statements
 ("notification", FUNC(OBJ))      #OBJ:
                                  #  - name "notification"
                                  #  - channel STR
                                  #  - payload STR
                                  #  - length NUM
                                  #  - processId NUM
CLIENT.on("notice", FUNC(STR))    #Fired with warning messages (otherwise printer in stdout)

                                  ┌─────────────┐
                                  │   POOLING   │
                                  └─────────────┘

PG.pools.getOrCreate([OBJ])       #Returns POOL (from GENERIC-POOL) of CLIENT that has extra method:
                                  #  - connect(FUNC(ERROR, CLIENT, FUNC2(ERROR2))): acquire a CLIENT and fires FUNC()
                                  #Created with params (either OBJ or PG.defaults):
                                  #  - name: OBJ stringified
                                  #  - max <- poolSize
                                  #  - idleTimeoutMillis <- poolIdleTimeout
                                  #  - reapIntervalMillis <- reapIntervalMillis
                                  #  - log <- poolLog
                                  #Other OBJ passed to new PG.CLIENT(OBJ)
                                  #If no POOL used, would use one new connection for each query.
PG.pools.all                      #POOL_OBJ

PG.connect(OBJ, FUNC)             #Like new PG.CLIENT(OBJ, FUNC).connect() but uses PG.pools.getOrCreate(OBJ)
PG.on
 ("error", FUNC(ERROR, CLIENT))   #
PG.end()                          #Close all CLIENT, even if currently querying.
