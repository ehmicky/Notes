
           
   SORTING  
           




ADAPTIVE SORTS ==>                #Sorting algorithm that is adaptive, performing better when input is already partially sorted
                                  #("presorted")

STABLE SORTS ==>                  #Whether when two values are equal (according to their sort key), their order in the
                                  #sorted array remains the same as in the initial array.
                                  #Goal:
                                  #  - if initial order mattered
                                  #  - including multi-stage sorting, i.e. previous stage's order matters

EXTERNAL SORTS ==>                #Sorting algorithms with low amount of memory, i.e. incremental.
                                  #Meant when input is bigger than machine's memory.
                                  #Often used: merge sorts, quicksort

COMPARISON SORTS ==>              #Sorting algorithms using a FUNC(VAL, VAL2)-> <= or >=
                                  #  - often use -1, 0 and 1
                                  #Average time complexity at least O(n log n)

DISTRIBUTION SORTS ==>            #Sorting algorithms using the value distribution instead of a comparison FUNC.
                                  #Average time complexity at least O(n)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:         BUCKET SORTS          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


BUCKET SORT ==>                   #Also called "bin sort"
                                  #Type of distribution sort
                                  #Steps:
                                  #  - "partition":
                                  #     - create k buckets
                                  #     - time complexity O(k)
                                  #     - space complexity O(k)
                                  #  - "scatter|disperse":
                                  #     - assign each value to a bucket|bin|category
                                  #     - each value must have a key used to find bucket in O(1)
                                  #        - e.g. first bucket for values < 100, second bucket for values 100 < x < 200, etc.
                                  #     - time complexity O(n)
                                  #     - space complexity O(n)
                                  #  - sort each bucket's values
                                  #     - using any sort algorithm
                                  #     - can also apply other sort algorithm on all buckets at once
                                  #        - if it is more performant for that algorithm
                                  #        - e.g. insertion sort which is fast when values do not move much
                                  #  - "gather|collect": concatenate all bucket's values
                                  #     - time complexity O(k)
                                  #Most time complexity is from sorting each bucket's values
                                  #  - i.e. better if buckets have few values
                                  #  - i.e. either:
                                  #     - evenly distributed
                                  #     - choosing different bucket sizes to match the distribution of the values,
                                  #       if the distribution is known
                                  #Pros:
                                  #  - best time complexity: O(n + k)
                                  #  - average time complexity: O(n + k + n*n/k)
                                  #  - stable
                                  #  - parallelizable
                                  #  - online, providing know distribution of values in advance
                                  #Cons:
                                  #  - worst time complexity: O(n**2 + k)
                                  #     - if not evenly distributed, e.g. all values in single bucket
                                  #     - i.e. requires being able to distribute evenly with a low amount of buckets
                                  #        - or matching the distribution of the values
                                  #  - not in-place, space complexity: O(n + k)
                                  #  - not adaptive

GENERIC BUCKET SORT ==>           #Bucket sort with:
                                  #  - even buckets
                                  #  - ranging from min|max of the keys
                                  #Example:
                                  #  - [52, 50, 70, 20, 10]
                                  #    -> [[], [], [], [], [], [], [], [], [], []] (partition)
                                  #    -> [[], [10], [20], [], [], [52, 50], [], [70], [], []] (scatter)
                                  #    -> [[], [10], [20], [], [], [50, 52], [], [70], [], []] (second sort)
                                  #    -> [10, 20, 50, 52, 70] (gather)

PIGEONHOLE SORT ==>               #Bucket sort where values inside each bucket are sort-equivalent.
                                  #Done by creating as many buckets as possible
                                  #  - e.g. when sorting integers, each bucket is exactly one integer
                                  #Pros|cons like bucket sort except:
                                  #  - pro:
                                  #     - average|worst time complexity O(n + k): because no second sort step
                                  #  - cons:
                                  #     - high space complexity due to empty buckets
                                  #     - higher time complexity when partioning and gathering, since number of buckets higher
                                  #     - i.e. best when number of buckets is close to number of values
                                  #Example:
                                  #   - [c, f, b, b, e]
                                  #  -> [[], [], [], [], [], []] (partition)
                                  #  -> [[], [b, b], [c], [], [e], [f]] (scatter)
                                  #  -> [b, b, c, e, f] (gather)

COUNTING SORT ==>                 #Also called "histogram sort"
                                  #Same as pigeonhole sort except each bucket contains only the number of occurrences,
                                  #not the values themselves.
                                  #  - i.e. the final array is produced by cumulating each bucket's offset,
                                  #    not by gathering the values from each bucket
                                  #Similar pros|cons as pigeonhole sort but:
                                  #  - pros:
                                  #     - low space complexity: by using a count of values instead of repeated values
                                  #     - faster time complexity: does not require moving values
                                  #  - cons:
                                  #     - pros only apply when number of buckets is much lower than number of values
                                  #Example:
                                  #   - [c, f, b, b, e]
                                  #                                         a  b    c  d  e  f
                                  #                                     -> [0, 0,   0, 0, 0, 0] (partition)
                                  #                                     -> [0, 2,   1, 0, 1, 1] (sums)
                                  #                                     -> [0, 0-1, 2, 3, 3, 4] (offsets)
                                  #  -> [2, 4, 0-1, 0-1, 3] (indices)
                                  #  -> [2, 4, 0, 1, 3]
                                  #  -> [b, b, c, e, f]

PROXMAP SORT ==>                  #Variant of bucket sort
                                  #When creating buckets, their number and size depend on values:
                                  #  - a FUNC(value)->INT reduces each value to an approximate overall position ("map key")
                                  #     - e.g. Math.floor(value % modulo)
                                  #     - 1 bucket === 1 map key
                                  #     - must be choosen:
                                  #        - both not enough buckets, and too many empty ones, lead to higher time complexity
                                  #        - i.e. must try to approach 1 bucket === 1 value
                                  #  - create a cumulative histogram ("proxmap") like counting sort does
                                  #  - time complexity: O(n)
                                  #When scattering values, and bucket > 1 value, use insertion sort.
                                  #Similar pros|cons as bucket sort but:
                                  #  - pros:
                                  #     - higher chance to distribute evenly
                                  #     - more space efficient, by lowering chances of empty buckets
                                  #     - allows proxmap search
                                  #  - cons:
                                  #     - additional cost of partitioning
                                  #     - finding the right map key FUNC depends on knowing the values distribution
                                  #Example:
                                  #   - [12, 6, 56, 24, 22, 58]                                                                0 10 20 30 40 50
                                  #                                                  -> [10, 0, 50, 20, 20, 50] (map)      -> [1, 1, 2, 0, 0, 2] (hit counts)
                                  #                                                                                        -> [0, 1, 2, 4, 4, 4] (proxmap)
                                  #                                                  -> [1,  0,  4,  2,  2 , 4] (location)
                                  #  -> [6, 12, [24, 22], [56, 58]] (scatter)
                                  #  -> [6, 12, [22, 24], [56, 58]] (insertion sort)
                                  #  -> [6, 12, 22, 24, 56, 58] (gather)

PROXMAP SEARCH ==>                #Fast searching based on proxmap sort:
                                  #  - apply the map key FUNC on a searched value
                                  #  - find start index using proxmap
                                  #  - if bucket had 1 value, correct index. Otherwise, do a linear|binary search forward
                                  #Time complexity:
                                  #  - best|average: O(1)
                                  #  - worst: O(n), if not evenly distributed, e.g. all values in single bucket
                                  #Example, re-using above example:
                                  #  - search 24
                                  #  - map key: 2
                                  #  - location: 2
                                  #  - search from index 2: 22 (not found), then 24 (found)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          RADIX SORTS          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


RADIX SORT ==>                    #Also called "digital sort"
                                  #Type of distribution sort
                                  #Sort symbol by symbol using another, when values can be broken down into sequences of w symbol
                                  #  - where each symbol order is more important than next one, i.e. lexicographic order
                                  #  - e.g. numbers|strings
                                  #Missing symbols must be filled with padding symbols
                                  #  - e.g. '0' for numbers or space for strings
                                  #  - with lower value than any other symbol
                                  #  - either on the left|highest or right|lowest symbol
                                  #Can use any other sorting algorithm for the symbols.
                                  #  - often used: counting sort, since it works well with digits|characters
                                  #Pros:
                                  #  - best|average time complexity: O(n * w)
                                  #  - space complexity: O(n + w)
                                  #     - low thanks to using a subset of the whole value in each step
                                  #     - i.e. works with large range of values
                                  #  - can be stable
                                  #Cons:
                                  #  - worst time complexity: O(n**2 * w)
                                  #     - when w too low, i.e. does not break down into enough symbols
                                  #     - i.e. best when values are sequences of symbols
                                  #  - not in-place
                                  #  - not online
                                  #  - not adaptive

LSD RADIX SORT ==>                #Also called "bottom-up radix sort"
                                  #Radix sort going from lowest to highest symbol.
                                  #Each new symbol:
                                  #  - must iterate over all values
                                  #  - must be stable, to keep sorting of next symbols
                                  #Padding usually on the left, so it can happen symbol by symbol
                                  #Instead of padding, can also group by length, then sort each group
                                  #Pros|cons like radix sort, with also:
                                  #  - cons:
                                  #     - not parallelizable
                                  #     - due to padding, best for numbers
                                  #Example:
                                  #   - 7 71 12 1
                                  #  -> [71 1] [12] [7] (last digit)
                                  #  -> 71 1 12 7
                                  #  -> [01 07] [12] [71] (second last digit)

MSD RADIX SORT ==>                #Also called "top-down radix sort" or "postman's sort"
                                  #Radix sort going from highest to lowest symbol.
                                  #Each new symbol:
                                  #  - must iterate over values grouped by previous symbols
                                  #  - does not need to be stable
                                  #Padding usually on the right, so it can happen symbol by symbol
                                  #Pros|cons like radix sort, with also:
                                  #  - pros:
                                  #     - parallelizable
                                  #  - cons:
                                  #     - due to padding, best for strings
                                  #Example:
                                  #   - g ga ab abc a
                                  #  -> [ab abc a] [g ga] (first character)
                                  #  -> [[a.] [ab abc]] [[g.] [ga]] (second character)
                                  #  -> [[[a..]] [[ab.] [abc]]] [[[g..]] [[ga.]]] (third character)
                                  #  -> a ab abc g ga

AMERICAN FLAG SORT ==>            #Also called "in-place MSD radix sort"
                                  #Variant of MSD that is in-place:
                                  #  - compute count of each value for highest symbol
                                  #  - compute indices of group for each value, using each count as group size
                                  #  - swap values to put them inside right group
                                  #  - recurse on each group with next symbol
                                  #Pros|cons like MSD radix sort, with also:
                                  #  - pros:
                                  #     - in-place
                                  #     - more efficient when bucket size is power of 2, because can implement with bitwise logic
                                  #  - cons:
                                  #     - not stable
                                  #Example:
                                  #   - g ga ab abc a
                                  #  -> a:3 g:2 (first character)
                                  #  -> [ab abc a] [g ga] (in-place swap)
                                  #  -> recurse


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:        INSERTION SORTS        :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


INSERTION SORT ==>                #Type of comparison sort
                                  #Insert each value, one at a time, to its sorted position in output array
                                  #  - i.e. to its first position where next value is bigger
                                  #Pros:
                                  #  - optionally in-place:
                                  #     - by using growing sub-array at beginning of array
                                  #     - as opposed to a separate output array
                                  #     - space complexity O(1)
                                  #  - online
                                  #  - adaptive:
                                  #     - best time complexity O(kn) when each element is ~k places away from sorted place
                                  #     - i.e. O(n) if already sorted
                                  #  - stable
                                  #  - fast when n is low
                                  #     - because high locality of reference
                                  #  - simple to implement
                                  #Cons:
                                  #  - average|worst time complexity O(n**2): due to having to move half of other values at each newly inserted value
                                  #  - not parallelizable
                                  #Example:
                                  #   - 4 2 1 3 5
                                  #  -> 2 4 1 3 5
                                  #  -> 1 2 4 3 5
                                  #  -> 1 2 3 4 5
                                  #  -> 1 2 3 4 5

SHELL SORT ==>                    #Use GAPs:
                                  #  - GAP number from 1 to n/2
                                  #  - divide input into GAP subarrays, each containing values with same position % GAP
                                  #     - e.g. if GAP is 3, [d, y, q, a, z] -> [d, a], [y, z], [q]
                                  #  - which series of GAP is chosen is implementation-specific, but must be decreasing and end with 1
                                  #     - often used: n/2, n/4, ..., 1
                                  #For each GAP:
                                  #  - for each subarray:
                                  #     - apply insertion sort


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:        EXCHANGE SORTS         :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


BUBBLE SORT ==>                   #Also called "sinking sort"
                                  #Type of comparison sort
                                  #How:
                                  #  - for each value, swap with next value if next value is smaller
                                  #  - repeat until sorted
                                  #Similar pros|cons as insertion sorts except:
                                  #  - pros:
                                  #     - does not require random access
                                  #  - cons:
                                  #     - usually slower, due to each value shifting to its sorted position with several swaps


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:        SELECTION SORTS        :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


SELECTION SORT ==>                #Type of comparison sort.
                                  #Find then append minimum remaining value, one at a time.
                                  #Similar pros|cons as insertion sorts except:
                                  #  - pros:
                                  #     - faster when writes|swaps are expensive compared to reads|comparisons,
                                  #       because do fewer writes|swaps and more reads|comparisons
                                  #  - cons:
                                  #     - best time complexity O(n**2): not adaptive
                                  #     - average|worst time complexity O(n**2): usually slower
                                  #     - not stable
                                  #     - not online
                                  #Example:
                                  #   - 4 2 1 3 5
                                  #  -> 1 4 2 3 5
                                  #  -> 1 2 4 3 5
                                  #  -> 1 2 3 4 5
                                  #  -> 1 2 3 4 5


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           HEAPSORT            :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


HEAPSORT ==>                      #Like selection sort but build a heap first to retrieve minimum values.
                                  #  - pro: O(log n) instead of O(n) to retrieve minimum
                                  #  - con: additional O(n log n) to build heap
                                  #Can be done in-place:
                                  #  - building a heap can be done in-place
                                  #  - when extracting each root (i.e. minimum value) can:
                                  #     - place it in a growing sorted array at end
                                  #     - swap with the last value, which becomes new root and is moved down the heap until satisfying the heap property
                                  #Pros:
                                  #  - general purpose, i.e. few constraint on values
                                  #  - best|average time complexity: O(n log n)
                                  #  - worst time complexity O(n log n)
                                  #     - best and worst performance close to each other
                                  #  - in-place, space complexity O(1)
                                  #Cons:
                                  #  - not online
                                  #  - not adaptive
                                  #  - not stable
                                  #  - not parallelizable

TOURNAMENT SORT ==>               #Like a heapsort but incremental, with heap size < values size:
                                  #  - heap is built bottom-up
                                  #  - incrementally:
                                  #     - top|min value is picked
                                  #     - a new bottom value is added
                                  #  - if a new bottom value < last min value, it is frozen:
                                  #     - still kept as a bottom leaf
                                  #     - but cannot move nor be picked as min value
                                  #  - when either:
                                  #     - all bottom values are frozen
                                  #     - no more new values
                                  #  - then:
                                  #     - sort frozen values using the heap
                                  #     - but output to a separate array
                                  #  - repeat everything with a new heap and a new output array
                                  #  - this finally results in multiple sorted arrays to combine with a k-way natural merge sort
                                  #     - can be done incrementally
                                  #Similar pros|cons as heapsort but:
                                  #  - pros:
                                  #     - online
                                  #     - space complexity O(m) with m being heap size, as opposed to O(n)
                                  #       (heapsort when not in-place)
                                  #  - cons:
                                  #     - not in-place
                                  #     - slower average time complexity due to additional logic


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           QUICKSORT           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


QUICKSORT ==>                     #Also called "partition-exchange sort"
                                  #Type of comparison sort
                                  #How:
                                  #  - choose one of the values as "pivot" ("selection")
                                  #  - move values so that all values < pivot come before other ones ("partition")
                                  #  - recurse over each group
                                  #     - excluding the pivot value, as an optimization, since known to be now sorted
                                  #Pros:
                                  #  - general purpose, i.e. few constraint on values
                                  #  - good best|average time complexity: O(n log n)
                                  #     - faster than heapsort or merge sort
                                  #     - O(log n) depth levels
                                  #        - optimally low when pivot is close to median value, resulting in equal splits
                                  #     - and O(n) at each depth level
                                  #  - in-place
                                  #  - parallelizable, but not as well as other sorting algorithms due to:
                                  #     - high recursion depth level
                                  #     - harder to parallelize when in-place
                                  #  - adaptive
                                  #Cons:
                                  #  - bad worst time complexity: O(n**2)
                                  #     - when pivot is always min|max value
                                  #     - i.e. effort on choosing right pivot selection
                                  #  - space complexity: O(log n), since each depth level keeps track of some information, e.g. of pivot
                                  #  - slower on small amount of values
                                  #  - not stable
                                  #  - not online

LOMUTO QUICKSORT ==>              #Quicksort partitioning by iterating over each value:
                                  #  - if <= pivot, move it to beginning of array
                                  #  - do each move by swapping values, then increasing index of where next swap will occur
                                  #Usually select array's last value as pivot.
                                  #Cons:
                                  #  - time complexity O(n**2) for either:
                                  #     - already sorted input
                                  #     - only equal values

HOARE QUICKSORT ==>               #Quicksort partitioning by iterating over values on both sides:
                                  #  - find first value at start >= pivot
                                  #  - find first value at end <= pivot
                                  #  - swap those values
                                  #  - repeat
                                  #Usually select array's middle value as pivot.
                                  #Pros:
                                  #  - more efficient than Lomuto quicksort:
                                  #     - swapping puts two values in right position instead of one
                                  #     - time complexity O(n log n) for either already sorted input, or only equal values

SEDGEWICK QUICKSORT ==>           #Quicksort selecting the median of the first, middle and last element as pivot.
                                  #I.e. good heuristics without knowing if the array is sorted, reversed, or neither.

THREE-WAY PARTITION QUICKSORT ==> #Quicksort not recursing on values equal to the pivot.
                                  #I.e. split values into 3 groups instead of 2: < pivot, == pivot, > pivot
                                  #Pros:
                                  #  - best time complexity O(n) when all values are equal
                                  #Cons:
                                  #  - slower when values are rarely equal


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          MERGE SORTS          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


MERGE SORT ==>                    #Type of comparison sort
                                  #Divide array into many groups of 1 value ("initial grouping") then:
                                  #  - merge each pair of groups into a single sorted group, by comparing their values in order ("merge step")
                                  #  - repeat with double group size
                                  #When merging each pair of groups, must create a temporary array with the result:
                                  #  - cannot do in-place
                                  #  - must be same size as array
                                  #  - optimization: can re-use same array for each depth level
                                  #Pros:
                                  #  - general purpose, i.e. few constraint on values
                                  #  - best|average|worst time complexity: O(n log n)
                                  #     - best:
                                  #        - when for each pair of group, all values in one group are > the other
                                  #           - because only needs to iterate through the values of one of the groups
                                  #        - i.e. when already sorted or reverse sorted
                                  #        - i.e. adaptive
                                  #     - average
                                  #        - when uniformly random, ~74% of worst time complexity
                                  #     - worst:
                                  #        - opposite of best case, i.e. when values alternate
                                  #           - specific sequence is known and called the "sorting numbers"
                                  #        - twice slower
                                  #  - very parallelizable
                                  #  - stable
                                  #  - does not require random access
                                  #Cons:
                                  #  - space complexity O(n): due to temporary array
                                  #  - not in-place

TOP-DOWN MERGE SORT ==>           #Merge sort where initial grouping:
                                  #  - splits whole array into 2 groups
                                  #  - which are recursively split until creating groups of 1 value

BOTTOM-UP MERGE SORT ==>          #Merge sort where initial grouping:
                                  #  - directly divides whole array into many groups of 1 value
                                  #Similar time|space complexity as top-down merge sort

NATURAL MERGE SORT ==>            #Merge sort where initial grouping:
                                  #  - Uses presorted parts of the array ("runs")
                                  #  - By going through whole array and group sequences that monotonically increase|decrease
                                  #Pros:
                                  #  - best time complexity O(n): if whole array already sorted
                                  #  - slower average time complexity: due to looking for runs, i.e. not good if array not presorted

ONLINE MERGE SORT ==>             #Can be online:
                                  #  - sort new values using any sorting algorithm
                                  #  - then do natural merge sort

LINKED LIST MERGE SORT ==>        #Merge sort that stores each value into linked lists instead of arrays.
                                  #Pros:
                                  #  - space complexity O(1): values are moved between linked lists instead of being copied
                                  #Cons:
                                  #  - slower time complexity: due to extra cost of linked lists logic

PING PONG MERGE SORT ==>          #Merge sort that, at each new depth level, swaps which array is considered the temporary and original one.
                                  #Pros:
                                  #  - faster time complexity: avoids moving values back from the temporary to the original array

K-WAY MERGE SORT ==>              #Merge sort where merge step merges multiple groups.
                                  #As opposed to merging pairs of groups ("2-way|binary merge sort"):
                                  #  - pro: can optimize performance when groups have different sizes
                                  #  - con: slower when groups have equal sizes

ITERATIVE K-WAY MERGE SORT ==>    #K-way merge sort which merges multiple groups together 2 by 2.
                                  #Optimization: merge smaller arrays together first.

DIRECT K-WAY MERGE SORT ==>       #K-way merge sort which merges multiple groups together all at once.

HEAP K-WAY MERGE SORT ==>         #Direct k-way merge sort that:
                                  #  - uses a heap with the min element of each group
                                  #  - to find the min element of all groups
                                  #Heap can be done in-place

NEAREST SMALLER VALUES MERGE SORT #Merge sort where merge step uses "all nearest smaller values" algorithm (see its doc)
 ==>                              #  - concatenate first group with reversed second group
                                  #  - calculate all nearest smaller values, in both directions
                                  #  - for each value, bigger neighbor should be previous value in merged array


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           BEAD SORT           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


BEAD SORT ==>                     #Also called "gravity sort"
                                  #Neither comparison|distribution sort.
                                  #Keys must be positive integers
                                  #Similar to using an abacus and mapping beads fall
                                  #Steps:
                                  #  - put numbers in a matrix: each number n is a row, filled with n 1s
                                  #  - remove all vertical gaps (i.e. make 1s "fall")
                                  #  - each row will represent a sorted number
                                  #Example:
                                  #  - [2, 4, 1, 3, 3]
                                  #    -> [1, 1, 0, 0] (2)
                                  #       [1, 1, 1, 1] (4)
                                  #       [1, 0, 0, 0] (1)
                                  #       [1, 1, 1, 0] (3)
                                  #       [1, 1, 1, 0] (3)
                                  #    -> [1, 0, 0, 0] (1)
                                  #       [1, 1, 0, 0] (2)
                                  #       [1, 1, 1, 0] (3)
                                  #       [1, 1, 1, 0] (3)
                                  #       [1, 1, 1, 1] (4)
                                  #Another way to look at it:
                                  #  - create array with length === max number
                                  #  - for each number n, increment n first items of array
                                  #  - for each array item, replace by difference with next item
                                  #  - for each array item m, replace by m times its 1-based index
                                  #Example:
                                  #  - [2, 4, 1, 3, 3]
                                  #    -> [0, 0, 0, 0]
                                  #    -> [1, 1, 0, 0] (2)
                                  #    -> [2, 2, 1, 1] (4)
                                  #    -> [3, 2, 1, 1] (1)
                                  #    -> [4, 3, 2, 1] (3)
                                  #    -> [5, 4, 3, 1] (3)
                                  #    -> [1, 1, 2, 1] (difference)
                                  #    -> [1, 2, 3, 3, 4] (indexes)
                                  #Pros:
                                  #  - best time complexity: O(n)
                                  #Cons:
                                  #  - only works with positive integers
                                  #     - i.e. stable
                                  #  - not in-place, high space complexity: O(n**2)
                                  #  - average|worst time complexity: O(S), with S being sum of all keys
                                  #  - best time complexity usually requires specialized hardware
                                  #  - not parallelizable
                                  #  - not online
                                  #  - not adaptive


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:            HYBRID             :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


TILED MERGE SORT ==>              #Insertion sort on each group of m values, then natural merge sort


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:              BAD              :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


BOGOSORT ==>                      #Also called "permutation sort", "stupid sort", "slowsort", "shotgun sort", "monkey sort"
                                  #Randomly shuffles whole array until shuffle output happens to be also sorted
                                  #  - or alternatively, try every permutation
                                  #Only meant as an example of a bad sorting algorithm
                                  #Pros:
                                  #  - in-place, space complexity: O(1)
                                  #Cons:
                                  #  - time complexity:
                                  #     - best: O(n): if already sorted
                                  #     - average: O(n * n!)
                                  #     - worst: O(n * n!) (if try every permutation) or infinite (otherwise)
                                  #  - not stable
                                  #  - not parallelizable
                                  #  - not online
                                  #  - not adaptive
