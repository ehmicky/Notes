
           
   SORTING  
           




ADAPTIVE SORTS ==>                #Sorting algorithm that is adaptive, performing better when input is already partially sorted

STABLE SORTS ==>                  #Whether when two values are equal (according to their sort key), their order in the
                                  #sorted array remains the same as in the initial array.
                                  #Goal:
                                  #  - if initial order mattered
                                  #  - including multi-stage sorting, i.e. previous stage's order matters

EXTERNAL SORTS ==>                #Sorting algorithms with low amount of memory, i.e. incremental.
                                  #Meant when input is bigger than machine's memory.
                                  #Often used: merge sorts, quicksort

COMPARISON SORTS ==>              #Sorting algorithms using a FUNC(VAL, VAL2)-> <= or >=
                                  #  - often use -1, 0 and 1
                                  #Average time complexity at least O(n log n)

DISTRIBUTION SORTS ==>            #Main type of sorts that are not comparison-based.
                                  #Average time complexity at least O(n)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:         BUCKET SORTS          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


BUCKET SORT ==>                   #Also called "bin sort"
                                  #Type of distribution sort
                                  #Steps:
                                  #  - "partition":
                                  #     - create k buckets
                                  #     - time complexity O(k)
                                  #     - space complexity O(k)
                                  #  - "scatter|disperse":
                                  #     - assign each value to a bucket|bin|category
                                  #     - each value must have a key used to find bucket in O(1)
                                  #        - e.g. first bucket for values < 100, second bucket for values 100 < x < 200, etc.
                                  #     - time complexity O(n)
                                  #     - space complexity O(n)
                                  #  - sort each bucket's values
                                  #     - using any sort algorithm
                                  #     - can also apply other sort algorithm on all buckets at once
                                  #        - if it is more performant for that algorithm
                                  #        - e.g. insertion sort which is fast when values do not move much
                                  #  - "gather|collect": concatenate all bucket's values
                                  #     - time complexity O(k)
                                  #Most time complexity is from sorting each bucket's values
                                  #  - i.e. better if buckets have few values
                                  #  - i.e. either:
                                  #     - evenly distributed
                                  #     - choosing different bucket sizes to match the distribution of the values,
                                  #       if the distribution is known
                                  #Time complexity:
                                  #  - average: O(n + k)
                                  #  - worst: O(n**2 + k), if not evenly distributed, e.g. all values in single bucket
                                  #Space complexity: O(n + k)
                                  #I.e. best when a low amount of buckets can be used to distribute evenly
                                  #(or matching the distribution of the values).
                                  #Stable sort

GENERIC BUCKET SORT ==>           #Bucket sort with:
                                  #  - even buckets
                                  #  - ranging from min|max of the keys
                                  #Example:
                                  #  - [52, 50, 70, 20, 10]
                                  #    -> [[], [], [], [], [], [], [], [], [], []] (partition)
                                  #    -> [[], [10], [20], [], [], [52, 50], [], [70], [], []] (scatter)
                                  #    -> [[], [10], [20], [], [], [50, 52], [], [70], [], []] (second sort)
                                  #    -> [10, 20, 50, 52, 70] (gather)

PIGEONHOLE SORT ==>               #Bucket sort where values inside each bucket are sort-equivalent.
                                  #Done by creating as many buckets as possible
                                  #  - e.g. when sorting integers, each bucket is exactly one integer
                                  #Pro: no second sort step
                                  #Cons:
                                  #  - higher space complexity due to empty buckets
                                  #  - higher time complexity when partioning and gathering, since number of buckets higher
                                  #  - i.e. best when number of buckets is close to number of values
                                  #Example:
                                  #   - [c, f, b, b, e]
                                  #  -> [[], [], [], [], [], []] (partition)
                                  #  -> [[], [b, b], [c], [], [e], [f]] (scatter)
                                  #  -> [b, b, c, e, f] (gather)

COUNTING SORT ==>                 #Also called "histogram sort"
                                  #Same as pigeonhole sort except each bucket contains only the number of occurrences,
                                  #not the values themselves.
                                  #  - i.e. the final array is produced by cumulating each bucket's offset,
                                  #    not by gathering the values from each bucket
                                  #Similar pros|cons and time complexity as pigeonhole sort but:
                                  #  - time complexity:
                                  #     - pro: does not require moving values
                                  #     - con: additional indices step
                                  #  - space complexity: lower by using a count of values instead of repeated values
                                  #  - i.e. better when number of buckets is much lower than number of values
                                  #Example:
                                  #   - [c, f, b, b, e]
                                  #                                         a  b    c  d  e  f
                                  #                                     -> [0, 0,   0, 0, 0, 0] (partition)
                                  #                                     -> [0, 2,   1, 0, 1, 1] (sums)
                                  #                                     -> [0, 0-1, 2, 3, 3, 4] (offsets)
                                  #  -> [2, 4, 0-1, 0-1, 3] (indices)
                                  #  -> [2, 4, 0, 1, 3]
                                  #  -> [b, b, c, e, f]

PROXMAP SORT ==>                  #Variant of bucket sort
                                  #When creating buckets, their number and size depend on values:
                                  #  - a FUNC(value)->INT reduces each value to an approximate overall position ("map key")
                                  #     - e.g. Math.floor(value % modulo)
                                  #     - 1 bucket === 1 map key
                                  #     - must be choosen:
                                  #        - both not enough buckets, and too many empty ones, lead to higher time complexity
                                  #        - i.e. must try to approach 1 bucket === 1 value
                                  #  - create a cumulative histogram ("proxmap") like counting sort does
                                  #  - time complexity: O(n)
                                  #When scattering values, and bucket > 1 value, use insertion sort.
                                  #Time complexity is similar to bucket sort.
                                  #Pros:
                                  #  - higher chance to distribute evenly
                                  #  - more space efficient, by lowering chances of empty buckets
                                  #  - allows proxmap search
                                  #Cons:
                                  #  - additional cost of partitioning
                                  #  - finding the right map key FUNC depends on knowing the values distribution
                                  #Example:
                                  #   - [12, 6, 56, 24, 22, 58]                                                                0 10 20 30 40 50
                                  #                                                  -> [10, 0, 50, 20, 20, 50] (map)      -> [1, 1, 2, 0, 0, 2] (hit counts)
                                  #                                                                                        -> [0, 1, 2, 4, 4, 4] (proxmap)
                                  #                                                  -> [1,  0,  4,  2,  2 , 4] (location)
                                  #  -> [6, 12, [24, 22], [56, 58]] (scatter)
                                  #  -> [6, 12, [22, 24], [56, 58]] (insertion sort)
                                  #  -> [6, 12, 22, 24, 56, 58] (gather)

PROXMAP SEARCH ==>                #Fast searching based on proxmap sort:
                                  #  - apply the map key FUNC on a searched value
                                  #  - find start index using proxmap
                                  #  - if bucket had 1 value, correct index. Otherwise, do a linear|binary search forward
                                  #Time complexity:
                                  #  - best|average: O(1)
                                  #  - worst: O(n), if not evenly distributed, e.g. all values in single bucket
                                  #Example, re-using above example:
                                  #  - search 24
                                  #  - map key: 2
                                  #  - location: 2
                                  #  - search from index 2: 22 (not found), then 24 (found)


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          RADIX SORTS          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


RADIX SORT ==>                    #Also called "digital sort"
                                  #Type of distribution sort
                                  #Sort symbol by symbol using another, when values can be broken down into sequences of w symbol
                                  #  - where each symbol order is more important than next one, i.e. lexicographic order
                                  #  - e.g. numbers|strings
                                  #Missing symbols must be filled with padding symbols
                                  #  - e.g. '0' for numbers or space for strings
                                  #  - with lower value than any other symbol
                                  #  - either on the left|highest or right|lowest symbol
                                  #Can use any other sorting algorithm for the symbols.
                                  #  - often used: counting sort, since it works well with digits|characters
                                  #Pros:
                                  #  - low space complexity:
                                  #     - by using a subset of the whole value in each step
                                  #     - i.e. works with large range of values
                                  #     - O(n + w)
                                  #  - similar time complexity as bucket sort but using w instead of k
                                  #     - average: O(n * w)
                                  #     - worst: O(n**2 * w), when w too low, i.e. does not break down into enough symbols
                                  #Best when values are sequences of symbols

LSD RADIX SORT ==>                #Also called "bottom-up radix sort"
                                  #Radix sort going from lowest to highest symbol.
                                  #Each new symbol must:
                                  #  - must iterate over all values
                                  #  - must be stable, to keep sorting of next symbols
                                  #Padding usually on the left, so it can happen symbol by symbol
                                  #  - i.e. best for numbers
                                  #Instead of padding, can also group by length, then sort each group
                                  #Example:
                                  #   - 7 71 12 1
                                  #  -> [71 1] [12] [7] (last digit)
                                  #  -> 71 1 12 7
                                  #  -> [01 07] [12] [71] (second last digit)

MSD RADIX SORT ==>                #Also called "top-down radix sort" or "postman's sort"
                                  #Radix sort going from highest to lowest symbol.
                                  #Each new symbol:
                                  #  - must iterate over values grouped by previous symbols, i.e. be recursive
                                  #  - does not need to be stable
                                  #Padding usually on the right, so it can happen symbol by symbol
                                  #  - i.e. best for strings
                                  #Example:
                                  #   - g ga ab abc a
                                  #  -> [ab abc a] [g ga] (first character)
                                  #  -> [[a.] [ab abc]] [[g.] [ga]] (second character)
                                  #  -> [[[a..]] [[ab.] [abc]]] [[[g..]] [[ga.]]] (third character)
                                  #  -> a ab abc g ga

AMERICAN FLAG SORT ==>            #Also called "in-place MSD radix sort"
                                  #Variant of MSD that is in-place:
                                  #  - compute count of each value for highest symbol
                                  #  - compute indices of group for each value, using each count as group size
                                  #  - swap values to put them inside right group
                                  #  - recurse on each group with next symbol
                                  #More efficient when bucket size is power of 2, because can implement with bitwise logic
                                  #Example:
                                  #   - g ga ab abc a
                                  #  -> a:3 g:2 (first character)
                                  #  -> [ab abc a] [g ga] (in-place swap)
                                  #  -> recurse


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:          MERGE SORTS          :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


MERGE SORT ==>                    #Conceptually the inverse of a bucket sort
                                  #How:
                                  #  - divide array into groups of 2 values
                                  #  - sort each group's values using any sorting algorithm
                                  #  - merge each group with next group, by comparing their values in order, to produce a sorted group
                                  #     - if last group is partial, still merge it
                                  #     - if there is an odd number of groups, last group is left as is
                                  #  - reiterate the merge with the newly formed groups
                                  #Can:
                                  #  - merge first array with next, iterately:
                                  #     - suboptimal and not parallel
                                  #  - merge each pair of arrays together
                                  #  - merge two smallest arrays together:
                                  #     - faster if array sizes are not uniform
                                  #Can be implemented either top-down or bottom-up, with similar efficiency
                                  #Is easy to be run in parallel
                                  #Merge step can be implemented:
                                  #  - using "all nearest smaller values" algorithm (see its doc):
                                  #     - concatenate first group with reversed second group
                                  #     - calculate all nearest smaller values, in both directions
                                  #     - for each value, bigger neigbor should be previous value in merged array


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:        INSERTION SORTS        :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


INSERTION SORT ==>                #Type of comparison sort
                                  #For over each valueA,
                                  #  - find first valueB of current output bigger than valueA
                                  #  - insert valueA into current output at that position
                                  #Output can be growing sub-array at beginning of array, to make it in-place.
                                  #Pros:
                                  #  - simple to implement
                                  #  - efficient when list to sort is small (e.g. <10-50 values)
                                  #     - often used with more efficient divide-and-conquer sort algorithms as a subroutine
                                  #  - can be in-place
                                  #  - stable
                                  #  - online
                                  #  - space complexity O(1)
                                  #  - adaptive, best time complexity O(n)
                                  #Cons:
                                  #  - average|worst time complexity O(n**2)

SHELL SORT ==>                    #Use GAPs:
                                  #  - GAP number from 1 to n/2
                                  #  - divide input into GAP subarrays, each containing values with same position % GAP
                                  #     - e.g. if GAP is 3, [d, y, q, a, z] -> [d, a], [y, z], [q]
                                  #  - which series of GAP is chosen is implementation-specific, but must be decreasing and end with 1
                                  #     - often used: n/2, n/4, ..., 1
                                  #For each GAP:
                                  #  - for each subarray:
                                  #     - apply insertion sort


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:        SELECTION SORTS        :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


SELECTION SORT ==>                #How:
                                  #  - find min item of the list
                                  #  - put min item to beginning, swapping in-place
                                  #  - recurse but without min item
                                  #Efficient when list to sort is small, but usually insertion sorts are better
                                  #Similar pros|cons as insertion sorts except:
                                  #  - not adaptive
                                  #  - better when writes are expensive, worst when reads are expensive
                                  #     - does not require shifting range of values
                                  #     - but each pass in selection sort goes through all values, while insertion sorts goes
                                  #       through half of them, i.e. does twice less operations

HEAPSORT ==>                      #How:
                                  #  - build a heap
                                  #  - extract the root of the heap, to iteratively create sorted array
                                  #Can be done in-place:
                                  #  - building a heap can be done in-place
                                  #  - when extracting each root can:
                                  #     - place it in a growing sorted array at end
                                  #     - swap with the last value, which becomes new root and is moved down the heap until satisfying the
                                  #       heap property


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:        EXCHANGE SORTS         :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


BUBBLE SORT ==>                   #Also called "sinking sort"
                                  #How:
                                  #  - for each value, swap with next value if next value is smaller
                                  #  - repeat whole iteration until sorted
                                  #Similar pros|cons as insertion sorts except:
                                  #  - slower: each value must shift to its sorted position with several swaps
                                  #  - does not require random access, e.g. can be done on linked lists
                                  #  - otherwise should be avoided, mostly used for educational purpose

QUICKSORT ==>                     #Also called "partition-exchange sort"

BOGOSORT ==>                      #Also called "permutation sort", "stupid sort", "slowsort", "shotgun sort", "monkey sort"
                                  #Randomly shuffles whole array until shuffle output happens to be also sorted
                                  #  - or alternatively, try every permutation
                                  #Only meant as a joke, or example of a bad sorting algorithm


                                             /=+===============================+=\
                                            /  :                               :  \
                                            )==:           BEAD SORT           :==(
                                            \  :_______________________________:  /
                                             \=+===============================+=/


BEAD SORT ==>                     #Also called "gravity sort"
                                  #Neither comparison nor distribution sort.
                                  #Keys must be positive integers
                                  #Similar to using an abacus and mapping beads fall
                                  #Steps:
                                  #  - put numbers in a matrix: each number n is a row, filled with n 1s
                                  #  - remove all vertical gaps (i.e. make 1s "fall")
                                  #  - each row will represent a sorted number
                                  #Example:
                                  #  - [2, 4, 1, 3, 3]
                                  #    -> [1, 1, 0, 0] (2)
                                  #       [1, 1, 1, 1] (4)
                                  #       [1, 0, 0, 0] (1)
                                  #       [1, 1, 1, 0] (3)
                                  #       [1, 1, 1, 0] (3)
                                  #    -> [1, 0, 0, 0] (1)
                                  #       [1, 1, 0, 0] (2)
                                  #       [1, 1, 1, 0] (3)
                                  #       [1, 1, 1, 0] (3)
                                  #       [1, 1, 1, 1] (4)
                                  #Another way to look at it:
                                  #  - create array with length === max number
                                  #  - for each number n, increment n first items of array
                                  #  - for each array item, replace by difference with next item
                                  #  - for each array item m, replace by m times its 1-based index
                                  #Example:
                                  #  - [2, 4, 1, 3, 3]
                                  #    -> [0, 0, 0, 0]
                                  #    -> [1, 1, 0, 0] (2)
                                  #    -> [2, 2, 1, 1] (4)
                                  #    -> [3, 2, 1, 1] (1)
                                  #    -> [4, 3, 2, 1] (3)
                                  #    -> [5, 4, 3, 1] (3)
                                  #    -> [1, 1, 2, 1] (difference)
                                  #    -> [1, 2, 3, 3, 4] (indexes)
                                  #Pros:
                                  #  - best time complexity: O(n)
                                  #Cons:
                                  #  - only works with positive integers
                                  #  - high space complexity: O(n**2)
                                  #  - average|worst time complexity: O(S), with S being sum of all keys
                                  #  - best time complexity usually requires specialized hardware
