
                                  ┏━━━━━━━━━━━━━┓
                                  ┃   MIN_MAX   ┃
                                  ┗━━━━━━━━━━━━━┛

                                  ┌───────────┐
                                  │   QUEUE   │
                                  └───────────┘


PRIORITY QUEUE ==>                #List with read|write to highest priority item, where each item is assigned a "priority",
                                  #which can be using any type (as long as it can be compared).
                                  #Operations:
                                  #  - insert(VAL, PRIORITY)
                                  #  - peek_max|min()->VAL
                                  #  - pull_max|min()->VAL
                                  #  - set_priority(INDEX, PRIORITY)
                                  #"Min|max-priority queue": when only min|max() is available
                                  #Often implemented as heaps

                                  ┌──────────┐
                                  │   HEAP   │
                                  └──────────┘

HEAP ==>                          #Tree satisfying the "heap property":
                                  #  - "max heap": parent node's key >= child's key
                                  #  - "min heap": parent node's key <= child's key
                                  #Goal:
                                  #  - performing min|max
                                  #  - e.g. implementing a priority queue
                                  #Operations:
                                  #  - peek_max|min(): O(1)
                                  #  - pull_max|min(): O(log n)
                                  #  - insert(NODE): O(log n)
                                  #  - delete(): arbitrary node
                                  #  - set_key(NODE, KEY): O(log n)
                                  #  - merge(HEAP, HEAP2)->HEAP3: O(n)
                                  #  - size()->NUM
                                  #Complexity depends on implementation (those are the most common).
                                  #Just like search trees, they must be balanced to keep O(log n) complexity
                                  #Building a heap from an array:
                                  #  - "William's method"/"top-down"/"siftDown":
                                  #     - insert one element at a time
                                  #     - online algorithm
                                  #     - O(n log n)
                                  #  - "Floyd's method"/"bottom-up"/"siftUp":
                                  #     - lay array as a binary tree, e.g. using its sequential representation
                                  #     - for each subtree, from bottom to top, move down the root of the subtree until the
                                  #       subtree satisfies the heap property
                                  #     - O(n)

CARTESIAN TREE ==>                #Heap built from a sequence of keys, that can be reversed to that sequence of keys with
                                  #an in-order traversal.
                                  #Construction:
                                  #  - time complexity: O(n)
                                  #  - from "all nearest smaller values" algorithm:
                                  #     - going in both directions, i.e. building left|right neighbors
                                  #     - if has no left|right neighbors, is root
                                  #     - if higher neighbor is left|right, put as right|left child of it
                                  #Goal is efficient range minimum|maximum query:
                                  #  - minimum|maximum of any subset of the original sequence of keys
                                  #    is the lowest common ancestor to the first and last keys of the subset
                                  #  - time complexity: O(1)
                                  #  - space complexity: O(n) (storing the tree itself)

TOURNAMENT TREE ==>               #Heap specialized for groups of presorted values

WINNER TREE ==>                   #Tournament tree where:
                                  #  - regular heap built bottom-up
                                  #  - each leaf is a single group of presorted values, output one at a time
                                  #  - each non-leaf keeps track of the index of its base leaf
                                  #Pull+insert:
                                  #  - pull root
                                  #  - replace leaf == root with new leaf x
                                  #  - re-compute nodes from leaf to root

LOSER TREE ==>                    #Tournament tree where:
                                  #  - each leaf has a corresponding non-leaf
                                  #  - each non-leaf is highest|lowest child leaf that is not already a child non-leaf
                                  #Binary tree, except root has a single child
                                  #Not heap, but root is min|max value
                                  #Can be built by:
                                  #  - doing a winner tree
                                  #  - in depth-first, replace each non-leaf by its other child
                                  #  - add final root
                                  #Similar pros|cons as winner tree, except faster pull+insert:
                                  #  - when re-computing each node, can just compare new leaf x with parent
                                  #     - if x < parent, swap: parent leaf becomes x, and vice-versa
                                  #     - i.e. no need to access sibling node

                                  ┌───────────────┐
                                  │   SELECTION   │
                                  └───────────────┘

SELECTION ALGORITHM ==>           #Algorithm to find the k-th smallest|highest value of an array
                                  #Generalization of min|max|median
                                  #Space complexity: O(1) (in-place)

SELECTION BY SORTING ==>          #Sort array then use random access to find nth value.
                                  #Pros:
                                  #  - fast for multiple queries: O(1) for each query
                                  #Cons:
                                  #  - slow for a single query: O(n log n) due to sorting
                                  #  - requires random access

SELECTION BY PARTIAL SORTING ==>  #Like selection by sorting, but using partial sorting
                                  #Pros:
                                  #  - O(n log k) time complexity instead of O(n log n)
                                  #Cons:
                                  #  - slower for multiple queries, if those are on different|unsorted ranges: O(n log k)

SELECTION BY PARTITIONING ==>     #Like selection by sorting, but using partioning followed by finding min|max value
                                  #Pros:
                                  #  - fast for single query: O(n) due to partioning
                                  #     - actually O(n + k): min|max, but k <= n, i.e. eliminated asymptotically
                                  #Cons:
                                  #  - slow for multiple queries: O(k) for each query due to min|max

PARTITION BY SELECTION ==>        #After selecting k-th smallest|highest value:
                                  #  - partition by linearly iterate through the array and pick any value <
                                  #  - any remaining value == k-th value

QUICKSELECT ==>                   #Selection by partial sorting:
                                  #  - using same logic as quicksort
                                  #  - except only recurse on a single group
                                  #Similar pros|cons as quicksort (see its doc) except:
                                  #  - pros:
                                  #     - best|average time complexity O(n): thanks to fewer recursions than quicksort
                                  #  - cons:
                                  #     - not parallelizable

MEDIAN OF MEDIANS ==>             #Like quickselect except:
                                  #  - first replace each group of m values by their median
                                  #     - values for m:
                                  #        - odd values easier for medians
                                  #        - often used: 5
                                  #           - guarantees finding value between 30th and 70th percentile
                                  #     - either done:
                                  #        - in-place (swapping values to subarray at beginning): space complexity O(1)
                                  #        - to a separate array: space complexity O(n), but faster time complexity
                                  #  - pivot selection uses median of medians itself, i.e. recursively
                                  #Pros|cons over quickselect:
                                  #  - pros:
                                  #     - worst time complexity: O(n) instead of O(n**2)
                                  #  - cons:
                                  #     - best|average time complexity: still O(n) but slower due to cost of finding medians initially

HEAPSELECT ==>                    #Selection by partial sorting:
                                  #  - using same logic as partial heapsort
                                  #  - with a size of 2**k - 1
                                  #Pros:
                                  #  - worst time complexity: O(n log k)
                                  #Cons:
                                  #  - best|average time complexity: O(n log k), but no constant cost like median of medians

ORDER-STATISTIC TREE ==>          #B-tree where each node keep track of number of children.
                                  #Allows selecting in O(log n)
                                  #Similar pros|cons as heapselect except:
                                  #  - pro: faster time complexity
                                  #  - con: slower to insert due to balancing

FREQUENCY TABLE ==>               #Selection by partial sorting:
                                  #  - using same logic as bucket sort
                                  #  - keeping track of each bucket size
                                  #Pros|cons similar as bucket sort
                                  #  - main pro: divide array size to search by m (number of buckets)
                                  #  - main con: require knowing distribution of values

INTROSELECT ==>                   #Hybrid of:
                                  #  - quickselect
                                  #     - used first
                                  #     - due to its best|average time complexity
                                  #  - median of medians, or heapselect
                                  #     - used second, if quickselect not fast enough
                                  #     - due to its worst time complexity
                                  #Different strategies to decide when switch happens:
                                  #  - after n recursions: bad because does not work on very small|big arrays
                                  #  - after n recursions that have been reducing array size by <m%
                                  #  - after log(array size) recursions
                                  #     - often used: 2 * log2(array size)

                                  ┌──────────────────┐
                                  │   PARTITIONING   │
                                  └──────────────────┘

PARTITIONING ==>                  #Separating n highest|lowest values from others.
                                  #Average time complexity: O(n)
                                  #Can be done in-place, i.e. space complexity O(1), by swapping values

K-WAY PARTITIONING ==>            #Generalization of 2-way partitioning, splitting into k partitions, each with all values lower than
                                  #any value of next partition
                                  #Same time|space complexity as 2-way partitioning

3-WAY PARTITION ==>               #Also called "Dutch national flag problem"
                                  #Given a specific pivot value for the middle partition, for each value:
                                  #  - If < pivot, move to beginning
                                  #  - Otherwise, either:
                                  #     - move values == pivot to end, then do final swap whole 2nd and 3rd partition
                                  #        - better if reads are expensive
                                  #     - do a second pass moving values != pivot after end of 1st partition
                                  #        - better if writes are expensive
                                  #     - move values > pivot to end
                                  #        - better if many values == pivot

                                  ┌─────────────────┐
                                  │   RANGE QUERY   │
                                  └─────────────────┘

RANGE QUERY ==>                   #Selection, but over an array subset.
                                  #Often used:
                                  #  - minimum|maximum ("range minimum|maximum query" (RMQ))
                                  #  - mode ("range mode query")
                                  #  - median

                                  ┌───────────┐
                                  │   OTHER   │
                                  └───────────┘

ALL NEAREST SMALLER VALUES ==>    #Algorithm:
                                  #  - in a sequence of values
                                  #  - for each value:
                                  #     - lookup all the previous values
                                  #        - sometimes done in both directions
                                  #     - find the indices of the closest lower|higher value
                                  #Example: [0, 8, 4, 9] -> [null, 0, 0, 2]
                                  #Can be efficiently implemented as a parallel algorithm.
